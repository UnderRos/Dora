{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to school today and I met a friend.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# 사전 학습된 MarianMT 모델 (예제: 한국어 ↔ 영어\n",
    "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "    tokens = tokenizer(text, return_tensors = \"pt\", padding = True, truncation = True)\n",
    "    translated_tokens = model.generate(**tokens)\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens = True)\n",
    "    return translated_text[0]\n",
    "\n",
    "translated_text = translate(\"나는 오늘 학교에 가서 친구를 만났어\")\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to school today and met a friend.\n"
     ]
    },
    {
     "ename": "LanguageNotSupportedException",
     "evalue": "sgn-US --> No support for the provided language.\nPlease select on of the supported languages:\n{'afrikaans': 'af', 'albanian': 'sq', 'amharic': 'am', 'arabic': 'ar', 'armenian': 'hy', 'assamese': 'as', 'aymara': 'ay', 'azerbaijani': 'az', 'bambara': 'bm', 'basque': 'eu', 'belarusian': 'be', 'bengali': 'bn', 'bhojpuri': 'bho', 'bosnian': 'bs', 'bulgarian': 'bg', 'catalan': 'ca', 'cebuano': 'ceb', 'chichewa': 'ny', 'chinese (simplified)': 'zh-CN', 'chinese (traditional)': 'zh-TW', 'corsican': 'co', 'croatian': 'hr', 'czech': 'cs', 'danish': 'da', 'dhivehi': 'dv', 'dogri': 'doi', 'dutch': 'nl', 'english': 'en', 'esperanto': 'eo', 'estonian': 'et', 'ewe': 'ee', 'filipino': 'tl', 'finnish': 'fi', 'french': 'fr', 'frisian': 'fy', 'galician': 'gl', 'georgian': 'ka', 'german': 'de', 'greek': 'el', 'guarani': 'gn', 'gujarati': 'gu', 'haitian creole': 'ht', 'hausa': 'ha', 'hawaiian': 'haw', 'hebrew': 'iw', 'hindi': 'hi', 'hmong': 'hmn', 'hungarian': 'hu', 'icelandic': 'is', 'igbo': 'ig', 'ilocano': 'ilo', 'indonesian': 'id', 'irish': 'ga', 'italian': 'it', 'japanese': 'ja', 'javanese': 'jw', 'kannada': 'kn', 'kazakh': 'kk', 'khmer': 'km', 'kinyarwanda': 'rw', 'konkani': 'gom', 'korean': 'ko', 'krio': 'kri', 'kurdish (kurmanji)': 'ku', 'kurdish (sorani)': 'ckb', 'kyrgyz': 'ky', 'lao': 'lo', 'latin': 'la', 'latvian': 'lv', 'lingala': 'ln', 'lithuanian': 'lt', 'luganda': 'lg', 'luxembourgish': 'lb', 'macedonian': 'mk', 'maithili': 'mai', 'malagasy': 'mg', 'malay': 'ms', 'malayalam': 'ml', 'maltese': 'mt', 'maori': 'mi', 'marathi': 'mr', 'meiteilon (manipuri)': 'mni-Mtei', 'mizo': 'lus', 'mongolian': 'mn', 'myanmar': 'my', 'nepali': 'ne', 'norwegian': 'no', 'odia (oriya)': 'or', 'oromo': 'om', 'pashto': 'ps', 'persian': 'fa', 'polish': 'pl', 'portuguese': 'pt', 'punjabi': 'pa', 'quechua': 'qu', 'romanian': 'ro', 'russian': 'ru', 'samoan': 'sm', 'sanskrit': 'sa', 'scots gaelic': 'gd', 'sepedi': 'nso', 'serbian': 'sr', 'sesotho': 'st', 'shona': 'sn', 'sindhi': 'sd', 'sinhala': 'si', 'slovak': 'sk', 'slovenian': 'sl', 'somali': 'so', 'spanish': 'es', 'sundanese': 'su', 'swahili': 'sw', 'swedish': 'sv', 'tajik': 'tg', 'tamil': 'ta', 'tatar': 'tt', 'telugu': 'te', 'thai': 'th', 'tigrinya': 'ti', 'tsonga': 'ts', 'turkish': 'tr', 'turkmen': 'tk', 'twi': 'ak', 'ukrainian': 'uk', 'urdu': 'ur', 'uyghur': 'ug', 'uzbek': 'uz', 'vietnamese': 'vi', 'welsh': 'cy', 'xhosa': 'xh', 'yiddish': 'yi', 'yoruba': 'yo', 'zulu': 'zu'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLanguageNotSupportedException\u001b[39m             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(translated_text)  \u001b[38;5;66;03m# \"I went to school today and met my friend.\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 영어 → 미국수어(ASL) 번역 (Google API에서는 완전한 지원이 안 될 수 있음)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m asl_translation = \u001b[43mGoogleTranslator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msgn-US\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.translate(translated_text)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(asl_translation)  \u001b[38;5;66;03m# ASL 스타일 문장 출력 가능성 있음\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/deep_translator/google.py:39\u001b[39m, in \u001b[36mGoogleTranslator.__init__\u001b[39m\u001b[34m(self, source, target, proxies, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m@param source: source language to translate from\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m@param target: target language to translate to\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.proxies = proxies\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBASE_URLS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGOOGLE_TRANSLATE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43melement_tag\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdiv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43melement_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mt0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpayload_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mq\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# key of text in the url\u001b[39;49;00m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m._alt_element_query = {\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mresult-container\u001b[39m\u001b[33m\"\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/deep_translator/base.py:44\u001b[39m, in \u001b[36mBaseTranslator.__init__\u001b[39m\u001b[34m(self, base_url, languages, source, target, payload_key, element_tag, element_query, **url_params)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidSourceOrTargetLanguage(target)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28mself\u001b[39m._source, \u001b[38;5;28mself\u001b[39m._target = \u001b[38;5;28mself\u001b[39m._map_language_to_code(source, target)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m._url_params = url_params\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m._element_tag = element_tag\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/deep_translator/base.py:84\u001b[39m, in \u001b[36mBaseTranslator._map_language_to_code\u001b[39m\u001b[34m(self, *languages)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._languages[language]\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LanguageNotSupportedException(\n\u001b[32m     85\u001b[39m         language,\n\u001b[32m     86\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo support for the provided language.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease select on of the supported languages:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._languages\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     89\u001b[39m     )\n",
      "\u001b[31mLanguageNotSupportedException\u001b[39m: sgn-US --> No support for the provided language.\nPlease select on of the supported languages:\n{'afrikaans': 'af', 'albanian': 'sq', 'amharic': 'am', 'arabic': 'ar', 'armenian': 'hy', 'assamese': 'as', 'aymara': 'ay', 'azerbaijani': 'az', 'bambara': 'bm', 'basque': 'eu', 'belarusian': 'be', 'bengali': 'bn', 'bhojpuri': 'bho', 'bosnian': 'bs', 'bulgarian': 'bg', 'catalan': 'ca', 'cebuano': 'ceb', 'chichewa': 'ny', 'chinese (simplified)': 'zh-CN', 'chinese (traditional)': 'zh-TW', 'corsican': 'co', 'croatian': 'hr', 'czech': 'cs', 'danish': 'da', 'dhivehi': 'dv', 'dogri': 'doi', 'dutch': 'nl', 'english': 'en', 'esperanto': 'eo', 'estonian': 'et', 'ewe': 'ee', 'filipino': 'tl', 'finnish': 'fi', 'french': 'fr', 'frisian': 'fy', 'galician': 'gl', 'georgian': 'ka', 'german': 'de', 'greek': 'el', 'guarani': 'gn', 'gujarati': 'gu', 'haitian creole': 'ht', 'hausa': 'ha', 'hawaiian': 'haw', 'hebrew': 'iw', 'hindi': 'hi', 'hmong': 'hmn', 'hungarian': 'hu', 'icelandic': 'is', 'igbo': 'ig', 'ilocano': 'ilo', 'indonesian': 'id', 'irish': 'ga', 'italian': 'it', 'japanese': 'ja', 'javanese': 'jw', 'kannada': 'kn', 'kazakh': 'kk', 'khmer': 'km', 'kinyarwanda': 'rw', 'konkani': 'gom', 'korean': 'ko', 'krio': 'kri', 'kurdish (kurmanji)': 'ku', 'kurdish (sorani)': 'ckb', 'kyrgyz': 'ky', 'lao': 'lo', 'latin': 'la', 'latvian': 'lv', 'lingala': 'ln', 'lithuanian': 'lt', 'luganda': 'lg', 'luxembourgish': 'lb', 'macedonian': 'mk', 'maithili': 'mai', 'malagasy': 'mg', 'malay': 'ms', 'malayalam': 'ml', 'maltese': 'mt', 'maori': 'mi', 'marathi': 'mr', 'meiteilon (manipuri)': 'mni-Mtei', 'mizo': 'lus', 'mongolian': 'mn', 'myanmar': 'my', 'nepali': 'ne', 'norwegian': 'no', 'odia (oriya)': 'or', 'oromo': 'om', 'pashto': 'ps', 'persian': 'fa', 'polish': 'pl', 'portuguese': 'pt', 'punjabi': 'pa', 'quechua': 'qu', 'romanian': 'ro', 'russian': 'ru', 'samoan': 'sm', 'sanskrit': 'sa', 'scots gaelic': 'gd', 'sepedi': 'nso', 'serbian': 'sr', 'sesotho': 'st', 'shona': 'sn', 'sindhi': 'sd', 'sinhala': 'si', 'slovak': 'sk', 'slovenian': 'sl', 'somali': 'so', 'spanish': 'es', 'sundanese': 'su', 'swahili': 'sw', 'swedish': 'sv', 'tajik': 'tg', 'tamil': 'ta', 'tatar': 'tt', 'telugu': 'te', 'thai': 'th', 'tigrinya': 'ti', 'tsonga': 'ts', 'turkish': 'tr', 'turkmen': 'tk', 'twi': 'ak', 'ukrainian': 'uk', 'urdu': 'ur', 'uyghur': 'ug', 'uzbek': 'uz', 'vietnamese': 'vi', 'welsh': 'cy', 'xhosa': 'xh', 'yiddish': 'yi', 'yoruba': 'yo', 'zulu': 'zu'}"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# 한국어 → 영어 번역\n",
    "text = \"나는 오늘 학교에 가서 친구를 만났어.\"\n",
    "translated_text = GoogleTranslator(source='ko', target='en').translate(text)\n",
    "print(translated_text)  # \"I went to school today and met my friend.\"\n",
    "\n",
    "# 영어 → 미국수어(ASL) 번역 (Google API에서는 완전한 지원이 안 될 수 있음)\n",
    "asl_translation = GoogleTranslator(source='en', target='sgn-US').translate(translated_text)\n",
    "print(asl_translation)  # ASL 스타일 문장 출력 가능성 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 94.7MB/s]                    \n",
      "2025-03-14 17:46:19 INFO: Downloaded file to /home/usou/stanza_resources/resources.json\n",
      "2025-03-14 17:46:19 INFO: Downloading default packages for language: ko (Korean) ...\n",
      "2025-03-14 17:46:20 INFO: File exists: /home/usou/stanza_resources/ko/default.zip\n",
      "2025-03-14 17:46:21 INFO: Finished downloading models and saved to /home/usou/stanza_resources\n",
      "2025-03-14 17:46:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 137MB/s]                     \n",
      "2025-03-14 17:46:21 INFO: Downloaded file to /home/usou/stanza_resources/resources.json\n",
      "2025-03-14 17:46:22 INFO: Loading these models for language: ko (Korean):\n",
      "==============================\n",
      "| Processor | Package        |\n",
      "------------------------------\n",
      "| tokenize  | kaist          |\n",
      "| pos       | kaist_nocharlm |\n",
      "| lemma     | kaist_nocharlm |\n",
      "| depparse  | kaist_nocharlm |\n",
      "==============================\n",
      "\n",
      "2025-03-14 17:46:22 INFO: Using device: cuda\n",
      "2025-03-14 17:46:22 INFO: Loading: tokenize\n",
      "2025-03-14 17:46:22 INFO: Loading: pos\n",
      "2025-03-14 17:46:24 INFO: Loading: lemma\n",
      "2025-03-14 17:46:25 INFO: Loading: depparse\n",
      "2025-03-14 17:46:25 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문장: 나는 지금 집에 가고 싶어.\n",
      "수어체 변환: 나 지금 집 가다.\n",
      "\n",
      "원본 문장: 내일 영화 보고 싶어.\n",
      "수어체 변환: 내일 영화 보다.\n",
      "\n",
      "원본 문장: 저는 집에서 밥을 먹고 싶어요.\n",
      "수어체 변환: 저 집 밥 먹다.\n",
      "\n",
      "원본 문장: 고양이가 창문 위에서 자고 있어.\n",
      "수어체 변환: 고양이 창문 위 자다.\n",
      "\n",
      "원본 문장: 나는 한국어를 배우고 싶지 않아.\n",
      "수어체 변환: 나 한국어 배우다.\n",
      "\n",
      "원본 문장: 나는 새로운 핸드폰을 사고 싶어.\n",
      "수어체 변환: 나 새로운 핸드폰 사다.\n",
      "\n",
      "원본 문장: 그는 책을 읽고 있어.\n",
      "수어체 변환: 그 책 읽다.\n",
      "\n",
      "원본 문장: 문문은 밥을 먹고 있어.\n",
      "수어체 변환: 문문 밥 먹다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import re\n",
    "\n",
    "# Stanza 한국어 모델 다운로드 (최초 실행 시 필요)\n",
    "stanza.download(\"ko\")\n",
    "nlp = stanza.Pipeline(\"ko\", processors=\"tokenize,pos,lemma,depparse\")\n",
    "\n",
    "# ✅ 모든 조사(은, 는, 이, 가, 를, 을 등)를 자동 제거하는 함수\n",
    "def remove_josa(word):\n",
    "    \"\"\"\n",
    "    한국어에서 명사(NOUN) 뒤에 붙은 조사(은, 는, 이, 가, 를, 을 등)를 자동 제거\n",
    "    \"\"\"\n",
    "    return re.sub(r\"(은|는|이|가|를|을)$\", \"\", word)\n",
    "\n",
    "# ✅ 동사 원형 변환을 위한 후처리 함수\n",
    "def refine_verb(verb):\n",
    "    verb = re.sub(r\"고$\", \"\", verb)  # \"고\" 제거\n",
    "    verb = re.sub(r\"어$\", \"\", verb)  # \"어\" 제거\n",
    "    verb = re.sub(r\"아$\", \"\", verb)  # \"아\" 제거\n",
    "    return verb + \"다\"  # 원형 복원\n",
    "\n",
    "# ✅ 불필요한 조사 및 \"+\" 문자 제거 함수\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence = re.sub(r\"\\+\", \"\", sentence)  # \"+\" 문자 완전히 제거\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()  # 불필요한 공백 정리\n",
    "    sentence = re.sub(r\"\\s*에서\\s*\", \" \", sentence)  # \"에서\" 제거\n",
    "    sentence = re.sub(r\"\\s*에\\s*\", \" \", sentence)  # \"에\" 제거\n",
    "    return sentence\n",
    "\n",
    "# ✅ 수어체 변환 함수 (주어 유지 + 조사 자동 제거)\n",
    "def translate_to_sign_language(text):\n",
    "    doc = nlp(text)  # 형태소 분석 수행\n",
    "    sign_sentence = []\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        words = []\n",
    "        verbs = []\n",
    "        removed_words = [\"PART\", \"PUNCT\", \"SCONJ\", \"AUX\", \"CCONJ\", \"ADP\", \"DET\"]  # 불필요한 조사, 부사, 접속사 제거\n",
    "\n",
    "        for word in sentence.words:\n",
    "            if word.upos in removed_words:\n",
    "                continue\n",
    "\n",
    "            # ✅ 명사(NOUN)에서 조사 제거 (예: \"고양이가\" → \"고양이\", \"책을\" → \"책\")\n",
    "            if word.upos == \"PRON\" or word.upos == \"NOUN\":\n",
    "                words.append(remove_josa(word.text))  # 조사 제거된 단어 추가\n",
    "                continue\n",
    "\n",
    "            # \"~고 싶다\" 변환: \"원하다\"로 변경\n",
    "            if word.text in [\"싶다\"] and verbs:\n",
    "                verbs.append(\"원하다\")\n",
    "                continue\n",
    "\n",
    "            # \"안/않다\" 같은 부정어 처리\n",
    "            if word.text in [\"안\", \"않다\"]:\n",
    "                verbs.append(\"아니다\")\n",
    "                continue\n",
    "\n",
    "            # ✅ 동사 변환 (예: \"배우고\" → \"배우다\")\n",
    "            if word.upos == \"VERB\":\n",
    "                lemma = refine_verb(word.lemma) if word.lemma else refine_verb(word.text)\n",
    "                verbs.append(lemma)  # 동사 원형 변환\n",
    "            else:\n",
    "                # ✅ 조사 제거 (은, 는, 이, 가, 를, 을 등을 자동 제거)\n",
    "                words.append(remove_josa(word.text))\n",
    "\n",
    "        # ✅ 최종 변환된 문장 추가\n",
    "        words_sov = words + verbs  # 동사를 문장 끝으로 이동\n",
    "        transformed_sentence = \" \".join(words_sov) + \".\"\n",
    "        cleaned_sentence = clean_up_sentence(transformed_sentence)  # 최종 정리된 문장\n",
    "        \n",
    "        sign_sentence.append(cleaned_sentence)\n",
    "\n",
    "    return \" \".join(sign_sentence)\n",
    "\n",
    "# ✅ 테스트 문장\n",
    "test_sentences = [\n",
    "    \"나는 지금 집에 가고 싶어.\",\n",
    "    \"내일 영화 보고 싶어.\",\n",
    "    \"저는 집에서 밥을 먹고 싶어요.\",\n",
    "    \"고양이가 창문 위에서 자고 있어.\",\n",
    "    \"나는 한국어를 배우고 싶지 않아.\",\n",
    "    \"나는 새로운 핸드폰을 사고 싶어.\",\n",
    "    \"그는 책을 읽고 있어.\",\n",
    "    \"문문은 밥을 먹고 있어.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translated_text = translate_to_sign_language(sentence)\n",
    "    print(f\"원본 문장: {sentence}\")\n",
    "    print(f\"수어체 변환: {translated_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문장: 문문은 지금 열심히 작업을 하고 있어요\n",
      "수어체 변환: 문문은 지금 열심히 작업 하다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 문장\n",
    "test_sentences = [\n",
    "  \"문문은 지금 열심히 작업을 하고 있어요\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translated_text = translate_to_sign_language(sentence)\n",
    "    print(f\"원본 문장: {sentence}\")\n",
    "    print(f\"수어체 변환: {translated_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/usou/venv/superbad/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 음성 녹음 시작... (2초 동안)\n",
      "🔴 녹음 종료\n",
      "\n",
      "📝 STT 변환 결과:  වවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවවව\n",
      "\n",
      "📊 감정 분석 결과:\n",
      "  anger: 0.1190\n",
      "  disgust: 0.0434\n",
      "  fear: 0.2542\n",
      "  joy: 0.0237\n",
      "  neutral: 0.4818\n",
      "  sadness: 0.0639\n",
      "  surprise: 0.0141\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# 마이크 설정\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000  # Whisper 모델과 호환되는 샘플 레이트\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2  # 녹음 시간\n",
    "WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "# 감정 분석 모델 로드 (Hugging Face)\n",
    "emotion_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"마이크에서 음성을 녹음하고 파일로 저장\"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"🎤 음성 녹음 시작... ({}초 동안)\".format(RECORD_SECONDS))\n",
    "    \n",
    "    frames = []\n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"🔴 녹음 종료\")\n",
    "\n",
    "    # 스트림 닫기\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # WAV 파일로 저장\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    return WAVE_OUTPUT_FILENAME\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"녹음된 오디오 파일을 Whisper를 이용해 텍스트로 변환\"\"\"\n",
    "    model = whisper.load_model(\"small\")  # Whisper 모델 (tiny, base, small, medium, large 선택 가능)\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def analyze_emotion(text):\n",
    "    \"\"\"텍스트를 감정 분석 모델에 입력하여 감정을 분석\"\"\"\n",
    "    analysis = emotion_model(text)\n",
    "    return analysis\n",
    "\n",
    "# 실행 흐름\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = record_audio()\n",
    "    transcribed_text = transcribe_audio(audio_file)\n",
    "    print(f\"\\n📝 STT 변환 결과: {transcribed_text}\")\n",
    "\n",
    "    emotion_result = analyze_emotion(transcribed_text)\n",
    "    print(\"\\n📊 감정 분석 결과:\")\n",
    "    for emotion in emotion_result[0]:  # 가장 높은 감정 선택\n",
    "        print(f\"  {emotion['label']}: {emotion['score']:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
