{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 완료: /home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_1.wav\n",
      "인식된 텍스트: 좋아요\n"
     ]
    }
   ],
   "source": [
    "def converto_to_wav(input_path, output_path = None):\n",
    "    \"\"\"\n",
    "    오디오 파일을 WAV로 변환하는 함수\n",
    "    \n",
    "    :param input_path: 변환할 원본 오디오 파일 경로\n",
    "    :param output_path: 변환된 WAV 파일 경로 (기본적으로 동일한 폴더에 저장)\n",
    "    :return: 변환된 WAV 파일 경로\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다. {input_path}\")\n",
    "    \n",
    "    # 출력 경로 설정    \n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "    \n",
    "    #오디오 파일 로드 및 WAV로 변환\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    audio.export(output_path, format = \"wav\")\n",
    "\n",
    "    print(f\"변환 완료: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# ETRI API 키 입력\n",
    "API_KEY = \"41a2a58b-2dae-4d98-b3cc-70a7f0d57887\"\n",
    "\n",
    "# ETRI API 엔드포인트\n",
    "URL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "# 음성을 텍스트로 변환하는 함수\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    if not os.path.exists(audio_file):\n",
    "        return \"파일이 존재하지 않습니다.\"\n",
    "\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data, language=\"ko-KR\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"음성을 인식할 수 없습니다.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Google API 요청 오류: {e}\"\n",
    "\n",
    "# 텍스트 감정 분석 요청 함수    \n",
    "def analyze_emotion(text):\n",
    "    request_body = {\n",
    "        \"access_key\": API_KEY,\n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": \"SA\"\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(URL, json=request_body)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"API 요청 실패 (HTTP {response.status_code})\"}\n",
    "\n",
    "# 음성 파일 입력\n",
    "audio_file = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_1.wav\"  # 분석할 음성 파일\n",
    "\n",
    "# 음성을 텍스트로 변환\n",
    "recognized_text = speech_to_text(converto_to_wav(audio_file))\n",
    "print(f\"인식된 텍스트: {recognized_text}\")\n",
    "\n",
    "# 오류 메시지가 아닌 경우 감정 분석 실행\n",
    "# if recognized_text and \"오류\" not in recognized_text and \"없습니다\" not in recognized_text:\n",
    "#     sentiment_result = analyze_emotion(recognized_text)\n",
    "#     print(json.dumps(sentiment_result, indent=4, ensure_ascii=False))\n",
    "# else:\n",
    "#     print(\"텍스트 변환 실패로 인해 감정 분석을 수행하지 않습니다.\")\n",
    "\n",
    "\n",
    "# 텍스트를 수어체로 변환\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 API 응답 코드: 403\n",
      "형태소 분석 API 응답 결과: {'result': -1, 'reason': 'Empty Auth Header'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# ETRI API 키\n",
    "API_KEY = \"41a2a58b-2dae-4d98-b3cc-70a7f0d57887\"  # 본인의 키 입력\n",
    "\n",
    "# ETRI 형태소 분석 API 엔드포인트\n",
    "URL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "# 요청 데이터\n",
    "request_body = {\n",
    "    \"access_key\": API_KEY,\n",
    "    \"argument\": {\n",
    "        \"text\": \"오늘 날씨가 좋네요.\",  # 테스트 문장\n",
    "        \"analysis_code\": \"morp\"  # 형태소 분석 코드\n",
    "    }\n",
    "}\n",
    "\n",
    "# API 요청 실행\n",
    "response = requests.post(URL, json=request_body)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"형태소 분석 API 응답 코드:\", response.status_code)\n",
    "print(\"형태소 분석 API 응답 결과:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n",
      "/home/usou/venv/superbad/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 음성 녹음 시작... (2초 동안)\n",
      "🔴 녹음 종료\n",
      "\n",
      "📝 STT 변환 결과:  Уitten!\n",
      "\n",
      "📊 감정 분석 결과:\n",
      "  anger: 0.2821\n",
      "  disgust: 0.0263\n",
      "  fear: 0.0224\n",
      "  joy: 0.0748\n",
      "  neutral: 0.1858\n",
      "  sadness: 0.0226\n",
      "  surprise: 0.3861\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# 마이크 설정\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000  # Whisper 모델과 호환되는 샘플 레이트\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2  # 녹음 시간\n",
    "WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "# 감정 분석 모델 로드 (Hugging Face)\n",
    "emotion_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"마이크에서 음성을 녹음하고 파일로 저장\"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"🎤 음성 녹음 시작... ({}초 동안)\".format(RECORD_SECONDS))\n",
    "    \n",
    "    frames = []\n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"🔴 녹음 종료\")\n",
    "\n",
    "    # 스트림 닫기\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # WAV 파일로 저장\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    return WAVE_OUTPUT_FILENAME\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"녹음된 오디오 파일을 Whisper를 이용해 텍스트로 변환\"\"\"\n",
    "    model = whisper.load_model(\"small\")  # Whisper 모델 (tiny, base, small, medium, large 선택 가능)\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def analyze_emotion(text):\n",
    "    \"\"\"텍스트를 감정 분석 모델에 입력하여 감정을 분석\"\"\"\n",
    "    analysis = emotion_model(text)\n",
    "    return analysis\n",
    "\n",
    "# 실행 흐름\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = record_audio()\n",
    "    transcribed_text = transcribe_audio(audio_file)\n",
    "    print(f\"\\n📝 STT 변환 결과: {transcribed_text}\")\n",
    "\n",
    "    emotion_result = analyze_emotion(transcribed_text)\n",
    "    print(\"\\n📊 감정 분석 결과:\")\n",
    "    for emotion in emotion_result[0]:  # 가장 높은 감정 선택\n",
    "        print(f\"  {emotion['label']}: {emotion['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STT 및 감정 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 완료: /home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_2.wav\n",
      "인식된 텍스트: 50분 알람\n",
      "\n",
      " 감정 분석 결과:\n",
      "  anger: 0.0186\n",
      "  disgust: 0.0104\n",
      "  fear: 0.0230\n",
      "  joy: 0.0106\n",
      "  neutral: 0.8688\n",
      "  sadness: 0.0282\n",
      "  surprise: 0.0403\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# ETRI API 키 입력\n",
    "API_KEY = \"41a2a58b-2dae-4d98-b3cc-70a7f0d57887\"\n",
    "\n",
    "# 감정 분석 모델 로드 (Hugging Face)\n",
    "emotion_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "# ETRI API 엔드포인트\n",
    "URL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "\n",
    "def converto_to_wav(input_path, output_path = None):\n",
    "    \"\"\"\n",
    "    오디오 파일을 WAV로 변환하는 함수\n",
    "    \n",
    "    :param input_path: 변환할 원본 오디오 파일 경로\n",
    "    :param output_path: 변환된 WAV 파일 경로 (기본적으로 동일한 폴더에 저장)\n",
    "    :return: 변환된 WAV 파일 경로\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일을 찾을 수 없습니다. {input_path}\")\n",
    "    \n",
    "    # 출력 경로 설정    \n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "    \n",
    "    #오디오 파일 로드 및 WAV로 변환\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    audio.export(output_path, format = \"wav\")\n",
    "\n",
    "    print(f\"변환 완료: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# 음성을 텍스트로 변환하는 함수\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    if not os.path.exists(audio_file):\n",
    "        return \"파일이 존재하지 않습니다.\"\n",
    "\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data, language=\"ko-KR\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"음성을 인식할 수 없습니다.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Google API 요청 오류: {e}\"\n",
    "    \n",
    "    \n",
    "# # 텍스트 감정 분석 요청 함수        \n",
    "def analyze_emotion(text):\n",
    "    \"\"\"텍스트를 감정 분석 모델에 입력하여 감정을 분석\"\"\"\n",
    "    analysis = emotion_model(text)\n",
    "    return analysis\n",
    "\n",
    "# 음성 파일 입력\n",
    "audio_file = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_2.wav\"  # 분석할 음성 파일\n",
    "\n",
    "# 음성을 텍스트로 변환\n",
    "recognized_text = speech_to_text(converto_to_wav(audio_file))\n",
    "print(f\"인식된 텍스트: {recognized_text}\")\n",
    "\n",
    "# 감정 분석 결과\n",
    "emotion_result = analyze_emotion(recognized_text)\n",
    "print(\"\\n 감정 분석 결과:\")\n",
    "best_emotion_score = 0\n",
    "best_emotion = 0\n",
    "for emotion in emotion_result[0]:  # 가장 높은 감정 선택\n",
    "    print(f\"  {emotion['label']}: {emotion['score']:.4f}\")\n",
    "    best_emotion_score = emotion[\"score\"]\n",
    "\n",
    "    # if emotion[\"score\"] >= best_emotion_score:\n",
    "    #     best_emotion = emotion[\"label\"]\n",
    "    #     print(f\"현재 감정 상태는 : {best_emotion}\")\n",
    "\n",
    "    # else:\n",
    "    #     continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
