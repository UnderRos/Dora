{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î≥ÄÌôò ÏôÑÎ£å: /home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_1.wav\n",
      "Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏: Ï¢ãÏïÑÏöî\n"
     ]
    }
   ],
   "source": [
    "def converto_to_wav(input_path, output_path = None):\n",
    "    \"\"\"\n",
    "    Ïò§ÎîîÏò§ ÌååÏùºÏùÑ WAVÎ°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò\n",
    "    \n",
    "    :param input_path: Î≥ÄÌôòÌï† ÏõêÎ≥∏ Ïò§ÎîîÏò§ ÌååÏùº Í≤ΩÎ°ú\n",
    "    :param output_path: Î≥ÄÌôòÎêú WAV ÌååÏùº Í≤ΩÎ°ú (Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÎèôÏùºÌïú Ìè¥ÎçîÏóê Ï†ÄÏû•)\n",
    "    :return: Î≥ÄÌôòÎêú WAV ÌååÏùº Í≤ΩÎ°ú\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. {input_path}\")\n",
    "    \n",
    "    # Ï∂úÎ†• Í≤ΩÎ°ú ÏÑ§Ï†ï    \n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "    \n",
    "    #Ïò§ÎîîÏò§ ÌååÏùº Î°úÎìú Î∞è WAVÎ°ú Î≥ÄÌôò\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    audio.export(output_path, format = \"wav\")\n",
    "\n",
    "    print(f\"Î≥ÄÌôò ÏôÑÎ£å: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# ETRI API ÌÇ§ ÏûÖÎ†•\n",
    "API_KEY = \"41a2a58b-2dae-4d98-b3cc-70a7f0d57887\"\n",
    "\n",
    "# ETRI API ÏóîÎìúÌè¨Ïù∏Ìä∏\n",
    "URL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "# ÏùåÏÑ±ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    if not os.path.exists(audio_file):\n",
    "        return \"ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\"\n",
    "\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data, language=\"ko-KR\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"ÏùåÏÑ±ÏùÑ Ïù∏ÏãùÌï† Ïàò ÏóÜÏäµÎãàÎã§.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Google API ÏöîÏ≤≠ Ïò§Î•ò: {e}\"\n",
    "\n",
    "# ÌÖçÏä§Ìä∏ Í∞êÏ†ï Î∂ÑÏÑù ÏöîÏ≤≠ Ìï®Ïàò    \n",
    "def analyze_emotion(text):\n",
    "    request_body = {\n",
    "        \"access_key\": API_KEY,\n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": \"SA\"\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(URL, json=request_body)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"API ÏöîÏ≤≠ Ïã§Ìå® (HTTP {response.status_code})\"}\n",
    "\n",
    "# ÏùåÏÑ± ÌååÏùº ÏûÖÎ†•\n",
    "audio_file = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_1.wav\"  # Î∂ÑÏÑùÌï† ÏùåÏÑ± ÌååÏùº\n",
    "\n",
    "# ÏùåÏÑ±ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "recognized_text = speech_to_text(converto_to_wav(audio_file))\n",
    "print(f\"Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏: {recognized_text}\")\n",
    "\n",
    "# Ïò§Î•ò Î©îÏãúÏßÄÍ∞Ä ÏïÑÎãå Í≤ΩÏö∞ Í∞êÏ†ï Î∂ÑÏÑù Ïã§Ìñâ\n",
    "# if recognized_text and \"Ïò§Î•ò\" not in recognized_text and \"ÏóÜÏäµÎãàÎã§\" not in recognized_text:\n",
    "#     sentiment_result = analyze_emotion(recognized_text)\n",
    "#     print(json.dumps(sentiment_result, indent=4, ensure_ascii=False))\n",
    "# else:\n",
    "#     print(\"ÌÖçÏä§Ìä∏ Î≥ÄÌôò Ïã§Ìå®Î°ú Ïù∏Ìï¥ Í∞êÏ†ï Î∂ÑÏÑùÏùÑ ÏàòÌñâÌïòÏßÄ ÏïäÏäµÎãàÎã§.\")\n",
    "\n",
    "\n",
    "# ÌÖçÏä§Ìä∏Î•º ÏàòÏñ¥Ï≤¥Î°ú Î≥ÄÌôò\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÌòïÌÉúÏÜå Î∂ÑÏÑù ÌÖåÏä§Ìä∏ ÏΩîÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌòïÌÉúÏÜå Î∂ÑÏÑù API ÏùëÎãµ ÏΩîÎìú: 403\n",
      "ÌòïÌÉúÏÜå Î∂ÑÏÑù API ÏùëÎãµ Í≤∞Í≥º: {'result': -1, 'reason': 'Empty Auth Header'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# ETRI API ÌÇ§\n",
    "API_KEY = \"41a2a58b-2dae-4d98-b3cc-70a7f0d57887\"  # Î≥∏Ïù∏Ïùò ÌÇ§ ÏûÖÎ†•\n",
    "\n",
    "# ETRI ÌòïÌÉúÏÜå Î∂ÑÏÑù API ÏóîÎìúÌè¨Ïù∏Ìä∏\n",
    "URL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "# ÏöîÏ≤≠ Îç∞Ïù¥ÌÑ∞\n",
    "request_body = {\n",
    "    \"access_key\": API_KEY,\n",
    "    \"argument\": {\n",
    "        \"text\": \"Ïò§Îäò ÎÇ†Ïî®Í∞Ä Ï¢ãÎÑ§Ïöî.\",  # ÌÖåÏä§Ìä∏ Î¨∏Ïû•\n",
    "        \"analysis_code\": \"morp\"  # ÌòïÌÉúÏÜå Î∂ÑÏÑù ÏΩîÎìú\n",
    "    }\n",
    "}\n",
    "\n",
    "# API ÏöîÏ≤≠ Ïã§Ìñâ\n",
    "response = requests.post(URL, json=request_body)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"ÌòïÌÉúÏÜå Î∂ÑÏÑù API ÏùëÎãµ ÏΩîÎìú:\", response.status_code)\n",
    "print(\"ÌòïÌÉúÏÜå Î∂ÑÏÑù API ÏùëÎãµ Í≤∞Í≥º:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n",
      "/home/usou/venv/superbad/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ ÏùåÏÑ± ÎÖπÏùå ÏãúÏûë... (2Ï¥à ÎèôÏïà)\n",
      "üî¥ ÎÖπÏùå Ï¢ÖÎ£å\n",
      "\n",
      "üìù STT Î≥ÄÌôò Í≤∞Í≥º:  –£itten!\n",
      "\n",
      "üìä Í∞êÏ†ï Î∂ÑÏÑù Í≤∞Í≥º:\n",
      "  anger: 0.2821\n",
      "  disgust: 0.0263\n",
      "  fear: 0.0224\n",
      "  joy: 0.0748\n",
      "  neutral: 0.1858\n",
      "  sadness: 0.0226\n",
      "  surprise: 0.3861\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# ÎßàÏù¥ÌÅ¨ ÏÑ§Ï†ï\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000  # Whisper Î™®Îç∏Í≥º Ìò∏ÌôòÎêòÎäî ÏÉòÌîå Î†àÏù¥Ìä∏\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 2  # ÎÖπÏùå ÏãúÍ∞Ñ\n",
    "WAVE_OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "# Í∞êÏ†ï Î∂ÑÏÑù Î™®Îç∏ Î°úÎìú (Hugging Face)\n",
    "emotion_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"ÎßàÏù¥ÌÅ¨ÏóêÏÑú ÏùåÏÑ±ÏùÑ ÎÖπÏùåÌïòÍ≥† ÌååÏùºÎ°ú Ï†ÄÏû•\"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "    print(\"üé§ ÏùåÏÑ± ÎÖπÏùå ÏãúÏûë... ({}Ï¥à ÎèôÏïà)\".format(RECORD_SECONDS))\n",
    "    \n",
    "    frames = []\n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"üî¥ ÎÖπÏùå Ï¢ÖÎ£å\")\n",
    "\n",
    "    # Ïä§Ìä∏Î¶º Îã´Í∏∞\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # WAV ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    \n",
    "    return WAVE_OUTPUT_FILENAME\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"ÎÖπÏùåÎêú Ïò§ÎîîÏò§ ÌååÏùºÏùÑ WhisperÎ•º Ïù¥Ïö©Ìï¥ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò\"\"\"\n",
    "    model = whisper.load_model(\"small\")  # Whisper Î™®Îç∏ (tiny, base, small, medium, large ÏÑ†ÌÉù Í∞ÄÎä•)\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "def analyze_emotion(text):\n",
    "    \"\"\"ÌÖçÏä§Ìä∏Î•º Í∞êÏ†ï Î∂ÑÏÑù Î™®Îç∏Ïóê ÏûÖÎ†•ÌïòÏó¨ Í∞êÏ†ïÏùÑ Î∂ÑÏÑù\"\"\"\n",
    "    analysis = emotion_model(text)\n",
    "    return analysis\n",
    "\n",
    "# Ïã§Ìñâ ÌùêÎ¶Ñ\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file = record_audio()\n",
    "    transcribed_text = transcribe_audio(audio_file)\n",
    "    print(f\"\\nüìù STT Î≥ÄÌôò Í≤∞Í≥º: {transcribed_text}\")\n",
    "\n",
    "    emotion_result = analyze_emotion(transcribed_text)\n",
    "    print(\"\\nüìä Í∞êÏ†ï Î∂ÑÏÑù Í≤∞Í≥º:\")\n",
    "    for emotion in emotion_result[0]:  # Í∞ÄÏû• ÎÜíÏùÄ Í∞êÏ†ï ÏÑ†ÌÉù\n",
    "        print(f\"  {emotion['label']}: {emotion['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STT Î∞è Í∞êÏ†ï Î∂ÑÏÑù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î≥ÄÌôò ÏôÑÎ£å: /home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_2.wav\n",
      "Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏: 50Î∂Ñ ÏïåÎûå\n",
      "\n",
      " Í∞êÏ†ï Î∂ÑÏÑù Í≤∞Í≥º:\n",
      "  anger: 0.0186\n",
      "  disgust: 0.0104\n",
      "  fear: 0.0230\n",
      "  joy: 0.0106\n",
      "  neutral: 0.8688\n",
      "  sadness: 0.0282\n",
      "  surprise: 0.0403\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import json\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# ETRI API ÌÇ§ ÏûÖÎ†•\n",
    "API_KEY = \"41a2a58b-2dae-4d98-b3cc-70a7f0d57887\"\n",
    "\n",
    "# Í∞êÏ†ï Î∂ÑÏÑù Î™®Îç∏ Î°úÎìú (Hugging Face)\n",
    "emotion_model = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "\n",
    "# ETRI API ÏóîÎìúÌè¨Ïù∏Ìä∏\n",
    "URL = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "\n",
    "\n",
    "def converto_to_wav(input_path, output_path = None):\n",
    "    \"\"\"\n",
    "    Ïò§ÎîîÏò§ ÌååÏùºÏùÑ WAVÎ°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò\n",
    "    \n",
    "    :param input_path: Î≥ÄÌôòÌï† ÏõêÎ≥∏ Ïò§ÎîîÏò§ ÌååÏùº Í≤ΩÎ°ú\n",
    "    :param output_path: Î≥ÄÌôòÎêú WAV ÌååÏùº Í≤ΩÎ°ú (Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÎèôÏùºÌïú Ìè¥ÎçîÏóê Ï†ÄÏû•)\n",
    "    :return: Î≥ÄÌôòÎêú WAV ÌååÏùº Í≤ΩÎ°ú\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. {input_path}\")\n",
    "    \n",
    "    # Ï∂úÎ†• Í≤ΩÎ°ú ÏÑ§Ï†ï    \n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "    \n",
    "    #Ïò§ÎîîÏò§ ÌååÏùº Î°úÎìú Î∞è WAVÎ°ú Î≥ÄÌôò\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    audio.export(output_path, format = \"wav\")\n",
    "\n",
    "    print(f\"Î≥ÄÌôò ÏôÑÎ£å: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# ÏùåÏÑ±ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    \n",
    "    if not os.path.exists(audio_file):\n",
    "        return \"ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\"\n",
    "\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data, language=\"ko-KR\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"ÏùåÏÑ±ÏùÑ Ïù∏ÏãùÌï† Ïàò ÏóÜÏäµÎãàÎã§.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Google API ÏöîÏ≤≠ Ïò§Î•ò: {e}\"\n",
    "    \n",
    "    \n",
    "# # ÌÖçÏä§Ìä∏ Í∞êÏ†ï Î∂ÑÏÑù ÏöîÏ≤≠ Ìï®Ïàò        \n",
    "def analyze_emotion(text):\n",
    "    \"\"\"ÌÖçÏä§Ìä∏Î•º Í∞êÏ†ï Î∂ÑÏÑù Î™®Îç∏Ïóê ÏûÖÎ†•ÌïòÏó¨ Í∞êÏ†ïÏùÑ Î∂ÑÏÑù\"\"\"\n",
    "    analysis = emotion_model(text)\n",
    "    return analysis\n",
    "\n",
    "# ÏùåÏÑ± ÌååÏùº ÏûÖÎ†•\n",
    "audio_file = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/data/usou/test_voice_record/test_2.wav\"  # Î∂ÑÏÑùÌï† ÏùåÏÑ± ÌååÏùº\n",
    "\n",
    "# ÏùåÏÑ±ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò\n",
    "recognized_text = speech_to_text(converto_to_wav(audio_file))\n",
    "print(f\"Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏: {recognized_text}\")\n",
    "\n",
    "# Í∞êÏ†ï Î∂ÑÏÑù Í≤∞Í≥º\n",
    "emotion_result = analyze_emotion(recognized_text)\n",
    "print(\"\\n Í∞êÏ†ï Î∂ÑÏÑù Í≤∞Í≥º:\")\n",
    "best_emotion_score = 0\n",
    "best_emotion = 0\n",
    "for emotion in emotion_result[0]:  # Í∞ÄÏû• ÎÜíÏùÄ Í∞êÏ†ï ÏÑ†ÌÉù\n",
    "    print(f\"  {emotion['label']}: {emotion['score']:.4f}\")\n",
    "    best_emotion_score = emotion[\"score\"]\n",
    "\n",
    "    # if emotion[\"score\"] >= best_emotion_score:\n",
    "    #     best_emotion = emotion[\"label\"]\n",
    "    #     print(f\"ÌòÑÏû¨ Í∞êÏ†ï ÏÉÅÌÉúÎäî : {best_emotion}\")\n",
    "\n",
    "    # else:\n",
    "    #     continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
