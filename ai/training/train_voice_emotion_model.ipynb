{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traindata 전처리\n",
    "\n",
    "# JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 처리된 JSON 수: 815491\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 라벨링 JSON 파일이 있는 최상위 폴더 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "\n",
    "# 실제 WAV 파일이 존재하는 원천 데이터의 최상위 경로\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 정상적으로 처리된 데이터 정보를 담을 리스트\n",
    "data = []\n",
    "\n",
    "# 오류 발생 시 해당 JSON 파일 또는 존재하지 않는 WAV 경로를 저장할 리스트\n",
    "broken_files = []\n",
    "\n",
    "# 라벨링 폴더 내부의 모든 JSON 파일을 재귀적으로 탐색\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # 현재 JSON 파일의 전체 경로 구성\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기 및 파싱\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # JSON 내부 정보 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로를 라벨 기준 상대경로로 변환\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 상대 경로에서 모든 TL을 TS로 변경\n",
    "                relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "\n",
    "                # WAV 경로를 원천 데이터 기준으로 재구성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일 존재 여부 확인\n",
    "                if os.path.exists(wav_path):\n",
    "                    # 정상 데이터 추가\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 존재하지 않는 경우 로그에 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 중 오류 발생 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# 정상적으로 수집된 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 CSV 파일로 저장\n",
    "os.makedirs(\"./data/usou\", exist_ok=True)\n",
    "df.to_csv(\"./data/usou/metadata_cleaned.csv\", index=False)\n",
    "\n",
    "# 오류가 발생한 경로들을 텍스트 파일로 저장\n",
    "with open(\"./data/usou/broken_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 최종 처리 결과 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출\n",
    "-  MFCC 추출이란\n",
    "    - 음성에서 특징을 뽑아낸 백터\n",
    "-  데이터 형태\n",
    "    - 2차원 배열(시간 프레임수, 13)\n",
    "- 배치\n",
    "    - 배치 : 전체 데이터를 나누어 처리하는 단위\n",
    "- 나누는 이유\n",
    "    - 메모리 부족으로 컴퓨터 프리징 발생\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17508/736413005.py:12: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "100%|██████████| 815491/815491 [2:58:19<00:00, 76.22it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공적으로 저장된 배치 수: 82\n",
      "실패한 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1. 메타데이터 로드\n",
    "# ============================\n",
    "# 사전에 정제된 메타데이터 CSV 파일 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ============================\n",
    "# 2. 설정값 정의\n",
    "# ============================\n",
    "sample_rate = 16000            # 음성 파일 샘플링 레이트 (Hz)\n",
    "max_duration = 5.0             # WAV 파일 최대 로딩 시간 (초) → 너무 긴 파일 방지\n",
    "save_interval = 10000          # 몇 개마다 배치로 저장할지 설정\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []             # MFCC 벡터 리스트\n",
    "labels = []                    # 감정 레이블 리스트\n",
    "error_files = []               # 처리 중 실패한 파일 목록\n",
    "save_counter = 0               # 배치 저장 인덱스\n",
    "\n",
    "# 저장 디렉토리 설정\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3. MFCC 추출 루프\n",
    "# ============================\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]  # 메타데이터에 포함된 wav 파일 전체 경로\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 13차원 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, n_mfcc)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 에러 발생 시 파일 경로 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 수 이상 쌓이면 배치 저장 후 메모리 초기화\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터가 있다면 마지막 배치 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ============================\n",
    "# 4. 에러 파일 저장\n",
    "# ============================\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/broken_audio_files.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ============================\n",
    "# 5. 처리 결과 출력\n",
    "# ============================\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 14:35:02.667534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743053702.684248   21141 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743053702.688507   21141 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743053702.700707   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743053702.700724   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743053702.700725   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743053702.700726   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-27 14:35:02.704932: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 컨볼루션 레이어: 필터 수 32, 커널 사이즈 3x3, 활성화 함수 ReLU\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    # 배치 정규화: 학습 안정성과 속도 개선\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 최대 풀링: 출력 크기 절반으로 줄임 (특징 추출과 과적합 방지)\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 두 번째 컨볼루션 레이어: 필터 수 64\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 세 번째 컨볼루션 레이어: 필터 수 128\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 전역 평균 풀링: 전체 피처 맵의 평균을 계산하여 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 완전 연결층(Dense Layer) 추가\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    # 과적합 방지를 위한 드롭아웃 (30%)\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # 출력층: softmax로 감정 클래스 확률 예측\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일: Adam 옵티마이저, sparse_categorical_crossentropy 손실 함수, 정확도 지표\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메타데이터 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 처리된 JSON 수: 112157\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "\n",
    "# 라벨링 JSON 파일이 저장된 루트 폴더\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "\n",
    "# 실제 음성 WAV 파일이 있는 루트 폴더\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "\n",
    "# ========================================\n",
    "# 2. 결과 저장 리스트 초기화\n",
    "# ========================================\n",
    "data = []             # 메타데이터 저장용 리스트\n",
    "broken_files = []     # 에러 발생한 파일 로그용 리스트\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 파일 순회 및 정보 추출\n",
    "# ========================================\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # 화자 정보에서 감정, 스타일, 세부 감정 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "\n",
    "                # WAV 파일 이름 추출\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로에서 라벨 루트를 기준으로 상대 경로 추출\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 실제 WAV 파일 경로 생성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일이 존재하면 메타데이터에 추가\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 없는 경우 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 실패 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}, 에러: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 결과 저장\n",
    "# ========================================\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 저장 경로 생성\n",
    "os.makedirs(\"/media/usou/PortableSSD/mldl_project/data/validation\", exist_ok=True)\n",
    "\n",
    "# 메타데이터 CSV 저장\n",
    "df.to_csv(\"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\", index=False)\n",
    "\n",
    "# 에러 파일 로그 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/validation/broken_val_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 요약 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 Validation 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112157/112157 [27:27<00:00, 68.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공적으로 저장된 배치 수: 12\n",
      "실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드\n",
    "# ========================================\n",
    "\n",
    "# validation용 정제된 메타데이터 CSV 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. 설정값 정의\n",
    "# ========================================\n",
    "\n",
    "sample_rate = 16000             # 음성 샘플링 레이트 (16kHz)\n",
    "max_duration = 5.0              # WAV 최대 로딩 시간 (초)\n",
    "save_interval = 10000           # 배치 저장 기준 개수\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []              # 추출된 MFCC 벡터 리스트\n",
    "labels = []                     # 감정 레이블 리스트\n",
    "error_files = []                # 실패한 파일 목록\n",
    "save_counter = 0                # 배치 파일 번호\n",
    "\n",
    "# ========================================\n",
    "# 3. MFCC 추출 루프\n",
    "# ========================================\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 추출 (13차원)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, 13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 로딩 실패 시 에러 출력 및 로그 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 개수 이상이면 배치 저장\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 루프 종료 후 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ========================================\n",
    "# 4. 에러 파일 저장\n",
    "# ========================================\n",
    "\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/validation/broken_audio_files_val.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 5. 처리 결과 출력\n",
    "# ========================================\n",
    "\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 데이터용 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC DataGenerator 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_dir, prefix, batch_size=1, shuffle=True):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 배치 파일 목록 생성\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "        self.indices = list(range(len(self.mfcc_files)))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_mfccs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "            label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "            mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_data = np.load(label_path)\n",
    "\n",
    "            # 가장 긴 시퀀스 기준으로 padding\n",
    "            max_len = max([x.shape[0] for x in mfcc_data])\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data, maxlen=max_len, dtype='float32', padding='post')\n",
    "            padded = np.expand_dims(padded, -1)  # (batch, time, n_mfcc, 1)\n",
    "\n",
    "            batch_mfccs.append(padded)\n",
    "            batch_labels.append(label_data)\n",
    "\n",
    "        X = np.concatenate(batch_mfccs, axis=0)\n",
    "        y = np.concatenate(batch_labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 활성화 및 안정 설정 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✔ GPU 메모리 자동 증가 설정 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. GPU 장치 목록 출력\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"사용 가능한 GPU:\", gpus)\n",
    "\n",
    "# 2. 메모리 자동 증가 설정 (안정성을 위해 권장)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✔ GPU 메모리 자동 증가 설정 완료\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"⚠ 메모리 설정 중 오류 발생:\", e)\n",
    "else:\n",
    "    print(\"❌ GPU를 찾을 수 없습니다. CPU로 진행됩니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_encoder.pkl을 로드해 동일하게 인코딩하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 레이블 인코딩 및 저장 완료 (배치 수: 12)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "encoded_label_dir = os.path.join(val_label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# 학습 데이터에서 저장한 LabelEncoder 로드\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 validation 레이블 수집\n",
    "# ============================\n",
    "label_files = sorted(glob.glob(os.path.join(val_label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "for i, label_file in enumerate(label_files):\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"✅ Validation 레이블 인코딩 및 저장 완료 (배치 수: {len(label_files)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())               # 학습 안정성 향상\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))     # 공간 크기 감소\n",
    "\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())           # 피처맵 전체 평균값\n",
    "\n",
    "    # [4] 완전 연결층 + 드롭아웃\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))                       # 과적합 방지\n",
    "\n",
    "    # [5] 출력층 - 클래스 수만큼 softmax 출력\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743057731.960520   22337 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4550 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Computed output size would be negative. Received `inputs shape=(None, 37, 1, 64)`, `kernel shape=(3, 3, 64, 128)`, `dilation_rate=[1 1]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     35\u001b[39m input_shape = sample_input.shape[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# (time, n_mfcc, 1)\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 4. 모델 생성 및 요약\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m model = \u001b[43mcreate_cnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m model.summary()\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 5. 콜백 정의 (모델 저장 및 EarlyStopping)\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mcreate_cnn_model\u001b[39m\u001b[34m(input_shape, num_classes)\u001b[39m\n\u001b[32m     25\u001b[39m model.add(layers.MaxPooling2D(pool_size=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)))\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# [3] 세 번째 컨볼루션 블록\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m model.add(layers.BatchNormalization())\n\u001b[32m     30\u001b[39m model.add(layers.GlobalAveragePooling2D())           \u001b[38;5;66;03m# 피처맵 전체 평균값\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/models/sequential.py:122\u001b[39m, in \u001b[36mSequential.add\u001b[39m\u001b[34m(self, layer, rebuild)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m._layers.append(layer)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/models/sequential.py:149\u001b[39m, in \u001b[36mSequential._maybe_rebuild\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    148\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].batch_shape\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[32m    154\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].input_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/layers/layer.py:229\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    228\u001b[39m     obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[32m    231\u001b[39m signature = inspect.signature(original_build_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/models/sequential.py:195\u001b[39m, in \u001b[36mSequential.build\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m1\u001b[39m:]:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/ops/operation_utils.py:221\u001b[39m, in \u001b[36mcompute_conv_output_shape\u001b[39m\u001b[34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] < \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    222\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mComputed output size would be negative. Received \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    226\u001b[39m             )\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m padding == \u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding == \u001b[33m\"\u001b[39m\u001b[33mcausal\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    228\u001b[39m     output_spatial_shape = np.floor((spatial_shape - \u001b[32m1\u001b[39m) / strides) + \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Computed output size would be negative. Received `inputs shape=(None, 37, 1, 64)`, `kernel shape=(3, 3, 64, 128)`, `dilation_rate=[1 1]`."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# 1. 데이터 제너레이터 생성\n",
    "# ============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 안정 위해 소량으로 시작\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. 클래스 수 설정\n",
    "# ============================\n",
    "import pickle\n",
    "\n",
    "# 학습 데이터의 레이블 인코더를 불러와 클래스 수 확인\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 3. 입력 형태 설정\n",
    "# ============================\n",
    "# 예시 입력 크기 지정 (임의 값, 실제 학습 데이터 확인 후 조정 가능)\n",
    "# 이 부분은 train_generator[0][0].shape 로 확인 가능\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# ============================\n",
    "# 4. 모델 생성 및 요약\n",
    "# ============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ============================\n",
    "# 5. 콜백 정의 (모델 저장 및 EarlyStopping)\n",
    "# ============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ============================\n",
    "# 6. 학습 실행\n",
    "# ============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 실패한 이유 \n",
    "- Conv2D 커널이 너무 커서 작은 입력에 비해 작동을 못함 - kernel size 축소 or padding =\"same\" 적용 -> 모델 재정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안정적인 CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    음성 감정 분류를 위한 CNN 모델 정의\n",
    "    \n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터의 형태 (시간축, MFCC 차원, 채널 수)\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Sequential: 컴파일된 모델 객체\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # ===============================\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    # Conv2D: 32개의 필터, 3x3 커널, relu 활성화 함수 사용\n",
    "    # padding='same'으로 출력 크기 감소 방지\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())  # 정규화로 학습 안정화\n",
    "    model.add(layers.MaxPooling2D((2, 2)))  # 출력 크기 절반으로 축소\n",
    "\n",
    "    # ===============================\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # ===============================\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # GlobalAveragePooling2D: 각 채널의 평균을 취해 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # ===============================\n",
    "    # [4] 완전 연결층 + 출력층\n",
    "    # ===============================\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))  # 과적합 방지\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # 감정 클래스 확률 출력\n",
    "\n",
    "    # ===============================\n",
    "    # [5] 모델 컴파일\n",
    "    # ===============================\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- 학습 도중 시스템이 멈추지 않도록 작은 배치 크기와 적절한 콜백 설정 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743058856.274355   22463 service.cc:152] XLA service 0x7e45fc006740 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743058856.274372   22463 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-03-27 16:00:56.357242: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "E0000 00:00:1743058856.801990   22463 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1743058856.922577   22463 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-03-27 16:00:56.930185: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-03-27 16:00:56.930218: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_22337/4153134984.py\", line 65, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_3523]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFailedPreconditionError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     48\u001b[39m callbacks = [\n\u001b[32m     49\u001b[39m     tf.keras.callbacks.ModelCheckpoint(\n\u001b[32m     50\u001b[39m         filepath=checkpoint_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     )\n\u001b[32m     60\u001b[39m ]\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 6. 학습 실행\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mFailedPreconditionError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_22337/4153134984.py\", line 65, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_3523]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# 1. 데이터 제너레이터 생성\n",
    "# ============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 절약을 위한 작은 배치\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. 레이블 인코더 로드 및 클래스 수 설정\n",
    "# ============================\n",
    "# 학습 데이터용 레이블 인코더를 통해 클래스 수 파악\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 3. 입력 형태 설정\n",
    "# ============================\n",
    "# 첫 배치에서 입력 형태 파악\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# ============================\n",
    "# 4. 모델 생성\n",
    "# ============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ============================\n",
    "# 5. 콜백 설정\n",
    "# ============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ============================\n",
    "# 6. 학습 실행\n",
    "# ============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU 메모리 부족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 경량화 프루닝 라이브러리 및 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfmot\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_pruned_cnn_model\u001b[39m(input_shape, num_classes):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/__init__.py:86\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# To ensure users only access the expected public API, the API structure is\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# created in the `api` directory. Import all api modules.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Import API modules for Tensorflow Model Optimization.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/clustering/__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Module containing code for clustering.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/clustering/keras/__init__.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_scope\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_weights\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m strip_clustering\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_wrapper\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clusterable_layer\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_registry\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/clustering_centroids.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_ops\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m     25\u001b[39m k = keras.backend\n\u001b[32m     26\u001b[39m CentroidInitialization = cluster_config.CentroidInitialization\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:41\u001b[39m\n\u001b[32m     37\u001b[39m     keras_internal = tf.keras\n\u001b[32m     38\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m keras_internal\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m keras = \u001b[43m_get_keras_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massign\u001b[39m(ref, value, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     44\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tf, \u001b[33m'\u001b[39m\u001b[33massign\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:33\u001b[39m, in \u001b[36m_get_keras_instance\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     30\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mTF_USE_LEGACY_KERAS\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Use Keras 2.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m version_fn = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mversion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version_fn \u001b[38;5;129;01mand\u001b[39;00m version_fn().startswith(\u001b[33m'\u001b[39m\u001b[33m3.\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     35\u001b[39m   \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras_internal\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,unused-import\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[39m, in \u001b[36mKerasLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule.startswith(\n\u001b[32m    205\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m__internal__.legacy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m   ):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not available with Keras 3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[39m, in \u001b[36mLazyLoader._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m module = importlib.import_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m._tfll_local_name] = module\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[39m, in \u001b[36mKerasLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule.startswith(\n\u001b[32m    205\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m__internal__.legacy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m   ):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not available with Keras 3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[39m, in \u001b[36mLazyLoader._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m module = importlib.import_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m._tfll_local_name] = module\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: KerasLazyLoader.__getattr__ at line 210 (1457 times), LazyLoader._load at line 52 (1457 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[39m, in \u001b[36mKerasLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule.startswith(\n\u001b[32m    205\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m__internal__.legacy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m   ):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not available with Keras 3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[39m, in \u001b[36mLazyLoader._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m module = importlib.import_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m._tfll_local_name] = module\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_pruned_cnn_model(input_shape, num_classes):\n",
    "    # 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=1000  # 조절 가능\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 밀집층\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "\n",
    "    # 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfmot\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_pruned_cnn_model\u001b[39m(input_shape, num_classes):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/__init__.py:86\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# To ensure users only access the expected public API, the API structure is\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# created in the `api` directory. Import all api modules.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Import API modules for Tensorflow Model Optimization.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/clustering/__init__.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Module containing code for clustering.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/api/clustering/keras/__init__.py:19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_scope\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_weights\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m strip_clustering\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster.py:22\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_wrapper\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/cluster_wrapper.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clusterable_layer\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_registry\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/clustering/keras/clustering_centroids.py:22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clustering_ops\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclustering\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m     25\u001b[39m k = keras.backend\n\u001b[32m     26\u001b[39m CentroidInitialization = cluster_config.CentroidInitialization\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:41\u001b[39m\n\u001b[32m     37\u001b[39m     keras_internal = tf.keras\n\u001b[32m     38\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m keras_internal\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m keras = \u001b[43m_get_keras_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massign\u001b[39m(ref, value, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     44\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tf, \u001b[33m'\u001b[39m\u001b[33massign\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:33\u001b[39m, in \u001b[36m_get_keras_instance\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     30\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mTF_USE_LEGACY_KERAS\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Use Keras 2.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m version_fn = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mversion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version_fn \u001b[38;5;129;01mand\u001b[39;00m version_fn().startswith(\u001b[33m'\u001b[39m\u001b[33m3.\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     35\u001b[39m   \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf_keras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras_internal\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,unused-import\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[39m, in \u001b[36mKerasLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule.startswith(\n\u001b[32m    205\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m__internal__.legacy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m   ):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not available with Keras 3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[39m, in \u001b[36mLazyLoader._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m module = importlib.import_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m._tfll_local_name] = module\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[39m, in \u001b[36mKerasLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule.startswith(\n\u001b[32m    205\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m__internal__.legacy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m   ):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not available with Keras 3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[39m, in \u001b[36mLazyLoader._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m module = importlib.import_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m._tfll_local_name] = module\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: KerasLazyLoader.__getattr__ at line 210 (1457 times), LazyLoader._load at line 52 (1457 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:210\u001b[39m, in \u001b[36mKerasLazyLoader.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfll_submodule.startswith(\n\u001b[32m    205\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33m__internal__.legacy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m   ):\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` is not available with Keras 3.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/util/lazy_loader.py:52\u001b[39m, in \u001b[36mLazyLoader._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m module = importlib.import_module(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m._tfll_parent_module_globals[\u001b[38;5;28mself\u001b[39m._tfll_local_name] = module\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_pruned_cnn_model(input_shape, num_classes):\n",
    "    # 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=1000  # 조절 가능\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 밀집층\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "\n",
    "    # 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 프루닝 실패\n",
    "1. Sequential 모델 안에 잘못된 레이어 구조를 넣었거나\n",
    "\n",
    "2. 프루닝 대상에 이미 프루닝된 레이어를 다시 적용하려고 하거나\n",
    "\n",
    "3. 모델 구조에서 무한 루프가 생겼거나\n",
    "\n",
    "4. 너무 많은 프루닝 wrapper가 중첩된 경우\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서 부터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCDataGenerator 클래스\n",
    "- tf.keras.utils.Sequence를 상속받아, 저장된 MFCC 및 레이블 배치 데이터를 Keras 모델 학습에 적합하게 동적으로 불러오고 전처리해주는 제너레이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 10:05:11.283826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743123911.301970    4800 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743123911.306197    4800 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743123911.319183    4800 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743123911.319198    4800 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743123911.319199    4800 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743123911.319200    4800 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 10:05:11.323094: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_dir, prefix, batch_size=1, shuffle=True):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 배치 리스트 구성\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "        self.indices = list(range(len(self.mfcc_files)))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 현재 배치 인덱스 범위 계산\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_mfccs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "            label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "            mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_data = np.load(label_path)\n",
    "\n",
    "            # 시퀀스 길이 맞추기 (Zero-padding)\n",
    "            max_len = max([x.shape[0] for x in mfcc_data])\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data, maxlen=max_len, dtype='float32', padding='post')\n",
    "            padded = np.expand_dims(padded, -1)  # CNN 입력 형식 맞추기\n",
    "\n",
    "            batch_mfccs.append(padded)\n",
    "            batch_labels.append(label_data)\n",
    "\n",
    "        X = np.concatenate(batch_mfccs, axis=0)\n",
    "        y = np.concatenate(batch_labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 감정 분류를 위한 CNN 모델을 정의한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    음성 감정 인식을 위한 CNN 모델 정의\n",
    "    - 입력: MFCC 시퀀스 (batch, time, n_mfcc, 1)\n",
    "    - 출력: 감정 클래스 확률 (softmax)\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())  # 피처맵 전체 평균값\n",
    "\n",
    "    # [4] 완전 연결층\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # 감정 클래스 개수만큼 출력\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU memory growth enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743069273.900138   11267 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743069277.256819   11330 service.cc:152] XLA service 0x7572800028e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743069277.256835   11330 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-03-27 18:54:37.327430: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "E0000 00:00:1743069277.696580   11330 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1743069277.792812   11330 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-03-27 18:54:37.799885: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-03-27 18:54:37.799933: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_11267/3582064655.py\", line 75, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_3439]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFailedPreconditionError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     58\u001b[39m callbacks = [\n\u001b[32m     59\u001b[39m     tf.keras.callbacks.ModelCheckpoint(\n\u001b[32m     60\u001b[39m         filepath=checkpoint_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m     )\n\u001b[32m     70\u001b[39m ]\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# [6] 모델 학습\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mFailedPreconditionError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_11267/3582064655.py\", line 75, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_3439]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===============================\n",
    "# [0] GPU 메모리 설정 (OOM 방지)\n",
    "# ===============================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ RuntimeError:\", e)\n",
    "\n",
    "# ===============================\n",
    "# [1] 데이터 제너레이터 생성\n",
    "# ===============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 안전 위해 최소 배치\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# [2] 레이블 인코더 로드 및 클래스 수\n",
    "# ===============================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ===============================\n",
    "# [3] 입력 형태 확인\n",
    "# ===============================\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "# ===============================\n",
    "# [4] 모델 생성\n",
    "# ===============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ===============================\n",
    "# [5] 콜백 설정 (모델 저장 + 조기 종료)\n",
    "# ===============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# [6] 모델 학습\n",
    "# ===============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 변경  PyTorch 기반 간단한 CNN 모델 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioEmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 데이터 로더 정의 (PyTorch용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, batch_dir, prefix):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "        label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "        # 여기서도 배치 데이터임\n",
    "        mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "        label_batch = np.load(label_path)\n",
    "\n",
    "        # 리스트로 묶어서 반환 (collate_fn에서 처리)\n",
    "        return list(zip(mfcc_batch, label_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate_fn 추가 (패딩과 텐서 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = sum(batch, [])  # [(mfcc1, label1), ..., (mfccN, labelN)]로 평탄화\n",
    "    seq_lens = [x[0].shape[0] for x in batch]\n",
    "    max_len = max(seq_lens)\n",
    "    n_mfcc = batch[0][0].shape[1]\n",
    "\n",
    "    padded_mfccs = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc, label in batch:\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:mfcc.shape[0], :] = mfcc\n",
    "        padded_mfccs.append(padded)\n",
    "        labels.append(label)\n",
    "\n",
    "    X = torch.tensor(padded_mfccs).unsqueeze(1)  # (batch, 1, time, n_mfcc)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MFCCDataset(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\", \"mfcc\")\n",
    "val_dataset = MFCCDataset(\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\", \"mfcc\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 0/21 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [5491, 1, 157, 13] at entry 0 and [10000, 1, 157, 13] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m     31\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m [Train]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects each tensor to be equal size, but got [5491, 1, 157, 13] at entry 0 and [10000, 1, 157, 13] at entry 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = AudioEmotionCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# ============================\n",
    "# 1. 학습 루프\n",
    "# ============================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 2. 검증 루프\n",
    "    # ============================\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"🔵 Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 3. 모델 저장\n",
    "    # ============================\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"💾 Best model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러 :  배치 안의 샘플들이 시퀀스 길이(time step)가 서로 달라서 torch.stack() 실패.\n",
    "PyTorch DataLoader는 collate_fn이 내부에서 torch.stack()을 사용하기 때문에, 입력 데이터들 크기가 다르면 에러가 납니다.\n",
    "TensorFlow에서는 padding으로 해결됐던 부분\n",
    "\n",
    "- 해결 방안 : 배치 크기를 맞추는 collate_fn 함수 구현\n",
    "    - collate_fn을 사용하여 배치 내 데이터 크기를 맞추는 방법을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 0/21 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[/media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_1.npy] shape 오류: (time, n_mfcc) 형식이 아님 → 실제 shape: (10000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    125\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m    126\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m [Train]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mMFCCDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 2D 배열인지 확인 (time, n_mfcc)\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mfcc_data.ndim != \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfcc_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] shape 오류: (time, n_mfcc) 형식이 아님 → 실제 shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfcc_data.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mfcc_data, label_data\n",
      "\u001b[31mValueError\u001b[39m: [/media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_1.npy] shape 오류: (time, n_mfcc) 형식이 아님 → 실제 shape: (10000,)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# ============================\n",
    "# 1. 레이블 인코더 로드 및 클래스 수 확인\n",
    "# ============================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 2. 데이터셋 클래스 정의\n",
    "# ============================\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, batch_dir, prefix):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.mfcc_files = sorted([f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "        label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "        mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "        label_data = np.load(label_path)\n",
    "\n",
    "        # 리스트 형태일 경우 numpy 배열로 변환\n",
    "        if isinstance(mfcc_data, list):\n",
    "            mfcc_data = np.array(mfcc_data)\n",
    "\n",
    "        # 2D 배열인지 확인 (time, n_mfcc)\n",
    "        if mfcc_data.ndim != 2:\n",
    "            raise ValueError(f\"[{mfcc_path}] shape 오류: (time, n_mfcc) 형식이 아님 → 실제 shape: {mfcc_data.shape}\")\n",
    "\n",
    "        return mfcc_data, label_data\n",
    "\n",
    "\n",
    "# 패딩을 위한 collate_fn 정의\n",
    "def collate_fn(batch):\n",
    "    # 각 샘플은 (sequence_len, n_mfcc)\n",
    "    seq_lens = [sample[0].shape[0] for sample in batch]\n",
    "    max_len = max(seq_lens)\n",
    "\n",
    "    padded_batch = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc_data, label_data in batch:\n",
    "        # mfcc_data shape: (time, n_mfcc)\n",
    "        time_len = mfcc_data.shape[0]\n",
    "        n_mfcc = mfcc_data.shape[1]\n",
    "\n",
    "        # (time, n_mfcc) → (max_len, n_mfcc)\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:time_len, :] = mfcc_data\n",
    "\n",
    "        padded_batch.append(padded)\n",
    "        labels.append(label_data)\n",
    "\n",
    "    # (batch, 1, time, n_mfcc)\n",
    "    X = torch.tensor(padded_batch).unsqueeze(1)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_dataset = MFCCDataset(batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\", prefix=\"mfcc\")\n",
    "val_dataset = MFCCDataset(batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\", prefix=\"mfcc\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ============================\n",
    "# 3. 모델 정의\n",
    "# ============================\n",
    "class AudioEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioEmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 모델과 손실 함수, 옵티마이저 설정\n",
    "model = AudioEmotionCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# ============================\n",
    "# 4. 학습 루프\n",
    "# ============================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 5. 검증 루프\n",
    "    # ============================\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"🔵 Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 6. 모델 저장\n",
    "    # ============================\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"💾 Best model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러\n",
    "allow_pickle=True 옵션으로 불러온 데이터를 np.load() 하면, 원래는 List[np.ndarray] 혹은 (time, n_mfcc) 구조여야 합니다.\n",
    "\n",
    "만약 이전에 이 mfcc_batch_1.npy를 배치 단위 리스트 형태로 저장했었다면:\n",
    "\n",
    "지금처럼 __getitem__에서 개별 .npy를 꺼낼 경우 배치 전체가 한 개의 1D 배열로 저장되어 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해결 방법: 각 샘플을 개별 .npy 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 10000개 샘플 저장 완료: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 원본 다중샘플 npy 경로\n",
    "input_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_1.npy\"\n",
    "\n",
    "# 저장할 경로\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "data = np.load(input_path, allow_pickle=True)\n",
    "\n",
    "# 각 샘플 저장\n",
    "for i, sample in enumerate(data):\n",
    "    save_path = os.path.join(output_dir, f\"sample_{i:04d}.npy\")\n",
    "    np.save(save_path, sample)\n",
    "\n",
    "print(f\"✅ 총 {len(data)}개 샘플 저장 완료: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 분할 저장 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 10000개 레이블 저장 완료: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 레이블 경로\n",
    "label_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels/label_batch_1.npy\"\n",
    "labels = np.load(label_path)\n",
    "\n",
    "# 저장할 디렉토리\n",
    "label_output_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\"\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# 분할 저장\n",
    "for i, label in enumerate(labels):\n",
    "    save_path = os.path.join(label_output_dir, f\"label_{i:04d}.npy\")\n",
    "    np.save(save_path, label)\n",
    "\n",
    "print(f\"✅ 총 {len(labels)}개 레이블 저장 완료: {label_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCSampleDataset 정의 (샘플 단위)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class MFCCSampleDataset(Dataset):\n",
    "    def __init__(self, sample_dir, label_dir):\n",
    "        self.sample_paths = sorted([\n",
    "            os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = np.load(self.sample_paths[idx])          # shape: (time, n_mfcc)\n",
    "        label = np.load(self.label_paths[idx])          # shape: ()\n",
    "\n",
    "        # 텐서로 변환 (채널 추가)\n",
    "        mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)  # (1, time, n_mfcc)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return mfcc_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate_fn 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    seq_lens = [x[0].shape[0] for x in batch]\n",
    "    max_len = max(seq_lens)\n",
    "\n",
    "    # n_mfcc 추정 시 더 안전하게\n",
    "    n_mfcc = None\n",
    "    for mfcc_data, _ in batch:\n",
    "        if isinstance(mfcc_data, np.ndarray) and mfcc_data.ndim == 2:\n",
    "            n_mfcc = mfcc_data.shape[1]\n",
    "            break\n",
    "\n",
    "    if n_mfcc is None:\n",
    "        raise ValueError(\"모든 샘플에서 유효한 2D MFCC 데이터를 찾을 수 없습니다.\")\n",
    "\n",
    "    padded_batch = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc_data, label_data in batch:\n",
    "        time_len = mfcc_data.shape[0]\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:time_len, :] = mfcc_data\n",
    "        padded_batch.append(padded)\n",
    "        labels.append(label_data)\n",
    "\n",
    "    X = torch.tensor(padded_batch).unsqueeze(1)  # (batch, 1, time, n_mfcc)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  기본 설정 및 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# 모델 정의 (이전에 정의한 AudioEmotionCNN 사용)\n",
    "model = AudioEmotionCNN(num_classes=8).to(device)  # 클래스 수에 맞게 수정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 0/2500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "모든 샘플에서 유효한 2D MFCC 데이터를 찾을 수 없습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m      9\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m [Train]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mcollate_fn\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_mfcc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m모든 샘플에서 유효한 2D MFCC 데이터를 찾을 수 없습니다.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m padded_batch = []\n\u001b[32m     16\u001b[39m labels = []\n",
      "\u001b[31mValueError\u001b[39m: 모든 샘플에서 유효한 2D MFCC 데이터를 찾을 수 없습니다."
     ]
    }
   ],
   "source": [
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 샘플 단위 .npy 파일을 위한 DataGenerator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class SampleMFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32, shuffle=True):\n",
    "        self.mfcc_paths = sorted([\n",
    "            os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = [], []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            mfcc = np.load(self.mfcc_paths[i])  # (time, n_mfcc)\n",
    "            label = np.load(self.label_paths[i])  # 정수 인코딩 레이블\n",
    "\n",
    "            X.append(mfcc)\n",
    "            y.append(label)\n",
    "\n",
    "        # Zero-padding\n",
    "        max_len = max(x.shape[0] for x in X)\n",
    "        X_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            X, maxlen=max_len, padding='post', dtype='float32'\n",
    "        )\n",
    "        X_pad = np.expand_dims(X_pad, -1)  # (batch, time, n_mfcc, 1)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return X_pad, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1  validation 데이터도 split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ validation용 10000개 샘플 및 레이블 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "val_input_path = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/mfcc_batch_0.npy\"\n",
    "val_label_path = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/label_batch_0.npy\"\n",
    "\n",
    "# 저장할 폴더\n",
    "val_sample_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\"\n",
    "os.makedirs(val_sample_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "mfcc_data = np.load(val_input_path, allow_pickle=True)\n",
    "label_data = np.load(val_label_path)\n",
    "\n",
    "# 저장\n",
    "for i, (sample, label) in enumerate(zip(mfcc_data, label_data)):\n",
    "    np.save(os.path.join(val_sample_dir, f\"sample_{i:04d}.npy\"), sample)\n",
    "    np.save(os.path.join(val_label_dir, f\"label_{i:04d}.npy\"), label)\n",
    "\n",
    "print(f\"✅ validation용 {len(mfcc_data)}개 샘플 및 레이블 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 콜백 설정 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 클래스 수: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,209</span> (430.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,209\u001b[0m (430.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,761</span> (428.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,761\u001b[0m (428.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/ops/nn.py:908: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "2025-03-28 11:16:45.087514: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n",
      "2025-03-28 11:16:45.087548: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Received a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n",
      "\t [[{{function_node __inference_one_step_on_data_6795}}{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_11170/2579500336.py\", line 62, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/ops/nn.py\", line 1964, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_6922]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     57\u001b[39m     model(tf.random.normal((\u001b[32m1\u001b[39m,) + input_shape))\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# [4] 모델 학습 실행\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ 모델 학습 완료 및 저장 완료\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_11170/2579500336.py\", line 62, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/ops/nn.py\", line 1964, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_6922]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# ===============================\n",
    "# [1] 학습 및 검증용 DataGenerator 정의\n",
    "# ===============================\n",
    "train_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "val_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# [2] 입력 형태 확인 및 모델 생성\n",
    "# ===============================\n",
    "sample_input, _ = train_generator[0]\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# 클래스 수 확인\n",
    "import glob\n",
    "label_paths = sorted(glob.glob(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels/*.npy\"))\n",
    "all_labels = [int(np.load(p)) for p in label_paths]\n",
    "num_classes = len(set(all_labels))\n",
    "\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ===============================\n",
    "# [3] 콜백 설정\n",
    "# ===============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_tf.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# GPU 초기화를 위한 예열용 더미 실행 (CPU에서 실행)\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    model(tf.random.normal((1,) + input_shape))\n",
    "\n",
    "# ===============================\n",
    "# [4] 모델 학습 실행\n",
    "# ===============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"✅ 모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpu 사용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cpu로 학습 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 11:18:00.012173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743128280.028215   11313 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743128280.033166   11313 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743128280.045344   11313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743128280.045397   11313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743128280.045399   11313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743128280.045401   11313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 11:18:00.050315: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 수: 1\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-28 11:18:03.401681: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-03-28 11:18:03.401701: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:167] env: CUDA_VISIBLE_DEVICES=\"-1\"\n",
      "2025-03-28 11:18:03.401706: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] CUDA_VISIBLE_DEVICES is set to -1 - this hides all GPUs from CUDA\n",
      "2025-03-28 11:18:03.401708: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-03-28 11:18:03.401711: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: usou-GP75-Leopard-10SEK\n",
      "2025-03-28 11:18:03.401713: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: usou-GP75-Leopard-10SEK\n",
      "2025-03-28 11:18:03.401854: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.144.3\n",
      "2025-03-28 11:18:03.401868: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.144.3\n",
      "2025-03-28 11:18:03.401870: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.144.3\n",
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/ops/nn.py:908: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "2025-03-28 11:18:05.721791: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n",
      "2025-03-28 11:18:05.721822: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Received a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n",
      "\t [[{{function_node __inference_one_step_on_data_3294}}{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_11313/2616878548.py\", line 105, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/ops/nn.py\", line 1964, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_3421]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m     99\u001b[39m callbacks = [\n\u001b[32m    100\u001b[39m     ModelCheckpoint(filepath=checkpoint_path, monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, verbose=\u001b[32m1\u001b[39m),\n\u001b[32m    101\u001b[39m     EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    102\u001b[39m ]\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# 7. 모델 학습\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m모델 학습 완료 및 저장 완료\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_11313/2616878548.py\", line 105, in <module>\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/losses/losses.py\", line 2246, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/ops/nn.py\", line 1964, in sparse_categorical_crossentropy\n\n  File \"/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\", line 744, in sparse_categorical_crossentropy\n\nReceived a label value of 3 which is outside the valid range of [0, 1).  Label values: 3 3 3 3 3 3 3 3\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_3421]"
     ]
    }
   ],
   "source": [
    "# 0. GPU 완전 비활성화 (가장 먼저 실행)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# 1. 필수 라이브러리 임포트\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "\n",
    "# 2. 사용자 정의 DataGenerator\n",
    "class SampleMFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32, shuffle=True):\n",
    "        self.mfcc_paths = sorted([\n",
    "            os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_mfcc = [np.load(self.mfcc_paths[i]) for i in batch_indexes]\n",
    "        batch_label = [np.load(self.label_paths[i]).item() for i in batch_indexes]  # .item() 추가\n",
    "\n",
    "        batch_mfcc = [np.expand_dims(x, axis=-1) for x in batch_mfcc]  # (time, n_mfcc, 1)\n",
    "\n",
    "        max_len = max(x.shape[0] for x in batch_mfcc)\n",
    "        padded_mfcc = np.array([\n",
    "            np.pad(x, ((0, max_len - x.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
    "            for x in batch_mfcc\n",
    "        ])\n",
    "\n",
    "        labels = np.array(batch_label, dtype=np.int32)\n",
    "        return padded_mfcc, labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# 3. CNN 모델 생성 함수\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. DataGenerator 설정\n",
    "train_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "val_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# 5. 입력 형상 및 클래스 수 확인\n",
    "sample_input, _ = train_generator[0]\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "label_paths = sorted(glob.glob(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels/*.npy\"))\n",
    "all_labels = [np.load(p).item() for p in label_paths]  # .item()으로 스칼라 추출\n",
    "num_classes = len(set(all_labels))\n",
    "print(f\"클래스 수: {num_classes}\")\n",
    "\n",
    "# 6. 모델 생성 및 콜백 설정\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_tf.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 모델 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신 러닝 시도\n",
    "## 작업 순서\n",
    "1. 데이터 로딩 및 통합\n",
    "    - metadata_cleaned (train)\n",
    "    - metadata_cleaned_val (validation)\n",
    "\n",
    "2. 특징(X)과 레이블(y) 분리\n",
    "    - MFCC는 X\n",
    "    - 감정 레이블은 y\n",
    "\n",
    "3. 레이블 인코딩\n",
    "    - 문자열 레이블(Happy, Sad 등)을 숫자로 변환\n",
    "\n",
    "4. 머신러닝 모델 선택 및 학습\n",
    "    - 예: RandomForestClassifier, SVC, GradientBoosting, LogisticRegression\n",
    "\n",
    "5. 검증 및 평가\n",
    "    - accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로딩 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 경로\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/metadata_cleaned\"\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/metadata_cleaned_val\"\n",
    "\n",
    "# 파일 불러오기\n",
    "train_mfcc_paths = sorted(glob(os.path.join(train_dir, \"*.npy\")))\n",
    "val_mfcc_paths = sorted(glob(os.path.join(val_dir, \"*.npy\")))\n",
    "\n",
    "# 데이터 로딩\n",
    "train_data = [np.load(f, allow_pickle=True).item() for f in train_mfcc_paths]\n",
    "val_data = [np.load(f, allow_pickle=True).item() for f in val_mfcc_paths]\n",
    "\n",
    "# 분리\n",
    "X_train = [d[\"mfcc\"] for d in train_data]\n",
    "y_train = [d[\"emotion\"] for d in train_data]\n",
    "\n",
    "X_val = [d[\"mfcc\"] for d in val_data]\n",
    "y_val = [d[\"emotion\"] for d in val_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특징(X)과 레이블(y) 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11956/3214042000.py:5: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata_cleaned = pd.read_csv(train_path)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mfcc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'mfcc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m metadata_cleaned_val = pd.read_csv(val_path)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# X: MFCC 특징, y: 감정 레이블\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m X_train = \u001b[43mmetadata_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmfcc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m y_train = metadata_cleaned[\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     15\u001b[39m X_val = metadata_cleaned_val[\u001b[33m\"\u001b[39m\u001b[33mmfcc\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'mfcc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 학습용 데이터 로딩\n",
    "train_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "metadata_cleaned = pd.read_csv(train_path)\n",
    "\n",
    "# 검증용 데이터 로딩\n",
    "val_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "metadata_cleaned_val = pd.read_csv(val_path)\n",
    "\n",
    "# X: MFCC 특징, y: 감정 레이블\n",
    "X_train = metadata_cleaned[\"mfcc\"]\n",
    "y_train = metadata_cleaned[\"emotion\"]\n",
    "\n",
    "X_val = metadata_cleaned_val[\"mfcc\"]\n",
    "y_val = metadata_cleaned_val[\"emotion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wav_path', 'emotion', 'style', 'sensitivity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(metadata_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\"\n",
    "\n",
    "def load_mfcc_from_path(path_series):\n",
    "    mfcc_list = []\n",
    "    for rel_path in path_series:\n",
    "        fname = os.path.splitext(os.path.basename(rel_path))[0]\n",
    "        mfcc_path = os.path.join(base_mfcc_dir, f\"{fname}.npy\")\n",
    "        if not os.path.exists(mfcc_path):\n",
    "            print(f\"⚠️ 누락된 MFCC 파일: {mfcc_path}\")\n",
    "            continue\n",
    "        mfcc = np.load(mfcc_path)\n",
    "        mfcc_list.append(mfcc.flatten())  # 머신러닝용 1D 벡터로\n",
    "    return np.array(mfcc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/usou/PortableSSD/mldl_project/data/mfcc_batches/0001_G1A3E1S0C0_PSB_000001.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# X (특징) 로딩\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train = \u001b[43mload_mfcc_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwav_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m X_val = load_mfcc_from_path(metadata_cleaned_val[\u001b[33m\"\u001b[39m\u001b[33mwav_path\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# y (레이블) 추출\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mload_mfcc_from_path\u001b[39m\u001b[34m(path_series)\u001b[39m\n\u001b[32m     10\u001b[39m     fname = os.path.splitext(os.path.basename(rel_path))[\u001b[32m0\u001b[39m]\n\u001b[32m     11\u001b[39m     mfcc_path = os.path.join(base_mfcc_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     mfcc = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     mfcc_list.append(mfcc.flatten())  \u001b[38;5;66;03m# 머신러닝 모델 입력 위해 1D로 평탄화\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(mfcc_list)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    425\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    428\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/media/usou/PortableSSD/mldl_project/data/mfcc_batches/0001_G1A3E1S0C0_PSB_000001.npy'"
     ]
    }
   ],
   "source": [
    "# X (특징) 로딩\n",
    "X_train = load_mfcc_from_path(metadata_cleaned[\"wav_path\"])\n",
    "X_val = load_mfcc_from_path(metadata_cleaned_val[\"wav_path\"])\n",
    "\n",
    "# y (레이블) 추출\n",
    "y_train = metadata_cleaned[\"emotion\"].values\n",
    "y_val = metadata_cleaned_val[\"emotion\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 이후 부터 딥러닝 다시 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩 및 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 MFCC 샘플 수: 815491\n",
      "총 레이블 수: 815491\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 파일 경로 정렬\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 로딩\n",
    "X_raw = [np.load(p, allow_pickle=True) for p in mfcc_paths]\n",
    "y_raw = [np.load(p) for p in label_paths]\n",
    "\n",
    "# 리스트로 되어 있는 MFCC들을 한 리스트로 합치기\n",
    "X_all = [sample for batch in X_raw for sample in batch]\n",
    "y_all = np.concatenate(y_raw)\n",
    "\n",
    "print(f\"총 MFCC 샘플 수: {len(X_all)}\")\n",
    "print(f\"총 레이블 수: {len(y_all)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 샘플 길이 정규화(패딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:40:02.434497: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743144002.464161    6212 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743144002.472918    6212 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743144002.501484    6212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743144002.501502    6212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743144002.501503    6212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743144002.501504    6212 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 15:40:02.509771: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 MFCC 시퀀스 길이: 157\n",
      "패딩된 X shape: (815491, 157, 13)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# MFCC의 각 샘플은 (time, 13) 형태 → 시퀀스 길이 맞추기\n",
    "max_len = max([x.shape[0] for x in X_all])\n",
    "print(\"가장 긴 MFCC 시퀀스 길이:\", max_len)\n",
    "\n",
    "# (샘플 수, time, n_mfcc)\n",
    "X_padded = pad_sequences(X_all, maxlen=max_len, padding='post', dtype='float32')\n",
    "print(\"패딩된 X shape:\", X_padded.shape)\n",
    "\n",
    "# 마지막 차원을 명시적으로 추가: (샘플 수, time, n_mfcc, 1)\n",
    "X_padded = np.expand_dims(X_padded, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증용 MFCC 샘플 수: 112157\n",
      "검증용 레이블 수: 112157\n"
     ]
    }
   ],
   "source": [
    "# 검증용 MFCC 데이터 로딩\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/encoded_labels\"\n",
    "\n",
    "val_mfcc_paths = sorted(glob(os.path.join(val_mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "val_label_paths = sorted(glob(os.path.join(val_label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "X_val_raw = [np.load(p, allow_pickle=True) for p in val_mfcc_paths]\n",
    "y_val_raw = [np.load(p) for p in val_label_paths]\n",
    "\n",
    "X_val_all = [sample for batch in X_val_raw for sample in batch]\n",
    "y_val = np.concatenate(y_val_raw)\n",
    "\n",
    "print(f\"검증용 MFCC 샘플 수: {len(X_val_all)}\")\n",
    "print(f\"검증용 레이블 수: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 기반 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743144025.889378    6212 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = X_padded.shape[1:]  # (157, 13, 1)\n",
    "num_classes = len(np.unique(y_all))\n",
    "\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 설정 & 모델 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 저장 경로\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_cnn.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m history = model.fit(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mX_train\u001b[49m, y_train,\n\u001b[32m      3\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m      4\u001b[39m     batch_size=\u001b[32m64\u001b[39m,\n\u001b[32m      5\u001b[39m     epochs=\u001b[32m30\u001b[39m,\n\u001b[32m      6\u001b[39m     callbacks=callbacks\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커널 재시작 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:42:45.988723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743144166.048874    6433 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743144166.067261    6433 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743144166.186217    6433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743144166.186233    6433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743144166.186234    6433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743144166.186235    6433 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 15:42:46.198741: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1. MFCC 및 레이블 로딩\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 경로\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 데이터 로딩\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "X_raw = [np.load(p, allow_pickle=True) for p in mfcc_paths]\n",
    "y_raw = [np.load(p) for p in label_paths]\n",
    "\n",
    "X_all = [sample for batch in X_raw for sample in batch]\n",
    "y_all = np.concatenate(y_raw)\n",
    "\n",
    "# 시퀀스 패딩\n",
    "max_len = 157  # 고정\n",
    "X_padded = pad_sequences(X_all, maxlen=max_len, padding='post', dtype='float32')\n",
    "X_padded = np.expand_dims(X_padded, -1)\n",
    "\n",
    "# 훈련/검증 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_padded, y_all, test_size=0.12, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "print(\"✅ 데이터 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 상황은 매우 자주 발생하는 Jupyter Notebook의 커널 메모리 한계 문제\n",
    "\n",
    "- 위 방법으로 해결 예저\n",
    "1. generator 정의\n",
    "2. gc.collect()\n",
    "3. model.fit(generator, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치 제너레이터 정의(훈련용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  # ✅ 반드시 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.mfcc_paths = mfcc_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_idx:\n",
    "            mfcc = np.load(self.mfcc_paths[i], allow_pickle=True)\n",
    "            label = np.load(self.label_paths[i])\n",
    "\n",
    "            # 유효한 MFCC만 처리\n",
    "            if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "                padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                    [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "                )[0]\n",
    "                X_batch.append(padded)\n",
    "                y_batch.append(label)\n",
    "\n",
    "        X_batch = np.expand_dims(np.array(X_batch), -1)  # (batch, time, n_mfcc, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제너레이터 생성 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 학습용 제너레이터\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=64, max_len=157, shuffle=True)\n",
    "\n",
    "# 가비지 컬렉션 실행 (메모리 확보)\n",
    "gc.collect()\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# 콜백 정의\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 검증용 데이터는 메모리 적재 방식으로 유지\n",
    "# 이 부분은 이전에 분리한 X_val, y_val을 사용해야 합니다\n",
    "# 혹시 없다면 validation set 따로 만들 수 있도록 알려주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[31mTypeError\u001b[39m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m X_val_paths:\n\u001b[32m     13\u001b[39m     mfcc = np.load(path, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     padded = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m157\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat32\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     17\u001b[39m     X_val_list.append(padded)\n\u001b[32m     19\u001b[39m X_val = np.expand_dims(np.array(X_val_list), -\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/sequence_utils.py:125\u001b[39m, in \u001b[36mpad_sequences\u001b[39m\u001b[34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTruncating type \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtruncating\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m not understood\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m trunc = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trunc.shape[\u001b[32m1\u001b[39m:] != sample_shape:\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    128\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrunc.shape[\u001b[32m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of sequence at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mposition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is different from expected shape \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# 전체 레이블 로딩\n",
    "all_labels = [np.load(p) for p in label_paths]\n",
    "y_all = np.concatenate(all_labels)\n",
    "\n",
    "# 전체 MFCC 로딩 (메모리 작은 검증셋만 로딩)\n",
    "val_size = 112157  # 예: 전체의 약 13%\n",
    "X_val_paths = mfcc_paths[-val_size:]\n",
    "y_val_paths = label_paths[-val_size:]\n",
    "\n",
    "# 검증 데이터 로딩\n",
    "X_val_list = []\n",
    "for path in X_val_paths:\n",
    "    mfcc = np.load(path, allow_pickle=True)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "    )[0]\n",
    "    X_val_list.append(padded)\n",
    "\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.concatenate([np.load(p) for p in y_val_paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_0.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_1.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_10.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_11.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_12.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_13.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_14.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_15.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_16.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_17.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_18.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_19.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_2.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_20.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_21.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_22.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_23.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_24.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_25.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_26.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_27.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_28.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_29.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_3.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_30.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_31.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_32.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_33.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_34.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_35.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_36.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_37.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_38.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_39.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_4.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_40.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_41.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_42.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_43.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_44.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_45.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_46.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_47.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_48.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_49.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_5.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_50.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_51.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_52.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_53.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_54.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_55.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_56.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_57.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_58.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_59.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_6.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_60.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_61.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_62.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_63.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_64.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_65.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_66.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_67.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_68.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_69.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_7.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_70.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_71.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_72.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_73.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_74.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_75.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_76.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_77.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_78.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_79.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_8.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_80.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_81.npy\n",
      "❌ 잘못된 MFCC: /media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_9.npy\n",
      "검증용 X shape: (0, 1)\n",
      "검증용 y shape: (0,)\n"
     ]
    }
   ],
   "source": [
    "X_val_list = []\n",
    "valid_y_list = []\n",
    "\n",
    "for mfcc_path, label_path in zip(X_val_paths, y_val_paths):\n",
    "    mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    \n",
    "    # (time, 13) 형식인지 확인\n",
    "    if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "        padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "        )[0]\n",
    "        X_val_list.append(padded)\n",
    "\n",
    "        label = np.load(label_path)\n",
    "        valid_y_list.append(label)\n",
    "    else:\n",
    "        print(\"❌ 잘못된 MFCC:\", mfcc_path)\n",
    "\n",
    "# 최종 배열로 변환\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.array(valid_y_list)\n",
    "\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증용 X shape: (90982, 157, 13, 1)\n",
      "✅ 검증용 y shape: (90982,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 경로\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 배치 파일 리스트\n",
    "mfcc_batch_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_batch_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 검증용 비율 기준으로 뒤에서 N개 배치만 선택\n",
    "val_batch_count = 10  # 예: 마지막 10개 배치만 사용\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "\n",
    "for mfcc_batch_path, label_batch_path in zip(mfcc_batch_paths[-val_batch_count:], label_batch_paths[-val_batch_count:]):\n",
    "    mfcc_batch = np.load(mfcc_batch_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_batch_path)\n",
    "\n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "\n",
    "# 배열로 변환\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"✅ 검증용 X shape:\", X_val.shape)\n",
    "print(\"✅ 검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 이 부분이 메모리에 있어야 해요!\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/superbad/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mMFCCBatchGenerator.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     30\u001b[39m     y_batch.append(label)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 패딩\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m padded = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfloat32\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     36\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     37\u001b[39m X_batch.append(padded)\n\u001b[32m     38\u001b[39m y_batch.append(label)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),  # 이 부분이 메모리에 있어야 해요!\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 정리 커널 재시작 후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 16:59:14.057234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743148754.070478    8542 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743148754.074722    8542 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743148754.087035    8542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743148754.087050    8542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743148754.087051    8542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743148754.087052    8542 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 16:59:14.090987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 데이터 재구성 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# 검증용 샘플 수 고정\n",
    "val_sample_size = 112157\n",
    "\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "\n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "# numpy 배열로 변환 (꼭 확인!)\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"✅ 검증 데이터 재구성 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.mfcc_paths = mfcc_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 전체 샘플을 flatten\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/superbad/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743148767.259957    8542 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m history = model.fit(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mtrain_generator\u001b[49m,\n\u001b[32m      3\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m      4\u001b[39m     epochs=\u001b[32m30\u001b[39m,\n\u001b[32m      5\u001b[39m     callbacks=callbacks\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 17:33:08.166012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743150788.183049    7684 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743150788.188898    7684 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743150788.202084    7684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743150788.202097    7684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743150788.202098    7684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743150788.202099    7684 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 17:33:08.206130: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 데이터 준비 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n",
      "✅ 유효한 학습용 샘플 수: 810992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-28 17:33:24.716822: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1743150804.717189    7684 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743150807.353714    7742 service.cc:152] XLA service 0x7cd894013f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743150807.353726    7742 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-03-28 17:33:27.412603: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743150807.737348    7742 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-03-28 17:33:28.101515: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[16,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,157,13]{3,2,1,0} %bitcast.5956, f32[32,1,3,3]{3,2,1,0} %bitcast.5963, f32[32]{0} %bitcast.6887), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:33:28.149395: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[16,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,78,6]{3,2,1,0} %bitcast.7052, f32[64,32,3,3]{3,2,1,0} %bitcast.6038, f32[64]{0} %bitcast.7112), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:33:28.237955: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[16,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,39,3]{3,2,1,0} %bitcast.7278, f32[128,64,3,3]{3,2,1,0} %bitcast.6113, f32[128]{0} %bitcast.7348), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   42/50687\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12\u001b[0m 4ms/step - accuracy: 0.2077 - loss: 2.0110   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743150810.311860    7742 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30887/50687\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 3ms/step - accuracy: 0.5033 - loss: 1.3827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 17:35:03.203048: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[6,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[6,32,78,6]{3,2,1,0} %bitcast.7026, f32[64,32,3,3]{3,2,1,0} %bitcast.6034, f32[64]{0} %bitcast.7086), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:35:03.257042: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[6,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[6,64,39,3]{3,2,1,0} %bitcast.7250, f32[128,64,3,3]{3,2,1,0} %bitcast.6105, f32[128]{0} %bitcast.7320), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5427 - loss: 1.2738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 17:36:05.447048: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-03-28 17:36:05.984792: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-03-28 17:36:06.666576: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,157,13]{3,2,1,0} %bitcast.662, f32[32,1,3,3]{3,2,1,0} %bitcast.669, f32[32]{0} %bitcast.671), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:36:06.714664: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,78,6]{3,2,1,0} %bitcast.699, f32[64,32,3,3]{3,2,1,0} %bitcast.706, f32[64]{0} %bitcast.708), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:36:06.803145: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,39,3]{3,2,1,0} %bitcast.736, f32[128,64,3,3]{3,2,1,0} %bitcast.743, f32[128]{0} %bitcast.745), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:36:12.351358: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[29,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,1,157,13]{3,2,1,0} %bitcast.662, f32[32,1,3,3]{3,2,1,0} %bitcast.669, f32[32]{0} %bitcast.671), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:36:12.402002: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[29,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,32,78,6]{3,2,1,0} %bitcast.699, f32[64,32,3,3]{3,2,1,0} %bitcast.706, f32[64]{0} %bitcast.708), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 17:36:12.475397: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[29,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,39,3]{3,2,1,0} %bitcast.736, f32[128,64,3,3]{3,2,1,0} %bitcast.743, f32[128]{0} %bitcast.745), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61804, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3ms/step - accuracy: 0.5427 - loss: 1.2737 - val_accuracy: 0.6180 - val_loss: 1.0669\n",
      "Epoch 2/30\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7176 - loss: 0.7934\n",
      "Epoch 2: val_accuracy improved from 0.61804 to 0.75991, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3ms/step - accuracy: 0.7177 - loss: 0.7934 - val_accuracy: 0.7599 - val_loss: 0.6334\n",
      "Epoch 3/30\n",
      "\u001b[1m50670/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7515 - loss: 0.7006\n",
      "Epoch 3: val_accuracy improved from 0.75991 to 0.76599, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.7515 - loss: 0.7006 - val_accuracy: 0.7660 - val_loss: 0.6305\n",
      "Epoch 4/30\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.6473\n",
      "Epoch 4: val_accuracy improved from 0.76599 to 0.82801, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.6473 - val_accuracy: 0.8280 - val_loss: 0.4804\n",
      "Epoch 5/30\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.6156\n",
      "Epoch 5: val_accuracy improved from 0.82801 to 0.85221, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.6156 - val_accuracy: 0.8522 - val_loss: 0.4106\n",
      "Epoch 6/30\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.5931\n",
      "Epoch 6: val_accuracy did not improve from 0.85221\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.7904 - loss: 0.5931 - val_accuracy: 0.8495 - val_loss: 0.4139\n",
      "Epoch 7/30\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.5715\n",
      "Epoch 7: val_accuracy did not improve from 0.85221\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.5715 - val_accuracy: 0.8343 - val_loss: 0.4614\n",
      "Epoch 8/30\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.5562\n",
      "Epoch 8: val_accuracy improved from 0.85221 to 0.86516, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3ms/step - accuracy: 0.8030 - loss: 0.5562 - val_accuracy: 0.8652 - val_loss: 0.3749\n",
      "Epoch 9/30\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.5446\n",
      "Epoch 9: val_accuracy improved from 0.86516 to 0.86551, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.5446 - val_accuracy: 0.8655 - val_loss: 0.3770\n",
      "Epoch 10/30\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5344\n",
      "Epoch 10: val_accuracy did not improve from 0.86551\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.5344 - val_accuracy: 0.8625 - val_loss: 0.3822\n",
      "Epoch 11/30\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.5248\n",
      "Epoch 11: val_accuracy did not improve from 0.86551\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.5248 - val_accuracy: 0.8642 - val_loss: 0.3781\n",
      "Epoch 12/30\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.5182\n",
      "Epoch 12: val_accuracy did not improve from 0.86551\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8167 - loss: 0.5182 - val_accuracy: 0.8644 - val_loss: 0.3801\n",
      "Epoch 13/30\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.5109\n",
      "Epoch 13: val_accuracy improved from 0.86551 to 0.87468, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8196 - loss: 0.5109 - val_accuracy: 0.8747 - val_loss: 0.3503\n",
      "Epoch 14/30\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.5025\n",
      "Epoch 14: val_accuracy improved from 0.87468 to 0.89463, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.5025 - val_accuracy: 0.8946 - val_loss: 0.2945\n",
      "Epoch 15/30\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4989\n",
      "Epoch 15: val_accuracy did not improve from 0.89463\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.4989 - val_accuracy: 0.8833 - val_loss: 0.3277\n",
      "Epoch 16/30\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.4929\n",
      "Epoch 16: val_accuracy did not improve from 0.89463\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.4929 - val_accuracy: 0.8873 - val_loss: 0.3183\n",
      "Epoch 17/30\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.4892\n",
      "Epoch 17: val_accuracy did not improve from 0.89463\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.4892 - val_accuracy: 0.8778 - val_loss: 0.3385\n",
      "Epoch 18/30\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.4852\n",
      "Epoch 18: val_accuracy did not improve from 0.89463\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4852 - val_accuracy: 0.8834 - val_loss: 0.3252\n",
      "Epoch 19/30\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4782\n",
      "Epoch 19: val_accuracy did not improve from 0.89463\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2ms/step - accuracy: 0.8311 - loss: 0.4782 - val_accuracy: 0.8856 - val_loss: 0.3223\n"
     ]
    }
   ],
   "source": [
    "# 1. 기본 라이브러리\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "# 2. 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 3. 검증 데이터 구성\n",
    "val_sample_size = 112157\n",
    "X_val_list, y_val_list = [], []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "    \n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "print(\"✅ 검증 데이터 준비 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n",
    "\n",
    "# 4. 학습용 제너레이터 정의 및 생성\n",
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=16)\n",
    "print(\"✅ 유효한 학습용 샘플 수:\", len(train_generator) * 16)\n",
    "\n",
    "# 5. 모델 정의\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 생성 및 콜백 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 가비지 컬렉션\n",
    "gc.collect()\n",
    "\n",
    "# 8. 학습 시작\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장된 모델 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "model = load_model(model_path)\n",
    "print(\"✅ 모델 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:22:19.439648: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-03-28 18:22:20.130757: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3505/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 정확도: 0.8946\n",
      "\n",
      "📊 분류 리포트:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     35952\n",
      "           1       0.86      0.88      0.87     11985\n",
      "           2       0.96      0.87      0.91     11974\n",
      "           3       0.94      0.83      0.88     11664\n",
      "           4       0.87      0.90      0.88     11943\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.92      0.89      0.91     27464\n",
      "           7       0.28      1.00      0.44      1175\n",
      "\n",
      "    accuracy                           0.89    112157\n",
      "   macro avg       0.72      0.79      0.73    112157\n",
      "weighted avg       0.91      0.89      0.90    112157\n",
      "\n",
      "🌀 혼동 행렬:\n",
      "[[33172   519   230    94   444    59   547   887]\n",
      " [  826 10521     4     6    24     4   356   244]\n",
      " [   87    37 10466    86   389   128   217   564]\n",
      " [   68    30    93  9707   609    40   543   574]\n",
      " [  141    92    73   302 10747    30   388   170]\n",
      " [    0     0     0     0     0     0     0     0]\n",
      " [  945  1069    73   103   201     9 24554   510]\n",
      " [    2     0     0     0     0     0     1  1172]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/usou/venv/test_super/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/usou/venv/test_super/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred_classes)\n",
    "print(f\"✅ 검증 정확도: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"📊 분류 리포트:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "\n",
    "print(\"🌀 혼동 행렬:\")\n",
    "print(confusion_matrix(y_val, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 로그 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 학습 로그 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 학습 직후 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/models/history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 로그 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 로그 불러 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 학습 로그 불러오기 완료\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/models/history.pkl\", \"rb\") as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "print(\"✅ 학습 로그 불러오기 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict[\"accuracy\"]\n",
    "val_acc = history_dict[\"val_accuracy\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoch 300 으로 accuracy 더 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:54:16.775607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743155656.793093   11297 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743155656.798809   11297 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743155656.812180   11297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743155656.812194   11297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743155656.812195   11297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743155656.812196   11297 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 18:54:16.815903: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 준비 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n",
      "유효한 학습용 샘플 수: 810992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-28 18:54:35.960404: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1743155675.960509   11297 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743155678.641846   11365 service.cc:152] XLA service 0x78633c013290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743155678.641867   11365 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-03-28 18:54:38.691288: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743155678.983289   11365 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-03-28 18:54:39.335420: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[16,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,157,13]{3,2,1,0} %bitcast.5956, f32[32,1,3,3]{3,2,1,0} %bitcast.5963, f32[32]{0} %bitcast.6887), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:54:39.376410: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[16,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,78,6]{3,2,1,0} %bitcast.7052, f32[64,32,3,3]{3,2,1,0} %bitcast.6038, f32[64]{0} %bitcast.7112), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:54:39.466701: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[16,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,39,3]{3,2,1,0} %bitcast.7278, f32[128,64,3,3]{3,2,1,0} %bitcast.6113, f32[128]{0} %bitcast.7348), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   45/50687\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:57\u001b[0m 4ms/step - accuracy: 0.2402 - loss: 2.0074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743155681.518078   11365 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42842/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.5324 - loss: 1.3064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:56:54.441807: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[6,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[6,32,78,6]{3,2,1,0} %bitcast.7026, f32[64,32,3,3]{3,2,1,0} %bitcast.6034, f32[64]{0} %bitcast.7086), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:56:54.495516: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[6,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[6,64,39,3]{3,2,1,0} %bitcast.7250, f32[128,64,3,3]{3,2,1,0} %bitcast.6105, f32[128]{0} %bitcast.7320), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50681/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5459 - loss: 1.2688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:57:20.828417: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-03-28 18:57:21.380281: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-03-28 18:57:22.099486: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,157,13]{3,2,1,0} %bitcast.662, f32[32,1,3,3]{3,2,1,0} %bitcast.669, f32[32]{0} %bitcast.671), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:57:22.149245: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,78,6]{3,2,1,0} %bitcast.699, f32[64,32,3,3]{3,2,1,0} %bitcast.706, f32[64]{0} %bitcast.708), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:57:22.219100: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,39,3]{3,2,1,0} %bitcast.736, f32[128,64,3,3]{3,2,1,0} %bitcast.743, f32[128]{0} %bitcast.745), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:57:28.041894: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[29,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,1,157,13]{3,2,1,0} %bitcast.662, f32[32,1,3,3]{3,2,1,0} %bitcast.669, f32[32]{0} %bitcast.671), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:57:28.084600: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[29,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,32,78,6]{3,2,1,0} %bitcast.699, f32[64,32,3,3]{3,2,1,0} %bitcast.706, f32[64]{0} %bitcast.708), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-28 18:57:28.173999: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[29,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,39,3]{3,2,1,0} %bitcast.736, f32[128,64,3,3]{3,2,1,0} %bitcast.743, f32[128]{0} %bitcast.745), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73920, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3ms/step - accuracy: 0.5459 - loss: 1.2688 - val_accuracy: 0.7392 - val_loss: 0.7049\n",
      "Epoch 2/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.7889\n",
      "Epoch 2: val_accuracy improved from 0.73920 to 0.76100, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3ms/step - accuracy: 0.7200 - loss: 0.7889 - val_accuracy: 0.7610 - val_loss: 0.6599\n",
      "Epoch 3/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.6951\n",
      "Epoch 3: val_accuracy improved from 0.76100 to 0.79591, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.6951 - val_accuracy: 0.7959 - val_loss: 0.5647\n",
      "Epoch 4/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7702 - loss: 0.6490\n",
      "Epoch 4: val_accuracy improved from 0.79591 to 0.83314, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3ms/step - accuracy: 0.7702 - loss: 0.6490 - val_accuracy: 0.8331 - val_loss: 0.4647\n",
      "Epoch 5/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.6143\n",
      "Epoch 5: val_accuracy did not improve from 0.83314\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.6143 - val_accuracy: 0.7883 - val_loss: 0.5739\n",
      "Epoch 6/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.5904\n",
      "Epoch 6: val_accuracy improved from 0.83314 to 0.83458, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.5904 - val_accuracy: 0.8346 - val_loss: 0.4563\n",
      "Epoch 7/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 0.5735\n",
      "Epoch 7: val_accuracy improved from 0.83458 to 0.83699, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3ms/step - accuracy: 0.7978 - loss: 0.5735 - val_accuracy: 0.8370 - val_loss: 0.4477\n",
      "Epoch 8/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.5592\n",
      "Epoch 8: val_accuracy did not improve from 0.83699\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3ms/step - accuracy: 0.8021 - loss: 0.5592 - val_accuracy: 0.8359 - val_loss: 0.4452\n",
      "Epoch 9/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.5455\n",
      "Epoch 9: val_accuracy improved from 0.83699 to 0.85486, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.5455 - val_accuracy: 0.8549 - val_loss: 0.4024\n",
      "Epoch 10/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5345\n",
      "Epoch 10: val_accuracy did not improve from 0.85486\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5345 - val_accuracy: 0.8383 - val_loss: 0.4449\n",
      "Epoch 11/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.5229\n",
      "Epoch 11: val_accuracy improved from 0.85486 to 0.86806, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.5229 - val_accuracy: 0.8681 - val_loss: 0.3678\n",
      "Epoch 12/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.5182\n",
      "Epoch 12: val_accuracy improved from 0.86806 to 0.88458, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.5182 - val_accuracy: 0.8846 - val_loss: 0.3262\n",
      "Epoch 13/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.5113\n",
      "Epoch 13: val_accuracy did not improve from 0.88458\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.5113 - val_accuracy: 0.8694 - val_loss: 0.3685\n",
      "Epoch 14/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.5034\n",
      "Epoch 14: val_accuracy did not improve from 0.88458\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8221 - loss: 0.5034 - val_accuracy: 0.8491 - val_loss: 0.4127\n",
      "Epoch 15/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.4962\n",
      "Epoch 15: val_accuracy did not improve from 0.88458\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8254 - loss: 0.4962 - val_accuracy: 0.8758 - val_loss: 0.3446\n",
      "Epoch 16/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.4937\n",
      "Epoch 16: val_accuracy improved from 0.88458 to 0.89182, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.4937 - val_accuracy: 0.8918 - val_loss: 0.3078\n",
      "Epoch 17/300\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4890\n",
      "Epoch 17: val_accuracy did not improve from 0.89182\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4890 - val_accuracy: 0.8887 - val_loss: 0.3169\n",
      "Epoch 18/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4827\n",
      "Epoch 18: val_accuracy did not improve from 0.89182\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4827 - val_accuracy: 0.8739 - val_loss: 0.3563\n",
      "Epoch 19/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4803\n",
      "Epoch 19: val_accuracy did not improve from 0.89182\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.4803 - val_accuracy: 0.8817 - val_loss: 0.3288\n",
      "Epoch 20/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4755\n",
      "Epoch 20: val_accuracy did not improve from 0.89182\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8319 - loss: 0.4755 - val_accuracy: 0.8910 - val_loss: 0.3112\n",
      "Epoch 21/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4732\n",
      "Epoch 21: val_accuracy did not improve from 0.89182\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.4732 - val_accuracy: 0.8831 - val_loss: 0.3276\n",
      "Epoch 22/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.4690\n",
      "Epoch 22: val_accuracy did not improve from 0.89182\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.4690 - val_accuracy: 0.8837 - val_loss: 0.3255\n",
      "Epoch 23/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.4676\n",
      "Epoch 23: val_accuracy improved from 0.89182 to 0.89559, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8351 - loss: 0.4676 - val_accuracy: 0.8956 - val_loss: 0.2927\n",
      "Epoch 24/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.4637\n",
      "Epoch 24: val_accuracy did not improve from 0.89559\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8370 - loss: 0.4637 - val_accuracy: 0.8792 - val_loss: 0.3382\n",
      "Epoch 25/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.4606\n",
      "Epoch 25: val_accuracy did not improve from 0.89559\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8378 - loss: 0.4606 - val_accuracy: 0.8947 - val_loss: 0.2959\n",
      "Epoch 26/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8390 - loss: 0.4567\n",
      "Epoch 26: val_accuracy did not improve from 0.89559\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.4567 - val_accuracy: 0.8838 - val_loss: 0.3238\n",
      "Epoch 27/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4554\n",
      "Epoch 27: val_accuracy improved from 0.89559 to 0.89774, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4554 - val_accuracy: 0.8977 - val_loss: 0.2871\n",
      "Epoch 28/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.4530\n",
      "Epoch 28: val_accuracy did not improve from 0.89774\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8406 - loss: 0.4531 - val_accuracy: 0.8882 - val_loss: 0.3185\n",
      "Epoch 29/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.4518\n",
      "Epoch 29: val_accuracy improved from 0.89774 to 0.90023, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.4518 - val_accuracy: 0.9002 - val_loss: 0.2826\n",
      "Epoch 30/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.4496\n",
      "Epoch 30: val_accuracy did not improve from 0.90023\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.4496 - val_accuracy: 0.8902 - val_loss: 0.3096\n",
      "Epoch 31/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8433 - loss: 0.4449\n",
      "Epoch 31: val_accuracy did not improve from 0.90023\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.4449 - val_accuracy: 0.8808 - val_loss: 0.3314\n",
      "Epoch 32/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.4447\n",
      "Epoch 32: val_accuracy improved from 0.90023 to 0.90044, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.4447 - val_accuracy: 0.9004 - val_loss: 0.2819\n",
      "Epoch 33/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.4404\n",
      "Epoch 33: val_accuracy improved from 0.90044 to 0.90689, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.4404 - val_accuracy: 0.9069 - val_loss: 0.2638\n",
      "Epoch 34/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8442 - loss: 0.4406\n",
      "Epoch 34: val_accuracy did not improve from 0.90689\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8442 - loss: 0.4406 - val_accuracy: 0.8980 - val_loss: 0.2845\n",
      "Epoch 35/300\n",
      "\u001b[1m50670/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.4384\n",
      "Epoch 35: val_accuracy did not improve from 0.90689\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.4384 - val_accuracy: 0.9003 - val_loss: 0.2773\n",
      "Epoch 36/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.4344\n",
      "Epoch 36: val_accuracy did not improve from 0.90689\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.4344 - val_accuracy: 0.9014 - val_loss: 0.2747\n",
      "Epoch 37/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4337\n",
      "Epoch 37: val_accuracy did not improve from 0.90689\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4337 - val_accuracy: 0.9017 - val_loss: 0.2760\n",
      "Epoch 38/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.4340\n",
      "Epoch 38: val_accuracy improved from 0.90689 to 0.90906, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.4340 - val_accuracy: 0.9091 - val_loss: 0.2561\n",
      "Epoch 39/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.4324\n",
      "Epoch 39: val_accuracy did not improve from 0.90906\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.4324 - val_accuracy: 0.8990 - val_loss: 0.2849\n",
      "Epoch 40/300\n",
      "\u001b[1m50670/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.4299\n",
      "Epoch 40: val_accuracy did not improve from 0.90906\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.4299 - val_accuracy: 0.9054 - val_loss: 0.2668\n",
      "Epoch 41/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.4309\n",
      "Epoch 41: val_accuracy improved from 0.90906 to 0.91300, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8484 - loss: 0.4309 - val_accuracy: 0.9130 - val_loss: 0.2459\n",
      "Epoch 42/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8490 - loss: 0.4303\n",
      "Epoch 42: val_accuracy did not improve from 0.91300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8490 - loss: 0.4303 - val_accuracy: 0.8968 - val_loss: 0.2891\n",
      "Epoch 43/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.4265\n",
      "Epoch 43: val_accuracy did not improve from 0.91300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.4265 - val_accuracy: 0.9112 - val_loss: 0.2540\n",
      "Epoch 44/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.4259\n",
      "Epoch 44: val_accuracy did not improve from 0.91300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.4259 - val_accuracy: 0.9036 - val_loss: 0.2725\n",
      "Epoch 45/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.4248\n",
      "Epoch 45: val_accuracy improved from 0.91300 to 0.91468, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.4248 - val_accuracy: 0.9147 - val_loss: 0.2441\n",
      "Epoch 46/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.4237\n",
      "Epoch 46: val_accuracy did not improve from 0.91468\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.4237 - val_accuracy: 0.9070 - val_loss: 0.2596\n",
      "Epoch 47/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.4212\n",
      "Epoch 47: val_accuracy did not improve from 0.91468\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.4212 - val_accuracy: 0.9067 - val_loss: 0.2623\n",
      "Epoch 48/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.4208\n",
      "Epoch 48: val_accuracy did not improve from 0.91468\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.4208 - val_accuracy: 0.9103 - val_loss: 0.2514\n",
      "Epoch 49/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.4210\n",
      "Epoch 49: val_accuracy improved from 0.91468 to 0.91474, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.4210 - val_accuracy: 0.9147 - val_loss: 0.2484\n",
      "Epoch 50/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4195\n",
      "Epoch 50: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4195 - val_accuracy: 0.8877 - val_loss: 0.3149\n",
      "Epoch 51/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4202\n",
      "Epoch 51: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4202 - val_accuracy: 0.9029 - val_loss: 0.2697\n",
      "Epoch 52/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.4160\n",
      "Epoch 52: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.4160 - val_accuracy: 0.9108 - val_loss: 0.2498\n",
      "Epoch 53/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.4162\n",
      "Epoch 53: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.4162 - val_accuracy: 0.9100 - val_loss: 0.2521\n",
      "Epoch 54/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.4162\n",
      "Epoch 54: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.4162 - val_accuracy: 0.9140 - val_loss: 0.2433\n",
      "Epoch 55/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.4160\n",
      "Epoch 55: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.4160 - val_accuracy: 0.9094 - val_loss: 0.2516\n",
      "Epoch 56/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.4112\n",
      "Epoch 56: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.4112 - val_accuracy: 0.9034 - val_loss: 0.2713\n",
      "Epoch 57/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.4141\n",
      "Epoch 57: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.4141 - val_accuracy: 0.9057 - val_loss: 0.2677\n",
      "Epoch 58/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.4120\n",
      "Epoch 58: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.4120 - val_accuracy: 0.9127 - val_loss: 0.2445\n",
      "Epoch 59/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.4105\n",
      "Epoch 59: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.4105 - val_accuracy: 0.9056 - val_loss: 0.2670\n",
      "Epoch 60/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.4113\n",
      "Epoch 60: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.4113 - val_accuracy: 0.9065 - val_loss: 0.2620\n",
      "Epoch 61/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.4067\n",
      "Epoch 61: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.4067 - val_accuracy: 0.9129 - val_loss: 0.2467\n",
      "Epoch 62/300\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.4081\n",
      "Epoch 62: val_accuracy did not improve from 0.91474\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.4081 - val_accuracy: 0.9064 - val_loss: 0.2585\n",
      "Epoch 63/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.4094\n",
      "Epoch 63: val_accuracy improved from 0.91474 to 0.91675, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.4094 - val_accuracy: 0.9168 - val_loss: 0.2366\n",
      "Epoch 64/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.4060\n",
      "Epoch 64: val_accuracy did not improve from 0.91675\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.4060 - val_accuracy: 0.9080 - val_loss: 0.2606\n",
      "Epoch 65/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 0.4064\n",
      "Epoch 65: val_accuracy did not improve from 0.91675\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 0.4064 - val_accuracy: 0.9064 - val_loss: 0.2663\n",
      "Epoch 66/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.4048\n",
      "Epoch 66: val_accuracy improved from 0.91675 to 0.91869, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8576 - loss: 0.4048 - val_accuracy: 0.9187 - val_loss: 0.2315\n",
      "Epoch 67/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.4057\n",
      "Epoch 67: val_accuracy did not improve from 0.91869\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.4057 - val_accuracy: 0.9023 - val_loss: 0.2709\n",
      "Epoch 68/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.4040\n",
      "Epoch 68: val_accuracy did not improve from 0.91869\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.4040 - val_accuracy: 0.9061 - val_loss: 0.2615\n",
      "Epoch 69/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.4032\n",
      "Epoch 69: val_accuracy did not improve from 0.91869\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.4032 - val_accuracy: 0.9029 - val_loss: 0.2662\n",
      "Epoch 70/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.4035\n",
      "Epoch 70: val_accuracy did not improve from 0.91869\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.4035 - val_accuracy: 0.9115 - val_loss: 0.2448\n",
      "Epoch 71/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.4012\n",
      "Epoch 71: val_accuracy did not improve from 0.91869\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.4012 - val_accuracy: 0.9135 - val_loss: 0.2395\n",
      "Epoch 72/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.4002\n",
      "Epoch 72: val_accuracy improved from 0.91869 to 0.92358, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.4002 - val_accuracy: 0.9236 - val_loss: 0.2172\n",
      "Epoch 73/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.4017\n",
      "Epoch 73: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.4017 - val_accuracy: 0.9091 - val_loss: 0.2503\n",
      "Epoch 74/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.4010\n",
      "Epoch 74: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.4010 - val_accuracy: 0.9159 - val_loss: 0.2389\n",
      "Epoch 75/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.4002\n",
      "Epoch 75: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.4002 - val_accuracy: 0.9196 - val_loss: 0.2303\n",
      "Epoch 76/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3984\n",
      "Epoch 76: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3984 - val_accuracy: 0.9163 - val_loss: 0.2370\n",
      "Epoch 77/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3983\n",
      "Epoch 77: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3983 - val_accuracy: 0.9170 - val_loss: 0.2363\n",
      "Epoch 78/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3976\n",
      "Epoch 78: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3976 - val_accuracy: 0.9099 - val_loss: 0.2507\n",
      "Epoch 79/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3980\n",
      "Epoch 79: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3980 - val_accuracy: 0.9082 - val_loss: 0.2561\n",
      "Epoch 80/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3984\n",
      "Epoch 80: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8593 - loss: 0.3984 - val_accuracy: 0.9122 - val_loss: 0.2482\n",
      "Epoch 81/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3972\n",
      "Epoch 81: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3972 - val_accuracy: 0.9221 - val_loss: 0.2216\n",
      "Epoch 82/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3950\n",
      "Epoch 82: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3950 - val_accuracy: 0.9093 - val_loss: 0.2573\n",
      "Epoch 83/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3943\n",
      "Epoch 83: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8610 - loss: 0.3943 - val_accuracy: 0.9079 - val_loss: 0.2562\n",
      "Epoch 84/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.3936\n",
      "Epoch 84: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8621 - loss: 0.3936 - val_accuracy: 0.9197 - val_loss: 0.2266\n",
      "Epoch 85/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3945\n",
      "Epoch 85: val_accuracy did not improve from 0.92358\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8615 - loss: 0.3945 - val_accuracy: 0.9184 - val_loss: 0.2276\n",
      "Epoch 86/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.3948\n",
      "Epoch 86: val_accuracy improved from 0.92358 to 0.92469, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3948 - val_accuracy: 0.9247 - val_loss: 0.2130\n",
      "Epoch 87/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3950\n",
      "Epoch 87: val_accuracy did not improve from 0.92469\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3950 - val_accuracy: 0.9220 - val_loss: 0.2231\n",
      "Epoch 88/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3946\n",
      "Epoch 88: val_accuracy did not improve from 0.92469\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.3946 - val_accuracy: 0.9144 - val_loss: 0.2426\n",
      "Epoch 89/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3929\n",
      "Epoch 89: val_accuracy did not improve from 0.92469\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3929 - val_accuracy: 0.9098 - val_loss: 0.2524\n",
      "Epoch 90/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3891\n",
      "Epoch 90: val_accuracy improved from 0.92469 to 0.92656, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3891 - val_accuracy: 0.9266 - val_loss: 0.2087\n",
      "Epoch 91/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3922\n",
      "Epoch 91: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8616 - loss: 0.3922 - val_accuracy: 0.9164 - val_loss: 0.2351\n",
      "Epoch 92/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3903\n",
      "Epoch 92: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3903 - val_accuracy: 0.9218 - val_loss: 0.2210\n",
      "Epoch 93/300\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.3898\n",
      "Epoch 93: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8630 - loss: 0.3898 - val_accuracy: 0.9154 - val_loss: 0.2413\n",
      "Epoch 94/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3904\n",
      "Epoch 94: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3904 - val_accuracy: 0.9196 - val_loss: 0.2279\n",
      "Epoch 95/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3876\n",
      "Epoch 95: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3876 - val_accuracy: 0.9213 - val_loss: 0.2222\n",
      "Epoch 96/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3881\n",
      "Epoch 96: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3881 - val_accuracy: 0.9194 - val_loss: 0.2295\n",
      "Epoch 97/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3888\n",
      "Epoch 97: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3888 - val_accuracy: 0.9214 - val_loss: 0.2188\n",
      "Epoch 98/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3868\n",
      "Epoch 98: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3868 - val_accuracy: 0.9089 - val_loss: 0.2535\n",
      "Epoch 99/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3890\n",
      "Epoch 99: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3890 - val_accuracy: 0.9214 - val_loss: 0.2250\n",
      "Epoch 100/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.3889\n",
      "Epoch 100: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.3889 - val_accuracy: 0.9099 - val_loss: 0.2501\n",
      "Epoch 101/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8636 - loss: 0.3872\n",
      "Epoch 101: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8636 - loss: 0.3872 - val_accuracy: 0.9230 - val_loss: 0.2178\n",
      "Epoch 102/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3883\n",
      "Epoch 102: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.3883 - val_accuracy: 0.9142 - val_loss: 0.2424\n",
      "Epoch 103/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3867\n",
      "Epoch 103: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3867 - val_accuracy: 0.9123 - val_loss: 0.2467\n",
      "Epoch 104/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3880\n",
      "Epoch 104: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3880 - val_accuracy: 0.9136 - val_loss: 0.2418\n",
      "Epoch 105/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3849\n",
      "Epoch 105: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3849 - val_accuracy: 0.9195 - val_loss: 0.2267\n",
      "Epoch 106/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3844\n",
      "Epoch 106: val_accuracy did not improve from 0.92656\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3844 - val_accuracy: 0.9198 - val_loss: 0.2293\n",
      "Epoch 107/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3834\n",
      "Epoch 107: val_accuracy improved from 0.92656 to 0.92791, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3834 - val_accuracy: 0.9279 - val_loss: 0.2043\n",
      "Epoch 108/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3848\n",
      "Epoch 108: val_accuracy did not improve from 0.92791\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3848 - val_accuracy: 0.9177 - val_loss: 0.2304\n",
      "Epoch 109/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.3844\n",
      "Epoch 109: val_accuracy did not improve from 0.92791\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3844 - val_accuracy: 0.9188 - val_loss: 0.2258\n",
      "Epoch 110/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3821\n",
      "Epoch 110: val_accuracy improved from 0.92791 to 0.93033, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3821 - val_accuracy: 0.9303 - val_loss: 0.2001\n",
      "Epoch 111/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3853\n",
      "Epoch 111: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3853 - val_accuracy: 0.9193 - val_loss: 0.2261\n",
      "Epoch 112/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3816\n",
      "Epoch 112: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3816 - val_accuracy: 0.9157 - val_loss: 0.2354\n",
      "Epoch 113/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.3833\n",
      "Epoch 113: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.3833 - val_accuracy: 0.9158 - val_loss: 0.2356\n",
      "Epoch 114/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3804\n",
      "Epoch 114: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3804 - val_accuracy: 0.9131 - val_loss: 0.2432\n",
      "Epoch 115/300\n",
      "\u001b[1m50681/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3821\n",
      "Epoch 115: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3821 - val_accuracy: 0.9221 - val_loss: 0.2188\n",
      "Epoch 116/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3830\n",
      "Epoch 116: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3830 - val_accuracy: 0.9219 - val_loss: 0.2207\n",
      "Epoch 117/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3816\n",
      "Epoch 117: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3816 - val_accuracy: 0.9220 - val_loss: 0.2198\n",
      "Epoch 118/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3786\n",
      "Epoch 118: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.3786 - val_accuracy: 0.9248 - val_loss: 0.2152\n",
      "Epoch 119/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3833\n",
      "Epoch 119: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8655 - loss: 0.3833 - val_accuracy: 0.9281 - val_loss: 0.2045\n",
      "Epoch 120/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.3822\n",
      "Epoch 120: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3822 - val_accuracy: 0.9153 - val_loss: 0.2401\n",
      "Epoch 121/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3801\n",
      "Epoch 121: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.3801 - val_accuracy: 0.9239 - val_loss: 0.2128\n",
      "Epoch 122/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3800\n",
      "Epoch 122: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.3800 - val_accuracy: 0.9142 - val_loss: 0.2393\n",
      "Epoch 123/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3813\n",
      "Epoch 123: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.3813 - val_accuracy: 0.9233 - val_loss: 0.2169\n",
      "Epoch 124/300\n",
      "\u001b[1m50681/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3812\n",
      "Epoch 124: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3812 - val_accuracy: 0.9180 - val_loss: 0.2313\n",
      "Epoch 125/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8668 - loss: 0.3782\n",
      "Epoch 125: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3782 - val_accuracy: 0.9080 - val_loss: 0.2564\n",
      "Epoch 126/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.3773\n",
      "Epoch 126: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.3773 - val_accuracy: 0.9135 - val_loss: 0.2371\n",
      "Epoch 127/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3779\n",
      "Epoch 127: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3779 - val_accuracy: 0.9289 - val_loss: 0.2048\n",
      "Epoch 128/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8664 - loss: 0.3796\n",
      "Epoch 128: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8664 - loss: 0.3796 - val_accuracy: 0.9226 - val_loss: 0.2159\n",
      "Epoch 129/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3785\n",
      "Epoch 129: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8674 - loss: 0.3785 - val_accuracy: 0.9187 - val_loss: 0.2271\n",
      "Epoch 130/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3769\n",
      "Epoch 130: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.3769 - val_accuracy: 0.9261 - val_loss: 0.2096\n",
      "Epoch 131/300\n",
      "\u001b[1m50681/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3757\n",
      "Epoch 131: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.3757 - val_accuracy: 0.9196 - val_loss: 0.2241\n",
      "Epoch 132/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.3762\n",
      "Epoch 132: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8675 - loss: 0.3762 - val_accuracy: 0.9259 - val_loss: 0.2110\n",
      "Epoch 133/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3744\n",
      "Epoch 133: val_accuracy did not improve from 0.93033\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3744 - val_accuracy: 0.9150 - val_loss: 0.2333\n",
      "Epoch 134/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8678 - loss: 0.3755\n",
      "Epoch 134: val_accuracy improved from 0.93033 to 0.93279, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3755 - val_accuracy: 0.9328 - val_loss: 0.1928\n",
      "Epoch 135/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3767\n",
      "Epoch 135: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3767 - val_accuracy: 0.9213 - val_loss: 0.2210\n",
      "Epoch 136/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3734\n",
      "Epoch 136: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3734 - val_accuracy: 0.9274 - val_loss: 0.2058\n",
      "Epoch 137/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3750\n",
      "Epoch 137: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3750 - val_accuracy: 0.9286 - val_loss: 0.2024\n",
      "Epoch 138/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3743\n",
      "Epoch 138: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3743 - val_accuracy: 0.9262 - val_loss: 0.2112\n",
      "Epoch 139/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3753\n",
      "Epoch 139: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8681 - loss: 0.3753 - val_accuracy: 0.9168 - val_loss: 0.2306\n",
      "Epoch 140/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3744\n",
      "Epoch 140: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3744 - val_accuracy: 0.9208 - val_loss: 0.2241\n",
      "Epoch 141/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3736\n",
      "Epoch 141: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3736 - val_accuracy: 0.9191 - val_loss: 0.2279\n",
      "Epoch 142/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3745\n",
      "Epoch 142: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3745 - val_accuracy: 0.9214 - val_loss: 0.2216\n",
      "Epoch 143/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3739\n",
      "Epoch 143: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3739 - val_accuracy: 0.9267 - val_loss: 0.2080\n",
      "Epoch 144/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3737\n",
      "Epoch 144: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3737 - val_accuracy: 0.9064 - val_loss: 0.2599\n",
      "Epoch 145/300\n",
      "\u001b[1m50675/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3732\n",
      "Epoch 145: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.3732 - val_accuracy: 0.9240 - val_loss: 0.2150\n",
      "Epoch 146/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.3723\n",
      "Epoch 146: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3723 - val_accuracy: 0.9290 - val_loss: 0.2016\n",
      "Epoch 147/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3718\n",
      "Epoch 147: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.3718 - val_accuracy: 0.9097 - val_loss: 0.2502\n",
      "Epoch 148/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3713\n",
      "Epoch 148: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3713 - val_accuracy: 0.9269 - val_loss: 0.2085\n",
      "Epoch 149/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8686 - loss: 0.3737\n",
      "Epoch 149: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.3737 - val_accuracy: 0.9298 - val_loss: 0.1990\n",
      "Epoch 150/300\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 0.3712\n",
      "Epoch 150: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3713 - val_accuracy: 0.9173 - val_loss: 0.2291\n",
      "Epoch 151/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3731\n",
      "Epoch 151: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.3731 - val_accuracy: 0.9302 - val_loss: 0.1973\n",
      "Epoch 152/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8698 - loss: 0.3717\n",
      "Epoch 152: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3717 - val_accuracy: 0.9252 - val_loss: 0.2120\n",
      "Epoch 153/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3717\n",
      "Epoch 153: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8692 - loss: 0.3717 - val_accuracy: 0.9274 - val_loss: 0.2039\n",
      "Epoch 154/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.3715\n",
      "Epoch 154: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.3715 - val_accuracy: 0.9180 - val_loss: 0.2298\n",
      "Epoch 155/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.3699\n",
      "Epoch 155: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.3699 - val_accuracy: 0.9131 - val_loss: 0.2409\n",
      "Epoch 156/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3708\n",
      "Epoch 156: val_accuracy did not improve from 0.93279\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.3708 - val_accuracy: 0.9243 - val_loss: 0.2099\n",
      "Epoch 157/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.3717\n",
      "Epoch 157: val_accuracy improved from 0.93279 to 0.93366, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.3717 - val_accuracy: 0.9337 - val_loss: 0.1905\n",
      "Epoch 158/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3685\n",
      "Epoch 158: val_accuracy improved from 0.93366 to 0.93542, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3685 - val_accuracy: 0.9354 - val_loss: 0.1852\n",
      "Epoch 159/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3703\n",
      "Epoch 159: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3703 - val_accuracy: 0.9157 - val_loss: 0.2349\n",
      "Epoch 160/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3677\n",
      "Epoch 160: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3677 - val_accuracy: 0.9167 - val_loss: 0.2330\n",
      "Epoch 161/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.3670\n",
      "Epoch 161: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.3670 - val_accuracy: 0.9178 - val_loss: 0.2280\n",
      "Epoch 162/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.3692\n",
      "Epoch 162: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8696 - loss: 0.3692 - val_accuracy: 0.9343 - val_loss: 0.1890\n",
      "Epoch 163/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3703\n",
      "Epoch 163: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3703 - val_accuracy: 0.9266 - val_loss: 0.2056\n",
      "Epoch 164/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3682\n",
      "Epoch 164: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.3682 - val_accuracy: 0.9215 - val_loss: 0.2173\n",
      "Epoch 165/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8707 - loss: 0.3677\n",
      "Epoch 165: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8707 - loss: 0.3677 - val_accuracy: 0.9245 - val_loss: 0.2113\n",
      "Epoch 166/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.3669\n",
      "Epoch 166: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3669 - val_accuracy: 0.9203 - val_loss: 0.2246\n",
      "Epoch 167/300\n",
      "\u001b[1m50672/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.3677\n",
      "Epoch 167: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8710 - loss: 0.3677 - val_accuracy: 0.9211 - val_loss: 0.2195\n",
      "Epoch 168/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3698\n",
      "Epoch 168: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3698 - val_accuracy: 0.9205 - val_loss: 0.2243\n",
      "Epoch 169/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8701 - loss: 0.3694\n",
      "Epoch 169: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3694 - val_accuracy: 0.9269 - val_loss: 0.2031\n",
      "Epoch 170/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.3701\n",
      "Epoch 170: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3701 - val_accuracy: 0.9268 - val_loss: 0.2069\n",
      "Epoch 171/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8710 - loss: 0.3669\n",
      "Epoch 171: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8710 - loss: 0.3669 - val_accuracy: 0.9246 - val_loss: 0.2125\n",
      "Epoch 172/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3690\n",
      "Epoch 172: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3690 - val_accuracy: 0.9323 - val_loss: 0.1914\n",
      "Epoch 173/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3662\n",
      "Epoch 173: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3662 - val_accuracy: 0.9178 - val_loss: 0.2285\n",
      "Epoch 174/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3675\n",
      "Epoch 174: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3675 - val_accuracy: 0.9098 - val_loss: 0.2513\n",
      "Epoch 175/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3676\n",
      "Epoch 175: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8704 - loss: 0.3676 - val_accuracy: 0.9239 - val_loss: 0.2131\n",
      "Epoch 176/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8698 - loss: 0.3695\n",
      "Epoch 176: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8698 - loss: 0.3695 - val_accuracy: 0.9333 - val_loss: 0.1902\n",
      "Epoch 177/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3660\n",
      "Epoch 177: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3660 - val_accuracy: 0.9295 - val_loss: 0.1982\n",
      "Epoch 178/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3660\n",
      "Epoch 178: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3660 - val_accuracy: 0.9261 - val_loss: 0.2096\n",
      "Epoch 179/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3652\n",
      "Epoch 179: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3652 - val_accuracy: 0.9188 - val_loss: 0.2295\n",
      "Epoch 180/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3656\n",
      "Epoch 180: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3656 - val_accuracy: 0.9316 - val_loss: 0.1951\n",
      "Epoch 181/300\n",
      "\u001b[1m50681/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3659\n",
      "Epoch 181: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3659 - val_accuracy: 0.9182 - val_loss: 0.2217\n",
      "Epoch 182/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3676\n",
      "Epoch 182: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3676 - val_accuracy: 0.9262 - val_loss: 0.2077\n",
      "Epoch 183/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3657\n",
      "Epoch 183: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3657 - val_accuracy: 0.9307 - val_loss: 0.1989\n",
      "Epoch 184/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.3651\n",
      "Epoch 184: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3651 - val_accuracy: 0.9209 - val_loss: 0.2248\n",
      "Epoch 185/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3648\n",
      "Epoch 185: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3648 - val_accuracy: 0.9325 - val_loss: 0.1920\n",
      "Epoch 186/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.3663\n",
      "Epoch 186: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3663 - val_accuracy: 0.9248 - val_loss: 0.2103\n",
      "Epoch 187/300\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.3635\n",
      "Epoch 187: val_accuracy did not improve from 0.93542\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.3635 - val_accuracy: 0.9271 - val_loss: 0.2080\n",
      "Epoch 188/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3647\n",
      "Epoch 188: val_accuracy improved from 0.93542 to 0.94152, saving model to /media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3647 - val_accuracy: 0.9415 - val_loss: 0.1709\n",
      "Epoch 189/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.3644\n",
      "Epoch 189: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8718 - loss: 0.3644 - val_accuracy: 0.9182 - val_loss: 0.2298\n",
      "Epoch 190/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.3637\n",
      "Epoch 190: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.3637 - val_accuracy: 0.9234 - val_loss: 0.2151\n",
      "Epoch 191/300\n",
      "\u001b[1m50668/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.3637\n",
      "Epoch 191: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.3637 - val_accuracy: 0.9184 - val_loss: 0.2270\n",
      "Epoch 192/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8720 - loss: 0.3637\n",
      "Epoch 192: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2ms/step - accuracy: 0.8720 - loss: 0.3637 - val_accuracy: 0.9360 - val_loss: 0.1817\n",
      "Epoch 193/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3622\n",
      "Epoch 193: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3622 - val_accuracy: 0.9173 - val_loss: 0.2292\n",
      "Epoch 194/300\n",
      "\u001b[1m50682/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3628\n",
      "Epoch 194: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3628 - val_accuracy: 0.9357 - val_loss: 0.1835\n",
      "Epoch 195/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3628\n",
      "Epoch 195: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3628 - val_accuracy: 0.9226 - val_loss: 0.2173\n",
      "Epoch 196/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8723 - loss: 0.3640\n",
      "Epoch 196: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.3640 - val_accuracy: 0.9363 - val_loss: 0.1805\n",
      "Epoch 197/300\n",
      "\u001b[1m50683/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.3630\n",
      "Epoch 197: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3630 - val_accuracy: 0.9255 - val_loss: 0.2077\n",
      "Epoch 198/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3617\n",
      "Epoch 198: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3617 - val_accuracy: 0.9331 - val_loss: 0.1927\n",
      "Epoch 199/300\n",
      "\u001b[1m50680/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3617\n",
      "Epoch 199: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3617 - val_accuracy: 0.9355 - val_loss: 0.1846\n",
      "Epoch 200/300\n",
      "\u001b[1m50673/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.3617\n",
      "Epoch 200: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3617 - val_accuracy: 0.9329 - val_loss: 0.1898\n",
      "Epoch 201/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3624\n",
      "Epoch 201: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3624 - val_accuracy: 0.9222 - val_loss: 0.2200\n",
      "Epoch 202/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.3616\n",
      "Epoch 202: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8725 - loss: 0.3616 - val_accuracy: 0.9217 - val_loss: 0.2217\n",
      "Epoch 203/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3607\n",
      "Epoch 203: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3607 - val_accuracy: 0.9311 - val_loss: 0.1959\n",
      "Epoch 204/300\n",
      "\u001b[1m50679/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.3628\n",
      "Epoch 204: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3628 - val_accuracy: 0.9225 - val_loss: 0.2176\n",
      "Epoch 205/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3608\n",
      "Epoch 205: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3608 - val_accuracy: 0.9191 - val_loss: 0.2257\n",
      "Epoch 206/300\n",
      "\u001b[1m50666/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3612\n",
      "Epoch 206: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3612 - val_accuracy: 0.9274 - val_loss: 0.2053\n",
      "Epoch 207/300\n",
      "\u001b[1m50684/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8726 - loss: 0.3618\n",
      "Epoch 207: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3618 - val_accuracy: 0.9237 - val_loss: 0.2115\n",
      "Epoch 208/300\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8730 - loss: 0.3629\n",
      "Epoch 208: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3629 - val_accuracy: 0.9339 - val_loss: 0.1852\n",
      "Epoch 209/300\n",
      "\u001b[1m50667/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3617\n",
      "Epoch 209: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3617 - val_accuracy: 0.9302 - val_loss: 0.1959\n",
      "Epoch 210/300\n",
      "\u001b[1m50685/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.3623\n",
      "Epoch 210: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.3623 - val_accuracy: 0.9211 - val_loss: 0.2208\n",
      "Epoch 211/300\n",
      "\u001b[1m50674/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.3585\n",
      "Epoch 211: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8736 - loss: 0.3585 - val_accuracy: 0.9221 - val_loss: 0.2192\n",
      "Epoch 212/300\n",
      "\u001b[1m50686/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8744 - loss: 0.3578\n",
      "Epoch 212: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3578 - val_accuracy: 0.9334 - val_loss: 0.1870\n",
      "Epoch 213/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3599\n",
      "Epoch 213: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.3599 - val_accuracy: 0.9297 - val_loss: 0.1981\n",
      "Epoch 214/300\n",
      "\u001b[1m50669/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.3596\n",
      "Epoch 214: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.3596 - val_accuracy: 0.9324 - val_loss: 0.1921\n",
      "Epoch 215/300\n",
      "\u001b[1m50671/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8727 - loss: 0.3622\n",
      "Epoch 215: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3622 - val_accuracy: 0.9366 - val_loss: 0.1804\n",
      "Epoch 216/300\n",
      "\u001b[1m50676/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.3591\n",
      "Epoch 216: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.3591 - val_accuracy: 0.9241 - val_loss: 0.2115\n",
      "Epoch 217/300\n",
      "\u001b[1m50677/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.3610\n",
      "Epoch 217: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3610 - val_accuracy: 0.9327 - val_loss: 0.1884\n",
      "Epoch 218/300\n",
      "\u001b[1m50678/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.3581\n",
      "Epoch 218: val_accuracy did not improve from 0.94152\n",
      "\u001b[1m50687/50687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.3581 - val_accuracy: 0.9230 - val_loss: 0.2159\n"
     ]
    }
   ],
   "source": [
    "# 1. 기본 라이브러리 불러오기 및 GPU 설정\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# GPU 메모리 과도할당 방지 설정\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 2. MFCC 및 레이블 파일 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 3. 검증 데이터셋 구성 (112157개 샘플)\n",
    "val_sample_size = 112157\n",
    "X_val_list, y_val_list = [], []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "    \n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"검증 데이터 준비 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n",
    "\n",
    "# 4. 학습용 데이터 제너레이터 정의\n",
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch, y_batch = [], []\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = pad_sequences([mfcc], maxlen=self.max_len, padding='post', dtype='float32')[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=16)\n",
    "print(\"유효한 학습용 샘플 수:\", len(train_generator) * 16)\n",
    "\n",
    "# 5. CNN 모델 정의 함수\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 구성 및 콜백 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 불필요한 메모리 수거\n",
    "gc.collect()\n",
    "\n",
    "# 8. 모델 학습 (epoch 300으로 확장)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=300,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 학습 로그 저장 완료\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 로그 저장 경로\n",
    "log_path = \"/media/usou/PortableSSD/mldl_project/models/train_history_log.json\"\n",
    "\n",
    "# history 객체를 JSON으로 저장\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(history.history, f)\n",
    "print(\"✅ 학습 로그 저장 완료\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .keras 포맷 으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 18:16:18.843871: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743412578.894178    7225 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743412578.909071    7225 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743412579.033035    7225 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743412579.033076    7225 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743412579.033078    7225 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743412579.033079    7225 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-31 18:16:19.045887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1743412583.847521    7225 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model_generator_voice_emotion_analyze.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델에서 클래스 수 확인하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 모델은 8개의 감정을 분류합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 불러오기\n",
    "model = load_model(\"best_model_generator_voice_emotion_analyze.keras\")\n",
    "\n",
    "# 출력층의 유닛 수로 클래스 수 확인\n",
    "num_classes = model.output_shape[-1]\n",
    "print(f\"이 모델은 {num_classes}개의 감정을 분류합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7225/2016716980.py:4: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(\"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 클래스 목록: ['Angry', 'Anxious', 'Embarrassed', 'Happy', 'Hurt', 'Neutrality', 'Sad']\n",
      "감정 개수: 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 메타데이터 로딩\n",
    "df_train = pd.read_csv(\"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\")\n",
    "df_val = pd.read_csv(\"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\")\n",
    "\n",
    "# 감정 열 병합 후 NaN 제거 및 문자열로 변환\n",
    "all_emotions = pd.concat([df_train[\"emotion\"], df_val[\"emotion\"]]).dropna().astype(str)\n",
    "emotion_classes = sorted(all_emotions.unique())\n",
    "\n",
    "print(\"감정 클래스 목록:\", emotion_classes)\n",
    "print(\"감정 개수:\", len(emotion_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 전체 감정 목록: ['Angry', 'Anxious', 'Embarrassed', 'Happy', 'Hurt', 'Neutrality', 'Sad', 'nan']\n",
      "LabelEncoder 기준 감정 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad']\n"
     ]
    }
   ],
   "source": [
    "# 모든 감정 모아보기 (dropna 전 포함)\n",
    "all_emotions_raw = pd.concat([df_train[\"emotion\"], df_val[\"emotion\"]]).astype(str)\n",
    "all_labels = all_emotions_raw.unique()\n",
    "\n",
    "# LabelEncoder 기준 클래스\n",
    "le_classes = le.classes_\n",
    "\n",
    "print(\"데이터셋 전체 감정 목록:\", sorted(all_labels))\n",
    "print(\"LabelEncoder 기준 감정 목록:\", le_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  m4a, mp4, mp3 → wav 변환\n",
    "- pip install pydub\n",
    "- sudo apt install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /home/usou/venv/test_super/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (5.2.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (2.1.3)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (1.1.0)\n",
      "Requirement already satisfied: pillow<11.0,>=9.2.0 in /home/usou/venv/test_super/lib/python3.12/site-packages (from moviepy) (10.4.0)\n",
      "Requirement already satisfied: tqdm in /home/usou/venv/test_super/lib/python3.12/site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmoviepy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_wav\u001b[39m(input_path, output_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    오디오 또는 비디오 파일을 WAV로 변환합니다.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    지원 포맷: .wav, .m4a, .mp3, .mp4\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33;03m    :return: 변환된 WAV 파일 경로\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def convert_to_wav(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    오디오 또는 비디오 파일을 WAV로 변환합니다.\n",
    "    지원 포맷: .wav, .m4a, .mp3, .mp4\n",
    "\n",
    "    :param input_path: 입력 파일 경로\n",
    "    :param output_path: 변환된 WAV 파일 경로 (없으면 같은 이름으로 .wav 저장)\n",
    "    :return: 변환된 WAV 파일 경로\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일이 존재하지 않아요: {input_path}\")\n",
    "\n",
    "    ext = os.path.splitext(input_path)[1].lower()\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "\n",
    "    if ext == \".mp4\":\n",
    "        video = VideoFileClip(input_path)\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile(output_path, verbose=False, logger=None)\n",
    "    else:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        audio.export(output_path, format=\"wav\")\n",
    "\n",
    "    print(\"변환 완료:\", output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC 추출(모델 입력 준비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, sr=16000, n_mfcc=40):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc = np.expand_dims(mfcc, axis=-1)  # CNN 입력을 위해 채널 차원 추가\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라벨인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 이 줄을 추가하세요 (현재 작업 디렉토리에 복사 용)\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정 분석 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 모델 로드\n",
    "model_path = \"best_model_generator_voice_emotion_analyze.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# LabelEncoder 로드\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "def predict_emotion(mfcc_data):\n",
    "    # 입력 형태 맞추기 (1, time, freq, 1)\n",
    "    X = np.expand_dims(mfcc_data, axis=0)\n",
    "    pred = model.predict(X)\n",
    "    idx = np.argmax(pred)\n",
    "    label = le.inverse_transform([idx])[0]\n",
    "    confidence = float(np.max(pred))\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 파이프라인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 변환 완료: /media/usou/PortableSSD/mldl_project/data/test_voice_emotion/sad_1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 18:59:08.261301: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,20,61]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,20,61]{3,2,1,0} %bitcast.403, f32[64,32,3,3]{3,2,1,0} %bitcast.410, f32[64]{0} %bitcast.412), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-03-31 18:59:08.311245: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[1,128,10,30]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,10,30]{3,2,1,0} %bitcast.440, f32[128,64,3,3]{3,2,1,0} %bitcast.447, f32[128]{0} %bitcast.449), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
      "\n",
      "🧠 감정 분석 결과: Happy (99.91% 확신)\n"
     ]
    }
   ],
   "source": [
    "# 1. 파일 변환\n",
    "input_path = \"/media/usou/PortableSSD/mldl_project/data/test_voice_emotion/happy_1.mp4\"  # 확장자만 바꾸면 됨\n",
    "wav_path = convert_to_wav(input_path)\n",
    "\n",
    "# 2. MFCC 추출\n",
    "mfcc = extract_mfcc(wav_path)  # 이미 정의된 MFCC 함수 사용\n",
    "\n",
    "# 3. 감정 예측\n",
    "emotion, score = predict_emotion(mfcc)\n",
    "print(f\"\\n감정 분석 결과: {emotion} ({score:.2%} 확신)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmoviepy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_to_wav\u001b[39m(input_path, output_path=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    오디오/비디오 파일을 WAV로 변환하는 함수\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m \u001b[33;03m    :return: 변환된 wav 파일 경로\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def convert_to_wav(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    오디오/비디오 파일을 WAV로 변환하는 함수\n",
    "\n",
    "    :param input_path: 변환할 입력 파일 경로 (m4a, mp3, mp4, wav 등)\n",
    "    :param output_path: 변환된 wav 파일 경로 (생략 시 같은 이름으로 저장)\n",
    "    :return: 변환된 wav 파일 경로\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일이 존재하지 않아요: {input_path}\")\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "\n",
    "    ext = os.path.splitext(input_path)[1].lower()\n",
    "\n",
    "    if ext == \".mp4\":\n",
    "        video = VideoFileClip(input_path)\n",
    "        audio = video.audio\n",
    "        audio.write_audiofile(output_path)\n",
    "    else:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        audio.export(output_path, format=\"wav\")\n",
    "\n",
    "    print(\"변환 완료:\", output_path)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 파일 변환\n",
    "    input_path = \"/media/usou/PortableSSD/mldl_project/data/test_voice_emotion/sad_1.m4a\"  # m4a/mp4 가능\n",
    "    wav_path = convert_to_wav(input_path)\n",
    "\n",
    "    # 2. MFCC 추출\n",
    "    mfcc = extract_mfcc(wav_path)\n",
    "\n",
    "    # 3. 감정 예측\n",
    "    emotion, score = predict_emotion(mfcc)\n",
    "    print(f\"\\n감정 분석 결과: {emotion} ({score:.2%} 확신)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_super",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
