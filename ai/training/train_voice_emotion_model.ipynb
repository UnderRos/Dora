{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traindata 전처리\n",
    "\n",
    "# JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 라벨링 JSON 파일이 있는 최상위 폴더 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "\n",
    "# 실제 WAV 파일이 존재하는 원천 데이터의 최상위 경로\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 정상적으로 처리된 데이터 정보를 담을 리스트\n",
    "data = []\n",
    "\n",
    "# 오류 발생 시 해당 JSON 파일 또는 존재하지 않는 WAV 경로를 저장할 리스트\n",
    "broken_files = []\n",
    "\n",
    "# 라벨링 폴더 내부의 모든 JSON 파일을 재귀적으로 탐색\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # 현재 JSON 파일의 전체 경로 구성\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기 및 파싱\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # JSON 내부 정보 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로를 라벨 기준 상대경로로 변환\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 상대 경로에서 모든 TL을 TS로 변경\n",
    "                relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "\n",
    "                # WAV 경로를 원천 데이터 기준으로 재구성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일 존재 여부 확인\n",
    "                if os.path.exists(wav_path):\n",
    "                    # 정상 데이터 추가\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 존재하지 않는 경우 로그에 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 중 오류 발생 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# 정상적으로 수집된 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 CSV 파일로 저장\n",
    "os.makedirs(\"./data/usou\", exist_ok=True)\n",
    "df.to_csv(\"./data/usou/metadata_cleaned.csv\", index=False)\n",
    "\n",
    "# 오류가 발생한 경로들을 텍스트 파일로 저장\n",
    "with open(\"./data/usou/broken_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 최종 처리 결과 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출\n",
    "-  MFCC 추출이란\n",
    "    - 음성에서 특징을 뽑아낸 백터\n",
    "-  데이터 형태\n",
    "    - 2차원 배열(시간 프레임수, 13)\n",
    "- 배치\n",
    "    - 배치 : 전체 데이터를 나누어 처리하는 단위\n",
    "- 나누는 이유\n",
    "    - 메모리 부족으로 컴퓨터 프리징 발생\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1. 메타데이터 로드\n",
    "# ============================\n",
    "# 사전에 정제된 메타데이터 CSV 파일 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ============================\n",
    "# 2. 설정값 정의\n",
    "# ============================\n",
    "sample_rate = 16000            # 음성 파일 샘플링 레이트 (Hz)\n",
    "max_duration = 5.0             # WAV 파일 최대 로딩 시간 (초) → 너무 긴 파일 방지\n",
    "save_interval = 10000          # 몇 개마다 배치로 저장할지 설정\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []             # MFCC 벡터 리스트\n",
    "labels = []                    # 감정 레이블 리스트\n",
    "error_files = []               # 처리 중 실패한 파일 목록\n",
    "save_counter = 0               # 배치 저장 인덱스\n",
    "\n",
    "# 저장 디렉토리 설정\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3. MFCC 추출 루프\n",
    "# ============================\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]  # 메타데이터에 포함된 wav 파일 전체 경로\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 13차원 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, n_mfcc)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 에러 발생 시 파일 경로 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 수 이상 쌓이면 배치 저장 후 메모리 초기화\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터가 있다면 마지막 배치 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ============================\n",
    "# 4. 에러 파일 저장\n",
    "# ============================\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/broken_audio_files.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ============================\n",
    "# 5. 처리 결과 출력\n",
    "# ============================\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 컨볼루션 레이어: 필터 수 32, 커널 사이즈 3x3, 활성화 함수 ReLU\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    # 배치 정규화: 학습 안정성과 속도 개선\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 최대 풀링: 출력 크기 절반으로 줄임 (특징 추출과 과적합 방지)\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 두 번째 컨볼루션 레이어: 필터 수 64\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 세 번째 컨볼루션 레이어: 필터 수 128\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 전역 평균 풀링: 전체 피처 맵의 평균을 계산하여 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 완전 연결층(Dense Layer) 추가\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    # 과적합 방지를 위한 드롭아웃 (30%)\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # 출력층: softmax로 감정 클래스 확률 예측\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일: Adam 옵티마이저, sparse_categorical_crossentropy 손실 함수, 정확도 지표\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메타데이터 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "\n",
    "# 라벨링 JSON 파일이 저장된 루트 폴더\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "\n",
    "# 실제 음성 WAV 파일이 있는 루트 폴더\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "\n",
    "# ========================================\n",
    "# 2. 결과 저장 리스트 초기화\n",
    "# ========================================\n",
    "data = []             # 메타데이터 저장용 리스트\n",
    "broken_files = []     # 에러 발생한 파일 로그용 리스트\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 파일 순회 및 정보 추출\n",
    "# ========================================\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # 화자 정보에서 감정, 스타일, 세부 감정 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "\n",
    "                # WAV 파일 이름 추출\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로에서 라벨 루트를 기준으로 상대 경로 추출\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 실제 WAV 파일 경로 생성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일이 존재하면 메타데이터에 추가\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 없는 경우 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 실패 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}, 에러: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 결과 저장\n",
    "# ========================================\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 저장 경로 생성\n",
    "os.makedirs(\"/media/usou/PortableSSD/mldl_project/data/validation\", exist_ok=True)\n",
    "\n",
    "# 메타데이터 CSV 저장\n",
    "df.to_csv(\"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\", index=False)\n",
    "\n",
    "# 에러 파일 로그 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/validation/broken_val_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 요약 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 Validation 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드\n",
    "# ========================================\n",
    "\n",
    "# validation용 정제된 메타데이터 CSV 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. 설정값 정의\n",
    "# ========================================\n",
    "\n",
    "sample_rate = 16000             # 음성 샘플링 레이트 (16kHz)\n",
    "max_duration = 5.0              # WAV 최대 로딩 시간 (초)\n",
    "save_interval = 10000           # 배치 저장 기준 개수\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []              # 추출된 MFCC 벡터 리스트\n",
    "labels = []                     # 감정 레이블 리스트\n",
    "error_files = []                # 실패한 파일 목록\n",
    "save_counter = 0                # 배치 파일 번호\n",
    "\n",
    "# ========================================\n",
    "# 3. MFCC 추출 루프\n",
    "# ========================================\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 추출 (13차원)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, 13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 로딩 실패 시 에러 출력 및 로그 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 개수 이상이면 배치 저장\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 루프 종료 후 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ========================================\n",
    "# 4. 에러 파일 저장\n",
    "# ========================================\n",
    "\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/validation/broken_audio_files_val.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 5. 처리 결과 출력\n",
    "# ========================================\n",
    "\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 데이터용 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC DataGenerator 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_dir, prefix, batch_size=1, shuffle=True):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 배치 파일 목록 생성\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "        self.indices = list(range(len(self.mfcc_files)))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_mfccs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "            label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "            mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_data = np.load(label_path)\n",
    "\n",
    "            # 가장 긴 시퀀스 기준으로 padding\n",
    "            max_len = max([x.shape[0] for x in mfcc_data])\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data, maxlen=max_len, dtype='float32', padding='post')\n",
    "            padded = np.expand_dims(padded, -1)  # (batch, time, n_mfcc, 1)\n",
    "\n",
    "            batch_mfccs.append(padded)\n",
    "            batch_labels.append(label_data)\n",
    "\n",
    "        X = np.concatenate(batch_mfccs, axis=0)\n",
    "        y = np.concatenate(batch_labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 활성화 및 안정 설정 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. GPU 장치 목록 출력\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"사용 가능한 GPU:\", gpus)\n",
    "\n",
    "# 2. 메모리 자동 증가 설정 (안정성을 위해 권장)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✔ GPU 메모리 자동 증가 설정 완료\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"⚠ 메모리 설정 중 오류 발생:\", e)\n",
    "else:\n",
    "    print(\"❌ GPU를 찾을 수 없습니다. CPU로 진행됩니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_encoder.pkl을 로드해 동일하게 인코딩하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "encoded_label_dir = os.path.join(val_label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# 학습 데이터에서 저장한 LabelEncoder 로드\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 validation 레이블 수집\n",
    "# ============================\n",
    "label_files = sorted(glob.glob(os.path.join(val_label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "for i, label_file in enumerate(label_files):\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"✅ Validation 레이블 인코딩 및 저장 완료 (배치 수: {len(label_files)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())               # 학습 안정성 향상\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))     # 공간 크기 감소\n",
    "\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())           # 피처맵 전체 평균값\n",
    "\n",
    "    # [4] 완전 연결층 + 드롭아웃\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))                       # 과적합 방지\n",
    "\n",
    "    # [5] 출력층 - 클래스 수만큼 softmax 출력\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# 1. 데이터 제너레이터 생성\n",
    "# ============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 안정 위해 소량으로 시작\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. 클래스 수 설정\n",
    "# ============================\n",
    "import pickle\n",
    "\n",
    "# 학습 데이터의 레이블 인코더를 불러와 클래스 수 확인\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 3. 입력 형태 설정\n",
    "# ============================\n",
    "# 예시 입력 크기 지정 (임의 값, 실제 학습 데이터 확인 후 조정 가능)\n",
    "# 이 부분은 train_generator[0][0].shape 로 확인 가능\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# ============================\n",
    "# 4. 모델 생성 및 요약\n",
    "# ============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ============================\n",
    "# 5. 콜백 정의 (모델 저장 및 EarlyStopping)\n",
    "# ============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ============================\n",
    "# 6. 학습 실행\n",
    "# ============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 실패한 이유 \n",
    "- Conv2D 커널이 너무 커서 작은 입력에 비해 작동을 못함 - kernel size 축소 or padding =\"same\" 적용 -> 모델 재정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안정적인 CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    음성 감정 분류를 위한 CNN 모델 정의\n",
    "    \n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터의 형태 (시간축, MFCC 차원, 채널 수)\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Sequential: 컴파일된 모델 객체\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # ===============================\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    # Conv2D: 32개의 필터, 3x3 커널, relu 활성화 함수 사용\n",
    "    # padding='same'으로 출력 크기 감소 방지\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())  # 정규화로 학습 안정화\n",
    "    model.add(layers.MaxPooling2D((2, 2)))  # 출력 크기 절반으로 축소\n",
    "\n",
    "    # ===============================\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # ===============================\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # GlobalAveragePooling2D: 각 채널의 평균을 취해 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # ===============================\n",
    "    # [4] 완전 연결층 + 출력층\n",
    "    # ===============================\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))  # 과적합 방지\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # 감정 클래스 확률 출력\n",
    "\n",
    "    # ===============================\n",
    "    # [5] 모델 컴파일\n",
    "    # ===============================\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- 학습 도중 시스템이 멈추지 않도록 작은 배치 크기와 적절한 콜백 설정 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# 1. 데이터 제너레이터 생성\n",
    "# ============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 절약을 위한 작은 배치\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. 레이블 인코더 로드 및 클래스 수 설정\n",
    "# ============================\n",
    "# 학습 데이터용 레이블 인코더를 통해 클래스 수 파악\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 3. 입력 형태 설정\n",
    "# ============================\n",
    "# 첫 배치에서 입력 형태 파악\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# ============================\n",
    "# 4. 모델 생성\n",
    "# ============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ============================\n",
    "# 5. 콜백 설정\n",
    "# ============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ============================\n",
    "# 6. 학습 실행\n",
    "# ============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU 메모리 부족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 경량화 프루닝 라이브러리 및 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_pruned_cnn_model(input_shape, num_classes):\n",
    "    # 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=1000  # 조절 가능\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 밀집층\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "\n",
    "    # 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_pruned_cnn_model(input_shape, num_classes):\n",
    "    # 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=1000  # 조절 가능\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 밀집층\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "\n",
    "    # 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 프루닝 실패\n",
    "1. Sequential 모델 안에 잘못된 레이어 구조를 넣었거나\n",
    "\n",
    "2. 프루닝 대상에 이미 프루닝된 레이어를 다시 적용하려고 하거나\n",
    "\n",
    "3. 모델 구조에서 무한 루프가 생겼거나\n",
    "\n",
    "4. 너무 많은 프루닝 wrapper가 중첩된 경우\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서 부터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCDataGenerator 클래스\n",
    "- tf.keras.utils.Sequence를 상속받아, 저장된 MFCC 및 레이블 배치 데이터를 Keras 모델 학습에 적합하게 동적으로 불러오고 전처리해주는 제너레이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_dir, prefix, batch_size=1, shuffle=True):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 배치 리스트 구성\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "        self.indices = list(range(len(self.mfcc_files)))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 현재 배치 인덱스 범위 계산\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_mfccs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "            label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "            mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_data = np.load(label_path)\n",
    "\n",
    "            # 시퀀스 길이 맞추기 (Zero-padding)\n",
    "            max_len = max([x.shape[0] for x in mfcc_data])\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data, maxlen=max_len, dtype='float32', padding='post')\n",
    "            padded = np.expand_dims(padded, -1)  # CNN 입력 형식 맞추기\n",
    "\n",
    "            batch_mfccs.append(padded)\n",
    "            batch_labels.append(label_data)\n",
    "\n",
    "        X = np.concatenate(batch_mfccs, axis=0)\n",
    "        y = np.concatenate(batch_labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 감정 분류를 위한 CNN 모델을 정의한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    음성 감정 인식을 위한 CNN 모델 정의\n",
    "    - 입력: MFCC 시퀀스 (batch, time, n_mfcc, 1)\n",
    "    - 출력: 감정 클래스 확률 (softmax)\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())  # 피처맵 전체 평균값\n",
    "\n",
    "    # [4] 완전 연결층\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # 감정 클래스 개수만큼 출력\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===============================\n",
    "# [0] GPU 메모리 설정 (OOM 방지)\n",
    "# ===============================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ RuntimeError:\", e)\n",
    "\n",
    "# ===============================\n",
    "# [1] 데이터 제너레이터 생성\n",
    "# ===============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 안전 위해 최소 배치\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# [2] 레이블 인코더 로드 및 클래스 수\n",
    "# ===============================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ===============================\n",
    "# [3] 입력 형태 확인\n",
    "# ===============================\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "# ===============================\n",
    "# [4] 모델 생성\n",
    "# ===============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ===============================\n",
    "# [5] 콜백 설정 (모델 저장 + 조기 종료)\n",
    "# ===============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# [6] 모델 학습\n",
    "# ===============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 변경  PyTorch 기반 간단한 CNN 모델 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioEmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 데이터 로더 정의 (PyTorch용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, batch_dir, prefix):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "        label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "        # 여기서도 배치 데이터임\n",
    "        mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "        label_batch = np.load(label_path)\n",
    "\n",
    "        # 리스트로 묶어서 반환 (collate_fn에서 처리)\n",
    "        return list(zip(mfcc_batch, label_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate_fn 추가 (패딩과 텐서 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = sum(batch, [])  # [(mfcc1, label1), ..., (mfccN, labelN)]로 평탄화\n",
    "    seq_lens = [x[0].shape[0] for x in batch]\n",
    "    max_len = max(seq_lens)\n",
    "    n_mfcc = batch[0][0].shape[1]\n",
    "\n",
    "    padded_mfccs = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc, label in batch:\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:mfcc.shape[0], :] = mfcc\n",
    "        padded_mfccs.append(padded)\n",
    "        labels.append(label)\n",
    "\n",
    "    X = torch.tensor(padded_mfccs).unsqueeze(1)  # (batch, 1, time, n_mfcc)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MFCCDataset(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\", \"mfcc\")\n",
    "val_dataset = MFCCDataset(\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\", \"mfcc\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = AudioEmotionCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# ============================\n",
    "# 1. 학습 루프\n",
    "# ============================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 2. 검증 루프\n",
    "    # ============================\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"🔵 Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 3. 모델 저장\n",
    "    # ============================\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"💾 Best model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러 :  배치 안의 샘플들이 시퀀스 길이(time step)가 서로 달라서 torch.stack() 실패.\n",
    "PyTorch DataLoader는 collate_fn이 내부에서 torch.stack()을 사용하기 때문에, 입력 데이터들 크기가 다르면 에러가 납니다.\n",
    "TensorFlow에서는 padding으로 해결됐던 부분\n",
    "\n",
    "- 해결 방안 : 배치 크기를 맞추는 collate_fn 함수 구현\n",
    "    - collate_fn을 사용하여 배치 내 데이터 크기를 맞추는 방법을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# ============================\n",
    "# 1. 레이블 인코더 로드 및 클래스 수 확인\n",
    "# ============================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 2. 데이터셋 클래스 정의\n",
    "# ============================\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, batch_dir, prefix):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.mfcc_files = sorted([f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "        label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "        mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "        label_data = np.load(label_path)\n",
    "\n",
    "        # 리스트 형태일 경우 numpy 배열로 변환\n",
    "        if isinstance(mfcc_data, list):\n",
    "            mfcc_data = np.array(mfcc_data)\n",
    "\n",
    "        # 2D 배열인지 확인 (time, n_mfcc)\n",
    "        if mfcc_data.ndim != 2:\n",
    "            raise ValueError(f\"[{mfcc_path}] shape 오류: (time, n_mfcc) 형식이 아님 → 실제 shape: {mfcc_data.shape}\")\n",
    "\n",
    "        return mfcc_data, label_data\n",
    "\n",
    "\n",
    "# 패딩을 위한 collate_fn 정의\n",
    "def collate_fn(batch):\n",
    "    # 각 샘플은 (sequence_len, n_mfcc)\n",
    "    seq_lens = [sample[0].shape[0] for sample in batch]\n",
    "    max_len = max(seq_lens)\n",
    "\n",
    "    padded_batch = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc_data, label_data in batch:\n",
    "        # mfcc_data shape: (time, n_mfcc)\n",
    "        time_len = mfcc_data.shape[0]\n",
    "        n_mfcc = mfcc_data.shape[1]\n",
    "\n",
    "        # (time, n_mfcc) → (max_len, n_mfcc)\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:time_len, :] = mfcc_data\n",
    "\n",
    "        padded_batch.append(padded)\n",
    "        labels.append(label_data)\n",
    "\n",
    "    # (batch, 1, time, n_mfcc)\n",
    "    X = torch.tensor(padded_batch).unsqueeze(1)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_dataset = MFCCDataset(batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\", prefix=\"mfcc\")\n",
    "val_dataset = MFCCDataset(batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\", prefix=\"mfcc\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ============================\n",
    "# 3. 모델 정의\n",
    "# ============================\n",
    "class AudioEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioEmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 모델과 손실 함수, 옵티마이저 설정\n",
    "model = AudioEmotionCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# ============================\n",
    "# 4. 학습 루프\n",
    "# ============================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 5. 검증 루프\n",
    "    # ============================\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"🔵 Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 6. 모델 저장\n",
    "    # ============================\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"💾 Best model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러\n",
    "allow_pickle=True 옵션으로 불러온 데이터를 np.load() 하면, 원래는 List[np.ndarray] 혹은 (time, n_mfcc) 구조여야 합니다.\n",
    "\n",
    "만약 이전에 이 mfcc_batch_1.npy를 배치 단위 리스트 형태로 저장했었다면:\n",
    "\n",
    "지금처럼 __getitem__에서 개별 .npy를 꺼낼 경우 배치 전체가 한 개의 1D 배열로 저장되어 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해결 방법: 각 샘플을 개별 .npy 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 원본 다중샘플 npy 경로\n",
    "input_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_1.npy\"\n",
    "\n",
    "# 저장할 경로\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "data = np.load(input_path, allow_pickle=True)\n",
    "\n",
    "# 각 샘플 저장\n",
    "for i, sample in enumerate(data):\n",
    "    save_path = os.path.join(output_dir, f\"sample_{i:04d}.npy\")\n",
    "    np.save(save_path, sample)\n",
    "\n",
    "print(f\"✅ 총 {len(data)}개 샘플 저장 완료: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 분할 저장 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 레이블 경로\n",
    "label_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels/label_batch_1.npy\"\n",
    "labels = np.load(label_path)\n",
    "\n",
    "# 저장할 디렉토리\n",
    "label_output_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\"\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# 분할 저장\n",
    "for i, label in enumerate(labels):\n",
    "    save_path = os.path.join(label_output_dir, f\"label_{i:04d}.npy\")\n",
    "    np.save(save_path, label)\n",
    "\n",
    "print(f\"✅ 총 {len(labels)}개 레이블 저장 완료: {label_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCSampleDataset 정의 (샘플 단위)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class MFCCSampleDataset(Dataset):\n",
    "    def __init__(self, sample_dir, label_dir):\n",
    "        self.sample_paths = sorted([\n",
    "            os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = np.load(self.sample_paths[idx])          # shape: (time, n_mfcc)\n",
    "        label = np.load(self.label_paths[idx])          # shape: ()\n",
    "\n",
    "        # 텐서로 변환 (채널 추가)\n",
    "        mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)  # (1, time, n_mfcc)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return mfcc_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate_fn 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    seq_lens = [x[0].shape[0] for x in batch]\n",
    "    max_len = max(seq_lens)\n",
    "\n",
    "    # n_mfcc 추정 시 더 안전하게\n",
    "    n_mfcc = None\n",
    "    for mfcc_data, _ in batch:\n",
    "        if isinstance(mfcc_data, np.ndarray) and mfcc_data.ndim == 2:\n",
    "            n_mfcc = mfcc_data.shape[1]\n",
    "            break\n",
    "\n",
    "    if n_mfcc is None:\n",
    "        raise ValueError(\"모든 샘플에서 유효한 2D MFCC 데이터를 찾을 수 없습니다.\")\n",
    "\n",
    "    padded_batch = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc_data, label_data in batch:\n",
    "        time_len = mfcc_data.shape[0]\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:time_len, :] = mfcc_data\n",
    "        padded_batch.append(padded)\n",
    "        labels.append(label_data)\n",
    "\n",
    "    X = torch.tensor(padded_batch).unsqueeze(1)  # (batch, 1, time, n_mfcc)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  기본 설정 및 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# 모델 정의 (이전에 정의한 AudioEmotionCNN 사용)\n",
    "model = AudioEmotionCNN(num_classes=8).to(device)  # 클래스 수에 맞게 수정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 샘플 단위 .npy 파일을 위한 DataGenerator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class SampleMFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32, shuffle=True):\n",
    "        self.mfcc_paths = sorted([\n",
    "            os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = [], []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            mfcc = np.load(self.mfcc_paths[i])  # (time, n_mfcc)\n",
    "            label = np.load(self.label_paths[i])  # 정수 인코딩 레이블\n",
    "\n",
    "            X.append(mfcc)\n",
    "            y.append(label)\n",
    "\n",
    "        # Zero-padding\n",
    "        max_len = max(x.shape[0] for x in X)\n",
    "        X_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            X, maxlen=max_len, padding='post', dtype='float32'\n",
    "        )\n",
    "        X_pad = np.expand_dims(X_pad, -1)  # (batch, time, n_mfcc, 1)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return X_pad, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1  validation 데이터도 split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "val_input_path = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/mfcc_batch_0.npy\"\n",
    "val_label_path = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/label_batch_0.npy\"\n",
    "\n",
    "# 저장할 폴더\n",
    "val_sample_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\"\n",
    "os.makedirs(val_sample_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "mfcc_data = np.load(val_input_path, allow_pickle=True)\n",
    "label_data = np.load(val_label_path)\n",
    "\n",
    "# 저장\n",
    "for i, (sample, label) in enumerate(zip(mfcc_data, label_data)):\n",
    "    np.save(os.path.join(val_sample_dir, f\"sample_{i:04d}.npy\"), sample)\n",
    "    np.save(os.path.join(val_label_dir, f\"label_{i:04d}.npy\"), label)\n",
    "\n",
    "print(f\"✅ validation용 {len(mfcc_data)}개 샘플 및 레이블 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 콜백 설정 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# ===============================\n",
    "# [1] 학습 및 검증용 DataGenerator 정의\n",
    "# ===============================\n",
    "train_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "val_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# [2] 입력 형태 확인 및 모델 생성\n",
    "# ===============================\n",
    "sample_input, _ = train_generator[0]\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# 클래스 수 확인\n",
    "import glob\n",
    "label_paths = sorted(glob.glob(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels/*.npy\"))\n",
    "all_labels = [int(np.load(p)) for p in label_paths]\n",
    "num_classes = len(set(all_labels))\n",
    "\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ===============================\n",
    "# [3] 콜백 설정\n",
    "# ===============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_tf.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# GPU 초기화를 위한 예열용 더미 실행 (CPU에서 실행)\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    model(tf.random.normal((1,) + input_shape))\n",
    "\n",
    "# ===============================\n",
    "# [4] 모델 학습 실행\n",
    "# ===============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"✅ 모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpu 사용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cpu로 학습 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. GPU 완전 비활성화 (가장 먼저 실행)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# 1. 필수 라이브러리 임포트\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "\n",
    "# 2. 사용자 정의 DataGenerator\n",
    "class SampleMFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32, shuffle=True):\n",
    "        self.mfcc_paths = sorted([\n",
    "            os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_mfcc = [np.load(self.mfcc_paths[i]) for i in batch_indexes]\n",
    "        batch_label = [np.load(self.label_paths[i]).item() for i in batch_indexes]  # .item() 추가\n",
    "\n",
    "        batch_mfcc = [np.expand_dims(x, axis=-1) for x in batch_mfcc]  # (time, n_mfcc, 1)\n",
    "\n",
    "        max_len = max(x.shape[0] for x in batch_mfcc)\n",
    "        padded_mfcc = np.array([\n",
    "            np.pad(x, ((0, max_len - x.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
    "            for x in batch_mfcc\n",
    "        ])\n",
    "\n",
    "        labels = np.array(batch_label, dtype=np.int32)\n",
    "        return padded_mfcc, labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# 3. CNN 모델 생성 함수\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. DataGenerator 설정\n",
    "train_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "val_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# 5. 입력 형상 및 클래스 수 확인\n",
    "sample_input, _ = train_generator[0]\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "label_paths = sorted(glob.glob(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels/*.npy\"))\n",
    "all_labels = [np.load(p).item() for p in label_paths]  # .item()으로 스칼라 추출\n",
    "num_classes = len(set(all_labels))\n",
    "print(f\"클래스 수: {num_classes}\")\n",
    "\n",
    "# 6. 모델 생성 및 콜백 설정\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_tf.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 모델 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신 러닝 시도\n",
    "## 작업 순서\n",
    "1. 데이터 로딩 및 통합\n",
    "    - metadata_cleaned (train)\n",
    "    - metadata_cleaned_val (validation)\n",
    "\n",
    "2. 특징(X)과 레이블(y) 분리\n",
    "    - MFCC는 X\n",
    "    - 감정 레이블은 y\n",
    "\n",
    "3. 레이블 인코딩\n",
    "    - 문자열 레이블(Happy, Sad 등)을 숫자로 변환\n",
    "\n",
    "4. 머신러닝 모델 선택 및 학습\n",
    "    - 예: RandomForestClassifier, SVC, GradientBoosting, LogisticRegression\n",
    "\n",
    "5. 검증 및 평가\n",
    "    - accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로딩 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 경로\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/metadata_cleaned\"\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/metadata_cleaned_val\"\n",
    "\n",
    "# 파일 불러오기\n",
    "train_mfcc_paths = sorted(glob(os.path.join(train_dir, \"*.npy\")))\n",
    "val_mfcc_paths = sorted(glob(os.path.join(val_dir, \"*.npy\")))\n",
    "\n",
    "# 데이터 로딩\n",
    "train_data = [np.load(f, allow_pickle=True).item() for f in train_mfcc_paths]\n",
    "val_data = [np.load(f, allow_pickle=True).item() for f in val_mfcc_paths]\n",
    "\n",
    "# 분리\n",
    "X_train = [d[\"mfcc\"] for d in train_data]\n",
    "y_train = [d[\"emotion\"] for d in train_data]\n",
    "\n",
    "X_val = [d[\"mfcc\"] for d in val_data]\n",
    "y_val = [d[\"emotion\"] for d in val_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특징(X)과 레이블(y) 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 학습용 데이터 로딩\n",
    "train_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "metadata_cleaned = pd.read_csv(train_path)\n",
    "\n",
    "# 검증용 데이터 로딩\n",
    "val_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "metadata_cleaned_val = pd.read_csv(val_path)\n",
    "\n",
    "# X: MFCC 특징, y: 감정 레이블\n",
    "X_train = metadata_cleaned[\"mfcc\"]\n",
    "y_train = metadata_cleaned[\"emotion\"]\n",
    "\n",
    "X_val = metadata_cleaned_val[\"mfcc\"]\n",
    "y_val = metadata_cleaned_val[\"emotion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\"\n",
    "\n",
    "def load_mfcc_from_path(path_series):\n",
    "    mfcc_list = []\n",
    "    for rel_path in path_series:\n",
    "        fname = os.path.splitext(os.path.basename(rel_path))[0]\n",
    "        mfcc_path = os.path.join(base_mfcc_dir, f\"{fname}.npy\")\n",
    "        if not os.path.exists(mfcc_path):\n",
    "            print(f\"⚠️ 누락된 MFCC 파일: {mfcc_path}\")\n",
    "            continue\n",
    "        mfcc = np.load(mfcc_path)\n",
    "        mfcc_list.append(mfcc.flatten())  # 머신러닝용 1D 벡터로\n",
    "    return np.array(mfcc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X (특징) 로딩\n",
    "X_train = load_mfcc_from_path(metadata_cleaned[\"wav_path\"])\n",
    "X_val = load_mfcc_from_path(metadata_cleaned_val[\"wav_path\"])\n",
    "\n",
    "# y (레이블) 추출\n",
    "y_train = metadata_cleaned[\"emotion\"].values\n",
    "y_val = metadata_cleaned_val[\"emotion\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 이후 부터 딥러닝 다시 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩 및 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 파일 경로 정렬\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 로딩\n",
    "X_raw = [np.load(p, allow_pickle=True) for p in mfcc_paths]\n",
    "y_raw = [np.load(p) for p in label_paths]\n",
    "\n",
    "# 리스트로 되어 있는 MFCC들을 한 리스트로 합치기\n",
    "X_all = [sample for batch in X_raw for sample in batch]\n",
    "y_all = np.concatenate(y_raw)\n",
    "\n",
    "print(f\"총 MFCC 샘플 수: {len(X_all)}\")\n",
    "print(f\"총 레이블 수: {len(y_all)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 샘플 길이 정규화(패딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# MFCC의 각 샘플은 (time, 13) 형태 → 시퀀스 길이 맞추기\n",
    "max_len = max([x.shape[0] for x in X_all])\n",
    "print(\"가장 긴 MFCC 시퀀스 길이:\", max_len)\n",
    "\n",
    "# (샘플 수, time, n_mfcc)\n",
    "X_padded = pad_sequences(X_all, maxlen=max_len, padding='post', dtype='float32')\n",
    "print(\"패딩된 X shape:\", X_padded.shape)\n",
    "\n",
    "# 마지막 차원을 명시적으로 추가: (샘플 수, time, n_mfcc, 1)\n",
    "X_padded = np.expand_dims(X_padded, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 MFCC 데이터 로딩\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/encoded_labels\"\n",
    "\n",
    "val_mfcc_paths = sorted(glob(os.path.join(val_mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "val_label_paths = sorted(glob(os.path.join(val_label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "X_val_raw = [np.load(p, allow_pickle=True) for p in val_mfcc_paths]\n",
    "y_val_raw = [np.load(p) for p in val_label_paths]\n",
    "\n",
    "X_val_all = [sample for batch in X_val_raw for sample in batch]\n",
    "y_val = np.concatenate(y_val_raw)\n",
    "\n",
    "print(f\"검증용 MFCC 샘플 수: {len(X_val_all)}\")\n",
    "print(f\"검증용 레이블 수: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 기반 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_padded.shape[1:]  # (157, 13, 1)\n",
    "num_classes = len(np.unique(y_all))\n",
    "\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 설정 & 모델 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 저장 경로\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_cnn.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커널 재시작 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MFCC 및 레이블 로딩\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 경로\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 데이터 로딩\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "X_raw = [np.load(p, allow_pickle=True) for p in mfcc_paths]\n",
    "y_raw = [np.load(p) for p in label_paths]\n",
    "\n",
    "X_all = [sample for batch in X_raw for sample in batch]\n",
    "y_all = np.concatenate(y_raw)\n",
    "\n",
    "# 시퀀스 패딩\n",
    "max_len = 157  # 고정\n",
    "X_padded = pad_sequences(X_all, maxlen=max_len, padding='post', dtype='float32')\n",
    "X_padded = np.expand_dims(X_padded, -1)\n",
    "\n",
    "# 훈련/검증 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_padded, y_all, test_size=0.12, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "print(\"✅ 데이터 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 상황은 매우 자주 발생하는 Jupyter Notebook의 커널 메모리 한계 문제\n",
    "\n",
    "- 위 방법으로 해결 예저\n",
    "1. generator 정의\n",
    "2. gc.collect()\n",
    "3. model.fit(generator, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치 제너레이터 정의(훈련용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  # ✅ 반드시 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.mfcc_paths = mfcc_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_idx:\n",
    "            mfcc = np.load(self.mfcc_paths[i], allow_pickle=True)\n",
    "            label = np.load(self.label_paths[i])\n",
    "\n",
    "            # 유효한 MFCC만 처리\n",
    "            if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "                padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                    [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "                )[0]\n",
    "                X_batch.append(padded)\n",
    "                y_batch.append(label)\n",
    "\n",
    "        X_batch = np.expand_dims(np.array(X_batch), -1)  # (batch, time, n_mfcc, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제너레이터 생성 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 학습용 제너레이터\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=64, max_len=157, shuffle=True)\n",
    "\n",
    "# 가비지 컬렉션 실행 (메모리 확보)\n",
    "gc.collect()\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# 콜백 정의\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 검증용 데이터는 메모리 적재 방식으로 유지\n",
    "# 이 부분은 이전에 분리한 X_val, y_val을 사용해야 합니다\n",
    "# 혹시 없다면 validation set 따로 만들 수 있도록 알려주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 레이블 로딩\n",
    "all_labels = [np.load(p) for p in label_paths]\n",
    "y_all = np.concatenate(all_labels)\n",
    "\n",
    "# 전체 MFCC 로딩 (메모리 작은 검증셋만 로딩)\n",
    "val_size = 112157  # 예: 전체의 약 13%\n",
    "X_val_paths = mfcc_paths[-val_size:]\n",
    "y_val_paths = label_paths[-val_size:]\n",
    "\n",
    "# 검증 데이터 로딩\n",
    "X_val_list = []\n",
    "for path in X_val_paths:\n",
    "    mfcc = np.load(path, allow_pickle=True)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "    )[0]\n",
    "    X_val_list.append(padded)\n",
    "\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.concatenate([np.load(p) for p in y_val_paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_list = []\n",
    "valid_y_list = []\n",
    "\n",
    "for mfcc_path, label_path in zip(X_val_paths, y_val_paths):\n",
    "    mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    \n",
    "    # (time, 13) 형식인지 확인\n",
    "    if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "        padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "        )[0]\n",
    "        X_val_list.append(padded)\n",
    "\n",
    "        label = np.load(label_path)\n",
    "        valid_y_list.append(label)\n",
    "    else:\n",
    "        print(\"❌ 잘못된 MFCC:\", mfcc_path)\n",
    "\n",
    "# 최종 배열로 변환\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.array(valid_y_list)\n",
    "\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 경로\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 배치 파일 리스트\n",
    "mfcc_batch_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_batch_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 검증용 비율 기준으로 뒤에서 N개 배치만 선택\n",
    "val_batch_count = 10  # 예: 마지막 10개 배치만 사용\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "\n",
    "for mfcc_batch_path, label_batch_path in zip(mfcc_batch_paths[-val_batch_count:], label_batch_paths[-val_batch_count:]):\n",
    "    mfcc_batch = np.load(mfcc_batch_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_batch_path)\n",
    "\n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "\n",
    "# 배열로 변환\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"✅ 검증용 X shape:\", X_val.shape)\n",
    "print(\"✅ 검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),  # 이 부분이 메모리에 있어야 해요!\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 정리 커널 재시작 후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# 검증용 샘플 수 고정\n",
    "val_sample_size = 112157\n",
    "\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "\n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "# numpy 배열로 변환 (꼭 확인!)\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"✅ 검증 데이터 재구성 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.mfcc_paths = mfcc_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 전체 샘플을 flatten\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 기본 라이브러리\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "# 2. 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 3. 검증 데이터 구성\n",
    "val_sample_size = 112157\n",
    "X_val_list, y_val_list = [], []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "    \n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "print(\"✅ 검증 데이터 준비 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n",
    "\n",
    "# 4. 학습용 제너레이터 정의 및 생성\n",
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=16)\n",
    "print(\"✅ 유효한 학습용 샘플 수:\", len(train_generator) * 16)\n",
    "\n",
    "# 5. 모델 정의\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 생성 및 콜백 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 가비지 컬렉션\n",
    "gc.collect()\n",
    "\n",
    "# 8. 학습 시작\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장된 모델 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "model = load_model(model_path)\n",
    "print(\"✅ 모델 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred_classes)\n",
    "print(f\"✅ 검증 정확도: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"📊 분류 리포트:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "\n",
    "print(\"🌀 혼동 행렬:\")\n",
    "print(confusion_matrix(y_val, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 로그 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 학습 직후 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/models/history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 로그 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 로그 불러 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/models/history.pkl\", \"rb\") as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "print(\"✅ 학습 로그 불러오기 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict[\"accuracy\"]\n",
    "val_acc = history_dict[\"val_accuracy\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoch 300 으로 accuracy 더 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 11:29:40.450437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743733780.511469    4638 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743733780.530245    4638 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743733780.669660    4638 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743733780.669689    4638 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743733780.669690    4638 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743733780.669692    4638 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 11:29:40.686493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 준비 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n",
      "유효한 학습용 샘플 수: 525776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-04 11:30:04.276858: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1743733804.277331    4638 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 기본 라이브러리 불러오기 및 GPU 설정\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# GPU 메모리 과도할당 방지 설정\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 2. MFCC 및 레이블 파일 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 3. 검증 데이터셋 구성 (112157개 샘플)\n",
    "val_sample_size = 112157\n",
    "X_val_list, y_val_list = [], []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "    \n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"검증 데이터 준비 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n",
    "\n",
    "# 4. 학습용 데이터 제너레이터 정의\n",
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch, y_batch = [], []\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = pad_sequences([mfcc], maxlen=self.max_len, padding='post', dtype='float32')[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=16)\n",
    "print(\"유효한 학습용 샘플 수:\", len(train_generator) * 16)\n",
    "\n",
    "# 5. CNN 모델 정의 함수\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 구성 및 콜백 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 불필요한 메모리 수거\n",
    "gc.collect()\n",
    "\n",
    "# # 8. 모델 학습 (epoch 300으로 확장)\n",
    "# history = model.fit(\n",
    "#     train_generator,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=300,\n",
    "#     callbacks=callbacks\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 11:30:53.196941: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-04-04 11:30:54.313232: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743733855.058142    8477 service.cc:152] XLA service 0x79e7ec0029d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743733855.058176    8477 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-04-04 11:30:55.079536: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743733855.180731    8477 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-04-04 11:30:55.615828: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,157,13]{3,2,1,0} %bitcast.352, f32[32,1,3,3]{3,2,1,0} %bitcast.359, f32[32]{0} %bitcast.361), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:30:55.704393: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,78,6]{3,2,1,0} %bitcast.389, f32[64,32,3,3]{3,2,1,0} %bitcast.396, f32[64]{0} %bitcast.398), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:30:55.844944: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,39,3]{3,2,1,0} %bitcast.426, f32[128,64,3,3]{3,2,1,0} %bitcast.433, f32[128]{0} %bitcast.435), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  26/3505\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 7ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743733856.306102    8477 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3498/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 11:31:06.529920: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[29,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,1,157,13]{3,2,1,0} %bitcast.352, f32[32,1,3,3]{3,2,1,0} %bitcast.359, f32[32]{0} %bitcast.361), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:31:06.591286: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[29,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,32,78,6]{3,2,1,0} %bitcast.389, f32[64,32,3,3]{3,2,1,0} %bitcast.396, f32[64]{0} %bitcast.398), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:31:06.689536: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[29,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,39,3]{3,2,1,0} %bitcast.426, f32[128,64,3,3]{3,2,1,0} %bitcast.433, f32[128]{0} %bitcast.435), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3505/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (8,) and arg 1 with shape (7,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m     22\u001b[39m bar_width = \u001b[32m0.25\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbar_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m plt.bar(x + bar_width, recall, width=bar_width, label=\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m plt.bar(x + \u001b[32m2\u001b[39m*bar_width, f1, width=bar_width, label=\u001b[33m'\u001b[39m\u001b[33mf1-score\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/matplotlib/pyplot.py:2979\u001b[39m, in \u001b[36mbar\u001b[39m\u001b[34m(x, height, width, bottom, align, data, **kwargs)\u001b[39m\n\u001b[32m   2968\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.bar)\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbar\u001b[39m(\n\u001b[32m   2970\u001b[39m     x: \u001b[38;5;28mfloat\u001b[39m | ArrayLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2977\u001b[39m     **kwargs,\n\u001b[32m   2978\u001b[39m ) -> BarContainer:\n\u001b[32m-> \u001b[39m\u001b[32m2979\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2984\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2986\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2987\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:2583\u001b[39m, in \u001b[36mAxes.bar\u001b[39m\u001b[34m(self, x, height, width, bottom, align, **kwargs)\u001b[39m\n\u001b[32m   2580\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2581\u001b[39m         yerr = \u001b[38;5;28mself\u001b[39m._convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m.convert_yunits)\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m x, height, width, y, linewidth, hatch = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orientation == \u001b[33m'\u001b[39m\u001b[33mvertical\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:540\u001b[39m, in \u001b[36mbroadcast_arrays\u001b[39m\u001b[34m(subok, *args)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[32m    536\u001b[39m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[32m    538\u001b[39m args = [np.array(_m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m, subok=subok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m shape = \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array.shape == shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[32m    543\u001b[39m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:422\u001b[39m, in \u001b[36m_broadcast_shape\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[33;03msupplied arrays against each other.\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m b = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[32m31\u001b[39m):\n\u001b[32m    425\u001b[39m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[32m    427\u001b[39m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (8,) and arg 1 with shape (7,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# 예시: 모델 예측값이 있다고 가정\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 레이블 디코더 로딩 (있다면)\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_labels)\n",
    "x = np.arange(len(class_names))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_width = 0.25\n",
    "plt.bar(x, precision, width=bar_width, label='precision')\n",
    "plt.bar(x + bar_width, recall, width=bar_width, label='recall')\n",
    "plt.bar(x + 2*bar_width, f1, width=bar_width, label='f1-score')\n",
    "plt.xticks(x + bar_width, class_names)\n",
    "plt.title(\"Precision / Recall / F1-score by Class\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# history 객체를 JSON으로 저장\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     json.dump(\u001b[43mhistory\u001b[49m.history, f)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ 학습 로그 저장 완료\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 시각화\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 로그 저장 경로\n",
    "log_path = \"/media/usou/PortableSSD/mldl_project/models/train_history_log.json\"\n",
    "\n",
    "# history 객체를 JSON으로 저장\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(history.history, f)\n",
    "print(\"✅ 학습 로그 저장 완료\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .keras 포맷 으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model_generator.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .keras -> .h5 로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 변환 완료: .keras → .h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. 기존 .keras 모델 경로\n",
    "keras_path = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/ai/models//voice_emotion_model.keras\"\n",
    "\n",
    "# 2. 저장할 .h5 모델 경로\n",
    "h5_path = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/ai/models//voice_emotion_model.h5\"\n",
    "\n",
    "# 3. 모델 로드 후 저장\n",
    "model = load_model(keras_path, compile=False)\n",
    "model.save(h5_path)\n",
    "\n",
    "print(\"✅ 변환 완료: .keras → .h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m4a → wav 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def convert_to_wav(input_path, output_path=None):\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일이 존재하지 않아요: {input_path}\")\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "\n",
    "    audio = AudioSegment.from_file(input_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "    print(\"✅ 변환 완료:\", output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m4a, mp3, mp4 -> wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_to_wav(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    오디오 또는 비디오 파일을 WAV로 변환합니다.\n",
    "    지원 포맷: .wav, .m4a, .mp3, .mp4 등\n",
    "    내부적으로 ffmpeg가 설치되어 있어야 합니다.\n",
    "\n",
    "    :param input_path: 입력 파일 경로\n",
    "    :param output_path: 출력 파일 경로 (None이면 자동 생성)\n",
    "    :return: 변환된 WAV 파일 경로\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일이 존재하지 않아요: {input_path}\")\n",
    "\n",
    "    ext = os.path.splitext(input_path)[1].lower()\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "\n",
    "    # pydub이 ffmpeg를 통해 모든 형식 처리함\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        audio.export(output_path, format=\"wav\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"오디오 변환 실패: {e}\")\n",
    "\n",
    "    print(\"변환 완료:\", output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC 추출(모델 입력 준비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, sr=16000, n_mfcc=40):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc = np.expand_dims(mfcc, axis=-1)  # CNN 입력을 위해 채널 차원 추가\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 유효 레이블 개수 (nan 제외): 530280\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad']\n",
      "유효 배치 수: 82\n",
      "nan 제거 및 레이블 인코딩 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집 및 'nan' 제거\n",
    "# ============================\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "all_labels = []\n",
    "batch_label_data = []\n",
    "valid_indices_per_batch = []\n",
    "\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    \n",
    "    # 'nan' 문자열 제거\n",
    "    valid_indices = [i for i, l in enumerate(labels) if str(l).lower() != 'nan']\n",
    "    valid_labels = [labels[i] for i in valid_indices]\n",
    "\n",
    "    all_labels.extend(valid_labels)\n",
    "    batch_label_data.append(valid_labels)\n",
    "    valid_indices_per_batch.append(valid_indices)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 유효 레이블 개수 (nan 제외): {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"유효 배치 수: {len(label_files)}\")\n",
    "print(\"nan 제거 및 레이블 인코딩 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감정 분석 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 모델 로드\n",
    "model_path = \"best_model_generator_voice_emotion_analyze.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# LabelEncoder 로드\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "def predict_emotion(mfcc_data):\n",
    "    # 입력 형태 맞추기 (1, time, freq, 1)\n",
    "    X = np.expand_dims(mfcc_data, axis=0)\n",
    "    pred = model.predict(X)\n",
    "    idx = np.argmax(pred)\n",
    "    label = le.inverse_transform([idx])[0]\n",
    "    confidence = float(np.max(pred))\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 파이프라인 실행 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 완료: /media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000011.wav\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bb037ece200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
      "\n",
      " 감정 분석 결과: Happy (100.00% 확신)\n"
     ]
    }
   ],
   "source": [
    "# 1. 파일 변환\n",
    "m4a_path = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000011.wav\"\n",
    "\n",
    "wav_path = convert_to_wav(m4a_path)\n",
    "\n",
    "# 2. MFCC 추출\n",
    "mfcc = extract_mfcc(wav_path)\n",
    "\n",
    "# 3. 감정 예측\n",
    "emotion, score = predict_emotion(mfcc)\n",
    "print(f\"\\n 감정 분석 결과: {emotion} ({score:.2%} 확신)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2025-04-02 12:21:20.363584: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[1,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,10,75]{3,2,1,0} %bitcast.440, f32[128,64,3,3]{3,2,1,0} %bitcast.447, f32[128]{0} %bitcast.449), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n",
      "Softmax 확률 분포: [6.35206882e-17 7.89071120e-13 1.22968635e-10 1.00000000e+00\n",
      " 3.78825990e-27 1.18888200e-12 5.54563053e-27 1.00396704e-16]\n",
      "예측된 감정: Happy\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "# 설정\n",
    "wav_path = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000011.wav\"  # 예: ./val_data/sample_001.wav\n",
    "label_encoder_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\"  # 예: ./label_encoder.pkl\n",
    "model_path = \"best_model_generator_voice_emotion_analyze.keras\"\n",
    "\n",
    "\n",
    "# 1. 모델 및 라벨 인코더 로드\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "with open(label_encoder_path, \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# 2. wav 파일에서 MFCC 추출\n",
    "def extract_mfcc(wav_path, sr=16000, n_mfcc=40, max_len=300):\n",
    "    y, sr = librosa.load(wav_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    # 길이 고정 (짧으면 패딩, 길면 자름)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# 3. 예측\n",
    "mfcc = extract_mfcc(wav_path)\n",
    "mfcc_input = mfcc[np.newaxis, ..., np.newaxis]  # (1, 40, 300, 1) 형태로 reshape\n",
    "\n",
    "y_pred = model.predict(mfcc_input)\n",
    "\n",
    "# 4. 결과 출력\n",
    "pred_index = np.argmax(y_pred)\n",
    "pred_emotion = label_encoder.inverse_transform([pred_index])[0]\n",
    "\n",
    "print(\"Softmax 확률 분포:\", y_pred[0])\n",
    "print(\"예측된 감정:\", pred_emotion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 재학습\n",
    "\n",
    "-  감정 클래스 7 -> 4개 축소\n",
    "- 행복, 슬픔, 분노, 중립\n",
    "- 데이터 증강 및 개선 모델 필요\n",
    "- 모델 성능 향상 전략\n",
    "    - 데이터 증강 + 하이퍼 파라미터 튜닝 + 과적합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 흐름 요약\n",
    "✅ 전체 흐름 요약\n",
    "\n",
    "| 단계         | 설명                                              |\n",
    "|--------------|---------------------------------------------------|\n",
    "| 1단계 (완료) | JSON → `metadata_cleaned.csv` 생성               |\n",
    "| 2단계        | 4개 감정만 필터링 → `metadata_4class.csv` 저장   |\n",
    "| 3단계        | MFCC 추출 + 증강 적용                             |\n",
    "| 4단계        | 인코딩 → 배치 분할 저장                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1단계: JSON → DataFrame 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 수집된 샘플: 300584\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 라벨링 JSON이 위치한 최상위 폴더 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "\n",
    "# 실제 wav 파일이 존재하는 원천 데이터 경로\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 결과 CSV 및 로그를 저장할 폴더 경로\n",
    "save_dir = \"./data/usou\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 사용할 감정 4개만 필터링 대상\n",
    "target_classes = ['Happy', 'Sad', 'Angry', 'Neutrality']\n",
    "\n",
    "# 정제된 데이터와 누락 파일 로그를 담을 리스트\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# 모든 하위 폴더를 순회하며 JSON 파일 탐색\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if not file_name.endswith(\".json\"):\n",
    "            continue  # JSON 파일만 처리\n",
    "\n",
    "        json_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            # JSON 파일 로딩\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                content = json.load(f)\n",
    "\n",
    "            # 감정 정보 추출 및 필터링\n",
    "            emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "            if emotion not in target_classes:\n",
    "                continue  # 지정된 감정이 아닌 경우 제외\n",
    "\n",
    "            # 그 외 부가 정보 추출\n",
    "            style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "            sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "            wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "            # 경로 변환 (TL → TS로 수정하여 wav 경로 재구성)\n",
    "            relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "            relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "            wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "            # wav 파일 존재 여부 확인 후 저장\n",
    "            if os.path.exists(wav_path):\n",
    "                data.append({\n",
    "                    \"wav_path\": wav_path,\n",
    "                    \"emotion\": emotion,\n",
    "                    \"style\": style,\n",
    "                    \"sensitivity\": sensitivity\n",
    "                })\n",
    "            else:\n",
    "                broken_files.append(wav_path)\n",
    "        except Exception as e:\n",
    "            # JSON 로딩 실패 또는 파싱 오류 발생 시 경로 저장\n",
    "            broken_files.append(json_path)\n",
    "\n",
    "# 수집된 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 CSV 저장\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_4class.csv\"), index=False)\n",
    "\n",
    "# 누락된 경로 저장\n",
    "with open(os.path.join(save_dir, \"broken_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 최종 처리 결과 출력\n",
    "print(\"총 수집된 샘플:\", len(df))\n",
    "print(\"에러 발생 수:\", len(broken_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 + 증강\n",
    "\n",
    "- metadata_4class.csv에서 경로와 감정 읽기\n",
    "\n",
    "- audiomentations로 증강 (2배)\n",
    "\n",
    "- MFCC 추출 (40 x 300)\n",
    "\n",
    "- mfcc_data.npy, labels.npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4643/3246010131.py:20: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "MFCC 추출 및 증강:   0%|          | 335/300584 [00:25<7:26:13, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 0 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   0%|          | 669/300584 [00:52<7:05:35, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   0%|          | 1003/300584 [01:19<6:33:32, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 2 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   0%|          | 1339/300584 [01:45<5:59:34, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 3 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 1672/300584 [02:12<7:22:27, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 4 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 2005/300584 [02:39<7:08:27, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 5 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 2339/300584 [03:09<9:13:48,  8.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 6 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 2673/300584 [03:38<7:00:54, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 7 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 3007/300584 [04:06<7:00:46, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 8 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 3341/300584 [04:36<10:25:53,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 9 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 3675/300584 [05:06<8:14:35, 10.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 10 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|▏         | 4011/300584 [05:34<5:49:34, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 11 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|▏         | 4343/300584 [06:02<6:37:31, 12.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 12 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 4678/300584 [06:30<6:45:41, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 13 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 5012/300584 [06:59<6:58:11, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 14 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 5345/300584 [07:27<7:35:58, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 15 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 5680/300584 [07:54<6:02:02, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 16 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 6014/300584 [08:21<6:38:06, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 17 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 6349/300584 [08:48<6:16:18, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 18 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 6683/300584 [09:15<6:27:29, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 19 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 7015/300584 [09:42<7:19:14, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 20 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 7350/300584 [10:09<6:11:35, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 21 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 7685/300584 [10:36<6:33:22, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 22 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 8018/300584 [11:03<7:40:19, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 23 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 8351/300584 [11:28<7:38:08, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 24 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 8686/300584 [11:55<5:35:51, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 25 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 9020/300584 [12:22<4:54:02, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 26 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 9354/300584 [12:48<7:11:23, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 27 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 9689/300584 [13:14<5:33:36, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 28 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 10022/300584 [13:41<6:44:33, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 29 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 10357/300584 [14:08<6:08:25, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 30 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▎         | 10689/300584 [14:34<6:47:13, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 31 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▎         | 11023/300584 [15:00<6:32:27, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 32 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 11357/300584 [15:27<6:18:30, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 33 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 11693/300584 [15:55<7:05:06, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 34 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 12024/300584 [16:23<6:30:57, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 35 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 12360/300584 [16:51<6:31:45, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 36 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 12693/300584 [17:17<6:25:28, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 37 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 13027/300584 [17:44<8:38:10,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 38 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 13362/300584 [18:11<6:04:20, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 39 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 13696/300584 [18:39<7:36:52, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 40 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 14029/300584 [19:06<7:31:44, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 41 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 14363/300584 [19:33<6:59:13, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 42 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 14699/300584 [20:01<6:29:44, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 43 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 15031/300584 [20:29<7:42:30, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 44 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 15364/300584 [20:57<6:24:02, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 45 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 15698/300584 [21:24<6:33:22, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 46 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 16034/300584 [21:51<5:45:14, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 47 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 16368/300584 [22:18<6:55:04, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 48 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 16701/300584 [22:47<6:55:37, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 49 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 17034/300584 [23:16<7:40:21, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 50 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 17370/300584 [23:43<7:05:24, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 51 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 17703/300584 [24:09<7:04:26, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 52 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 18037/300584 [24:39<6:26:37, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 53 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 18371/300584 [25:08<8:10:08,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 54 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 18706/300584 [25:34<5:56:39, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 55 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▋         | 19039/300584 [26:03<6:39:39, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 56 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▋         | 19374/300584 [26:30<7:01:24, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 57 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 19707/300584 [26:58<5:38:40, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 58 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 20041/300584 [27:25<6:55:44, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 59 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 20375/300584 [27:52<9:08:28,  8.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 60 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 20708/300584 [28:24<11:21:42,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 61 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 21043/300584 [28:53<6:35:56, 11.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 62 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 21378/300584 [29:20<6:21:37, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 63 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 21713/300584 [29:45<5:36:24, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 64 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 22047/300584 [30:11<5:27:02, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 65 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 22381/300584 [30:38<6:23:49, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 66 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 22715/300584 [31:03<6:10:05, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 67 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 23048/300584 [31:31<6:14:15, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 68 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 23382/300584 [31:59<7:04:44, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 69 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 23716/300584 [32:25<6:20:27, 12.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 70 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 24050/300584 [32:52<5:44:22, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 71 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 24383/300584 [33:19<6:53:25, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 72 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 24719/300584 [33:45<5:48:29, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 73 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 25051/300584 [34:12<7:25:22, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 74 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 25386/300584 [34:40<5:18:55, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 75 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▊         | 25719/300584 [35:07<6:28:26, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 76 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▊         | 26053/300584 [35:34<7:16:49, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 77 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 26386/300584 [36:04<6:30:50, 11.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 78 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 26723/300584 [36:30<5:33:30, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 79 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 27054/300584 [36:58<8:05:43,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 80 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 27389/300584 [37:29<8:02:09,  9.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 81 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 27725/300584 [37:55<6:48:43, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 82 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 28058/300584 [38:21<5:41:57, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 83 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 28392/300584 [38:47<6:44:39, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 84 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 28725/300584 [39:13<5:37:48, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 85 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 29059/300584 [39:40<5:58:31, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 86 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 29395/300584 [40:07<5:41:57, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 87 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 29727/300584 [40:33<6:23:40, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 88 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 30062/300584 [40:59<5:44:52, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 89 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 30395/300584 [41:27<8:33:38,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 90 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 30728/300584 [41:58<6:32:35, 11.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 91 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 31062/300584 [42:26<8:10:57,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 92 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 31397/300584 [42:56<8:03:38,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 93 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 31732/300584 [43:26<7:46:42,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 94 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 32064/300584 [43:54<7:16:46, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 95 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 32401/300584 [44:22<5:59:09, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 96 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 32732/300584 [44:49<6:10:44, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 97 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 33068/300584 [45:18<6:16:20, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 98 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 33401/300584 [45:46<7:26:32,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 99 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 33736/300584 [46:15<5:53:52, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 100 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█▏        | 34070/300584 [46:43<6:17:56, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 101 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█▏        | 34403/300584 [47:10<6:59:45, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 102 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 34738/300584 [47:37<7:14:55, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 103 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 35073/300584 [48:05<6:38:47, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 104 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 35404/300584 [48:32<5:53:39, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 105 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 35739/300584 [49:00<6:34:12, 11.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 106 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 36073/300584 [49:28<7:33:03,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 107 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 36408/300584 [49:56<6:51:10, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 108 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 36742/300584 [50:25<7:42:21,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 109 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 37077/300584 [50:53<6:37:57, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 110 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 37410/300584 [51:24<7:01:46, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 111 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 37744/300584 [51:53<6:54:57, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 112 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 38077/300584 [52:21<6:13:23, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 113 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 38412/300584 [52:49<8:07:04,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 114 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 38747/300584 [53:18<6:17:29, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 115 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 39079/300584 [53:45<8:45:32,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 116 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 39413/300584 [54:11<6:43:02, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 117 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 39748/300584 [54:35<6:34:44, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 118 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 40082/300584 [55:01<5:41:57, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 119 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 40416/300584 [55:25<6:54:30, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 120 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▎        | 40749/300584 [55:53<6:15:25, 11.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 121 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▎        | 41085/300584 [56:20<5:37:39, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 122 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 41419/300584 [56:47<6:52:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 123 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 41751/300584 [57:12<6:04:29, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 124 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 42085/300584 [57:38<7:05:15, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 125 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 42420/300584 [58:03<6:33:10, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 126 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 42754/300584 [58:29<6:14:19, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 127 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 43088/300584 [58:58<7:13:24,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 128 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 43422/300584 [59:27<6:35:31, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 129 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 43758/300584 [59:53<5:46:19, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 130 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 44089/300584 [1:00:23<7:26:08,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 131 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 44423/300584 [1:00:54<7:04:34, 10.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 132 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 44757/300584 [1:01:28<9:09:55,  7.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 133 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 45092/300584 [1:02:04<6:15:40, 11.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 134 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 45424/300584 [1:02:36<13:53:21,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 135 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 45759/300584 [1:03:16<9:04:47,  7.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 136 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 46093/300584 [1:03:47<6:46:32, 10.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 137 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 46426/300584 [1:04:20<6:45:12, 10.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 138 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 46760/300584 [1:04:54<7:23:27,  9.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 139 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 47096/300584 [1:05:25<6:48:10, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 140 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 47431/300584 [1:05:56<6:27:59, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 141 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 47763/300584 [1:06:22<6:02:19, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 142 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 48099/300584 [1:06:50<5:00:54, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 143 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 48432/300584 [1:07:17<5:43:21, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 144 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 48766/300584 [1:07:43<5:45:38, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 145 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▋        | 49100/300584 [1:08:09<6:57:47, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 146 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▋        | 49434/300584 [1:08:37<6:23:28, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 147 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 49768/300584 [1:09:04<6:40:14, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 148 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 50102/300584 [1:09:33<6:23:46, 10.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 149 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 50435/300584 [1:10:00<5:48:35, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 150 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 50770/300584 [1:10:29<5:57:33, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 151 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 51104/300584 [1:10:59<6:21:36, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 152 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 51439/300584 [1:11:29<5:59:10, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 153 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 51772/300584 [1:11:56<7:16:43,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 154 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 52106/300584 [1:12:25<6:47:22, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 155 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 52438/300584 [1:12:53<6:14:11, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 156 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 52775/300584 [1:13:23<5:11:48, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 157 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 53108/300584 [1:13:53<5:45:59, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 158 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 53442/300584 [1:14:26<6:29:56, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 159 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 53776/300584 [1:14:56<6:44:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 160 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 54108/300584 [1:15:25<7:19:08,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 161 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 54444/300584 [1:15:57<7:44:17,  8.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 162 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 54777/300584 [1:16:27<7:33:52,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 163 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 55112/300584 [1:16:57<7:29:39,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 164 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 55446/300584 [1:17:27<6:01:05, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 165 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▊        | 55780/300584 [1:17:57<8:08:32,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 166 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▊        | 56113/300584 [1:18:27<6:50:55,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 167 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 56447/300584 [1:18:57<5:27:02, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 168 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 56782/300584 [1:19:26<5:48:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 169 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 57116/300584 [1:19:51<5:34:26, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 170 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 57449/300584 [1:20:17<5:10:20, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 171 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 57785/300584 [1:20:43<6:08:23, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 172 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 58117/300584 [1:21:08<5:32:21, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 173 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 58453/300584 [1:21:34<5:10:34, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 174 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 58785/300584 [1:22:00<5:49:39, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 175 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 59120/300584 [1:22:27<5:39:20, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 176 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 59454/300584 [1:22:53<5:10:38, 12.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 177 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 59789/300584 [1:23:17<5:00:42, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 178 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 60121/300584 [1:23:43<6:06:59, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 179 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 60455/300584 [1:24:07<5:23:11, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 180 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 60790/300584 [1:24:33<5:39:15, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 181 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 61125/300584 [1:25:02<5:48:50, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 182 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 61458/300584 [1:25:28<6:04:02, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 183 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 61791/300584 [1:25:54<5:44:17, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 184 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 62127/300584 [1:26:21<5:26:07, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 185 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 62458/300584 [1:26:53<10:27:15,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 186 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 62792/300584 [1:27:26<7:45:13,  8.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 187 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 63127/300584 [1:27:55<9:00:55,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 188 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 63461/300584 [1:28:24<6:29:54, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 189 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 63794/300584 [1:28:53<5:50:52, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 190 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██▏       | 64129/300584 [1:29:25<6:05:26, 10.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 191 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██▏       | 64463/300584 [1:29:56<6:40:46,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 192 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 64797/300584 [1:30:22<5:29:50, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 193 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 65132/300584 [1:30:47<5:54:34, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 194 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 65464/300584 [1:31:12<6:21:28, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 195 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 65799/300584 [1:31:36<4:24:49, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 196 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 66133/300584 [1:32:01<5:01:06, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 197 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 66468/300584 [1:32:22<4:04:16, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 198 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 66804/300584 [1:32:43<3:49:20, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 199 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 67135/300584 [1:33:05<5:10:15, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 200 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 67469/300584 [1:33:27<5:13:52, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 201 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 67804/300584 [1:33:49<4:14:17, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 202 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 68137/300584 [1:34:13<4:06:39, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 203 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 68472/300584 [1:34:36<4:15:29, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 204 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 68807/300584 [1:34:57<4:22:59, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 205 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 69140/300584 [1:35:19<4:30:31, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 206 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 69472/300584 [1:35:41<5:08:33, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 207 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 69809/300584 [1:36:02<4:11:58, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 208 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 70142/300584 [1:36:24<3:44:43, 17.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 209 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 70476/300584 [1:36:44<3:44:15, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 210 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▎       | 70812/300584 [1:37:04<4:01:13, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 211 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▎       | 71145/300584 [1:37:25<4:31:36, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 212 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 71477/300584 [1:37:45<6:41:12,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 213 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 71812/300584 [1:38:06<3:58:55, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 214 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 72146/300584 [1:38:29<6:14:31, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 215 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 72481/300584 [1:38:52<4:20:51, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 216 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 72814/300584 [1:39:14<5:04:47, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 217 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 73149/300584 [1:39:35<3:26:51, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 218 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 73480/300584 [1:39:57<5:04:41, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 219 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 73817/300584 [1:40:18<3:20:04, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 220 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 74149/300584 [1:40:41<5:14:40, 11.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 221 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 74486/300584 [1:41:01<3:29:21, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 222 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 74819/300584 [1:41:22<4:17:38, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 223 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 75153/300584 [1:41:42<3:49:47, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 224 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 75485/300584 [1:42:04<5:33:40, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 225 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 75821/300584 [1:42:25<3:05:27, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 226 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 76156/300584 [1:42:46<3:19:16, 18.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 227 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 76488/300584 [1:43:07<3:14:00, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 228 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 76821/300584 [1:43:29<5:32:30, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 229 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 77156/300584 [1:43:51<3:53:18, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 230 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 77490/300584 [1:44:13<5:59:30, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 231 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 77824/300584 [1:44:36<4:39:51, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 232 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 78159/300584 [1:44:58<4:25:26, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 233 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 78494/300584 [1:45:20<3:53:16, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 234 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 78825/300584 [1:45:43<4:02:14, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 235 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▋       | 79161/300584 [1:46:04<5:04:26, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 236 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▋       | 79495/300584 [1:46:26<4:44:33, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 237 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 79830/300584 [1:46:48<3:44:16, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 238 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 80160/300584 [1:47:10<4:33:14, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 239 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 80496/300584 [1:47:32<3:42:58, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 240 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 80830/300584 [1:47:56<4:17:38, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 241 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 81165/300584 [1:48:18<4:35:53, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 242 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 81498/300584 [1:48:40<4:02:10, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 243 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 81833/300584 [1:49:04<4:28:43, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 244 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 82167/300584 [1:49:26<4:12:07, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 245 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 82500/300584 [1:49:49<5:29:21, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 246 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 82835/300584 [1:50:10<5:09:16, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 247 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 83169/300584 [1:50:30<3:43:05, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 248 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 83504/300584 [1:50:51<3:42:11, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 249 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 83836/300584 [1:51:12<4:01:33, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 250 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 84170/300584 [1:51:32<4:36:59, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 251 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 84503/300584 [1:51:52<4:40:47, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 252 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 84839/300584 [1:52:15<4:30:41, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 253 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 85173/300584 [1:52:36<3:55:54, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 254 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 85506/300584 [1:52:57<4:11:08, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 255 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▊       | 85841/300584 [1:53:19<3:35:13, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 256 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▊       | 86175/300584 [1:53:42<4:30:28, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 257 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 86507/300584 [1:54:04<5:03:18, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 258 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 86844/300584 [1:54:25<3:01:38, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 259 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 87175/300584 [1:54:45<3:30:41, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 260 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 87511/300584 [1:55:08<4:28:13, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 261 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 87844/300584 [1:55:30<3:58:19, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 262 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 88177/300584 [1:55:52<4:17:27, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 263 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 88511/300584 [1:56:14<3:48:21, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 264 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 88846/300584 [1:56:35<4:41:21, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 265 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 89181/300584 [1:56:57<3:09:24, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 266 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 89513/300584 [1:57:19<5:09:11, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 267 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 89847/300584 [1:57:42<3:59:50, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 268 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 90183/300584 [1:58:07<5:12:29, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 269 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 90516/300584 [1:58:32<3:57:18, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 270 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 90850/300584 [1:58:54<5:18:26, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 271 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 91184/300584 [1:59:16<3:35:56, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 272 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 91519/300584 [1:59:37<4:00:02, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 273 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 91852/300584 [2:00:00<4:29:04, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 274 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 92187/300584 [2:00:24<4:04:46, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 275 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 92521/300584 [2:00:46<3:49:19, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 276 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 92853/300584 [2:01:08<5:29:33, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 277 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 93187/300584 [2:01:30<3:40:42, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 278 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 93524/300584 [2:01:53<3:42:45, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 279 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 93856/300584 [2:02:15<3:15:40, 17.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 280 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███▏      | 94190/300584 [2:02:39<3:58:11, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 281 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███▏      | 94524/300584 [2:03:01<4:28:58, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 282 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 94859/300584 [2:03:24<3:58:18, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 283 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 95192/300584 [2:03:46<4:41:13, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 284 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 95528/300584 [2:04:12<4:14:14, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 285 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 95861/300584 [2:04:41<4:58:48, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 286 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 96193/300584 [2:05:08<4:28:02, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 287 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 96526/300584 [2:05:37<7:14:53,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 288 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 96862/300584 [2:06:04<3:51:11, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 289 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 97195/300584 [2:06:29<4:57:17, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 290 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 97530/300584 [2:06:55<4:29:48, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 291 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 97864/300584 [2:07:22<4:28:48, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 292 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 98197/300584 [2:07:48<5:14:29, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 293 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 98531/300584 [2:08:15<6:08:32,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 294 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 98864/300584 [2:08:43<5:13:33, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 295 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 99198/300584 [2:09:14<5:54:05,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 296 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 99532/300584 [2:09:44<5:26:52, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 297 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 99866/300584 [2:10:13<6:02:04,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 298 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 100201/300584 [2:10:44<6:50:08,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 299 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 100536/300584 [2:11:16<4:08:11, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 300 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▎      | 100872/300584 [2:11:42<4:28:46, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 301 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▎      | 101203/300584 [2:12:09<7:23:45,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 302 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 101537/300584 [2:12:36<4:37:54, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 303 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 101871/300584 [2:13:04<4:43:39, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 304 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 102205/300584 [2:13:33<5:00:15, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 305 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 102540/300584 [2:14:01<4:18:28, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 306 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 102875/300584 [2:14:27<4:00:07, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 307 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 103207/300584 [2:14:53<4:54:52, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 308 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 103542/300584 [2:15:21<4:52:44, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 309 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 103876/300584 [2:15:48<5:16:08, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 310 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 104210/300584 [2:16:18<5:46:32,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 311 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 104543/300584 [2:16:46<10:10:12,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 312 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 104879/300584 [2:17:20<4:52:49, 11.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 313 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 105211/300584 [2:17:53<7:03:48,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 314 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 105546/300584 [2:18:25<4:05:32, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 315 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 105879/300584 [2:18:56<7:43:28,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 316 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 106212/300584 [2:19:27<4:49:17, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 317 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 106548/300584 [2:19:59<4:29:53, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 318 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 106881/300584 [2:20:25<5:11:04, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 319 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 107217/300584 [2:20:50<5:17:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 320 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 107550/300584 [2:21:16<5:11:42, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 321 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 107884/300584 [2:21:44<5:30:36,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 322 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 108218/300584 [2:22:11<4:25:07, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 323 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 108552/300584 [2:22:38<4:38:24, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 324 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 108885/300584 [2:23:04<4:48:45, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 325 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▋      | 109220/300584 [2:23:30<5:58:15,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 326 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▋      | 109553/300584 [2:23:57<4:37:28, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 327 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 109887/300584 [2:24:24<6:13:12,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 328 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 110222/300584 [2:24:50<4:18:20, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 329 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 110556/300584 [2:25:17<4:25:11, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 330 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 110889/300584 [2:25:43<3:45:15, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 331 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 111224/300584 [2:26:10<4:02:07, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 332 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 111558/300584 [2:26:36<3:40:20, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 333 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 111893/300584 [2:27:06<6:02:06,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 334 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 112225/300584 [2:27:38<6:34:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 335 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 112560/300584 [2:28:08<3:58:33, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 336 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 112894/300584 [2:28:38<4:19:15, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 337 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 113227/300584 [2:29:08<4:45:10, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 338 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 113563/300584 [2:29:38<4:41:38, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 339 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 113895/300584 [2:30:08<6:42:32,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 340 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 114231/300584 [2:30:40<5:24:33,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 341 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 114565/300584 [2:31:11<5:17:55,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 342 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 114898/300584 [2:31:38<4:43:30, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 343 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 115231/300584 [2:32:07<4:57:58, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 344 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 115565/300584 [2:32:34<4:27:11, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 345 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▊      | 115900/300584 [2:33:02<3:42:18, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 346 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▊      | 116232/300584 [2:33:31<5:20:55,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 347 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 116567/300584 [2:34:05<5:21:50,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 348 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 116901/300584 [2:34:42<8:26:47,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 349 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 117236/300584 [2:35:16<5:48:12,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 350 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 117570/300584 [2:35:49<4:52:50, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 351 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 117903/300584 [2:36:23<5:44:05,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 352 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 118239/300584 [2:37:00<5:25:34,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 353 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 118572/300584 [2:37:33<5:14:15,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 354 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 118906/300584 [2:38:03<5:53:42,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 355 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 119240/300584 [2:38:27<3:42:36, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 356 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 119572/300584 [2:38:48<3:13:43, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 357 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 119907/300584 [2:39:14<4:42:18, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 358 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 120241/300584 [2:39:38<5:49:25,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 359 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 120577/300584 [2:40:02<3:46:50, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 360 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 120910/300584 [2:40:26<4:47:32, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 361 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 121244/300584 [2:40:49<3:32:20, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 362 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 121578/300584 [2:41:11<5:51:05,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 363 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 121912/300584 [2:41:34<4:14:45, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 364 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 122246/300584 [2:41:57<3:40:12, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 365 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 122579/300584 [2:42:21<4:14:19, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 366 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 122914/300584 [2:42:45<5:16:19,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 367 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 123249/300584 [2:43:08<3:32:56, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 368 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 123584/300584 [2:43:33<4:25:21, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 369 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 123916/300584 [2:43:58<4:16:05, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 370 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████▏     | 124250/300584 [2:44:21<3:18:26, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 371 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████▏     | 124584/300584 [2:44:46<4:19:28, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 372 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 124918/300584 [2:45:12<4:37:41, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 373 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 125253/300584 [2:45:37<3:46:26, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 374 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 125585/300584 [2:46:01<4:37:19, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 375 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 125921/300584 [2:46:25<2:54:51, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 376 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 126255/300584 [2:46:48<4:27:38, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 377 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 126587/300584 [2:47:13<5:33:05,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 378 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 126922/300584 [2:47:37<3:28:45, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 379 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 127256/300584 [2:48:01<4:35:02, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 380 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 127591/300584 [2:48:25<4:19:50, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 381 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 127924/300584 [2:48:50<3:41:20, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 382 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 128257/300584 [2:49:14<4:01:30, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 383 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 128591/300584 [2:49:40<3:59:05, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 384 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 128927/300584 [2:50:03<2:33:02, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 385 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 129260/300584 [2:50:26<4:33:55, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 386 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 129593/300584 [2:50:52<4:08:05, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 387 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 129928/300584 [2:51:17<4:01:35, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 388 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 130261/300584 [2:51:41<4:28:27, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 389 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 130596/300584 [2:52:05<2:36:55, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 390 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▎     | 130931/300584 [2:52:26<2:56:20, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 391 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▎     | 131264/300584 [2:52:47<3:24:57, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 392 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 131598/300584 [2:53:07<2:22:58, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 393 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 131933/300584 [2:53:29<2:44:53, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 394 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 132266/300584 [2:53:50<4:06:35, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 395 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 132601/300584 [2:54:12<3:10:51, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 396 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 132935/300584 [2:54:33<2:51:52, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 397 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 133267/300584 [2:54:53<3:21:25, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 398 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 133604/300584 [2:55:12<2:30:32, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 399 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 133936/300584 [2:55:33<3:13:17, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 400 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 134270/300584 [2:55:53<2:52:42, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 401 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 134603/300584 [2:56:13<2:49:38, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 402 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 134938/300584 [2:56:34<3:11:37, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 403 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 135273/300584 [2:56:54<3:31:50, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 404 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 135608/300584 [2:57:14<2:47:28, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 405 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 135939/300584 [2:57:35<3:09:57, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 406 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 136274/300584 [2:57:55<3:08:44, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 407 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 136610/300584 [2:58:17<2:46:35, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 408 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 136943/300584 [2:58:37<3:02:09, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 409 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 137276/300584 [2:58:59<3:06:36, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 410 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 137610/300584 [2:59:19<3:00:21, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 411 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 137945/300584 [2:59:39<3:20:54, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 412 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 138279/300584 [3:00:00<2:53:22, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 413 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 138612/300584 [3:00:20<3:15:49, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 414 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 138947/300584 [3:00:42<3:30:07, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 415 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▋     | 139280/300584 [3:01:01<2:44:24, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 416 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▋     | 139614/300584 [3:01:22<2:28:04, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 417 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 139948/300584 [3:01:41<2:39:52, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 418 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 140282/300584 [3:02:01<3:10:47, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 419 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 140617/300584 [3:02:20<3:03:09, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 420 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 140949/300584 [3:02:39<2:37:38, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 421 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 141284/300584 [3:02:59<2:58:47, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 422 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 141618/300584 [3:03:18<2:06:28, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 423 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 141952/300584 [3:03:38<2:45:51, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 424 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 142286/300584 [3:03:58<2:59:25, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 425 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 142618/300584 [3:04:20<3:20:57, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 426 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 142955/300584 [3:04:42<3:16:48, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 427 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 143287/300584 [3:05:03<3:13:38, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 428 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 143622/300584 [3:05:24<2:43:55, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 429 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 143957/300584 [3:05:45<2:47:32, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 430 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 144289/300584 [3:06:04<3:08:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 431 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 144625/300584 [3:06:25<3:17:30, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 432 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 144957/300584 [3:06:46<3:07:40, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 433 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 145294/300584 [3:07:06<2:35:12, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 434 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 145626/300584 [3:07:25<2:38:41, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 435 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▊     | 145960/300584 [3:07:47<2:59:46, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 436 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▊     | 146294/300584 [3:08:08<3:19:57, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 437 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 146629/300584 [3:08:28<2:45:18, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 438 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 146963/300584 [3:08:48<2:23:30, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 439 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 147297/300584 [3:09:09<2:19:16, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 440 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 147630/300584 [3:09:32<3:24:57, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 441 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 147963/300584 [3:09:58<4:58:54,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 442 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 148298/300584 [3:10:24<3:39:18, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 443 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 148634/300584 [3:10:46<2:44:52, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 444 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 148965/300584 [3:11:10<2:59:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 445 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 149300/300584 [3:11:33<3:46:43, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 446 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 149635/300584 [3:11:55<3:12:52, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 447 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 149968/300584 [3:12:16<3:08:00, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 448 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 150303/300584 [3:12:37<2:54:13, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 449 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 150635/300584 [3:12:57<2:45:13, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 450 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 150970/300584 [3:13:18<2:51:01, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 451 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 151304/300584 [3:13:39<2:26:25, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 452 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 151637/300584 [3:13:59<2:53:25, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 453 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 151972/300584 [3:14:20<3:17:08, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 454 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 152307/300584 [3:14:41<2:23:06, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 455 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 152640/300584 [3:15:00<2:20:58, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 456 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 152975/300584 [3:15:21<2:45:23, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 457 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 153309/300584 [3:15:42<2:25:12, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 458 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 153643/300584 [3:16:02<2:33:11, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 459 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 153975/300584 [3:16:24<2:51:30, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 460 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████▏    | 154310/300584 [3:16:45<2:32:14, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 461 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████▏    | 154644/300584 [3:17:06<2:37:08, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 462 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 154978/300584 [3:17:29<2:44:00, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 463 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 155314/300584 [3:17:49<2:02:30, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 464 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 155647/300584 [3:18:10<2:15:34, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 465 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 155979/300584 [3:18:30<3:03:55, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 466 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 156313/300584 [3:18:50<2:39:16, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 467 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 156648/300584 [3:19:10<2:50:57, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 468 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 156983/300584 [3:19:30<2:19:08, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 469 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 157317/300584 [3:19:49<2:02:29, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 470 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 157649/300584 [3:20:10<3:08:53, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 471 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 157984/300584 [3:20:32<3:27:44, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 472 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 158318/300584 [3:20:54<2:36:01, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 473 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 158649/300584 [3:21:15<1:54:07, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 474 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 158988/300584 [3:21:36<2:25:02, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 475 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 159320/300584 [3:22:00<2:25:49, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 476 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 159653/300584 [3:22:22<3:16:00, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 477 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 159989/300584 [3:22:43<2:59:41, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 478 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 160323/300584 [3:23:05<2:38:35, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 479 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 160656/300584 [3:23:26<2:34:19, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 480 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▎    | 160989/300584 [3:23:46<2:33:39, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 481 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▎    | 161323/300584 [3:24:08<2:55:59, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 482 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 161659/300584 [3:24:29<2:42:37, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 483 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 161992/300584 [3:24:52<2:35:32, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 484 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 162326/300584 [3:25:17<3:16:19, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 485 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 162660/300584 [3:25:39<3:28:13, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 486 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 162993/300584 [3:26:02<3:22:31, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 487 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 163328/300584 [3:26:25<2:17:21, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 488 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 163661/300584 [3:26:47<2:36:50, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 489 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 163997/300584 [3:27:08<2:18:42, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 490 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 164329/300584 [3:27:29<1:58:02, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 491 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 164664/300584 [3:27:49<2:03:03, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 492 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 164997/300584 [3:28:08<2:21:02, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 493 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 165334/300584 [3:28:29<1:58:17, 19.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 494 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 165665/300584 [3:28:49<2:28:25, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 495 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 166000/300584 [3:29:11<2:32:08, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 496 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 166335/300584 [3:29:31<2:39:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 497 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 166668/300584 [3:29:51<1:57:30, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 498 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 167002/300584 [3:30:12<2:13:36, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 499 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 167336/300584 [3:30:33<2:51:30, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 500 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 167672/300584 [3:30:54<2:13:19, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 501 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 168005/300584 [3:31:13<2:03:43, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 502 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 168338/300584 [3:31:34<2:10:35, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 503 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 168672/300584 [3:31:56<2:40:38, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 504 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 169007/300584 [3:32:20<2:33:36, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 505 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▋    | 169340/300584 [3:32:42<2:46:08, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 506 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▋    | 169674/300584 [3:33:08<3:34:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 507 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 170008/300584 [3:33:35<3:58:30,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 508 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 170343/300584 [3:34:01<2:49:24, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 509 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 170675/300584 [3:34:26<2:37:54, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 510 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 171009/300584 [3:34:54<3:03:14, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 511 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 171343/300584 [3:35:20<2:40:22, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 512 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 171677/300584 [3:35:47<2:58:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 513 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 172011/300584 [3:36:14<3:42:54,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 514 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 172345/300584 [3:36:40<2:42:39, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 515 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 172679/300584 [3:37:07<3:25:43, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 516 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 173013/300584 [3:37:37<4:20:06,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 517 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 173348/300584 [3:38:09<2:48:36, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 518 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 173683/300584 [3:38:38<2:43:21, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 519 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 174017/300584 [3:39:04<2:32:43, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 520 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 174349/300584 [3:39:32<3:25:18, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 521 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 174683/300584 [3:40:02<3:24:20, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 522 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 175018/300584 [3:40:30<3:22:23, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 523 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 175351/300584 [3:40:59<3:04:19, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 524 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 175687/300584 [3:41:29<3:03:16, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 525 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▊    | 176019/300584 [3:41:58<2:55:55, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 526 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▊    | 176354/300584 [3:42:26<2:55:48, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 527 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 176688/300584 [3:42:52<2:39:03, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 528 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 177024/300584 [3:43:19<2:30:54, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 529 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 177356/300584 [3:43:44<2:38:48, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 530 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 177690/300584 [3:44:11<3:18:37, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 531 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 178024/300584 [3:44:38<3:12:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 532 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 178357/300584 [3:45:04<3:40:42,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 533 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 178692/300584 [3:45:31<3:51:42,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 534 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 179026/300584 [3:45:57<3:00:18, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 535 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 179358/300584 [3:46:22<2:48:43, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 536 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 179695/300584 [3:46:50<2:30:04, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 537 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 180026/300584 [3:47:18<2:41:23, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 538 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 180361/300584 [3:47:45<3:43:36,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 539 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 180696/300584 [3:48:14<3:51:10,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 540 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 181029/300584 [3:48:40<3:20:15,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 541 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 181364/300584 [3:49:06<3:12:32, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 542 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 181696/300584 [3:49:34<3:54:50,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 543 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 182031/300584 [3:50:02<2:58:23, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 544 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 182364/300584 [3:50:30<6:00:51,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 545 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 182702/300584 [3:50:58<3:06:15, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 546 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 183033/300584 [3:51:25<3:18:11,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 547 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 183369/300584 [3:51:52<3:11:43, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 548 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 183703/300584 [3:52:22<3:34:21,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 549 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 184036/300584 [3:52:51<4:01:59,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 550 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████▏   | 184370/300584 [3:53:21<3:33:51,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 551 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████▏   | 184704/300584 [3:53:52<3:35:45,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 552 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 185037/300584 [3:54:20<4:13:52,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 553 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 185371/300584 [3:54:50<3:37:42,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 554 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 185705/300584 [3:55:22<3:43:37,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 555 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 186039/300584 [3:55:51<2:09:02, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 556 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 186374/300584 [3:56:18<2:16:37, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 557 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 186708/300584 [3:56:45<2:45:59, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 558 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 187043/300584 [3:57:12<2:15:04, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 559 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 187376/300584 [3:57:37<2:26:04, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 560 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 187711/300584 [3:58:04<2:19:41, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 561 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 188044/300584 [3:58:31<2:20:16, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 562 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 188378/300584 [3:58:57<2:07:10, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 563 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 188711/300584 [3:59:23<3:03:54, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 564 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 189046/300584 [3:59:48<2:21:13, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 565 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 189378/300584 [4:00:13<2:47:51, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 566 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 189714/300584 [4:00:40<2:11:35, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 567 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 190048/300584 [4:01:04<1:54:16, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 568 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 190382/300584 [4:01:30<2:23:23, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 569 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 190717/300584 [4:01:59<1:53:42, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 570 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▎   | 191049/300584 [4:02:25<3:03:17,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 571 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▎   | 191386/300584 [4:02:50<2:14:04, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 572 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 191718/300584 [4:03:19<2:47:13, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 573 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 192051/300584 [4:03:48<3:37:16,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 574 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 192387/300584 [4:04:17<2:24:42, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 575 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 192721/300584 [4:04:45<2:19:23, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 576 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 193053/300584 [4:05:11<2:39:13, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 577 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 193387/300584 [4:05:37<2:31:19, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 578 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 193722/300584 [4:06:05<2:32:16, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 579 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 194056/300584 [4:06:30<2:16:10, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 580 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 194388/300584 [4:06:56<2:35:46, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 581 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 194722/300584 [4:07:26<2:08:48, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 582 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 195056/300584 [4:07:55<3:30:22,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 583 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 195391/300584 [4:08:22<2:42:12, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 584 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 195726/300584 [4:08:51<2:48:38, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 585 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 196060/300584 [4:09:18<2:07:17, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 586 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 196393/300584 [4:09:42<2:01:34, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 587 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 196726/300584 [4:10:07<2:10:40, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 588 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 197062/300584 [4:10:32<2:18:29, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 589 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 197397/300584 [4:10:55<1:52:08, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 590 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 197731/300584 [4:11:16<1:55:14, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 591 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 198063/300584 [4:11:39<2:07:59, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 592 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 198398/300584 [4:12:00<2:12:27, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 593 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 198731/300584 [4:12:19<2:20:20, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 594 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 199066/300584 [4:12:39<1:50:07, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 595 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▋   | 199400/300584 [4:13:01<2:16:37, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 596 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▋   | 199736/300584 [4:13:20<1:40:11, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 597 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 200068/300584 [4:13:42<2:26:57, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 598 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 200403/300584 [4:14:01<1:51:50, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 599 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 200738/300584 [4:14:19<1:54:25, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 600 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 201070/300584 [4:14:37<1:37:35, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 601 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 201403/300584 [4:14:56<2:23:07, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 602 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 201739/300584 [4:15:16<1:38:44, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 603 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 202074/300584 [4:15:37<1:51:14, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 604 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 202406/300584 [4:15:57<2:05:58, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 605 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 202739/300584 [4:16:18<2:01:45, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 606 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 203075/300584 [4:16:41<1:53:30, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 607 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 203408/300584 [4:17:02<2:10:01, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 608 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 203742/300584 [4:17:26<2:02:05, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 609 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 204077/300584 [4:17:48<1:51:54, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 610 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 204410/300584 [4:18:12<2:04:11, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 611 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 204745/300584 [4:18:34<1:40:41, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 612 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 205077/300584 [4:18:55<2:18:20, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 613 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 205411/300584 [4:19:19<2:16:48, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 614 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 205745/300584 [4:19:43<2:38:53,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 615 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▊   | 206080/300584 [4:20:06<2:08:05, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 616 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▊   | 206415/300584 [4:20:32<1:41:22, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 617 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 206748/300584 [4:20:52<1:37:12, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 618 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 207084/300584 [4:21:12<2:06:39, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 619 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 207415/300584 [4:21:32<2:11:09, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 620 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 207749/300584 [4:21:54<1:44:08, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 621 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 208083/300584 [4:22:15<1:50:46, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 622 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 208419/300584 [4:22:37<1:34:25, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 623 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 208751/300584 [4:22:56<1:18:22, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 624 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 209086/300584 [4:23:17<1:48:30, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 625 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 209420/300584 [4:23:42<2:05:08, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 626 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 209752/300584 [4:24:07<1:28:08, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 627 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 210087/300584 [4:24:32<2:14:56, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 628 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 210422/300584 [4:24:58<2:44:32,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 629 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 210756/300584 [4:25:23<2:47:45,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 630 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 211089/300584 [4:25:45<2:38:01,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 631 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 211425/300584 [4:26:08<1:48:35, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 632 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 211757/300584 [4:26:34<2:16:54, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 633 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 212092/300584 [4:27:03<2:22:31, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 634 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 212425/300584 [4:27:28<1:42:44, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 635 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 212759/300584 [4:27:50<1:48:20, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 636 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 213095/300584 [4:28:10<1:21:51, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 637 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 213429/300584 [4:28:31<1:30:11, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 638 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 213761/300584 [4:28:53<1:45:39, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 639 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 214098/300584 [4:29:15<1:26:30, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 640 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████▏  | 214429/300584 [4:29:38<2:06:55, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 641 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████▏  | 214766/300584 [4:29:59<1:15:39, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 642 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 215099/300584 [4:30:20<1:29:04, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 643 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 215430/300584 [4:30:43<2:02:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 644 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 215766/300584 [4:31:06<2:07:54, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 645 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 216101/300584 [4:31:28<1:32:15, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 646 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 216434/300584 [4:31:52<1:29:22, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 647 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 216767/300584 [4:32:13<1:27:09, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 648 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 217104/300584 [4:32:33<1:27:12, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 649 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 217434/300584 [4:32:58<1:46:32, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 650 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 217769/300584 [4:33:23<1:49:50, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 651 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 218105/300584 [4:33:47<1:50:48, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 652 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 218437/300584 [4:34:12<1:55:14, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 653 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 218771/300584 [4:34:36<1:54:51, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 654 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 219105/300584 [4:35:02<2:06:10, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 655 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 219440/300584 [4:35:33<1:55:53, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 656 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 219773/300584 [4:36:00<2:28:42,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 657 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 220107/300584 [4:36:26<1:44:18, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 658 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 220441/300584 [4:36:54<2:08:20, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 659 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 220775/300584 [4:37:19<1:36:44, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 660 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▎  | 221109/300584 [4:37:42<1:33:01, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 661 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▎  | 221443/300584 [4:38:08<1:39:49, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 662 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 221779/300584 [4:38:31<1:16:28, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 663 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 222111/300584 [4:38:54<2:01:45, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 664 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 222446/300584 [4:39:19<1:23:42, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 665 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 222779/300584 [4:39:39<1:46:12, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 666 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 223114/300584 [4:40:03<1:37:10, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 667 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 223447/300584 [4:40:26<1:29:31, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 668 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 223784/300584 [4:40:49<1:12:55, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 669 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 224117/300584 [4:41:11<1:06:19, 19.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 670 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 224450/300584 [4:41:35<1:32:56, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 671 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 224784/300584 [4:41:57<1:36:33, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 672 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 225118/300584 [4:42:18<1:24:45, 14.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 673 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 225452/300584 [4:42:42<1:18:18, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 674 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 225785/300584 [4:43:06<1:44:41, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 675 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 226119/300584 [4:43:29<2:02:59, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 676 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 226454/300584 [4:43:52<1:15:57, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 677 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 226789/300584 [4:44:13<1:18:58, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 678 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 227121/300584 [4:44:33<1:40:48, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 679 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 227455/300584 [4:44:57<1:43:14, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 680 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 227790/300584 [4:45:22<1:25:29, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 681 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 228125/300584 [4:45:46<1:27:52, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 682 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 228458/300584 [4:46:09<1:15:47, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 683 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 228795/300584 [4:46:28<55:43, 21.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 684 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 229126/300584 [4:46:47<1:11:25, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 685 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▋  | 229461/300584 [4:47:09<1:19:27, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 686 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▋  | 229794/300584 [4:47:30<1:04:11, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 687 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 230130/300584 [4:47:50<1:22:49, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 688 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 230462/300584 [4:48:14<1:19:20, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 689 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 230796/300584 [4:48:35<1:22:06, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 690 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 231130/300584 [4:48:57<1:25:19, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 691 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 231464/300584 [4:49:21<1:40:40, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 692 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 231798/300584 [4:49:44<1:32:05, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 693 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 232131/300584 [4:50:10<1:28:13, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 694 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 232466/300584 [4:50:34<1:20:49, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 695 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 232800/300584 [4:50:55<1:16:47, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 696 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 233133/300584 [4:51:17<1:38:09, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 697 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 233467/300584 [4:51:42<1:33:16, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 698 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 233801/300584 [4:52:05<1:34:31, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 699 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 234135/300584 [4:52:30<1:48:14, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 700 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 234470/300584 [4:52:56<1:32:33, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 701 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 234803/300584 [4:53:17<1:27:26, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 702 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 235138/300584 [4:53:39<1:12:27, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 703 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 235473/300584 [4:54:04<1:03:35, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 704 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 235805/300584 [4:54:28<1:16:59, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 705 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▊  | 236138/300584 [4:54:52<1:24:46, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 706 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▊  | 236473/300584 [4:55:15<1:10:33, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 707 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 236808/300584 [4:55:35<1:12:35, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 708 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 237142/300584 [4:55:57<1:25:00, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 709 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 237477/300584 [4:56:21<1:04:49, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 710 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 237810/300584 [4:56:43<1:06:04, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 711 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 238142/300584 [4:57:09<1:17:52, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 712 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 238477/300584 [4:57:32<58:45, 17.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 713 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 238811/300584 [4:57:51<1:08:41, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 714 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 239147/300584 [4:58:12<59:59, 17.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 715 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 239479/300584 [4:58:36<1:33:38, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 716 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 239815/300584 [4:58:59<1:08:42, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 717 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 240148/300584 [4:59:24<1:27:17, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 718 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 240481/300584 [4:59:47<1:17:51, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 719 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 240816/300584 [5:00:08<1:21:32, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 720 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 241150/300584 [5:00:31<1:07:28, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 721 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 241482/300584 [5:00:56<1:28:56, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 722 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 241818/300584 [5:01:21<58:53, 16.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 723 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 242152/300584 [5:01:46<1:14:22, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 724 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 242486/300584 [5:02:11<1:10:38, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 725 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 242820/300584 [5:02:33<1:09:00, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 726 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 243153/300584 [5:02:58<1:28:33, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 727 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 243487/300584 [5:03:25<1:27:40, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 728 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 243823/300584 [5:03:49<1:02:27, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 729 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 244156/300584 [5:04:16<1:18:16, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 730 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████▏ | 244491/300584 [5:04:38<54:40, 17.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 731 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████▏ | 244826/300584 [5:04:58<52:21, 17.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 732 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 245157/300584 [5:05:18<1:04:46, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 733 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 245492/300584 [5:05:40<56:47, 16.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 734 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 245827/300584 [5:06:02<55:52, 16.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 735 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 246159/300584 [5:06:25<1:15:16, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 736 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 246493/300584 [5:06:47<52:32, 17.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 737 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 246829/300584 [5:07:08<46:09, 19.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 738 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 247161/300584 [5:07:29<1:14:44, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 739 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 247495/300584 [5:07:53<1:08:55, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 740 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 247830/300584 [5:08:14<1:01:41, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 741 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 248163/300584 [5:08:38<1:16:49, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 742 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 248499/300584 [5:08:58<57:10, 15.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 743 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 248832/300584 [5:09:17<56:10, 15.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 744 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 249166/300584 [5:09:37<51:13, 16.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 745 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 249499/300584 [5:10:00<57:11, 14.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 746 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 249833/300584 [5:10:21<1:04:26, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 747 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 250168/300584 [5:10:45<1:06:43, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 748 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 250503/300584 [5:11:07<52:38, 15.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 749 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 250837/300584 [5:11:28<1:03:03, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 750 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▎ | 251170/300584 [5:11:49<1:03:25, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 751 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▎ | 251504/300584 [5:12:13<1:11:33, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 752 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 251837/300584 [5:12:35<1:03:58, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 753 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 252171/300584 [5:13:00<1:45:20,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 754 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 252505/300584 [5:13:35<2:08:59,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 755 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 252840/300584 [5:14:03<1:00:41, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 756 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 253174/300584 [5:14:29<1:05:46, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 757 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 253508/300584 [5:14:57<1:00:06, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 758 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 253841/300584 [5:15:24<1:25:51,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 759 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 254176/300584 [5:15:52<1:10:30, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 760 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 254509/300584 [5:16:17<59:16, 12.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 761 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 254843/300584 [5:16:41<1:05:26, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 762 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 255179/300584 [5:17:06<1:55:08,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 763 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 255511/300584 [5:17:32<1:06:32, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 764 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 255845/300584 [5:17:58<1:40:52,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 765 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 256180/300584 [5:18:25<1:12:04, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 766 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 256515/300584 [5:18:52<1:12:34, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 767 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 256848/300584 [5:19:18<1:17:23,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 768 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 257181/300584 [5:19:45<1:13:30,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 769 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 257516/300584 [5:20:15<1:15:46,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 770 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 257850/300584 [5:20:44<1:18:00,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 771 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 258183/300584 [5:21:14<1:08:51, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 772 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 258519/300584 [5:21:42<53:09, 13.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 773 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 258851/300584 [5:22:09<1:05:11, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 774 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 259186/300584 [5:22:39<1:05:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 775 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▋ | 259519/300584 [5:23:09<1:34:41,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 776 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▋ | 259852/300584 [5:23:38<1:16:29,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 777 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 260187/300584 [5:24:09<1:17:27,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 778 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 260520/300584 [5:24:39<55:38, 12.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 779 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 260855/300584 [5:25:10<1:28:39,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 780 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 261189/300584 [5:25:39<1:01:52, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 781 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 261524/300584 [5:26:08<50:14, 12.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 782 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 261860/300584 [5:26:36<55:48, 11.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 783 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 262191/300584 [5:27:04<1:34:47,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 784 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 262525/300584 [5:27:37<1:24:19,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 785 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 262859/300584 [5:28:10<1:19:51,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 786 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 263193/300584 [5:28:42<52:01, 11.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 787 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 263528/300584 [5:29:08<44:30, 13.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 788 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 263862/300584 [5:29:31<42:19, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 789 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 264196/300584 [5:29:55<48:25, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 790 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 264531/300584 [5:30:21<51:21, 11.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 791 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 264864/300584 [5:30:47<43:41, 13.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 792 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 265198/300584 [5:31:12<41:53, 14.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 793 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 265533/300584 [5:31:36<58:07, 10.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 794 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 265867/300584 [5:32:00<47:09, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 795 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▊ | 266202/300584 [5:32:23<44:17, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 796 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▊ | 266533/300584 [5:32:46<43:55, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 797 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 266869/300584 [5:33:08<38:54, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 798 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 267204/300584 [5:33:30<36:15, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 799 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 267537/300584 [5:33:50<39:56, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 800 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 267869/300584 [5:34:09<36:10, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 801 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 268204/300584 [5:34:30<46:38, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 802 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 268538/300584 [5:34:54<54:13,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 803 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 268873/300584 [5:35:17<38:54, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 804 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 269207/300584 [5:35:40<38:17, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 805 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 269540/300584 [5:36:02<36:20, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 806 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 269875/300584 [5:36:24<36:54, 13.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 807 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 270209/300584 [5:36:46<40:28, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 808 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 270541/300584 [5:37:07<37:54, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 809 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 270876/300584 [5:37:28<28:54, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 810 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 271212/300584 [5:37:49<33:43, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 811 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 271543/300584 [5:38:08<32:56, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 812 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 271879/300584 [5:38:28<29:22, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 813 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 272211/300584 [5:38:49<37:31, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 814 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 272544/300584 [5:39:14<53:17,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 815 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 272879/300584 [5:39:37<37:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 816 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 273214/300584 [5:39:58<27:15, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 817 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 273549/300584 [5:40:19<41:27, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 818 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 273881/300584 [5:40:40<32:19, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 819 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 274217/300584 [5:41:00<28:45, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 820 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████▏| 274551/300584 [5:41:19<29:21, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 821 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████▏| 274885/300584 [5:41:42<39:14, 10.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 822 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 275218/300584 [5:42:05<26:48, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 823 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 275552/300584 [5:42:28<36:45, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 824 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 275887/300584 [5:42:53<29:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 825 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 276220/300584 [5:43:15<29:27, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 826 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 276554/300584 [5:43:38<28:51, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 827 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 276887/300584 [5:44:02<29:02, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 828 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 277222/300584 [5:44:25<30:20, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 829 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 277555/300584 [5:44:51<29:21, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 830 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 277889/300584 [5:45:15<33:05, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 831 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 278223/300584 [5:45:37<30:45, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 832 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 278559/300584 [5:45:59<27:02, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 833 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 278892/300584 [5:46:21<24:11, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 834 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 279226/300584 [5:46:44<33:05, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 835 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 279560/300584 [5:47:05<24:00, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 836 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 279895/300584 [5:47:25<22:42, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 837 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 280228/300584 [5:47:45<20:18, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 838 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 280563/300584 [5:48:05<21:07, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 839 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 280894/300584 [5:48:26<21:17, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 840 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▎| 281230/300584 [5:48:49<24:32, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 841 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▎| 281564/300584 [5:49:13<31:13, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 842 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 281898/300584 [5:49:36<21:39, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 843 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 282233/300584 [5:49:58<20:02, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 844 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 282567/300584 [5:50:19<19:26, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 845 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 282899/300584 [5:50:43<21:15, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 846 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 283232/300584 [5:51:08<33:27,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 847 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 283567/300584 [5:51:34<22:27, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 848 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 283901/300584 [5:51:58<26:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 849 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 284236/300584 [5:52:23<28:45,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 850 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 284569/300584 [5:52:47<22:25, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 851 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 284905/300584 [5:53:08<17:46, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 852 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 285238/300584 [5:53:28<16:48, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 853 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 285573/300584 [5:53:49<16:12, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 854 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 285906/300584 [5:54:08<17:41, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 855 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 286240/300584 [5:54:28<14:58, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 856 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 286574/300584 [5:54:47<17:08, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 857 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 286907/300584 [5:55:08<15:47, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 858 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 287241/300584 [5:55:31<21:13, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 859 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 287577/300584 [5:55:53<12:43, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 860 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 287910/300584 [5:56:14<18:05, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 861 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 288244/300584 [5:56:35<12:00, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 862 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 288577/300584 [5:56:54<13:46, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 863 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 288913/300584 [5:57:16<14:42, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 864 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 289246/300584 [5:57:38<13:29, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 865 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▋| 289580/300584 [5:58:00<14:15, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 866 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▋| 289915/300584 [5:58:22<12:19, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 867 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 290250/300584 [5:58:43<10:16, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 868 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 290582/300584 [5:59:04<10:17, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 869 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 290917/300584 [5:59:25<10:19, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 870 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 291251/300584 [5:59:46<08:43, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 871 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 291584/300584 [6:00:08<10:29, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 872 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 291918/300584 [6:00:28<08:03, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 873 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 292252/300584 [6:00:49<10:11, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 874 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 292586/300584 [6:01:10<10:18, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 875 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 292921/300584 [6:01:31<07:51, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 876 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 293253/300584 [6:01:51<08:14, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 877 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 293589/300584 [6:02:12<06:47, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 878 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 293923/300584 [6:02:32<06:43, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 879 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 294257/300584 [6:02:52<06:36, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 880 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 294591/300584 [6:03:12<07:03, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 881 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 294922/300584 [6:03:36<06:22, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 882 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 295258/300584 [6:04:00<07:26, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 883 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 295592/300584 [6:04:23<05:22, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 884 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 295927/300584 [6:04:42<03:58, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 885 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▊| 296259/300584 [6:05:01<04:19, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 886 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▊| 296596/300584 [6:05:20<03:36, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 887 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 296927/300584 [6:05:42<04:29, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 888 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 297261/300584 [6:06:03<04:17, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 889 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 297596/300584 [6:06:25<03:35, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 890 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 297929/300584 [6:06:46<02:31, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 891 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 298265/300584 [6:07:07<02:55, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 892 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 298598/300584 [6:07:28<02:20, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 893 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 298931/300584 [6:07:50<01:47, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 894 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 299266/300584 [6:08:12<01:28, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 895 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 299600/300584 [6:08:35<01:12, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 896 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 299934/300584 [6:08:57<00:41, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 897 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 300268/300584 [6:09:19<00:24, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 898 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|██████████| 300584/300584 [6:09:40<00:00, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막 배치 899 저장 완료 - 954개\n",
      "전체 MFCC 추출 및 저장 작업 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 입력 및 출력 경로 설정\n",
    "csv_path = \"./data/usou/metadata_4class.csv\"\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. 오디오 및 MFCC 관련 설정\n",
    "n_mfcc = 40                     # 추출할 MFCC 계수 수\n",
    "max_len = 300                  # MFCC 길이 고정값\n",
    "n_augment = 2                  # 증강 횟수 (원본 포함 총 3배)\n",
    "batch_size = 1000              # 배치 저장 단위\n",
    "\n",
    "# 3. 데이터프레임 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 4. 증강 파이프라인 설정\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.7),\n",
    "    TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    Shift(min_shift=-0.2, max_shift=0.2, p=0.5)\n",
    "])\n",
    "\n",
    "# 5. MFCC 추출 함수 정의\n",
    "def extract_mfcc(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "\n",
    "# 6. 배치별로 데이터를 저장하기 위한 변수 초기화\n",
    "mfcc_batch = []\n",
    "label_batch = []\n",
    "batch_index = 0\n",
    "\n",
    "# 7. tqdm을 이용해 전체 진행 상황 표시\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"MFCC 추출 및 증강\"):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    emotion = row[\"emotion\"]\n",
    "\n",
    "    try:\n",
    "        # 원본 로딩\n",
    "        y, sr = librosa.load(wav_path, sr=16000)\n",
    "\n",
    "        # 원본 MFCC 저장\n",
    "        mfcc_batch.append(extract_mfcc(y, sr))\n",
    "        label_batch.append(emotion)\n",
    "\n",
    "        # 증강 MFCC 저장\n",
    "        for _ in range(n_augment):\n",
    "            y_aug = augment(samples=y, sample_rate=sr)\n",
    "            mfcc_batch.append(extract_mfcc(y_aug, sr))\n",
    "            label_batch.append(emotion)\n",
    "\n",
    "        # 일정 크기의 배치가 모이면 저장 후 초기화\n",
    "        if len(mfcc_batch) >= batch_size:\n",
    "            np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "            np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "            print(f\"배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "            batch_index += 1\n",
    "            mfcc_batch.clear()\n",
    "            label_batch.clear()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {wav_path} → {e}\")\n",
    "        continue\n",
    "\n",
    "# 8. 마지막에 남은 배치도 저장\n",
    "if mfcc_batch:\n",
    "    np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "    np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "    print(f\"마지막 배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "\n",
    "print(\"전체 MFCC 추출 및 저장 작업 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 수집된 검증 샘플 수: 300584\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 검증 데이터의 JSON 폴더 경로 (변경 필요)\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "wav_root   = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "save_dir = \"./data/usou\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "target_classes = ['Happy', 'Sad', 'Angry', 'Neutrality']\n",
    "\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if not file_name.endswith(\".json\"):\n",
    "            continue\n",
    "        json_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                content = json.load(f)\n",
    "\n",
    "            emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "            if emotion not in target_classes:\n",
    "                continue\n",
    "\n",
    "            style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "            sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "            wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "            relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "            relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "            wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "            if os.path.exists(wav_path):\n",
    "                data.append({\n",
    "                    \"wav_path\": wav_path,\n",
    "                    \"emotion\": emotion,\n",
    "                    \"style\": style,\n",
    "                    \"sensitivity\": sensitivity\n",
    "                })\n",
    "            else:\n",
    "                broken_files.append(wav_path)\n",
    "        except Exception as e:\n",
    "            broken_files.append(json_path)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_4class_val.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(save_dir, \"broken_files_val.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(\"총 수집된 검증 샘플 수:\", len(df))\n",
    "print(\"에러 발생 수:\", len(broken_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검증용 MFCC 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# ✅ CNN 모델 정의 함수 호출\n",
    "model = build_cnn_model()\n",
    "\n",
    "# ✅ 하이퍼파라미터\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 30\n",
    "\n",
    "# ✅ 학습 데이터 경로\n",
    "train_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "train_label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "\n",
    "# ✅ 검증 데이터 배치 파일들이 저장된 경로\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"\n",
    "val_mfcc_files = sorted(glob.glob(os.path.join(val_dir, \"mfcc_val_batch_*.npy\")))\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "# ✅ 검증 데이터 로딩\n",
    "val_x = np.concatenate([np.load(f) for f in val_mfcc_files], axis=0)\n",
    "val_y = np.concatenate([np.load(f) for f in val_label_files], axis=0)\n",
    "\n",
    "# ✅ 학습용 배치 제너레이터\n",
    "def data_generator(mfcc_dir, label_dir, batch_size):\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)\n",
    "            y = np.load(label_file)\n",
    "            for i in range(0, len(x), batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "# ✅ 콜백 설정\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/model_ckpt/best_model_voice_emotion_analysis.keras\"\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "\n",
    "# ✅ 전체 학습 스텝 계산\n",
    "train_steps = sum([np.load(f).shape[0] for f in glob.glob(os.path.join(train_label_dir, \"label_batch_*.npy\"))]) // BATCH_SIZE\n",
    "\n",
    "# ✅ 모델 학습 시작\n",
    "model.fit(\n",
    "    data_generator(train_mfcc_dir, train_label_dir, BATCH_SIZE),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train, Validation 라벨 인코딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터의 모든 배치 레이블을 모아서 LabelEncoder를 fit 합니다.\n",
    "- label_encoder.pkl로 저장하여 나중에 복원 가능하게 합니다.\n",
    "- 학습 데이터와 검증 데이터 모두 동일한 인코더로 인코딩하여 일관성 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 레이블 수집:   0%|          | 0/900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 레이블 수집: 100%|██████████| 900/900 [00:00<00:00, 6233.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder 저장 완료: /media/usou/PortableSSD/mldl_project/data4class_batches/voice_label_encoder.pkl\n",
      "클래스 목록: [0 1 2 3]\n",
      "학습용 레이블 인코딩 완료\n",
      "검증 배치 0는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 1는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 2는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 3는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 4는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 5는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 6는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 7는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 8는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 9는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 10는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 11는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 12는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 13는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 14는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 15는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 16는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 17는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 18는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 19는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 20는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 21는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 22는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 23는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 24는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 25는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 26는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 27는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 28는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 29는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 30는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 31는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 32는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 33는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 34는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 35는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 36는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 37는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 38는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 39는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 40는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 41는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 42는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 43는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 44는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 45는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 46는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 47는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 48는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 49는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 50는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 51는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 52는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 53는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 54는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 55는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 56는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 57는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 58는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 59는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 60는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 61는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 62는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 63는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 64는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 65는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 66는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 67는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 68는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 69는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 70는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 71는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 72는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 73는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 74는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 75는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 76는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 77는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 78는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 79는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 80는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 81는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 82는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 83는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 84는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 85는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 86는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 87는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 88는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 89는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 90는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 91는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 92는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 93는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 94는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 95는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 96는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 97는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 98는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 99는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 100는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 101는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 102는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 103는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 104는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 105는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 106는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 107는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 108는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 109는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 110는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 111는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 112는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 113는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 114는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 115는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 116는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 117는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 118는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 119는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 120는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 121는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 122는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 123는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 124는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 125는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 126는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 127는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 128는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 129는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 130는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 131는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 132는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 133는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 134는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 135는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 136는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 137는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 138는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 139는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 140는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 141는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 142는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 143는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 144는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 145는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 146는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 147는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 148는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 149는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 150는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 151는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 152는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 153는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 154는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 155는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 156는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 157는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 158는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 159는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 160는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 161는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 162는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 163는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 164는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 165는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 166는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 167는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 168는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 169는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 170는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 171는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 172는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 173는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 174는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 175는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 176는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 177는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 178는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 179는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 180는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 181는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 182는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 183는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 184는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 185는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 186는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 187는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 188는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 189는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 190는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 191는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 192는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 193는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 194는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 195는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 196는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 197는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 198는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 199는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 200는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 201는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 202는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 203는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 204는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 205는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 206는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 207는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 208는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 209는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 210는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 211는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 212는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 213는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 214는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 215는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 216는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 217는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 218는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 219는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 220는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 221는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 222는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 223는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 224는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 225는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 226는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 227는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 228는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 229는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 230는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 231는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 232는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 233는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 234는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 235는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 236는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 237는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 238는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 239는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 240는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 241는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 242는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 243는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 244는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 245는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 246는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 247는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 248는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 249는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 250는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 251는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 252는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 253는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 254는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 255는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 256는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 257는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 258는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 259는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 260는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 261는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 262는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 263는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 264는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 265는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 266는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 267는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 268는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 269는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 270는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 271는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 272는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 273는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 274는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 275는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 276는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 277는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 278는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 279는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 280는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 281는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 282는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 283는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 284는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 285는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 286는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 287는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 288는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 289는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 290는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 291는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 292는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 293는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 294는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 295는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 296는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 297는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 298는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 299는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 300는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증용 레이블 인코딩 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "train_label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"\n",
    "encoder_save_path = os.path.join(train_label_dir, \"voice_label_encoder.pkl\")\n",
    "\n",
    "# 학습용 레이블 로딩\n",
    "label_files = sorted([\n",
    "    f for f in os.listdir(train_label_dir)\n",
    "    if f.startswith(\"label_batch_\") and f.endswith(\".npy\")\n",
    "])\n",
    "\n",
    "all_labels = []\n",
    "label_batches = []\n",
    "\n",
    "for f in tqdm(label_files, desc=\"학습 레이블 수집\"):\n",
    "    labels = np.load(os.path.join(train_label_dir, f), allow_pickle=True)\n",
    "    label_batches.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# LabelEncoder 학습 및 저장\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "with open(encoder_save_path, \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"LabelEncoder 저장 완료:\", encoder_save_path)\n",
    "print(\"클래스 목록:\", label_encoder.classes_)\n",
    "\n",
    "# 학습용 인코딩 저장\n",
    "for i, labels in enumerate(label_batches):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    np.save(os.path.join(train_label_dir, f\"label_batch_{i}.npy\"), encoded)\n",
    "\n",
    "print(\"학습용 레이블 인코딩 완료\")\n",
    "\n",
    "# 검증용 인코딩\n",
    "val_label_files = sorted([\n",
    "    f for f in os.listdir(val_label_dir)\n",
    "    if f.startswith(\"label_val_batch_\") and f.endswith(\".npy\")\n",
    "])\n",
    "\n",
    "for i, f in enumerate(val_label_files):\n",
    "    path = os.path.join(val_label_dir, f)\n",
    "    labels = np.load(path, allow_pickle=True)\n",
    "\n",
    "    # 배열 전체의 dtype으로 판단 (보다 안전하게 처리)\n",
    "    if np.issubdtype(labels.dtype, np.str_):\n",
    "        try:\n",
    "            encoded = label_encoder.transform(labels)\n",
    "            np.save(path, encoded)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 검증 배치 {i} 인코딩 중 오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"검증 배치 {i}는 이미 숫자형으로 인코딩되어 있어 건너뜀\")\n",
    "\n",
    "print(\"검증용 레이블 인코딩 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 및 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import glob\n",
    "\n",
    "# GPU 메모리 과도할당 방지 설정\n",
    "# GPU 메모리를 사용할 만큼만 점진적으로 할당하도록 설정하여 OOM 방지\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 64           # 한 배치에 들어가는 샘플 수\n",
    "EPOCHS = 300              # 학습 반복 횟수\n",
    "PATIENCE = 30             # EarlyStopping이 참조할 patience 값\n",
    "\n",
    "# 데이터 디렉토리 경로 설정\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"           # 학습 데이터 배치 경로\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"         # 검증 데이터 배치 경로\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/model_ckpt/best_model_voice_emotion_analysis.keras\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow CNN 모델 정의 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 300, 1), num_classes=4):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델을 정의합니다.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (MFCC의 높이, 너비, 채널 수)\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        model (tf.keras.Model): 컴파일된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 완전 연결층\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # 과적합 방지용 드롭아웃\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "model = build_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습용 데이터 제너레이터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def data_generator(mfcc_dir, label_dir, batch_size):\n",
    "    \"\"\"\n",
    "    학습 데이터를 배치 단위로 로드하는 제너레이터 함수입니다.\n",
    "\n",
    "    Parameters:\n",
    "        mfcc_dir (str): MFCC 배치 파일 디렉토리\n",
    "        label_dir (str): 라벨 배치 파일 디렉토리\n",
    "        batch_size (int): 배치 크기\n",
    "\n",
    "    Yields:\n",
    "        Tuple of (x_batch, y_batch): 배치 단위의 입력과 정답\n",
    "    \"\"\"\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)\n",
    "            y = np.load(label_file)\n",
    "\n",
    "            # 데이터 길이 맞추기 (불일치 방지)\n",
    "            min_len = min(len(x), len(y))\n",
    "            x = x[:min_len]\n",
    "            y = y[:min_len]\n",
    "\n",
    "            # 채널 차원 추가\n",
    "            x = x[..., np.newaxis]  # (batch, 40, 300, 1)\n",
    "\n",
    "            for i in range(0, min_len, batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 shape: (3000, 40, 300, 1) (3000,)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# 셀 4. 안정적인 검증 데이터 로딩\n",
    "\n",
    "val_mfcc_files = sorted(glob.glob(os.path.join(val_dir, \"mfcc_val_batch_*.npy\")))\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "val_x_list, val_y_list = [], []\n",
    "\n",
    "# 너무 많은 파일을 한 번에 로드하지 않도록 제한\n",
    "max_files = 3  # 우선 3개 파일로 테스트 → 점진적으로 늘릴 수 있음\n",
    "\n",
    "for mfcc_file, label_file in zip(val_mfcc_files[:max_files], val_label_files[:max_files]):\n",
    "    x = np.load(mfcc_file, mmap_mode='r')[..., np.newaxis]  # 메모리 매핑으로 로딩 효율 개선\n",
    "    y = np.load(label_file, allow_pickle=True)\n",
    "    \n",
    "    val_x_list.append(x)\n",
    "    val_y_list.append(y)\n",
    "\n",
    "val_x = np.concatenate(val_x_list, axis=0)\n",
    "val_y = np.concatenate(val_y_list, axis=0)\n",
    "\n",
    "print(\"검증 데이터 shape:\", val_x.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743682332.209154   26837 service.cc:152] XLA service 0x7fd1dc002220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743682332.209578   26837 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-04-03 21:12:12.298548: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743682332.669803   26837 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-04-03 21:12:13.096315: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[64,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,40,300]{3,2,1,0} %bitcast.6075, f32[32,1,3,3]{3,2,1,0} %bitcast.6082, f32[32]{0} %bitcast.7058), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:13.184354: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[64,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,32,20,150]{3,2,1,0} %bitcast.7223, f32[64,32,3,3]{3,2,1,0} %bitcast.6157, f32[64]{0} %bitcast.7283), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:13.569306: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[64,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,10,75]{3,2,1,0} %bitcast.7449, f32[128,64,3,3]{3,2,1,0} %bitcast.6232, f32[128]{0} %bitcast.7509), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:14.212689: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:14.379634: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    5/14089\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:36\u001b[0m 37ms/step - accuracy: 0.6218 - loss: 1.2386 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743682337.550856   26837 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   15/14089\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:25\u001b[0m 32ms/step - accuracy: 0.8168 - loss: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:12:18.649738: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[42,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[42,1,40,300]{3,2,1,0} %bitcast.6075, f32[32,1,3,3]{3,2,1,0} %bitcast.6082, f32[32]{0} %bitcast.7058), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:18.662184: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[42,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[42,32,20,150]{3,2,1,0} %bitcast.7223, f32[64,32,3,3]{3,2,1,0} %bitcast.6157, f32[64]{0} %bitcast.7283), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:18.922032: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[42,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[42,64,10,75]{3,2,1,0} %bitcast.7449, f32[128,64,3,3]{3,2,1,0} %bitcast.6232, f32[128]{0} %bitcast.7509), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:19.432696: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:19.592934: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:20.383662: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:20.653420: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:20.911935: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12765/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m37s\u001b[0m 28ms/step - accuracy: 0.4891 - loss: 4.3896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:18:18.906775: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[58,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,1,40,300]{3,2,1,0} %bitcast.6075, f32[32,1,3,3]{3,2,1,0} %bitcast.6082, f32[32]{0} %bitcast.7058), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:18:18.940993: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[58,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,32,20,150]{3,2,1,0} %bitcast.7223, f32[64,32,3,3]{3,2,1,0} %bitcast.6157, f32[64]{0} %bitcast.7283), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:18:19.274469: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[58,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,64,10,75]{3,2,1,0} %bitcast.7449, f32[128,64,3,3]{3,2,1,0} %bitcast.6232, f32[128]{0} %bitcast.7509), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:18:19.867075: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:20.035184: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:20.911919: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:21.185970: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:21.458632: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:21.506758: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.3 = (f32[58,32,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,64,20,150]{3,2,1,0} %bitcast.7287, f32[64,32,3,3]{3,2,1,0} %bitcast.6157), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/sequential_1/conv2d_1_2/convolution/Conv2DBackpropInput\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-03 21:18:21.729967: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.004842: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.274539: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.550212: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.820847: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:23.093690: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:23.366832: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:23.383539: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.876351237s\n",
      "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.3 = (f32[58,32,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,64,20,150]{3,2,1,0} %bitcast.7287, f32[64,32,3,3]{3,2,1,0} %bitcast.6157), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/sequential_1/conv2d_1_2/convolution/Conv2DBackpropInput\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4829 - loss: 4.2140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:19:03.321099: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,40,300]{3,2,1,0} %bitcast.658, f32[32,1,3,3]{3,2,1,0} %bitcast.665, f32[32]{0} %bitcast.667), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:03.330652: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,20,150]{3,2,1,0} %bitcast.695, f32[64,32,3,3]{3,2,1,0} %bitcast.702, f32[64]{0} %bitcast.704), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:03.527905: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,10,75]{3,2,1,0} %bitcast.732, f32[128,64,3,3]{3,2,1,0} %bitcast.739, f32[128]{0} %bitcast.741), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:04.471919: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[24,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,1,40,300]{3,2,1,0} %bitcast.658, f32[32,1,3,3]{3,2,1,0} %bitcast.665, f32[32]{0} %bitcast.667), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:04.487801: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[24,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,32,20,150]{3,2,1,0} %bitcast.695, f32[64,32,3,3]{3,2,1,0} %bitcast.702, f32[64]{0} %bitcast.704), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:04.650035: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[24,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,64,10,75]{3,2,1,0} %bitcast.732, f32[128,64,3,3]{3,2,1,0} %bitcast.739, f32[128]{0} %bitcast.741), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 29ms/step - accuracy: 0.4829 - loss: 4.2138 - val_accuracy: 0.0000e+00 - val_loss: 1.1736\n",
      "Epoch 2/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 28ms/step - accuracy: 0.4244 - loss: 1.3382 - val_accuracy: 0.3333 - val_loss: 1.1441\n",
      "Epoch 3/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 28ms/step - accuracy: 0.4067 - loss: 1.3278 - val_accuracy: 0.6667 - val_loss: 1.1410\n",
      "Epoch 4/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 27ms/step - accuracy: 0.3746 - loss: 1.3312 - val_accuracy: 0.0000e+00 - val_loss: 1.2207\n",
      "Epoch 5/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3768 - loss: 1.3111 - val_accuracy: 0.0000e+00 - val_loss: 1.3933\n",
      "Epoch 6/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3552 - loss: 1.3110 - val_accuracy: 0.0000e+00 - val_loss: 1.3153\n",
      "Epoch 7/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.4015 - loss: 1.2857 - val_accuracy: 0.3333 - val_loss: 1.2338\n",
      "Epoch 8/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3956 - loss: 1.2785 - val_accuracy: 0.3333 - val_loss: 1.1687\n",
      "Epoch 9/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3812 - loss: 1.2776 - val_accuracy: 0.3333 - val_loss: 1.0949\n",
      "Epoch 10/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3686 - loss: 1.2852 - val_accuracy: 0.3333 - val_loss: 1.0227\n",
      "Epoch 11/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 26ms/step - accuracy: 0.3472 - loss: 1.3216 - val_accuracy: 0.3333 - val_loss: 1.0150\n",
      "Epoch 12/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 27ms/step - accuracy: 0.3830 - loss: 1.2876 - val_accuracy: 0.6667 - val_loss: 1.0011\n",
      "Epoch 13/300\n",
      "\u001b[1m11298/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:24\u001b[0m 30ms/step - accuracy: 0.3823 - loss: 1.2551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     10\u001b[39m callbacks = [\n\u001b[32m     11\u001b[39m     EarlyStopping(\n\u001b[32m     12\u001b[39m         monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,          \u001b[38;5;66;03m# 검증 정확도를 기준으로\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     )\n\u001b[32m     21\u001b[39m ]\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 모델 학습 시작\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# → 배치 제너레이터로 학습 데이터를 공급하고, 메모리에 올린 검증 데이터를 사용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습 데이터 제너레이터\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# 에폭당 스텝 수\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                     \u001b[49m\u001b[38;5;66;43;03m# 총 에폭 수\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# 검증 데이터\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# 조기 종료 및 체크포인트\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 전체 학습 스텝 수 계산\n",
    "# → 각 배치 파일의 샘플 수를 모두 더한 후, 배치 크기로 나누어 steps_per_epoch 계산\n",
    "train_steps = sum([\n",
    "    np.load(f).shape[0] \n",
    "    for f in glob.glob(os.path.join(train_dir, \"label_batch_*.npy\"))\n",
    "]) // BATCH_SIZE\n",
    "\n",
    "# 콜백 정의\n",
    "# → 성능이 개선되지 않으면 조기 종료, 최고 성능 모델만 저장\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',          # 검증 정확도를 기준으로\n",
    "        patience=PATIENCE,               # patience 기간 설정\n",
    "        restore_best_weights=True        # 가장 좋은 성능의 가중치 복원\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,        # 모델 저장 경로\n",
    "        monitor='val_accuracy',          # 모니터링 기준\n",
    "        save_best_only=True              # 최고 성능만 저장\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델 학습 시작\n",
    "# → 배치 제너레이터로 학습 데이터를 공급하고, 메모리에 올린 검증 데이터를 사용\n",
    "model.fit(\n",
    "    data_generator(train_dir, train_dir, BATCH_SIZE),  # 학습 데이터 제너레이터\n",
    "    steps_per_epoch=train_steps,                       # 에폭당 스텝 수\n",
    "    epochs=EPOCHS,                                     # 총 에폭 수\n",
    "    validation_data=(val_x, val_y),                    # 검증 데이터\n",
    "    callbacks=callbacks                                # 조기 종료 및 체크포인트\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 발생\n",
    "\n",
    "- val_accuracy가 0.3333, 0.6667에서 반복됨 → 특정 클래스만 예측되고 있는 문제 가능성\n",
    "\n",
    "- loss는 줄긴 하지만 전체적으로 정체 상태\n",
    "\n",
    "- accuracy가 점점 낮아지는 경향도 보임\n",
    "\n",
    "- 약 80분 투자했지만, EarlyStopping 조건을 만족하지 못하고 긴 학습 예상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불균형 확인용 코드\n",
    "- 데이터셋의 감정 라벨 분포를 확인해서, 특정 감정이 너무 많거나 적은 경우 모델이 그 감정으로만 예측할 가능성이 있기 때문에 반드시 체크해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 분포: Counter({0: 245001, 1: 235755, 3: 228996, 2: 192000})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 라벨 배치 파일 경로 설정\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 라벨 수집\n",
    "all_labels = []\n",
    "\n",
    "for file in label_files:\n",
    "    labels = np.load(file, allow_pickle=True)\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "# 라벨 분포 확인\n",
    "label_counts = Counter(all_labels)\n",
    "print(\"라벨 분포:\", label_counts)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(label_counts.keys(), label_counts.values())\n",
    "plt.title(\"Emotion Label Distribution (Train Set)\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정 클래스 불균형 확인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 라벨 배치 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 모든 라벨 로딩\n",
    "all_labels = []\n",
    "for file in label_files:\n",
    "    labels = np.load(file, allow_pickle=True)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 라벨 분포 확인\n",
    "label_counter = Counter(all_labels)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(label_counter.keys(), label_counter.values())\n",
    "plt.title(\"Training Label Distribution\")\n",
    "plt.xlabel(\"Emotion Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class_weight 적용\n",
    "\n",
    "- 증강 재조정\n",
    "\n",
    "- 또는 RandomUnderSampler, SMOTE 등 대안 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. class-weight 적용\n",
    "- 클래스 불균형 문제를 완화하기 위해 각 클래스에 역비례 가중치를 적용할 수 있습니다. 아래는 전체 라벨을 분석하고 class_weight을 자동으로 계산하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용할 class_weight: {0: 0.9201513463210355, 1: 0.9562384679009989, 2: 1.17415625, 3: 0.9844626107006236}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# 전체 라벨을 숫자로 인코딩한 리스트라고 가정 (예: [0, 1, 0, 2, 3, 1, ...])\n",
    "all_labels_array = np.array(all_labels)\n",
    "\n",
    "# 고유 클래스 목록\n",
    "classes = np.unique(all_labels_array)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=all_labels_array)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "print(\"적용할 class_weight:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 학습 코드 개선\n",
    "- 지금까지 개선사항을 반영하여, 각 셀에 맞게 구성해드립니다. (class_weight 적용 포함)\n",
    "\n",
    "### 셀 1. 환경 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 23:59:16.882290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743692356.950121   44334 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743692356.973294   44334 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743692357.116733   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743692357.116793   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743692357.116796   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743692357.116799   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-03 23:59:17.135814: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# GPU 메모리 점진적 할당\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 하이퍼파라미터\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 30\n",
    "\n",
    "# 경로 설정\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/model_ckpt/best_model_voice_emotion_analysis.keras\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 2. CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-03 23:59:22.700145: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1743692362.700595   44334 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def build_cnn_model(input_shape=(40, 300, 1), num_classes=4):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 3. 데이터 제너레이터 및 클래스 가중치 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용할 클래스 가중치: {0: 0.9201513463210355, 1: 0.9562384679009989, 2: 1.17415625, 3: 0.9844626107006236}\n"
     ]
    }
   ],
   "source": [
    "def data_generator(mfcc_dir, label_dir, batch_size):\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)\n",
    "            y = np.load(label_file, allow_pickle=True)\n",
    "\n",
    "            min_len = min(len(x), len(y))\n",
    "            x = x[:min_len][..., np.newaxis]\n",
    "            y = y[:min_len]\n",
    "\n",
    "            for i in range(0, min_len, batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "# 전체 라벨을 모아서 class_weight 계산\n",
    "all_labels = []\n",
    "for f in glob.glob(os.path.join(train_dir, \"label_batch_*.npy\")):\n",
    "    labels = np.load(f, allow_pickle=True)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "classes = np.unique(all_labels)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=all_labels)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "print(\"적용할 클래스 가중치:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 4. 검증 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 shape: (5000, 40, 300, 1) (5000,)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 검증 데이터 배치 파일 목록\n",
    "val_mfcc_files = sorted(glob.glob(os.path.join(val_dir, \"mfcc_val_batch_*.npy\")))\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "# 최대 로딩할 샘플 수 제한 (예: 5000개)\n",
    "max_samples = 5000\n",
    "loaded = 0\n",
    "\n",
    "val_x_list, val_y_list = [], []\n",
    "\n",
    "for mfcc_file, label_file in zip(val_mfcc_files, val_label_files):\n",
    "    # 각 배치 파일 로딩\n",
    "    x = np.load(mfcc_file)[..., np.newaxis]  # (배치, 40, 300, 1)\n",
    "    y = np.load(label_file, allow_pickle=True)\n",
    "\n",
    "    # 남은 개수 계산 후 일부만 사용 (과도한 메모리 사용 방지)\n",
    "    remaining = max_samples - loaded\n",
    "    if len(x) > remaining:\n",
    "        x = x[:remaining]\n",
    "        y = y[:remaining]\n",
    "\n",
    "    val_x_list.append(x)\n",
    "    val_y_list.append(y)\n",
    "    loaded += len(x)\n",
    "\n",
    "    if loaded >= max_samples:\n",
    "        break\n",
    "\n",
    "# 최종 배열로 병합\n",
    "val_x = np.concatenate(val_x_list, axis=0)\n",
    "val_y = np.concatenate(val_y_list, axis=0)\n",
    "\n",
    "print(\"검증 데이터 shape:\", val_x.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 문자열을 숫자로 매핑 (예: 감정 레이블이 str인 경우)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val_y.dtype.type \u001b[38;5;129;01mis\u001b[39;00m np.str_ \u001b[38;5;129;01mor\u001b[39;00m val_y.dtype.type \u001b[38;5;129;01mis\u001b[39;00m np.object_:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     unique_labels = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     label_to_index = {label: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_labels)}\n\u001b[32m      5\u001b[39m     val_y = np.array([label_to_index[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m val_y])\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# 문자열을 숫자로 매핑 (예: 감정 레이블이 str인 경우)\n",
    "if val_y.dtype.type is np.str_ or val_y.dtype.type is np.object_:\n",
    "    unique_labels = sorted(set(val_y))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    val_y = np.array([label_to_index[label] for label in val_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m classes = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m class_weights = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(compute_class_weight(\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, classes=classes, y=val_y)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/arraysetops.py:274\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    272\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/arraysetops.py:336\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[39m\n\u001b[32m    334\u001b[39m     aux = ar[perm]\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     aux = ar\n\u001b[32m    338\u001b[39m mask = np.empty(aux.shape, dtype=np.bool_)\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(val_y)\n",
    "class_weights = dict(enumerate(compute_class_weight('balanced', classes=classes, y=val_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 가중치: {0: 25.048666666666666, 1: 2.087388888888889, 2: 0.6288341889782888, 3: 0.8134664826391708, 4: 0.8491073446327684, 5: 0.6739672460492565}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 검증 라벨 배치 파일 경로\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "# 클래스 가중치 계산용 라벨만 메모리에 점진적으로 로딩\n",
    "val_labels = []\n",
    "\n",
    "for label_file in val_label_files:\n",
    "    y = np.load(label_file, allow_pickle=True)\n",
    "    val_labels.extend(y)\n",
    "\n",
    "val_y_raw = np.array(val_labels)\n",
    "\n",
    "# 문자열 라벨이면 숫자 인덱스로 인코딩\n",
    "if val_y_raw.dtype.type is np.str_ or val_y_raw.dtype.type is np.object_:\n",
    "    unique_labels = sorted(set(val_y_raw))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    val_y = np.array([label_to_index[label] for label in val_y_raw])\n",
    "else:\n",
    "    val_y = val_y_raw.copy()\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "classes = np.unique(val_y)\n",
    "class_weights = dict(enumerate(compute_class_weight(class_weight='balanced', classes=classes, y=val_y)))\n",
    "\n",
    "# 결과 출력\n",
    "print(\"클래스 가중치:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def val_data_generator(val_mfcc_dir, val_label_dir, batch_size):\n",
    "    \"\"\"\n",
    "    검증 데이터를 배치 단위로 불러오는 제너레이터 함수입니다.\n",
    "    - 메모리 이슈를 피하기 위해 배치 단위로 불러옵니다.\n",
    "    \n",
    "    Parameters:\n",
    "        val_mfcc_dir (str): MFCC 검증 배치 파일 경로\n",
    "        val_label_dir (str): 라벨 검증 배치 파일 경로\n",
    "        batch_size (int): 배치 크기\n",
    "\n",
    "    Yields:\n",
    "        Tuple[np.ndarray, np.ndarray]: (x_batch, y_batch)\n",
    "    \"\"\"\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(val_mfcc_dir, \"mfcc_val_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(val_label_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)[..., np.newaxis]  # (batch, 40, 300, 1)\n",
    "            y_raw = np.load(label_file, allow_pickle=True)\n",
    "\n",
    "            # 문자열 레이블이면 숫자로 변환\n",
    "            if y_raw.dtype.type is np.str_ or y_raw.dtype.type is np.object_:\n",
    "                unique_labels = sorted(set(y_raw))\n",
    "                label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "                y = np.array([label_to_index[label] for label in y_raw])\n",
    "            else:\n",
    "                y = y_raw.copy()\n",
    "\n",
    "            min_len = min(len(x), len(y))\n",
    "            x = x[:min_len]\n",
    "            y = y[:min_len]\n",
    "\n",
    "            for i in range(0, min_len, batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 제너레이터 인스턴스 생성\n",
    "val_generator = val_data_generator(val_dir, val_dir, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `class_weight` is not supported for Python generator inputs. Received: class_weight={0: 25.048666666666666, 1: 2.087388888888889, 2: 0.6288341889782888, 3: 0.8134664826391708, 4: 0.8491073446327684, 5: 0.6739672460492565}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     17\u001b[39m callbacks = [\n\u001b[32m     18\u001b[39m     EarlyStopping(\n\u001b[32m     19\u001b[39m         monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     )\n\u001b[32m     28\u001b[39m ]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 모델 학습 실행\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습용 제너레이터\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# 검증용 제너레이터\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# 클래스 가중치 적용\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/__init__.py:113\u001b[39m, in \u001b[36mget_data_adapter\u001b[39m\u001b[34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[39m\n\u001b[32m    109\u001b[39m         raise_unsupported_arg(\n\u001b[32m    110\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msample_weights\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mthe sample weights\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPyDataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m         )\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    114\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArgument `class_weight` is not supported for Python \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgenerator inputs. Received: class_weight=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_weight\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    116\u001b[39m         )\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Argument `class_weight` is not supported for Python generator inputs. Received: class_weight={0: 25.048666666666666, 1: 2.087388888888889, 2: 0.6288341889782888, 3: 0.8134664826391708, 4: 0.8491073446327684, 5: 0.6739672460492565}"
     ]
    }
   ],
   "source": [
    "# 검증 제너레이터 인스턴스 생성\n",
    "val_generator = val_data_generator(val_dir, val_dir, BATCH_SIZE)\n",
    "\n",
    "# 학습 스텝 수 계산 (전체 학습 샘플 수 / 배치 크기)\n",
    "train_steps = sum([\n",
    "    np.load(f).shape[0]\n",
    "    for f in glob.glob(os.path.join(train_dir, \"label_batch_*.npy\"))\n",
    "]) // BATCH_SIZE\n",
    "\n",
    "# 검증 스텝 수 계산 (전체 검증 샘플 수 / 배치 크기)\n",
    "val_steps = sum([\n",
    "    np.load(f, allow_pickle=True).shape[0]\n",
    "    for f in glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\"))\n",
    "]) // BATCH_SIZE\n",
    "\n",
    "# 콜백 정의\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델 학습 실행\n",
    "history = model.fit(\n",
    "    data_generator(train_dir, train_dir, BATCH_SIZE),  # 학습용 제너레이터\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,                    # 검증용 제너레이터\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights                        # 클래스 가중치 적용\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오류의 원인은 class_weight 인자는 Python 제너레이터 기반 입력에 사용할 수 없기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 4클래스 필터링 완료: 0개 → ./data/usou/metadata_4class.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 설정\n",
    "json_dir = \"/media/usou/PortableSSD/mldl_project/json_data\"\n",
    "output_csv_path = \"./data/usou/metadata_4class.csv\"\n",
    "target_emotions = {\"angry\", \"happy\", \"neutrality\", \"sad\"}\n",
    "\n",
    "data = []\n",
    "for root, _, files in os.walk(json_dir):\n",
    "    for fname in files:\n",
    "        if fname.endswith(\".json\"):\n",
    "            with open(os.path.join(root, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                content = json.load(f)\n",
    "                if content[\"emotion\"] in target_emotions:\n",
    "                    data.append({\"wav_path\": content[\"wav_path\"], \"emotion\": content[\"emotion\"]})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"✅ 4클래스 필터링 완료: {len(df)}개 → {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class_weight 효과를 반영한 데이터 오버샘플링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5428/2753053002.py:20: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "오버샘플링된 MFCC 추출:   0%|          | 12/326668 [00:01<12:16:51,  7.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     y, sr = librosa.load(row[\u001b[33m\"\u001b[39m\u001b[33mwav_path\u001b[39m\u001b[33m\"\u001b[39m], sr=\u001b[32m16000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     mfcc = \u001b[43mextract_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     mfcc_batch.append(mfcc)\n\u001b[32m     54\u001b[39m     label_batch.append(row[\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mextract_mfcc\u001b[39m\u001b[34m(y, sr)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_mfcc\u001b[39m(y, sr):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     mfcc = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mfcc.shape[\u001b[32m1\u001b[39m] < max_len:\n\u001b[32m     38\u001b[39m         pad_width = max_len - mfcc.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/feature/spectral.py:1993\u001b[39m, in \u001b[36mmfcc\u001b[39m\u001b[34m(y, sr, S, n_mfcc, dct_type, norm, lifter, mel_norm, **kwargs)\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[32m   1847\u001b[39m \n\u001b[32m   1848\u001b[39m \u001b[33;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1989\u001b[39m \u001b[33;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1992\u001b[39m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m     S = power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1995\u001b[39m fft = get_fftlib()\n\u001b[32m   1996\u001b[39m M: np.ndarray = fft.dct(S, axis=-\u001b[32m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m=dct_type, norm=norm)[\n\u001b[32m   1997\u001b[39m     ..., :n_mfcc, :\n\u001b[32m   1998\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/feature/spectral.py:2135\u001b[39m, in \u001b[36mmelspectrogram\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[39m\n\u001b[32m   2013\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmelspectrogram\u001b[39m(\n\u001b[32m   2014\u001b[39m     *,\n\u001b[32m   2015\u001b[39m     y: Optional[np.ndarray] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     **kwargs: Any,\n\u001b[32m   2026\u001b[39m ) -> np.ndarray:\n\u001b[32m   2027\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[32m   2028\u001b[39m \n\u001b[32m   2029\u001b[39m \u001b[33;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2133\u001b[39m \u001b[33;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[32m   2134\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2135\u001b[39m     S, n_fft = \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2147\u001b[39m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[32m   2148\u001b[39m     mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/core/spectrum.py:2945\u001b[39m, in \u001b[36m_spectrogram\u001b[39m\u001b[34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[39m\n\u001b[32m   2939\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2940\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[32m   2941\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2942\u001b[39m         )\n\u001b[32m   2943\u001b[39m     S = (\n\u001b[32m   2944\u001b[39m         np.abs(\n\u001b[32m-> \u001b[39m\u001b[32m2945\u001b[39m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2946\u001b[39m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2947\u001b[39m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2948\u001b[39m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2949\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2950\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2951\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2952\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2953\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2954\u001b[39m         )\n\u001b[32m   2955\u001b[39m         ** power\n\u001b[32m   2956\u001b[39m     )\n\u001b[32m   2958\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/core/spectrum.py:387\u001b[39m, in \u001b[36mstft\u001b[39m\u001b[34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, y_frames.shape[-\u001b[32m1\u001b[39m], n_columns):\n\u001b[32m    385\u001b[39m     bl_t = \u001b[38;5;28mmin\u001b[39m(bl_s + n_columns, y_frames.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     stft_matrix[..., bl_s + off_start : bl_t + off_start] = \u001b[43mfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfft_window\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43my_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbl_s\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbl_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_backend.py:28\u001b[39m, in \u001b[36m_ScipyBackend.__ua_function__\u001b[39m\u001b[34m(method, args, kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:91\u001b[39m, in \u001b[36mrfft\u001b[39m\u001b[34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrfft\u001b[39m(x, n=\u001b[38;5;28;01mNone\u001b[39;00m, axis=-\u001b[32m1\u001b[39m, norm=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     90\u001b[39m          overwrite_x=\u001b[38;5;28;01mFalse\u001b[39;00m, workers=\u001b[38;5;28;01mNone\u001b[39;00m, *, plan=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_1D\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrfft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:32\u001b[39m, in \u001b[36m_execute_1D\u001b[39m\u001b[34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[32m     31\u001b[39m     x = np.asarray(x)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m norm = _validate_fft_args(workers, plan, norm)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[33m'\u001b[39m\u001b[33mfft\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:61\u001b[39m, in \u001b[36mr2c\u001b[39m\u001b[34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid number of data points (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp.shape[axis]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Note: overwrite_x is not utilised\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 경로 설정\n",
    "csv_path = \"./data/usou/metadata_4class.csv\"\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data4class_oversampled_batches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. MFCC 설정\n",
    "n_mfcc = 40\n",
    "max_len = 300\n",
    "batch_size = 1000\n",
    "\n",
    "# 3. 데이터 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 4. 클래스별 분포 확인\n",
    "label_counts = df['emotion'].value_counts()\n",
    "max_count = label_counts.max()\n",
    "\n",
    "# 5. 오버샘플링 수행\n",
    "oversampled_df = pd.DataFrame()\n",
    "\n",
    "for emotion, group in df.groupby('emotion'):\n",
    "    # 클래스별로 최대 수만큼 오버샘플링\n",
    "    group_oversampled = resample(group, replace=True, n_samples=max_count, random_state=42)\n",
    "    oversampled_df = pd.concat([oversampled_df, group_oversampled])\n",
    "\n",
    "# 6. MFCC 추출 함수\n",
    "def extract_mfcc(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "\n",
    "# 7. 배치 저장\n",
    "mfcc_batch = []\n",
    "label_batch = []\n",
    "batch_index = 0\n",
    "\n",
    "for _, row in tqdm(oversampled_df.iterrows(), total=len(oversampled_df), desc=\"오버샘플링된 MFCC 추출\"):\n",
    "    try:\n",
    "        y, sr = librosa.load(row[\"wav_path\"], sr=16000)\n",
    "        mfcc = extract_mfcc(y, sr)\n",
    "        mfcc_batch.append(mfcc)\n",
    "        label_batch.append(row[\"emotion\"])\n",
    "\n",
    "        if len(mfcc_batch) >= batch_size:\n",
    "            np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "            np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "            print(f\"배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "            batch_index += 1\n",
    "            mfcc_batch.clear()\n",
    "            label_batch.clear()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류: {row['wav_path']} → {e}\")\n",
    "        continue\n",
    "\n",
    "# 8. 마지막 배치 저장\n",
    "if mfcc_batch:\n",
    "    np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "    np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "    print(f\"마지막 배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "\n",
    "print(\"오버샘플링 기반 MFCC 추출 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라벨 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "전체 라벨 로딩:   0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "전체 라벨 로딩: 100%|██████████| 327/327 [00:01<00:00, 321.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LabelEncoder 학습 및 저장 완료: /media/usou/PortableSSD/mldl_project/models/label_encoder_4class.pkl\n",
      "클래스 목록: ['Angry' 'Happy' 'Neutrality' 'Sad']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 경로 설정\n",
    "label_path = \"/media/usou/PortableSSD/mldl_project/data4class_oversampled_batches/label_batch_*.npy\"\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 2. 전체 라벨 수집\n",
    "all_labels = []\n",
    "for label_file in tqdm(sorted(glob(label_path)), desc=\"전체 라벨 로딩\"):\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 3. 라벨 인코더 학습 및 저장\n",
    "le = LabelEncoder()\n",
    "le.fit(all_labels)\n",
    "\n",
    "encoder_path = os.path.join(save_dir, \"label_encoder_4class.pkl\")\n",
    "with open(encoder_path, \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"✅ LabelEncoder 학습 및 저장 완료:\", encoder_path)\n",
    "print(\"클래스 목록:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 제너레이터 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 17:24:28.947118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743755068.995799    5428 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743755069.009420    5428 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743755069.127231    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743755069.127250    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743755069.127251    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743755069.127253    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 17:24:29.142424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class MFCCBatchGenerator(Sequence):\n",
    "    def __init__(self, data_dir, encoder_path, batch_size=32, shuffle=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 파일 목록\n",
    "        self.mfcc_files = sorted([f for f in os.listdir(data_dir) if f.startswith(\"mfcc_batch_\")])\n",
    "        self.label_files = sorted([f for f in os.listdir(data_dir) if f.startswith(\"label_batch_\")])\n",
    "        self.indexes = np.arange(len(self.mfcc_files))\n",
    "\n",
    "        # 라벨 인코더 로드\n",
    "        with open(encoder_path, \"rb\") as f:\n",
    "            self.encoder = pickle.load(f)\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.indexes[idx]\n",
    "        mfcc_path = os.path.join(self.data_dir, self.mfcc_files[i])\n",
    "        label_path = os.path.join(self.data_dir, self.label_files[i])\n",
    "\n",
    "        X = np.load(mfcc_path)\n",
    "        y = np.load(label_path, allow_pickle=True)\n",
    "        y_encoded = self.encoder.transform(y)\n",
    "\n",
    "        return X[..., np.newaxis], y_encoded\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구조 추천 (성능 좋은 CNN 기반)\n",
    "- 기존보다 조금 더 깊고, BatchNormalization, Dropout 등을 넣어서 일반화 성능을 높이는 구조입니다.\n",
    "\n",
    "- 커널 과부하를 막기 위해 파라미터 수를 100만 이하로 제한했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 300, 1), num_classes=4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MFCCBatchGenerator.__init__() missing 1 required positional argument: 'encoder_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m history_save_path = \u001b[33m\"\u001b[39m\u001b[33m./ai/models/history_4class.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 배치 제너레이터 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m train_generator = \u001b[43mMFCCBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 모델 빌드\u001b[39;00m\n\u001b[32m     14\u001b[39m model = build_cnn_model(input_shape=(\u001b[32m40\u001b[39m, \u001b[32m300\u001b[39m, \u001b[32m1\u001b[39m), num_classes=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: MFCCBatchGenerator.__init__() missing 1 required positional argument: 'encoder_path'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pickle\n",
    "\n",
    "# 경로 설정\n",
    "train_data_dir = \"/media/usou/PortableSSD/mldl_project/data4class_oversampled_batches\"\n",
    "model_save_path = \"./ai/models/voice_emotion_model_4class.keras\"\n",
    "history_save_path = \"./ai/models/history_4class.pkl\"\n",
    "\n",
    "# 배치 제너레이터 생성\n",
    "train_generator = MFCCBatchGenerator(data_dir=train_data_dir, batch_size=64, shuffle=True)\n",
    "\n",
    "# 모델 빌드\n",
    "model = build_cnn_model(input_shape=(40, 300, 1), num_classes=4)\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='loss', patience=60, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint(model_save_path, monitor='loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=300,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 학습 이력 저장\n",
    "with open(history_save_path, \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 완료 및 모델/이력 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 시작 \n",
    "# JSON -> DataFrame 변환(4개 감정만 필터링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON 파일 탐색: 449it [02:39,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정상 처리된 데이터 수: 236584\n",
      "⚠️ 오류 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 사용할 감정 4종\n",
    "target_emotions = {\"neutral\", \"angry\", \"happy\", \"sad\"}\n",
    "\n",
    "# JSON 및 WAV 최상위 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 결과 저장 경로: 외장 하드 mldl_4class 폴더\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 수집 리스트\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# JSON 탐색 및 처리\n",
    "for folder_path, _, files in tqdm(os.walk(label_root), desc=\"JSON 파일 탐색\"):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                if emotion.lower() not in target_emotions:\n",
    "                    continue\n",
    "\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root).replace(\"TL\", \"TS\")\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion.lower(),\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"[WAV 없음] {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[JSON 오류] {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# DataFrame 저장\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_cleaned.csv\"), index=False)\n",
    "\n",
    "# 오류 로그 저장\n",
    "with open(os.path.join(save_dir, \"broken_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"✅ 정상 처리된 데이터 수: {len(df)}\")\n",
    "print(f\"⚠️ 오류 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/4277833996.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/tmp/ipykernel_5551/4277833996.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = df.groupby('emotion', group_keys=False).apply(lambda x: x.sample(min_class_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 균형 샘플 수: 76332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 중: 100%|██████████| 228996/228996 [44:48<00:00, 85.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장된 MFCC 배치 수: 23\n",
      "⚠️ 실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================\n",
    "# 1. 메타데이터 로드 및 클래스 균형 맞춤\n",
    "# ============================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 클래스별 개수 파악\n",
    "min_class_count = df['emotion'].value_counts().min()\n",
    "\n",
    "# 클래스별 균형 맞춤\n",
    "balanced_df = df.groupby('emotion', group_keys=False).apply(lambda x: x.sample(min_class_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(\"각 클래스 균형 샘플 수:\", min_class_count)\n",
    "\n",
    "# ============================\n",
    "# 2. 설정값 정의\n",
    "# ============================\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_interval = 10000\n",
    "\n",
    "# 저장 디렉토리\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3. MFCC 추출 루프 (제너레이터 스타일)\n",
    "# ============================\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "error_files = []\n",
    "save_counter = 0\n",
    "\n",
    "for idx, row in tqdm(balanced_df.iterrows(), total=len(balanced_df), desc=\"MFCC 추출 중\"):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ============================\n",
    "# 4. 에러 로그 저장\n",
    "# ============================\n",
    "error_path = \"/media/usou/PortableSSD/mldl_4class/broken_audio_files.txt\"\n",
    "with open(error_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ============================\n",
    "# 5. 요약 출력\n",
    "# ============================\n",
    "print(f\"✅ 저장된 MFCC 배치 수: {save_counter + 1}\")\n",
    "print(f\"⚠️ 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩(Train 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/2700387088.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 레이블 인코딩 완료 및 저장\n",
      "📦 저장 경로: /media/usou/PortableSSD/mldl_4class/mfcc_batches/encoded_labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# 1. 메타데이터 로드\n",
    "# ===============================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ===============================\n",
    "# 2. 레이블 인코딩\n",
    "# ===============================\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(df[\"emotion\"])  # 'happy' → 0, ...\n",
    "\n",
    "# ===============================\n",
    "# 3. 인코더 저장 (나중에 검증 데이터에 동일하게 적용)\n",
    "# ===============================\n",
    "encoder_path = \"./label_encoder.pkl\"  # 현재 코드 폴더에 저장\n",
    "with open(encoder_path, \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# ===============================\n",
    "# 4. 라벨을 MFCC 배치 기준으로 분리 저장\n",
    "# ===============================\n",
    "\n",
    "# 학습 데이터의 MFCC 배치 수 확인\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "mfcc_batches = sorted([f for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "label_save_dir = os.path.join(mfcc_dir, \"encoded_labels\")\n",
    "os.makedirs(label_save_dir, exist_ok=True)\n",
    "\n",
    "start_idx = 0\n",
    "for i, batch_name in enumerate(mfcc_batches):\n",
    "    mfcc_path = os.path.join(mfcc_dir, batch_name)\n",
    "    batch_mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    end_idx = start_idx + len(batch_mfcc)\n",
    "    batch_labels = encoded_labels[start_idx:end_idx]\n",
    "    \n",
    "    # 저장\n",
    "    np.save(os.path.join(label_save_dir, f\"label_batch_{i}.npy\"), batch_labels)\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(\"✅ 레이블 인코딩 완료 및 저장\")\n",
    "print(\"📦 저장 경로:\", label_save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation 전처리 (Train 과 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation JSON 탐색: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation JSON 탐색: 88it [00:05, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 데이터 수: 36207\n",
      "⚠️ 오류 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class/validation\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 2. 필터링 감정 정의 및 리스트 초기화\n",
    "# ========================================\n",
    "\n",
    "target_emotions = {\"neutral\", \"angry\", \"happy\", \"sad\"}\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 탐색 및 필터링 처리\n",
    "# ========================================\n",
    "\n",
    "for folder_path, _, files in tqdm(os.walk(label_root), desc=\"Validation JSON 탐색\"):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"].lower()\n",
    "                if emotion not in target_emotions:\n",
    "                    continue\n",
    "\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"JSON 읽기 오류: {json_path}, 에러: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 결과 저장\n",
    "# ========================================\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_cleaned_val.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(save_dir, \"broken_val_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"✅ Validation 데이터 수: {len(df)}\")\n",
    "print(f\"⚠️ 오류 파일 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC 추출 (Validation용, 클래스 불균형 조정 없이 전체 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 중 (Validation): 100%|██████████| 36207/36207 [10:14<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장된 MFCC 배치 수: 4\n",
      "⚠️ 실패한 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드\n",
    "# ========================================\n",
    "\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. 설정값 정의\n",
    "# ========================================\n",
    "\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_interval = 10000\n",
    "\n",
    "# 저장 디렉토리\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 3. MFCC 추출 루프 (제너레이터 방식)\n",
    "# ========================================\n",
    "\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "error_files = []\n",
    "save_counter = 0\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"MFCC 추출 중 (Validation)\"):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ========================================\n",
    "# 4. 에러 로그 저장\n",
    "# ========================================\n",
    "\n",
    "with open(\"/media/usou/PortableSSD/mldl_4class/validation/broken_audio_val.txt\", \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 5. 결과 출력\n",
    "# ========================================\n",
    "\n",
    "print(f\"✅ 저장된 MFCC 배치 수: {save_counter + 1}\")\n",
    "print(f\"⚠️ 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 레이블 인코딩 (학습용 인코더 재사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 라벨 인코딩 완료 및 저장\n",
      "📦 저장 경로: /media/usou/PortableSSD/mldl_4class/validation/mfcc_batches/encoded_labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. LabelEncoder 로드\n",
    "# ========================================\n",
    "encoder_path = \"./label_encoder.pkl\"  # Train 3번 셀에서 저장한 인코더\n",
    "with open(encoder_path, \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# ========================================\n",
    "# 2. Validation 메타데이터 로드\n",
    "# ========================================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 3. 레이블 인코딩 적용\n",
    "# ========================================\n",
    "encoded_labels = encoder.transform(df[\"emotion\"])\n",
    "\n",
    "# ========================================\n",
    "# 4. MFCC 배치 기준으로 라벨 분리 저장\n",
    "# ========================================\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "mfcc_batches = sorted([f for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "label_save_dir = os.path.join(mfcc_dir, \"encoded_labels\")\n",
    "os.makedirs(label_save_dir, exist_ok=True)\n",
    "\n",
    "start_idx = 0\n",
    "for i, batch_name in enumerate(mfcc_batches):\n",
    "    mfcc_path = os.path.join(mfcc_dir, batch_name)\n",
    "    batch_mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    end_idx = start_idx + len(batch_mfcc)\n",
    "    batch_labels = encoded_labels[start_idx:end_idx]\n",
    "    \n",
    "    # 저장\n",
    "    np.save(os.path.join(label_save_dir, f\"label_batch_{i}.npy\"), batch_labels)\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(\"✅ Validation 라벨 인코딩 완료 및 저장\")\n",
    "print(\"📦 저장 경로:\", label_save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의 (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 22:04:02.463416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743771842.481758   21737 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743771842.487580   21737 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743771842.501105   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743771842.501129   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743771842.501130   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743771842.501131   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 22:04:02.505074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-04 22:04:05.800758: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-04-04 22:04:05.800780: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-04-04 22:04:05.800784: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: usou-GP75-Leopard-10SEK\n",
      "2025-04-04 22:04:05.800787: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: usou-GP75-Leopard-10SEK\n",
      "2025-04-04 22:04:05.800876: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.144.3\n",
      "2025-04-04 22:04:05.800887: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.144.3\n",
      "2025-04-04 22:04:05.800889: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.144.3\n",
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7680</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">983,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7680\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m983,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,077,252</span> (4.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,077,252\u001b[0m (4.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,076,804</span> (4.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,076,804\u001b[0m (4.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# GPU 메모리 점진 할당\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 100, 1), num_classes=4):  # ← 줄인 입력\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = build_cnn_model(input_shape=(40, 100, 1), num_classes=4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2027 - loss: 3.1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 4s/step - accuracy: 0.2051 - loss: 3.0772 - val_accuracy: 0.3149 - val_loss: 1.2610\n",
      "Epoch 2/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 5s/step - accuracy: 0.3663 - loss: 1.1645 - val_accuracy: 0.3414 - val_loss: 1.3809\n",
      "Epoch 3/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3615 - loss: 1.1496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 5s/step - accuracy: 0.3599 - loss: 1.1505 - val_accuracy: 0.3349 - val_loss: 1.1638\n",
      "Epoch 4/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3368 - loss: 1.1462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 5s/step - accuracy: 0.3373 - loss: 1.1459 - val_accuracy: 0.2621 - val_loss: 1.1333\n",
      "Epoch 5/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - accuracy: 0.3099 - loss: 1.1686 - val_accuracy: 0.2642 - val_loss: 1.1390\n",
      "Epoch 6/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4517 - loss: 1.1090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 5s/step - accuracy: 0.4465 - loss: 1.1123 - val_accuracy: 0.3261 - val_loss: 1.1330\n",
      "Epoch 7/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2651 - loss: 1.1654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.2664 - loss: 1.1652 - val_accuracy: 0.2822 - val_loss: 1.1324\n",
      "Epoch 8/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3532 - loss: 1.1339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3524 - loss: 1.1342 - val_accuracy: 0.2450 - val_loss: 1.1249\n",
      "Epoch 9/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3006 - loss: 1.1394 - val_accuracy: 0.3115 - val_loss: 1.1345\n",
      "Epoch 10/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.4110 - loss: 1.0952 - val_accuracy: 0.1949 - val_loss: 1.1297\n",
      "Epoch 11/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3814 - loss: 1.1115 - val_accuracy: 0.1884 - val_loss: 1.1356\n",
      "Epoch 12/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3903 - loss: 1.1074 - val_accuracy: 0.2793 - val_loss: 1.1410\n",
      "Epoch 13/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3617 - loss: 1.1145 - val_accuracy: 0.2570 - val_loss: 1.1457\n",
      "Epoch 14/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3680 - loss: 1.1364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 5s/step - accuracy: 0.3656 - loss: 1.1376 - val_accuracy: 0.2433 - val_loss: 1.1226\n",
      "Epoch 15/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3630 - loss: 1.1103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3618 - loss: 1.1107 - val_accuracy: 0.3411 - val_loss: 1.1187\n",
      "Epoch 16/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3613 - loss: 1.1172 - val_accuracy: 0.3214 - val_loss: 1.1275\n",
      "Epoch 17/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3556 - loss: 1.1164 - val_accuracy: 0.3163 - val_loss: 1.1356\n",
      "Epoch 18/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3601 - loss: 1.1171 - val_accuracy: 0.2519 - val_loss: 1.1342\n",
      "Epoch 19/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3586 - loss: 1.1072 - val_accuracy: 0.3008 - val_loss: 1.1405\n",
      "Epoch 20/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3168 - loss: 1.1444 - val_accuracy: 0.2285 - val_loss: 1.1235\n",
      "Epoch 21/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3062 - loss: 1.1207 - val_accuracy: 0.2825 - val_loss: 1.1190\n",
      "Epoch 22/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3809 - loss: 1.1091 - val_accuracy: 0.2540 - val_loss: 1.1246\n",
      "Epoch 23/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 5s/step - accuracy: 0.3396 - loss: 1.1154 - val_accuracy: 0.1686 - val_loss: 1.1221\n",
      "Epoch 24/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3956 - loss: 1.1021 - val_accuracy: 0.1889 - val_loss: 1.1284\n",
      "Epoch 25/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3629 - loss: 1.1064 - val_accuracy: 0.2572 - val_loss: 1.1326\n",
      "Epoch 26/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3005 - loss: 1.1222 - val_accuracy: 0.2399 - val_loss: 1.1288\n",
      "Epoch 27/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3474 - loss: 1.1167 - val_accuracy: 0.1613 - val_loss: 1.1311\n",
      "Epoch 28/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3800 - loss: 1.1024 - val_accuracy: 0.2122 - val_loss: 1.1373\n",
      "Epoch 29/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3673 - loss: 1.1005 - val_accuracy: 0.2523 - val_loss: 1.1351\n",
      "Epoch 30/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3406 - loss: 1.0992 - val_accuracy: 0.1660 - val_loss: 1.1370\n",
      "Epoch 31/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3578 - loss: 1.0996 - val_accuracy: 0.1874 - val_loss: 1.1347\n",
      "Epoch 32/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 4s/step - accuracy: 0.3675 - loss: 1.0999 - val_accuracy: 0.1350 - val_loss: 1.1443\n",
      "Epoch 33/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.2945 - loss: 1.1164 - val_accuracy: 0.2314 - val_loss: 1.1370\n",
      "Epoch 34/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3202 - loss: 1.1106 - val_accuracy: 0.1958 - val_loss: 1.1325\n",
      "Epoch 35/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3428 - loss: 1.1012 - val_accuracy: 0.1536 - val_loss: 1.1376\n",
      "Epoch 36/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3612 - loss: 1.1013 - val_accuracy: 0.2322 - val_loss: 1.1390\n",
      "Epoch 37/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3865 - loss: 1.0886 - val_accuracy: 0.1668 - val_loss: 1.1576\n",
      "Epoch 38/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3492 - loss: 1.1005 - val_accuracy: 0.1624 - val_loss: 1.1365\n",
      "Epoch 39/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3546 - loss: 1.0961 - val_accuracy: 0.1607 - val_loss: 1.1570\n",
      "Epoch 40/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.4010 - loss: 1.0841 - val_accuracy: 0.1990 - val_loss: 1.1483\n",
      "Epoch 41/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.4465 - loss: 1.0725 - val_accuracy: 0.1493 - val_loss: 1.1424\n",
      "Epoch 42/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3413 - loss: 1.1071 - val_accuracy: 0.1608 - val_loss: 1.1376\n",
      "Epoch 43/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3419 - loss: 1.0985 - val_accuracy: 0.2479 - val_loss: 1.1485\n",
      "Epoch 44/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3719 - loss: 1.0842 - val_accuracy: 0.1405 - val_loss: 1.1616\n",
      "Epoch 45/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3283 - loss: 1.1023 - val_accuracy: 0.1554 - val_loss: 1.1648\n",
      "✅ 학습 완료 및 저장됨\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# =============================\n",
    "# 1. 제너레이터 정의 (샘플 개수 맞춤 처리 포함)\n",
    "# =============================\n",
    "class MFCCGenerator(Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32):\n",
    "        self.mfcc_paths = sorted([os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "        self.label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.startswith(\"label_batch\")])\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.mfcc_paths[idx], allow_pickle=True)\n",
    "        y = np.load(self.label_paths[idx])\n",
    "\n",
    "        # 오류 방지: 길이 맞춤\n",
    "        min_len = min(len(x), len(y))\n",
    "        x = x[:min_len]\n",
    "        y = y[:min_len]\n",
    "\n",
    "        # Padding & Shape 변환\n",
    "        x = np.stack([\n",
    "            np.pad(sample, ((0, max(0, 40 - sample.shape[0])), (0, 0)), mode='constant')[:40]\n",
    "            for sample in x\n",
    "        ])\n",
    "        x = np.transpose(x, (0, 2, 1))            # (batch, 13, 40)\n",
    "        x = x[..., np.newaxis]                    # (batch, 13, 40, 1)\n",
    "        x = np.transpose(x, (0, 2, 1, 3))         # → (batch, 40, 13, 1)\n",
    "        return x, y\n",
    "\n",
    "# =============================\n",
    "# 2. 경로 설정\n",
    "# =============================\n",
    "train_mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "train_label_dir = os.path.join(train_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "val_label_dir = os.path.join(val_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "# =============================\n",
    "# 3. 제너레이터 준비\n",
    "# =============================\n",
    "train_gen = MFCCGenerator(train_mfcc_dir, train_label_dir, batch_size=32)\n",
    "val_gen = MFCCGenerator(val_mfcc_dir, val_label_dir, batch_size=32)\n",
    "\n",
    "# =============================\n",
    "# 4. 모델 불러오기 (4번 셀에서 정의된 함수 사용)\n",
    "# =============================\n",
    "model = build_cnn_model(input_shape=(40, 13, 1), num_classes=4)\n",
    "\n",
    "# =============================\n",
    "# 5. 콜백 설정\n",
    "# =============================\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=30, restore_best_weights=True, monitor='val_loss'),\n",
    "    ModelCheckpoint(\"voice_emotion_analyze.h5\", save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "# =============================\n",
    "# 6. 학습 실행\n",
    "# =============================\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=300,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# 7. 학습 기록 저장 (.pkl)\n",
    "# =============================\n",
    "with open(\"voice_emotion_analyze_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 완료 및 저장됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================\n",
    "# 1. history 로드\n",
    "# ================================\n",
    "with open(\"voice_emotion_analyze_history.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# ================================\n",
    "# 2. 시각화\n",
    "# ================================\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능 개선 CNN + LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m192\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,252</span> (333.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,252\u001b[0m (333.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,060</span> (332.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,060\u001b[0m (332.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import TimeDistributed, Flatten, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# GPU 메모리 점진 할당 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def build_cnn_lstm_model(input_shape=(40, 13, 1), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # CNN block\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = TimeDistributed(Flatten())(x)  # (batch, time_steps, features)\n",
    "\n",
    "    # LSTM block\n",
    "    x = LSTM(64, return_sequences=False)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "model = build_cnn_lstm_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolbom_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
