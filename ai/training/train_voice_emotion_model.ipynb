{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traindata 전처리\n",
    "\n",
    "# JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 처리된 JSON 수: 815491\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 라벨링 JSON 파일이 있는 최상위 폴더 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "\n",
    "# 실제 WAV 파일이 존재하는 원천 데이터의 최상위 경로\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 정상적으로 처리된 데이터 정보를 담을 리스트\n",
    "data = []\n",
    "\n",
    "# 오류 발생 시 해당 JSON 파일 또는 존재하지 않는 WAV 경로를 저장할 리스트\n",
    "broken_files = []\n",
    "\n",
    "# 라벨링 폴더 내부의 모든 JSON 파일을 재귀적으로 탐색\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # 현재 JSON 파일의 전체 경로 구성\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기 및 파싱\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # JSON 내부 정보 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로를 라벨 기준 상대경로로 변환\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 상대 경로에서 모든 TL을 TS로 변경\n",
    "                relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "\n",
    "                # WAV 경로를 원천 데이터 기준으로 재구성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일 존재 여부 확인\n",
    "                if os.path.exists(wav_path):\n",
    "                    # 정상 데이터 추가\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 존재하지 않는 경우 로그에 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 중 오류 발생 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# 정상적으로 수집된 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 CSV 파일로 저장\n",
    "os.makedirs(\"./data/usou\", exist_ok=True)\n",
    "df.to_csv(\"./data/usou/metadata_cleaned.csv\", index=False)\n",
    "\n",
    "# 오류가 발생한 경로들을 텍스트 파일로 저장\n",
    "with open(\"./data/usou/broken_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 최종 처리 결과 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출\n",
    "## MFCC 추출이란\n",
    "- 음성에서 특징을 뽑아낸 백터\n",
    "## 데이터 형태\n",
    "- 2차원 배열(시간 프레임수, 13)\n",
    "# 배치\n",
    "- 배치 : 전체 데이터를 나누어 처리하는 단위\n",
    "## 나누는 이유\n",
    "- 메모리 부족으로 컴퓨터 프리징 발생\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17508/736413005.py:12: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "100%|██████████| 815491/815491 [2:58:19<00:00, 76.22it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공적으로 저장된 배치 수: 82\n",
      "실패한 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1. 메타데이터 로드\n",
    "# ============================\n",
    "# 사전에 정제된 메타데이터 CSV 파일 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ============================\n",
    "# 2. 설정값 정의\n",
    "# ============================\n",
    "sample_rate = 16000            # 음성 파일 샘플링 레이트 (Hz)\n",
    "max_duration = 5.0             # WAV 파일 최대 로딩 시간 (초) → 너무 긴 파일 방지\n",
    "save_interval = 10000          # 몇 개마다 배치로 저장할지 설정\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []             # MFCC 벡터 리스트\n",
    "labels = []                    # 감정 레이블 리스트\n",
    "error_files = []               # 처리 중 실패한 파일 목록\n",
    "save_counter = 0               # 배치 저장 인덱스\n",
    "\n",
    "# 저장 디렉토리 설정\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3. MFCC 추출 루프\n",
    "# ============================\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]  # 메타데이터에 포함된 wav 파일 전체 경로\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 13차원 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, n_mfcc)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 에러 발생 시 파일 경로 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 수 이상 쌓이면 배치 저장 후 메모리 초기화\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터가 있다면 마지막 배치 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ============================\n",
    "# 4. 에러 파일 저장\n",
    "# ============================\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/broken_audio_files.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ============================\n",
    "# 5. 처리 결과 출력\n",
    "# ============================\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "✅ 레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 14:35:02.667534: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743053702.684248   21141 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743053702.688507   21141 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743053702.700707   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743053702.700724   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743053702.700725   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743053702.700726   21141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-27 14:35:02.704932: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 컨볼루션 레이어: 필터 수 32, 커널 사이즈 3x3, 활성화 함수 ReLU\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    # 배치 정규화: 학습 안정성과 속도 개선\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 최대 풀링: 출력 크기 절반으로 줄임 (특징 추출과 과적합 방지)\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 두 번째 컨볼루션 레이어: 필터 수 64\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 세 번째 컨볼루션 레이어: 필터 수 128\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 전역 평균 풀링: 전체 피처 맵의 평균을 계산하여 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 완전 연결층(Dense Layer) 추가\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    # 과적합 방지를 위한 드롭아웃 (30%)\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # 출력층: softmax로 감정 클래스 확률 예측\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일: Adam 옵티마이저, sparse_categorical_crossentropy 손실 함수, 정확도 지표\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메타데이터 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 처리된 JSON 수: 112157\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "\n",
    "# 라벨링 JSON 파일이 저장된 루트 폴더\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "\n",
    "# 실제 음성 WAV 파일이 있는 루트 폴더\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "\n",
    "# ========================================\n",
    "# 2. 결과 저장 리스트 초기화\n",
    "# ========================================\n",
    "data = []             # 메타데이터 저장용 리스트\n",
    "broken_files = []     # 에러 발생한 파일 로그용 리스트\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 파일 순회 및 정보 추출\n",
    "# ========================================\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # 화자 정보에서 감정, 스타일, 세부 감정 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "\n",
    "                # WAV 파일 이름 추출\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로에서 라벨 루트를 기준으로 상대 경로 추출\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 실제 WAV 파일 경로 생성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일이 존재하면 메타데이터에 추가\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 없는 경우 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 실패 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}, 에러: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 결과 저장\n",
    "# ========================================\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 저장 경로 생성\n",
    "os.makedirs(\"/media/usou/PortableSSD/mldl_project/data/validation\", exist_ok=True)\n",
    "\n",
    "# 메타데이터 CSV 저장\n",
    "df.to_csv(\"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\", index=False)\n",
    "\n",
    "# 에러 파일 로그 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/validation/broken_val_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 요약 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 Validation 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112157/112157 [27:27<00:00, 68.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공적으로 저장된 배치 수: 12\n",
      "실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드\n",
    "# ========================================\n",
    "\n",
    "# validation용 정제된 메타데이터 CSV 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. 설정값 정의\n",
    "# ========================================\n",
    "\n",
    "sample_rate = 16000             # 음성 샘플링 레이트 (16kHz)\n",
    "max_duration = 5.0              # WAV 최대 로딩 시간 (초)\n",
    "save_interval = 10000           # 배치 저장 기준 개수\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []              # 추출된 MFCC 벡터 리스트\n",
    "labels = []                     # 감정 레이블 리스트\n",
    "error_files = []                # 실패한 파일 목록\n",
    "save_counter = 0                # 배치 파일 번호\n",
    "\n",
    "# ========================================\n",
    "# 3. MFCC 추출 루프\n",
    "# ========================================\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 추출 (13차원)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, 13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 로딩 실패 시 에러 출력 및 로그 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 개수 이상이면 배치 저장\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 루프 종료 후 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ========================================\n",
    "# 4. 에러 파일 저장\n",
    "# ========================================\n",
    "\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/validation/broken_audio_files_val.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 5. 처리 결과 출력\n",
    "# ========================================\n",
    "\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 데이터용 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# ========================\n",
    "# 1. 배치 로딩 함수 정의\n",
    "# ========================\n",
    "def load_batches(batch_dir, prefix):\n",
    "    mfcc_list = []\n",
    "    label_list = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        mfcc_path = os.path.join(batch_dir, f\"{prefix}_batch_{i}.npy\")\n",
    "        label_path = os.path.join(batch_dir, \"encoded_labels\", f\"label_batch_{i}.npy\")\n",
    "        if not os.path.exists(mfcc_path):\n",
    "            break\n",
    "        mfccs = np.load(mfcc_path, allow_pickle=True)\n",
    "        labels = np.load(label_path)\n",
    "        mfcc_list.extend(mfccs)\n",
    "        label_list.extend(labels)\n",
    "        i += 1\n",
    "    return mfcc_list, label_list\n",
    "\n",
    "# ========================\n",
    "# 2. 학습 / 검증 데이터 로딩\n",
    "# ========================\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data/validation_batches\"\n",
    "\n",
    "X_train_raw, y_train = load_batches(train_dir, \"mfcc\")\n",
    "X_val_raw, y_val = load_batches(val_dir, \"mfcc\")\n",
    "\n",
    "# ========================\n",
    "# 3. 패딩 및 형태 변환\n",
    "# ========================\n",
    "max_len = max([x.shape[0] for x in X_train_raw + X_val_raw])\n",
    "X_train = pad_sequences(X_train_raw, maxlen=max_len, dtype='float32', padding='post')\n",
    "X_val = pad_sequences(X_val_raw, maxlen=max_len, dtype='float32', padding='post')\n",
    "\n",
    "# CNN 입력을 위해 채널 차원 추가\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_val = np.expand_dims(X_val, -1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# ========================\n",
    "# 4. CNN 모델 정의\n",
    "# ========================\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ========================\n",
    "# 5. 모델 생성 및 학습\n",
    "# ========================\n",
    "input_shape = X_train.shape[1:]  # (time, n_mfcc, 1)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy', mode='max')\n",
    "]\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superbad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
