{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743649386.737998   47640 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743649386.740982   97034 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743649386.774063   97024 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743649386.795430   97029 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "굳 (351, 100)\n",
      "굳 (321, 30, 100)\n",
      "Epoch 1/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - acc: 0.5363 - loss: 17.6913\n",
      "Epoch 1: val_acc improved from -inf to 0.98165, saving model to ./models/gesture_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - acc: 0.5401 - loss: 17.4177 - val_acc: 0.9817 - val_loss: 0.0878 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9830 - loss: 0.2299\n",
      "Epoch 2: val_acc improved from 0.98165 to 1.00000, saving model to ./models/gesture_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 0.9848 - loss: 0.2028 - val_acc: 1.0000 - val_loss: 3.3580e-06 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.3197e-04\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.1704e-04 - val_acc: 1.0000 - val_loss: 4.9606e-06 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.8702e-04\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.5730e-04 - val_acc: 1.0000 - val_loss: 4.4971e-06 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.6971e-05\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 4.4860e-05 - val_acc: 1.0000 - val_loss: 4.1113e-06 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.7384e-07\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 7.4240e-06 - val_acc: 1.0000 - val_loss: 3.7713e-06 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4608e-06\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 7.6532e-06 - val_acc: 1.0000 - val_loss: 3.3307e-06 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.0063e-05\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 6.2225e-05 - val_acc: 1.0000 - val_loss: 2.8278e-06 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8363e-05\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.9199e-05 - val_acc: 1.0000 - val_loss: 2.5982e-06 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7397e-06\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 7.6496e-06 - val_acc: 1.0000 - val_loss: 2.4178e-06 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.4851e-06\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 7.8008e-06 - val_acc: 1.0000 - val_loss: 2.2275e-06 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0454e-05\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.2264e-05 - val_acc: 1.0000 - val_loss: 1.9487e-06 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8626e-05\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.7054e-05 - val_acc: 1.0000 - val_loss: 1.8612e-06 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.6824e-06\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 3.9585e-06 - val_acc: 1.0000 - val_loss: 1.7388e-06 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.2950e-05\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.9087e-05 - val_acc: 1.0000 - val_loss: 1.5780e-06 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8848e-06\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.4646e-06 - val_acc: 1.0000 - val_loss: 1.5037e-06 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4040e-05\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.3247e-05 - val_acc: 1.0000 - val_loss: 1.4063e-06 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7285e-05\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.6273e-05 - val_acc: 1.0000 - val_loss: 1.3265e-06 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.3302e-06\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 9.2333e-06 - val_acc: 1.0000 - val_loss: 1.2620e-06 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.2677e-06\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 7.4489e-06 - val_acc: 1.0000 - val_loss: 1.1986e-06 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7244e-06\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 7.7241e-06 - val_acc: 1.0000 - val_loss: 1.1308e-06 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.1724e-06\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.8554e-06 - val_acc: 1.0000 - val_loss: 1.0794e-06 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3108e-05\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.1071e-05 - val_acc: 1.0000 - val_loss: 1.0269e-06 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0423e-06\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 7.8369e-06 - val_acc: 1.0000 - val_loss: 9.8971e-07 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9134e-05\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.6733e-05 - val_acc: 1.0000 - val_loss: 9.4378e-07 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4491e-06\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.6345e-06 - val_acc: 1.0000 - val_loss: 9.2519e-07 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1819e-05\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.1036e-05 - val_acc: 1.0000 - val_loss: 8.7052e-07 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3760e-06\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 4.4615e-06 - val_acc: 1.0000 - val_loss: 8.4427e-07 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1150e-06\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.6091e-06 - val_acc: 1.0000 - val_loss: 8.3005e-07 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.2862e-06\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 5.2461e-06 - val_acc: 1.0000 - val_loss: 7.7428e-07 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.9151e-06\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 5.7434e-06 - val_acc: 1.0000 - val_loss: 7.4694e-07 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4512e-06\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 5.1937e-06 - val_acc: 1.0000 - val_loss: 7.3273e-07 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7377e-06\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.1358e-06 - val_acc: 1.0000 - val_loss: 7.0429e-07 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4560e-06\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 4.4349e-06 - val_acc: 1.0000 - val_loss: 6.7586e-07 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.1749e-06\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.5670e-06 - val_acc: 1.0000 - val_loss: 6.5836e-07 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.8352e-06\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.9342e-06 - val_acc: 1.0000 - val_loss: 6.3758e-07 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7436e-06\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.9199e-06 - val_acc: 1.0000 - val_loss: 6.2337e-07 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4230e-06\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.5946e-06 - val_acc: 1.0000 - val_loss: 6.0915e-07 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3192e-06\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.0667e-06 - val_acc: 1.0000 - val_loss: 5.8728e-07 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6930e-06\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.9964e-06 - val_acc: 1.0000 - val_loss: 5.8072e-07 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2097e-06\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4960e-06 - val_acc: 1.0000 - val_loss: 5.6869e-07 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0160e-06\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.3992e-06 - val_acc: 1.0000 - val_loss: 5.5775e-07 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.0076e-06\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 3.8814e-06 - val_acc: 1.0000 - val_loss: 5.3479e-07 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.5356e-06\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 4.3732e-06 - val_acc: 1.0000 - val_loss: 5.2385e-07 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.4151e-06\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.3823e-06 - val_acc: 1.0000 - val_loss: 5.1510e-07 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5034e-06\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.5937e-06 - val_acc: 1.0000 - val_loss: 5.0088e-07 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3567e-06\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.3098e-06 - val_acc: 1.0000 - val_loss: 4.9214e-07 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0180e-06\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.1365e-06 - val_acc: 1.0000 - val_loss: 4.8448e-07 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5003e-06\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.5486e-06 - val_acc: 1.0000 - val_loss: 4.7136e-07 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4512e-06\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.4971e-06 - val_acc: 1.0000 - val_loss: 4.6370e-07 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7450e-06\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.8709e-06 - val_acc: 1.0000 - val_loss: 4.5386e-07 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.1437e-07\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 8.1484e-07 - val_acc: 1.0000 - val_loss: 4.5277e-07 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.7606e-06\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 4.5623e-06 - val_acc: 1.0000 - val_loss: 4.4074e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5843e-06\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.7429e-06 - val_acc: 1.0000 - val_loss: 4.3855e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.3464e-06\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 4.0822e-06 - val_acc: 1.0000 - val_loss: 4.3199e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.5051e-07\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 9.0146e-07 - val_acc: 1.0000 - val_loss: 4.2871e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4700e-06\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.6057e-06 - val_acc: 1.0000 - val_loss: 4.2652e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.3802e-06\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.5643e-06 - val_acc: 1.0000 - val_loss: 4.2105e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5110e-06\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.5134e-06 - val_acc: 1.0000 - val_loss: 4.1777e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 60/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1286e-06\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 1.3926e-06 - val_acc: 1.0000 - val_loss: 4.1558e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 61/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.9911e-06\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 4.4596e-06 - val_acc: 1.0000 - val_loss: 4.0902e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 62/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6275e-06\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.7886e-06 - val_acc: 1.0000 - val_loss: 4.0574e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 63/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.8575e-06\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.7478e-06 - val_acc: 1.0000 - val_loss: 4.0137e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 64/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9308e-06\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.9833e-06 - val_acc: 1.0000 - val_loss: 3.9699e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 65/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8056e-07\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 6.9341e-07 - val_acc: 1.0000 - val_loss: 3.9699e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 66/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0112e-06\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.1292e-06 - val_acc: 1.0000 - val_loss: 3.9480e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 67/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.0367e-06\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.9437e-06 - val_acc: 1.0000 - val_loss: 3.8606e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 68/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3579e-06\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.3473e-06 - val_acc: 1.0000 - val_loss: 3.8277e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 69/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4411e-06\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.5406e-06 - val_acc: 1.0000 - val_loss: 3.8059e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 70/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2432e-06\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.2396e-06 - val_acc: 1.0000 - val_loss: 3.7731e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 71/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3136e-06\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.2976e-06 - val_acc: 1.0000 - val_loss: 3.7293e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 72/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5114e-06\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.4612e-06 - val_acc: 1.0000 - val_loss: 3.6746e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 73/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0738e-06\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.0717e-06 - val_acc: 1.0000 - val_loss: 3.6528e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 74/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7196e-06\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.7684e-06 - val_acc: 1.0000 - val_loss: 3.6309e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 75/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1202e-06\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.1199e-06 - val_acc: 1.0000 - val_loss: 3.5871e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 76/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9363e-06\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.8792e-06 - val_acc: 1.0000 - val_loss: 3.5543e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 77/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2057e-06\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.1469e-06 - val_acc: 1.0000 - val_loss: 3.5434e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 78/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.0449e-06\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 2.0410e-06 - val_acc: 1.0000 - val_loss: 3.5106e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 79/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 2.5111e-06 \n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - acc: 1.0000 - loss: 2.4763e-06 - val_acc: 1.0000 - val_loss: 3.4668e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 80/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.3591e-06\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 1.3770e-06 - val_acc: 1.0000 - val_loss: 3.4231e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 81/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1476e-06\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 1.1714e-06 - val_acc: 1.0000 - val_loss: 3.4012e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 82/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7295e-06\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 1.7914e-06 - val_acc: 1.0000 - val_loss: 3.3684e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 83/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.8849e-07\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.0601e-07 - val_acc: 1.0000 - val_loss: 3.3575e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 84/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8595e-06\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.8676e-06 - val_acc: 1.0000 - val_loss: 3.3028e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 85/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0877e-06\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.1840e-06 - val_acc: 1.0000 - val_loss: 3.2700e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 86/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.5815e-07\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 6.3575e-07 - val_acc: 1.0000 - val_loss: 3.2481e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 87/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.6215e-06\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.4952e-06 - val_acc: 1.0000 - val_loss: 3.2044e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 88/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.0692e-07\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.1389e-07 - val_acc: 1.0000 - val_loss: 3.1934e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 89/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5040e-07\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 9.1244e-07 - val_acc: 1.0000 - val_loss: 3.1606e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5372e-06\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.4180e-06 - val_acc: 1.0000 - val_loss: 3.1278e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4035e-06\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4577e-06 - val_acc: 1.0000 - val_loss: 3.0950e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5200e-06\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.3745e-06 - val_acc: 1.0000 - val_loss: 3.0622e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5974e-06\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.4584e-06 - val_acc: 1.0000 - val_loss: 3.0403e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4302e-06\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4708e-06 - val_acc: 1.0000 - val_loss: 3.0075e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.7963e-07\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.0403e-06 - val_acc: 1.0000 - val_loss: 2.9857e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3717e-06\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4272e-06 - val_acc: 1.0000 - val_loss: 2.9528e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4042e-06\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4130e-06 - val_acc: 1.0000 - val_loss: 2.9091e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3935e-06\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4403e-06 - val_acc: 1.0000 - val_loss: 2.9200e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.1571e-06\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.9584e-06 - val_acc: 1.0000 - val_loss: 2.8872e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.5463e-07\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 8.7533e-07 - val_acc: 1.0000 - val_loss: 2.8654e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.9473e-06\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.8686e-06 - val_acc: 1.0000 - val_loss: 2.8216e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.3360e-06\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.3588e-06 - val_acc: 1.0000 - val_loss: 2.7888e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.2418e-07\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 7.7955e-07 - val_acc: 1.0000 - val_loss: 2.7997e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.0717e-06\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.9831e-06 - val_acc: 1.0000 - val_loss: 2.7669e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1136e-06\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.1463e-06 - val_acc: 1.0000 - val_loss: 2.7669e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5034e-06\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.4809e-06 - val_acc: 1.0000 - val_loss: 2.7451e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.0673e-07\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.8675e-07 - val_acc: 1.0000 - val_loss: 2.7232e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.2877e-06\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.3373e-06 - val_acc: 1.0000 - val_loss: 2.7122e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7843e-06\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.7609e-06 - val_acc: 1.0000 - val_loss: 2.7013e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5138e-06\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.5029e-06 - val_acc: 1.0000 - val_loss: 2.6904e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3756e-06\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.3789e-06 - val_acc: 1.0000 - val_loss: 2.6794e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4002e-07\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 2.9005e-07 - val_acc: 1.0000 - val_loss: 2.6685e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.5222e-07\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.5605e-07 - val_acc: 1.0000 - val_loss: 2.6466e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.2728e-06\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 1.2843e-06 - val_acc: 1.0000 - val_loss: 2.6466e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m25/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.8104e-07\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 5.9522e-07 - val_acc: 1.0000 - val_loss: 2.6248e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.1031e-06\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.9735e-06 - val_acc: 1.0000 - val_loss: 2.6029e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.5163e-06\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.5008e-06 - val_acc: 1.0000 - val_loss: 2.6029e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.6357e-07\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 6.6325e-07 - val_acc: 1.0000 - val_loss: 2.5810e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0009e-06\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0205e-06 - val_acc: 1.0000 - val_loss: 2.5701e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1992e-06\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.3010e-06 - val_acc: 1.0000 - val_loss: 2.5591e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1087e-06\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9071e-06 - val_acc: 1.0000 - val_loss: 2.5482e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.7256e-07\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.2127e-07 - val_acc: 1.0000 - val_loss: 2.5373e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.1225e-07\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.6233e-07 - val_acc: 1.0000 - val_loss: 2.5263e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5650e-07\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.1958e-07 - val_acc: 1.0000 - val_loss: 2.5154e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.1681e-07\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.3688e-07 - val_acc: 1.0000 - val_loss: 2.5045e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.8376e-07\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.9515e-07 - val_acc: 1.0000 - val_loss: 2.4716e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6771e-06\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.5709e-06 - val_acc: 1.0000 - val_loss: 2.4607e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.3987e-07\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0643e-06 - val_acc: 1.0000 - val_loss: 2.4498e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.8907e-07\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.0561e-07 - val_acc: 1.0000 - val_loss: 2.4388e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.0165e-06\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.8138e-06 - val_acc: 1.0000 - val_loss: 2.4279e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.5288e-07\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.8612e-07 - val_acc: 1.0000 - val_loss: 2.4060e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.1982e-07\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.4940e-07 - val_acc: 1.0000 - val_loss: 2.4060e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m20/31\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5518e-07\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.9455e-07 - val_acc: 1.0000 - val_loss: 2.3951e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5962e-06\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.5830e-06 - val_acc: 1.0000 - val_loss: 2.3623e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9929e-06\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6617e-06 - val_acc: 1.0000 - val_loss: 2.3623e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6942e-06\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.5673e-06 - val_acc: 1.0000 - val_loss: 2.3404e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1906e-06\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.2300e-06 - val_acc: 1.0000 - val_loss: 2.3295e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9095e-06\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.8611e-06 - val_acc: 1.0000 - val_loss: 2.3076e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m27/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6678e-06\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.5888e-06 - val_acc: 1.0000 - val_loss: 2.2967e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1000e-06\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.0777e-06 - val_acc: 1.0000 - val_loss: 2.2748e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.9579e-07\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.8816e-07 - val_acc: 1.0000 - val_loss: 2.2748e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1986e-07\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.8940e-07 - val_acc: 1.0000 - val_loss: 2.2639e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0817e-06\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1278e-06 - val_acc: 1.0000 - val_loss: 2.2420e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.4256e-07\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.6846e-07 - val_acc: 1.0000 - val_loss: 2.2310e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8289e-06\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6085e-06 - val_acc: 1.0000 - val_loss: 2.2092e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.5615e-07\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.6561e-07 - val_acc: 1.0000 - val_loss: 2.1982e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1051e-06\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1004e-06 - val_acc: 1.0000 - val_loss: 2.1873e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1876e-06\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1759e-06 - val_acc: 1.0000 - val_loss: 2.1764e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.0197e-07\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.0599e-07 - val_acc: 1.0000 - val_loss: 2.1654e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2194e-06\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1013e-06 - val_acc: 1.0000 - val_loss: 2.1545e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.8518e-07\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.9240e-07 - val_acc: 1.0000 - val_loss: 2.1436e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6986e-07\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.8647e-07 - val_acc: 1.0000 - val_loss: 2.1217e-07 - learning_rate: 2.5000e-04\n",
      "Epoch 153/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9634e-06\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9332e-06 - val_acc: 1.0000 - val_loss: 2.1107e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 154/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0824e-06\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.0795e-06 - val_acc: 1.0000 - val_loss: 2.1107e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 155/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.2182e-07\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.8140e-07 - val_acc: 1.0000 - val_loss: 2.0998e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 156/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7101e-07\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.0802e-07 - val_acc: 1.0000 - val_loss: 2.0998e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 157/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2360e-06\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.1919e-06 - val_acc: 1.0000 - val_loss: 2.0889e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 158/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.6848e-07\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.6400e-07 - val_acc: 1.0000 - val_loss: 2.0779e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 159/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3117e-06\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9309e-06 - val_acc: 1.0000 - val_loss: 2.0670e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 160/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.1370e-06\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 2.3921e-06 - val_acc: 1.0000 - val_loss: 2.0561e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 161/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8987e-06\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6620e-06 - val_acc: 1.0000 - val_loss: 2.0561e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 162/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3156e-07\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 5.7162e-07 - val_acc: 1.0000 - val_loss: 2.0561e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6245e-06\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4442e-06 - val_acc: 1.0000 - val_loss: 2.0451e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 164/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2891e-07\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7975e-07 - val_acc: 1.0000 - val_loss: 2.0451e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 165/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9825e-06\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.6736e-06 - val_acc: 1.0000 - val_loss: 2.0233e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.3635e-07\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.4226e-07 - val_acc: 1.0000 - val_loss: 2.0233e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 167/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7735e-06\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.4435e-06 - val_acc: 1.0000 - val_loss: 2.0123e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 168/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.6092e-07\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.6904e-07 - val_acc: 1.0000 - val_loss: 2.0014e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.3238e-07\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.4389e-07 - val_acc: 1.0000 - val_loss: 1.9904e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3650e-06\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.2465e-06 - val_acc: 1.0000 - val_loss: 1.9795e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.3434e-07\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.7729e-07 - val_acc: 1.0000 - val_loss: 1.9795e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.3143e-07\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.7946e-07 - val_acc: 1.0000 - val_loss: 1.9686e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.5526e-07\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.3484e-07 - val_acc: 1.0000 - val_loss: 1.9686e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.0639e-07\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7314e-07 - val_acc: 1.0000 - val_loss: 1.9576e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9659e-07\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 3.9623e-07 - val_acc: 1.0000 - val_loss: 1.9576e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.1882e-07\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.2891e-07 - val_acc: 1.0000 - val_loss: 1.9358e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.4239e-07\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 7.4374e-07 - val_acc: 1.0000 - val_loss: 1.9248e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.3284e-07\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 8.3513e-07 - val_acc: 1.0000 - val_loss: 1.9139e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 9.2801e-07\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 1.0000 - loss: 9.2202e-07 - val_acc: 1.0000 - val_loss: 1.9139e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 6.1502e-07\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 6.4741e-07 - val_acc: 1.0000 - val_loss: 1.9030e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.2857e-07\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 6.5859e-07 - val_acc: 1.0000 - val_loss: 1.8920e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 182/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.3078e-07\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 9.2820e-07 - val_acc: 1.0000 - val_loss: 1.8920e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0334e-06\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 1.0049e-06 - val_acc: 1.0000 - val_loss: 1.8811e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.6373e-07\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.9413e-07 - val_acc: 1.0000 - val_loss: 1.8701e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.2841e-07\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.8165e-07 - val_acc: 1.0000 - val_loss: 1.8592e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 186/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6549e-06\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.3826e-06 - val_acc: 1.0000 - val_loss: 1.8483e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 187/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.1962e-07\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.8300e-07 - val_acc: 1.0000 - val_loss: 1.8483e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 188/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7671e-06\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.4677e-06 - val_acc: 1.0000 - val_loss: 1.8373e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 189/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0477e-06\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0045e-06 - val_acc: 1.0000 - val_loss: 1.8264e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 190/200\n",
      "\u001b[1m22/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4608e-06\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9589e-06 - val_acc: 1.0000 - val_loss: 1.8155e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 191/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8192e-06\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.7873e-06 - val_acc: 1.0000 - val_loss: 1.8155e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 192/200\n",
      "\u001b[1m21/31\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.5452e-07\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.4468e-07 - val_acc: 1.0000 - val_loss: 1.8045e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 193/200\n",
      "\u001b[1m23/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4061e-07\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.0043e-07 - val_acc: 1.0000 - val_loss: 1.8045e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0703e-06\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0153e-06 - val_acc: 1.0000 - val_loss: 1.7936e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m24/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9357e-07\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2938e-07 - val_acc: 1.0000 - val_loss: 1.7827e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 8.2565e-07\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - acc: 1.0000 - loss: 8.2398e-07 - val_acc: 1.0000 - val_loss: 1.7717e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m26/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 1.9363e-06\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - acc: 1.0000 - loss: 1.7221e-06 - val_acc: 1.0000 - val_loss: 1.7608e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 198/200\n",
      "\u001b[1m28/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7551e-07\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 1.0000 - loss: 3.3788e-07 - val_acc: 1.0000 - val_loss: 1.7608e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 199/200\n",
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.6476e-07\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 4.9245e-07 - val_acc: 1.0000 - val_loss: 1.7389e-07 - learning_rate: 1.2500e-04\n",
      "Epoch 200/200\n",
      "\u001b[1m30/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.9204e-07\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 1.0000 - loss: 6.9561e-07 - val_acc: 1.0000 - val_loss: 1.7280e-07 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time, os\n",
    "import json\n",
    "from tensorflow.keras.utils import to_categorical   \n",
    "from sklearn.model_selection import train_test_split    \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense         \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau       \n",
    "def collect_and_train(gesture_name, data_path, model_path, secs_for_action=15):\n",
    "    \"\"\"\n",
    "    사용자로부터 제스처 데이터를 수집하고 기존 제스처 파일들과 함께 모델을 학습합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    actions = []  \n",
    "    seq_length = 30    \n",
    "\n",
    "    # MediaPipe hands model\n",
    "    mp_hands = mp.solutions.hands      \n",
    "    mp_drawing = mp.solutions.drawing_utils       \n",
    "    hands = mp_hands.Hands(                     \n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    created_time = int(time.time())             \n",
    "    os.makedirs(data_path, exist_ok=True)         \n",
    "\n",
    "    # 새로운 데이터 수집\n",
    "    while cap.isOpened():\n",
    "        for idx, action in enumerate([gesture_name]): \n",
    "            data = []\n",
    "\n",
    "            ret, img = cap.read()                \n",
    "            img = cv2.flip(img, 1)          \n",
    "\n",
    "            cv2.putText(img, f'Collecting {action.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "            cv2.imshow('img', img)       \n",
    "            cv2.waitKey(3000)\n",
    "\n",
    "            start_time = time.time()      \n",
    "\n",
    "            while time.time() - start_time < secs_for_action:   \n",
    "                ret, img = cap.read()                               \n",
    "                img = cv2.flip(img, 1)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n",
    "                result = hands.process(img)                       \n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                if result.multi_hand_landmarks is not None:      \n",
    "                    for res in result.multi_hand_landmarks:       \n",
    "                        joint = np.zeros((21, 4))               \n",
    "                        for j, lm in enumerate(res.landmark):\n",
    "                            joint[j] = [lm.x, lm.y, lm.z, lm.visibility]    \n",
    "\n",
    "                        v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3]      \n",
    "                        v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3]    \n",
    "                        v = v2 - v1      \n",
    "                        v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]   \n",
    "\n",
    "                        angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                            v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:],\n",
    "                            v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]))         \n",
    "\n",
    "                        angle = np.degrees(angle)         \n",
    "\n",
    "                        angle_label = np.array([angle], dtype=np.float32)           \n",
    "                        angle_label = np.append(angle_label, idx)                  \n",
    "\n",
    "                        d = np.concatenate([joint.flatten(), angle_label])          \n",
    "                        data.append(d)                                              \n",
    "                        mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)      \n",
    "\n",
    "                cv2.imshow('img', img)              \n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    return\n",
    "\n",
    "            data = np.array(data)\n",
    "            print(action, data.shape)\n",
    "            np.save(os.path.join(data_path, f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "            full_seq_data = []\n",
    "            for seq in range(len(data) - seq_length):\n",
    "                full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "            full_seq_data = np.array(full_seq_data)\n",
    "            print(action, full_seq_data.shape)\n",
    "            np.save(os.path.join(data_path, f'seq_{action}_{created_time}'), full_seq_data)\n",
    "        break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # 기존 데이터 로드 및 병합\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for filename in os.listdir(data_path):\n",
    "        if filename.startswith('seq_') and filename.endswith('.npy'):\n",
    "            action_name = filename.split('_')[1]\n",
    "            if action_name not in actions:\n",
    "                actions.append(action_name)\n",
    "\n",
    "            action_index = actions.index(action_name)\n",
    "            data = np.load(os.path.join(data_path, filename))\n",
    "            x_data.extend(data[:, :, :-1].tolist())\n",
    "            y_data.extend([action_index] * len(data))\n",
    "\n",
    "    x_data = np.array(x_data)\n",
    "    y_data = np.array(y_data)\n",
    "    y_data = to_categorical(y_data, num_classes=len(actions))\n",
    "\n",
    "    x_data = x_data.astype(np.float32)\n",
    "    y_data = y_data.astype(np.float32)\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=43)\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(len(actions), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=200,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 모델 학습 후 레이블 저장\n",
    "    with open('./training/gesture_labels.json', 'w') as f:\n",
    "        json.dump(actions, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gesture_name = input(\"학습할 제스처 이름을 입력하세요: \")\n",
    "    data_path = './training'\n",
    "    model_path = './models/gesture_model.h5'\n",
    "\n",
    "    collect_and_train(gesture_name, data_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1743649760.944437   47640 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743649760.950415  118932 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "W0000 00:00:1743649760.997593  118922 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743649761.032179  118925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def put_korean_text(img, text, position, font_size=32, color=(0, 0, 255)):\n",
    "    \"\"\"\n",
    "    OpenCV 이미지에 한글 텍스트를 그리기 위해 PIL을 사용합니다.\n",
    "    img: OpenCV BGR 이미지\n",
    "    text: 출력할 텍스트 (한글 포함)\n",
    "    position: 텍스트 위치 (x, y)\n",
    "    font_size: 텍스트 크기\n",
    "    color: 텍스트 색상 (B, G, R)\n",
    "    \"\"\"\n",
    "    # OpenCV BGR 이미지를 RGB로 변환하고 PIL 이미지로 변경\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img_rgb)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    try:\n",
    "        # Ubuntu 환경에서 Nanum Gothic 폰트 사용\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\", font_size)\n",
    "    except IOError:\n",
    "        print(\"NanumGothic.ttf not found. Using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "    # PIL은 색상을 RGB 순서로 사용합니다.\n",
    "    draw.text(position, text, font=font, fill=(color[2], color[1], color[0]))\n",
    "    # PIL 이미지를 다시 OpenCV BGR 이미지로 변환\n",
    "    img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "    return img\n",
    "\n",
    "def recognize_gesture(model_path):\n",
    "    \"\"\"\n",
    "    실시간으로 제스처를 인식하고 화면에 표시합니다.\n",
    "    \"\"\"\n",
    "    seq_length = 30\n",
    "\n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Model file not found at {model_path}\")\n",
    "        return\n",
    "\n",
    "    # 모델의 레이블(제스처 이름) 가져오기\n",
    "    try:\n",
    "        with open('./training/gesture_labels.json', 'r') as f:\n",
    "            actions = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: gesture_labels.json file not found.\")\n",
    "        return\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    hands = mp_hands.Hands(\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    seq = []\n",
    "    action_seq = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Frame not captured.\")\n",
    "            break\n",
    "\n",
    "        img = cv2.flip(img, 1)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(img_rgb)\n",
    "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    joint[j] = [landmark.x, landmark.y, landmark.z, landmark.visibility]\n",
    "\n",
    "                v1 = joint[[0, 1, 2, 3, 0, 5, 6, 7, 0, 9, 10, 11, 0, 13, 14, 15, 0, 17, 18, 19], :3]\n",
    "                v2 = joint[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], :3]\n",
    "                v = v2 - v1\n",
    "                norm = np.linalg.norm(v, axis=1)\n",
    "                norm[norm == 0] = 1e-6  # 0으로 나누는 경우 방지\n",
    "                v = v / norm[:, np.newaxis]\n",
    "\n",
    "                angle = np.arccos(np.clip(np.einsum('nt,nt->n',\n",
    "                    v[[0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18], :],\n",
    "                    v[[1, 2, 3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 19], :]), -1.0, 1.0))\n",
    "                angle = np.degrees(angle)\n",
    "\n",
    "                d = np.concatenate([joint.flatten(), angle])\n",
    "                seq.append(d)\n",
    "\n",
    "                mp_drawing.draw_landmarks(img_bgr, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                if len(seq) < seq_length:\n",
    "                    continue\n",
    "\n",
    "                input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "                y_pred = model.predict(input_data).squeeze()\n",
    "\n",
    "                if y_pred.ndim == 0:\n",
    "                    print(\"No prediction result.\")\n",
    "                    continue\n",
    "\n",
    "                i_pred = int(np.argmax(y_pred))\n",
    "                conf = y_pred[i_pred]\n",
    "\n",
    "                if conf < 0.9:\n",
    "                    continue\n",
    "\n",
    "                predicted_action = actions[i_pred]\n",
    "                action_seq.append(predicted_action)\n",
    "\n",
    "                if len(action_seq) < 3:\n",
    "                    continue\n",
    "\n",
    "                this_action = '?'\n",
    "                if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                    this_action = predicted_action\n",
    "\n",
    "                text = f'{this_action.upper()} ({conf:.2f})'\n",
    "                img_bgr = put_korean_text(img_bgr, text, (10, 60), font_size=32, color=(0, 0, 255))\n",
    "        else:\n",
    "            img_bgr = put_korean_text(img_bgr, \"손이 감지되지 않았습니다.\", (10, 60), font_size=24, color=(0, 255, 0))\n",
    "\n",
    "        cv2.imshow('img', img_bgr)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = './models/gesture_model.h5'\n",
    "    recognize_gesture(model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dora_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
