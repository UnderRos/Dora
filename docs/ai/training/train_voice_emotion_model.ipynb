{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traindata 전처리\n",
    "\n",
    "# JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 처리된 JSON 수: 815491\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 라벨링 JSON 파일이 있는 최상위 폴더 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "\n",
    "# 실제 WAV 파일이 존재하는 원천 데이터의 최상위 경로\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 정상적으로 처리된 데이터 정보를 담을 리스트\n",
    "data = []\n",
    "\n",
    "# 오류 발생 시 해당 JSON 파일 또는 존재하지 않는 WAV 경로를 저장할 리스트\n",
    "broken_files = []\n",
    "\n",
    "# 라벨링 폴더 내부의 모든 JSON 파일을 재귀적으로 탐색\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            # 현재 JSON 파일의 전체 경로 구성\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기 및 파싱\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # JSON 내부 정보 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로를 라벨 기준 상대경로로 변환\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 상대 경로에서 모든 TL을 TS로 변경\n",
    "                relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "\n",
    "                # WAV 경로를 원천 데이터 기준으로 재구성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일 존재 여부 확인\n",
    "                if os.path.exists(wav_path):\n",
    "                    # 정상 데이터 추가\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 존재하지 않는 경우 로그에 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 중 오류 발생 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# 정상적으로 수집된 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 CSV 파일로 저장\n",
    "os.makedirs(\"./data/usou\", exist_ok=True)\n",
    "df.to_csv(\"./data/usou/metadata_cleaned.csv\", index=False)\n",
    "\n",
    "# 오류가 발생한 경로들을 텍스트 파일로 저장\n",
    "with open(\"./data/usou/broken_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 최종 처리 결과 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출\n",
    "-  MFCC 추출이란\n",
    "    - 음성에서 특징을 뽑아낸 백터\n",
    "-  데이터 형태\n",
    "    - 2차원 배열(시간 프레임수, 13)\n",
    "- 배치\n",
    "    - 배치 : 전체 데이터를 나누어 처리하는 단위\n",
    "- 나누는 이유\n",
    "    - 메모리 부족으로 컴퓨터 프리징 발생\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13245/736413005.py:12: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      " 94%|█████████▍| 768404/815491 [3:09:18<13:17, 59.07it/s]  "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 1. 메타데이터 로드\n",
    "# ============================\n",
    "# 사전에 정제된 메타데이터 CSV 파일 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ============================\n",
    "# 2. 설정값 정의\n",
    "# ============================\n",
    "sample_rate = 16000            # 음성 파일 샘플링 레이트 (Hz)\n",
    "max_duration = 5.0             # WAV 파일 최대 로딩 시간 (초) → 너무 긴 파일 방지\n",
    "save_interval = 10000          # 몇 개마다 배치로 저장할지 설정\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []             # MFCC 벡터 리스트\n",
    "labels = []                    # 감정 레이블 리스트\n",
    "error_files = []               # 처리 중 실패한 파일 목록\n",
    "save_counter = 0               # 배치 저장 인덱스\n",
    "\n",
    "# 저장 디렉토리 설정\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3. MFCC 추출 루프\n",
    "# ============================\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]  # 메타데이터에 포함된 wav 파일 전체 경로\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 13차원 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, n_mfcc)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 에러 발생 시 파일 경로 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 수 이상 쌓이면 배치 저장 후 메모리 초기화\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터가 있다면 마지막 배치 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ============================\n",
    "# 4. 에러 파일 저장\n",
    "# ============================\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/broken_audio_files.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ============================\n",
    "# 5. 처리 결과 출력\n",
    "# ============================\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13245/1154100914.py:5: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    }
   ],
   "source": [
    "import os, librosa, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data_7class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "existing = [f for f in os.listdir(save_dir) if f.startswith(\"mfcc_batch_\")]\n",
    "start_idx = len(existing)\n",
    "batch_size = 10000\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "error_files = []\n",
    "\n",
    "for batch_idx in range(start_idx, (len(df) // batch_size) + 1):\n",
    "    start = batch_idx * batch_size\n",
    "    end = min(start + batch_size, len(df))\n",
    "    mfccs, labels = [], []\n",
    "    print(f\"▶️ Batch {batch_idx}: {start}~{end}\")\n",
    "    for i in tqdm(range(start, end)):\n",
    "        path, emo = df.loc[i, \"wav_path\"], df.loc[i, \"emotion\"]\n",
    "        try:\n",
    "            y, sr = librosa.load(path, sr=sample_rate, duration=max_duration)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            mfccs.append(mfcc.T)\n",
    "            labels.append(emo)\n",
    "        except: error_files.append(path)\n",
    "    np.save(f\"{save_dir}/mfcc_batch_{batch_idx}.npy\", np.array(mfccs, dtype=object))\n",
    "    np.save(f\"{save_dir}/label_batch_{batch_idx}.npy\", np.array(labels))\n",
    "\n",
    "with open(f\"{save_dir}/broken_files.txt\", \"a\") as f:\n",
    "    for path in error_files: f.write(path + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13245/1179290027.py:8: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 재실행: Split 10/10 (샘플 733941~815491)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81550/81550 [20:38<00:00, 65.84it/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 필요한 변수 다시 선언\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data_7class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_interval = 1000\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 재시작 변수\n",
    "split_idx = 9  # 마지막 분할\n",
    "split_count = 10\n",
    "total = len(df)\n",
    "split_size = total // split_count\n",
    "start = split_idx * split_size\n",
    "end = total\n",
    "df_split = df.iloc[start:end]\n",
    "\n",
    "# 초기화\n",
    "save_counter = len([f for f in os.listdir(save_dir) if f.startswith(\"mfcc_batch_\")])\n",
    "error_files = []\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "\n",
    "print(f\"\\n🔄 재실행: Split {split_idx+1}/{split_count} (샘플 {start}~{end})\")\n",
    "\n",
    "for _, row in tqdm(df_split.iterrows(), total=len(df_split)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 마지막 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "    save_counter += 1\n",
    "\n",
    "# 에러 로그 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data_7class/broken_audio_files.txt\", \"a\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC 배치 파일 수: 902\n",
      "레이블 배치 파일 수: 902\n",
      "마지막 MFCC 파일: mfcc_batch_99.npy\n",
      "마지막 Label 파일: label_batch_99.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "\n",
    "# 저장된 MFCC 배치 파일 목록 확인\n",
    "mfcc_files = sorted([f for f in os.listdir(save_dir) if f.startswith(\"mfcc_batch_\")])\n",
    "label_files = sorted([f for f in os.listdir(save_dir) if f.startswith(\"label_batch_\")])\n",
    "\n",
    "print(f\"MFCC 배치 파일 수: {len(mfcc_files)}\")\n",
    "print(f\"레이블 배치 파일 수: {len(label_files)}\")\n",
    "\n",
    "# 마지막 배치 파일 이름 확인\n",
    "print(\"마지막 MFCC 파일:\", mfcc_files[-1])\n",
    "print(\"마지막 Label 파일:\", label_files[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 MFCC 샘플 수: 1000\n",
      "🧾 레이블 수: 1000\n",
      "🔍 첫 샘플 shape: (140, 13)\n",
      "🔤 첫 레이블: Happy\n",
      "🔤 첫 레이블: Happy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 예: 마지막 저장된 배치 번호가 16이라면\n",
    "mfcc = np.load(os.path.join(save_dir, \"mfcc_batch_16.npy\"), allow_pickle=True)\n",
    "labels = np.load(os.path.join(save_dir, \"label_batch_16.npy\"))\n",
    "\n",
    "print(\"📦 MFCC 샘플 수:\", len(mfcc))\n",
    "print(\"🧾 레이블 수:\", len(labels))\n",
    "print(\"🔍 첫 샘플 shape:\", mfcc[0].shape)\n",
    "print(\"🔤 첫 레이블:\", labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전체 저장된 MFCC 샘플 수: 897041\n"
     ]
    }
   ],
   "source": [
    "total_mfcc = 0\n",
    "for f in mfcc_files:\n",
    "    data = np.load(os.path.join(save_dir, f), allow_pickle=True)\n",
    "    total_mfcc += len(data)\n",
    "print(\"✅ 전체 저장된 MFCC 샘플 수:\", total_mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 컨볼루션 레이어: 필터 수 32, 커널 사이즈 3x3, 활성화 함수 ReLU\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    # 배치 정규화: 학습 안정성과 속도 개선\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 최대 풀링: 출력 크기 절반으로 줄임 (특징 추출과 과적합 방지)\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 두 번째 컨볼루션 레이어: 필터 수 64\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 세 번째 컨볼루션 레이어: 필터 수 128\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # 전역 평균 풀링: 전체 피처 맵의 평균을 계산하여 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 완전 연결층(Dense Layer) 추가\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    # 과적합 방지를 위한 드롭아웃 (30%)\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # 출력층: softmax로 감정 클래스 확률 예측\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일: Adam 옵티마이저, sparse_categorical_crossentropy 손실 함수, 정확도 지표\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메타데이터 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 처리된 JSON 수: 112157\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "\n",
    "# 라벨링 JSON 파일이 저장된 루트 폴더\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "\n",
    "# 실제 음성 WAV 파일이 있는 루트 폴더\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "\n",
    "# ========================================\n",
    "# 2. 결과 저장 리스트 초기화\n",
    "# ========================================\n",
    "data = []             # 메타데이터 저장용 리스트\n",
    "broken_files = []     # 에러 발생한 파일 로그용 리스트\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 파일 순회 및 정보 추출\n",
    "# ========================================\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                # JSON 파일 열기\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                # 화자 정보에서 감정, 스타일, 세부 감정 추출\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "\n",
    "                # WAV 파일 이름 추출\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                # 현재 JSON 경로에서 라벨 루트를 기준으로 상대 경로 추출\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "\n",
    "                # 실제 WAV 파일 경로 생성\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                # WAV 파일이 존재하면 메타데이터에 추가\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    # WAV 파일이 없는 경우 기록\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                # JSON 파싱 실패 시 기록\n",
    "                print(f\"JSON 읽기 오류: {json_path}, 에러: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 결과 저장\n",
    "# ========================================\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 저장 경로 생성\n",
    "os.makedirs(\"/media/usou/PortableSSD/mldl_project/data/validation\", exist_ok=True)\n",
    "\n",
    "# 메타데이터 CSV 저장\n",
    "df.to_csv(\"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\", index=False)\n",
    "\n",
    "# 에러 파일 로그 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/validation/broken_val_files.txt\", \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 요약 출력\n",
    "print(f\"정상 처리된 JSON 수: {len(df)}\")\n",
    "print(f\"에러 발생 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 Validation 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112157/112157 [29:11<00:00, 64.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성공적으로 저장된 배치 수: 12\n",
      "실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드\n",
    "# ========================================\n",
    "\n",
    "# validation용 정제된 메타데이터 CSV 경로\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. 설정값 정의\n",
    "# ========================================\n",
    "\n",
    "sample_rate = 16000             # 음성 샘플링 레이트 (16kHz)\n",
    "max_duration = 5.0              # WAV 최대 로딩 시간 (초)\n",
    "save_interval = 10000           # 배치 저장 기준 개수\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 저장용 리스트 초기화\n",
    "mfcc_features = []              # 추출된 MFCC 벡터 리스트\n",
    "labels = []                     # 감정 레이블 리스트\n",
    "error_files = []                # 실패한 파일 목록\n",
    "save_counter = 0                # 배치 파일 번호\n",
    "\n",
    "# ========================================\n",
    "# 3. MFCC 추출 루프\n",
    "# ========================================\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "\n",
    "    try:\n",
    "        # WAV 파일 로딩 (최대 max_duration 초까지만 로드)\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "\n",
    "        # MFCC 추출 (13차원)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # 시간 축 기준으로 전치 (time_step, 13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        # 로딩 실패 시 에러 출력 및 로그 저장\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    # 일정 개수 이상이면 배치 저장\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 루프 종료 후 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ========================================\n",
    "# 4. 에러 파일 저장\n",
    "# ========================================\n",
    "\n",
    "error_log_path = \"/media/usou/PortableSSD/mldl_project/data/validation/broken_audio_files_val.txt\"\n",
    "with open(error_log_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 5. 처리 결과 출력\n",
    "# ========================================\n",
    "\n",
    "print(f\"성공적으로 저장된 배치 수: {save_counter + 1}\")\n",
    "print(f\"실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 데이터용 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 레이블 개수: 815491\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad' 'nan']\n",
      "배치 수: 82\n",
      "레이블 인코딩 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집\n",
    "# ============================\n",
    "# label_batch_*.npy 파일 경로 리스트\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 레이블 리스트 생성\n",
    "all_labels = []\n",
    "batch_label_data = []  # 배치별 데이터도 임시 저장\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    batch_label_data.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장 (추후 예측 결과 복원용)\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 레이블 개수: {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"배치 수: {len(label_files)}\")\n",
    "print(\"레이블 인코딩 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC DataGenerator 클래스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_dir, prefix, batch_size=1, shuffle=True):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 배치 파일 목록 생성\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "        self.indices = list(range(len(self.mfcc_files)))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_mfccs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "            label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "            mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_data = np.load(label_path)\n",
    "\n",
    "            # 가장 긴 시퀀스 기준으로 padding\n",
    "            max_len = max([x.shape[0] for x in mfcc_data])\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data, maxlen=max_len, dtype='float32', padding='post')\n",
    "            padded = np.expand_dims(padded, -1)  # (batch, time, n_mfcc, 1)\n",
    "\n",
    "            batch_mfccs.append(padded)\n",
    "            batch_labels.append(label_data)\n",
    "\n",
    "        X = np.concatenate(batch_mfccs, axis=0)\n",
    "        y = np.concatenate(batch_labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 활성화 및 안정 설정 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 가능한 GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "✔ GPU 메모리 자동 증가 설정 완료\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. GPU 장치 목록 출력\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"사용 가능한 GPU:\", gpus)\n",
    "\n",
    "# 2. 메모리 자동 증가 설정 (안정성을 위해 권장)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✔ GPU 메모리 자동 증가 설정 완료\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"⚠ 메모리 설정 중 오류 발생:\", e)\n",
    "else:\n",
    "    print(\"❌ GPU를 찾을 수 없습니다. CPU로 진행됩니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label_encoder.pkl을 로드해 동일하게 인코딩하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 레이블 인코딩 및 저장 완료 (배치 수: 12)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "encoded_label_dir = os.path.join(val_label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# 학습 데이터에서 저장한 LabelEncoder 로드\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 validation 레이블 수집\n",
    "# ============================\n",
    "label_files = sorted(glob.glob(os.path.join(val_label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "for i, label_file in enumerate(label_files):\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"✅ Validation 레이블 인코딩 및 저장 완료 (배치 수: {len(label_files)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델 정의\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (예: (시간축 길이, MFCC 차원 수, 채널 수))\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        tensorflow.keras.Model: 컴파일 완료된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())               # 학습 안정성 향상\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))     # 공간 크기 감소\n",
    "\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())           # 피처맵 전체 평균값\n",
    "\n",
    "    # [4] 완전 연결층 + 드롭아웃\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))                       # 과적합 방지\n",
    "\n",
    "    # [5] 출력층 - 클래스 수만큼 softmax 출력\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,442</span> (1.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332,442\u001b[0m (1.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,330</span> (864.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m221,330\u001b[0m (864.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Computed output size would be negative. Received `inputs shape=(None, 37, 1, 64)`, `kernel shape=(3, 3, 64, 128)`, `dilation_rate=[1 1]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     35\u001b[39m input_shape = sample_input.shape[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# (time, n_mfcc, 1)\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# 4. 모델 생성 및 요약\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m model = \u001b[43mcreate_cnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m model.summary()\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 5. 콜백 정의 (모델 저장 및 EarlyStopping)\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mcreate_cnn_model\u001b[39m\u001b[34m(input_shape, num_classes)\u001b[39m\n\u001b[32m     25\u001b[39m model.add(layers.MaxPooling2D(pool_size=(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)))\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# [3] 세 번째 컨볼루션 블록\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m model.add(layers.BatchNormalization())\n\u001b[32m     30\u001b[39m model.add(layers.GlobalAveragePooling2D())           \u001b[38;5;66;03m# 피처맵 전체 평균값\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/models/sequential.py:122\u001b[39m, in \u001b[36mSequential.add\u001b[39m\u001b[34m(self, layer, rebuild)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mself\u001b[39m._layers.append(layer)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rebuild:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/models/sequential.py:149\u001b[39m, in \u001b[36mSequential._maybe_rebuild\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    148\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].batch_shape\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33minput_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._layers) > \u001b[32m1\u001b[39m:\n\u001b[32m    151\u001b[39m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[32m    154\u001b[39m     input_shape = \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m0\u001b[39m].input_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/layer.py:230\u001b[39m, in \u001b[36mLayer.__new__.<locals>.build_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    229\u001b[39m     obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[32m    232\u001b[39m signature = inspect.signature(original_build_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/models/sequential.py:195\u001b[39m, in \u001b[36mSequential.build\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers[\u001b[32m1\u001b[39m:]:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/ops/operation_utils.py:221\u001b[39m, in \u001b[36mcompute_conv_output_shape\u001b[39m\u001b[34m(input_shape, filters, kernel_size, strides, padding, data_format, dilation_rate)\u001b[39m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output_spatial_shape)):\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m none_dims \u001b[38;5;129;01mand\u001b[39;00m output_spatial_shape[i] < \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    222\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mComputed output size would be negative. Received \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`inputs shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`kernel shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`dilation_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdilation_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    226\u001b[39m             )\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m padding == \u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m padding == \u001b[33m\"\u001b[39m\u001b[33mcausal\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    228\u001b[39m     output_spatial_shape = np.floor((spatial_shape - \u001b[32m1\u001b[39m) / strides) + \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Computed output size would be negative. Received `inputs shape=(None, 37, 1, 64)`, `kernel shape=(3, 3, 64, 128)`, `dilation_rate=[1 1]`."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# ========================================\n",
    "# 1. MFCC 제너레이터 클래스 정의\n",
    "# ========================================\n",
    "class MFCCDataGenerator(Sequence):\n",
    "    def __init__(self, batch_dir, prefix=\"mfcc\", batch_size=32):\n",
    "        self.mfcc_paths = sorted([os.path.join(batch_dir, f) for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch\") and f.endswith(\".npy\") and \"label\" not in f])\n",
    "        self.label_paths = sorted([os.path.join(batch_dir, \"encoded_labels\", f) for f in os.listdir(os.path.join(batch_dir, \"encoded_labels\")) if f.startswith(f\"label_batch\")])\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.mfcc_paths[idx], allow_pickle=True)\n",
    "        y = np.load(self.label_paths[idx])\n",
    "\n",
    "        min_len = min(len(x), len(y))\n",
    "        x = x[:min_len]\n",
    "        y = y[:min_len]\n",
    "\n",
    "        x = np.stack([\n",
    "            np.pad(sample, ((0, max(0, 40 - sample.shape[0])), (0, 0)), mode='constant')[:40]\n",
    "            for sample in x\n",
    "        ])\n",
    "        x = x[..., np.newaxis]  # (batch, 40, 13, 1)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# ========================================\n",
    "# 2. 경로 설정 및 제너레이터 생성\n",
    "# ========================================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# 3. 클래스 수 및 입력 형태 정의\n",
    "# ========================================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "sample_input = train_generator[0][0]  # shape: (batch, 40, 13, 1)\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "# ========================================\n",
    "# 4. CNN 모델 정의 (Conv2D padding 수정 포함)\n",
    "# ========================================\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))  # ← 수정됨\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 요약\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "# model.summary()  # → 주석 처리 (따로 실행할 경우만)\n",
    "\n",
    "# ========================================\n",
    "# 5. 콜백 정의\n",
    "# ========================================\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"v2_8class_emotion_analyze.h5\", monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=60, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# 6. 학습 실행\n",
    "# ========================================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# 7. 학습 이력 저장\n",
    "# ========================================\n",
    "with open(\"v2_8class_emotion_analyze.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 실패한 이유 \n",
    "- Conv2D 커널이 너무 커서 작은 입력에 비해 작동을 못함 - kernel size 축소 or padding =\"same\" 적용 -> 모델 재정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안정적인 CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    음성 감정 분류를 위한 CNN 모델 정의\n",
    "    \n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터의 형태 (시간축, MFCC 차원, 채널 수)\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "        \n",
    "    Returns:\n",
    "        keras.models.Sequential: 컴파일된 모델 객체\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # ===============================\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    # Conv2D: 32개의 필터, 3x3 커널, relu 활성화 함수 사용\n",
    "    # padding='same'으로 출력 크기 감소 방지\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())  # 정규화로 학습 안정화\n",
    "    model.add(layers.MaxPooling2D((2, 2)))  # 출력 크기 절반으로 축소\n",
    "\n",
    "    # ===============================\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # ===============================\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    # ===============================\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # GlobalAveragePooling2D: 각 채널의 평균을 취해 1D 벡터로 변환\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # ===============================\n",
    "    # [4] 완전 연결층 + 출력층\n",
    "    # ===============================\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))  # 과적합 방지\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # 감정 클래스 확률 출력\n",
    "\n",
    "    # ===============================\n",
    "    # [5] 모델 컴파일\n",
    "    # ===============================\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습\n",
    "- 학습 도중 시스템이 멈추지 않도록 작은 배치 크기와 적절한 콜백 설정 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 18:43:21.302730: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.45GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-06 18:43:21.311399: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-04-06 18:43:21.311817: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_18214/3867025553.py\", line 65, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_6962]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     48\u001b[39m callbacks = [\n\u001b[32m     49\u001b[39m     tf.keras.callbacks.ModelCheckpoint(\n\u001b[32m     50\u001b[39m         filepath=checkpoint_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     )\n\u001b[32m     60\u001b[39m ]\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 6. 학습 실행\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mUnknownError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_18214/3867025553.py\", line 65, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_2_1/conv2d_6_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_6962]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# ============================\n",
    "# 1. 데이터 제너레이터 생성\n",
    "# ============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 절약을 위한 작은 배치\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. 레이블 인코더 로드 및 클래스 수 설정\n",
    "# ============================\n",
    "# 학습 데이터용 레이블 인코더를 통해 클래스 수 파악\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 3. 입력 형태 설정\n",
    "# ============================\n",
    "# 첫 배치에서 입력 형태 파악\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# ============================\n",
    "# 4. 모델 생성\n",
    "# ============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ============================\n",
    "# 5. 콜백 설정\n",
    "# ============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=50,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ============================\n",
    "# 6. 학습 실행\n",
    "# ============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU 메모리 부족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 경량화 프루닝 라이브러리 및 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_model_optimization'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtfmot\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_pruned_cnn_model\u001b[39m(input_shape, num_classes):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow_model_optimization'"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_pruned_cnn_model(input_shape, num_classes):\n",
    "    # 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=1000  # 조절 가능\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 밀집층\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "\n",
    "    # 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_pruned_cnn_model(input_shape, num_classes):\n",
    "    # 프루닝 설정: 가중치의 50%를 0으로 만듦 (비율은 조절 가능)\n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=0.0,\n",
    "            final_sparsity=0.5,\n",
    "            begin_step=0,\n",
    "            end_step=1000  # 조절 가능\n",
    "        )\n",
    "    }\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 블록\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # 밀집층\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(tfmot.sparsity.keras.prune_low_magnitude(\n",
    "        layers.Dense(num_classes, activation='softmax'),\n",
    "        **pruning_params\n",
    "    ))\n",
    "\n",
    "    # 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 프루닝 실패\n",
    "1. Sequential 모델 안에 잘못된 레이어 구조를 넣었거나\n",
    "\n",
    "2. 프루닝 대상에 이미 프루닝된 레이어를 다시 적용하려고 하거나\n",
    "\n",
    "3. 모델 구조에서 무한 루프가 생겼거나\n",
    "\n",
    "4. 너무 많은 프루닝 wrapper가 중첩된 경우\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기서 부터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCDataGenerator 클래스\n",
    "- tf.keras.utils.Sequence를 상속받아, 저장된 MFCC 및 레이블 배치 데이터를 Keras 모델 학습에 적합하게 동적으로 불러오고 전처리해주는 제너레이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 18:41:36.722288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743932496.741807   18214 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743932496.747429   18214 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743932496.762396   18214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743932496.762415   18214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743932496.762417   18214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743932496.762418   18214 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-06 18:41:36.766999: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class MFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_dir, prefix, batch_size=1, shuffle=True):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 배치 리스트 구성\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "        self.indices = list(range(len(self.mfcc_files)))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 현재 배치 인덱스 범위 계산\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        batch_mfccs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for idx in batch_indices:\n",
    "            mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "            label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "            mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_data = np.load(label_path)\n",
    "\n",
    "            # 시퀀스 길이 맞추기 (Zero-padding)\n",
    "            max_len = max([x.shape[0] for x in mfcc_data])\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data, maxlen=max_len, dtype='float32', padding='post')\n",
    "            padded = np.expand_dims(padded, -1)  # CNN 입력 형식 맞추기\n",
    "\n",
    "            batch_mfccs.append(padded)\n",
    "            batch_labels.append(label_data)\n",
    "\n",
    "        X = np.concatenate(batch_mfccs, axis=0)\n",
    "        y = np.concatenate(batch_labels, axis=0)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음성 감정 분류를 위한 CNN 모델을 정의한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    음성 감정 인식을 위한 CNN 모델 정의\n",
    "    - 입력: MFCC 시퀀스 (batch, time, n_mfcc, 1)\n",
    "    - 출력: 감정 클래스 확률 (softmax)\n",
    "    \"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # [1] 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # [2] 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # [3] 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())  # 피처맵 전체 평균값\n",
    "\n",
    "    # [4] 완전 연결층\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # 감정 클래스 개수만큼 출력\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU memory growth enabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743932526.930633   18214 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4778 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743932531.155245   18282 service.cc:152] XLA service 0x7495b8006af0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743932531.155259   18282 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-04-06 18:42:11.226165: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743932531.646884   18282 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-04-06 18:42:12.155359: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.45GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-06 18:42:12.164979: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "2025-04-06 18:42:12.165117: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_18214/2572943114.py\", line 75, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_3439]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     58\u001b[39m callbacks = [\n\u001b[32m     59\u001b[39m     tf.keras.callbacks.ModelCheckpoint(\n\u001b[32m     60\u001b[39m         filepath=checkpoint_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m     69\u001b[39m     )\n\u001b[32m     70\u001b[39m ]\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# [6] 모델 학습\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mUnknownError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_18214/2572943114.py\", line 75, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_3439]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===============================\n",
    "# [0] GPU 메모리 설정 (OOM 방지)\n",
    "# ===============================\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✅ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"❌ RuntimeError:\", e)\n",
    "\n",
    "# ===============================\n",
    "# [1] 데이터 제너레이터 생성\n",
    "# ===============================\n",
    "train_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1  # 메모리 안전 위해 최소 배치\n",
    ")\n",
    "\n",
    "val_generator = MFCCDataGenerator(\n",
    "    batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\",\n",
    "    prefix=\"mfcc\",\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# [2] 레이블 인코더 로드 및 클래스 수\n",
    "# ===============================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ===============================\n",
    "# [3] 입력 형태 확인\n",
    "# ===============================\n",
    "sample_input = train_generator[0][0]  # shape: (batch, time, n_mfcc, 1)\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "# ===============================\n",
    "# [4] 모델 생성\n",
    "# ===============================\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ===============================\n",
    "# [5] 콜백 설정 (모델 저장 + 조기 종료)\n",
    "# ===============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# [6] 모델 학습\n",
    "# ===============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 변경  PyTorch 기반 간단한 CNN 모델 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AudioEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioEmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 데이터 로더 정의 (PyTorch용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, batch_dir, prefix):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.mfcc_files = sorted([\n",
    "            f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "        label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "        # 여기서도 배치 데이터임\n",
    "        mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "        label_batch = np.load(label_path)\n",
    "\n",
    "        # 리스트로 묶어서 반환 (collate_fn에서 처리)\n",
    "        return list(zip(mfcc_batch, label_batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate_fn 추가 (패딩과 텐서 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = sum(batch, [])  # [(mfcc1, label1), ..., (mfccN, labelN)]로 평탄화\n",
    "    seq_lens = [x[0].shape[0] for x in batch]\n",
    "    max_len = max(seq_lens)\n",
    "    n_mfcc = batch[0][0].shape[1]\n",
    "\n",
    "    padded_mfccs = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc, label in batch:\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:mfcc.shape[0], :] = mfcc\n",
    "        padded_mfccs.append(padded)\n",
    "        labels.append(label)\n",
    "\n",
    "    X = torch.tensor(padded_mfccs).unsqueeze(1)  # (batch, 1, time, n_mfcc)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MFCCDataset(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\", \"mfcc\")\n",
    "val_dataset = MFCCDataset(\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\", \"mfcc\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = AudioEmotionCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# ============================\n",
    "# 1. 학습 루프\n",
    "# ============================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 2. 검증 루프\n",
    "    # ============================\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"🔵 Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 3. 모델 저장\n",
    "    # ============================\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"💾 Best model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러 :  배치 안의 샘플들이 시퀀스 길이(time step)가 서로 달라서 torch.stack() 실패.\n",
    "PyTorch DataLoader는 collate_fn이 내부에서 torch.stack()을 사용하기 때문에, 입력 데이터들 크기가 다르면 에러가 납니다.\n",
    "TensorFlow에서는 padding으로 해결됐던 부분\n",
    "\n",
    "- 해결 방안 : 배치 크기를 맞추는 collate_fn 함수 구현\n",
    "    - collate_fn을 사용하여 배치 내 데이터 크기를 맞추는 방법을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# ============================\n",
    "# 0. 기본 설정\n",
    "# ============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# ============================\n",
    "# 1. 레이블 인코더 로드 및 클래스 수 확인\n",
    "# ============================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# ============================\n",
    "# 2. 데이터셋 클래스 정의\n",
    "# ============================\n",
    "class MFCCDataset(Dataset):\n",
    "    def __init__(self, batch_dir, prefix):\n",
    "        self.batch_dir = batch_dir\n",
    "        self.prefix = prefix\n",
    "        self.mfcc_files = sorted([f for f in os.listdir(batch_dir) if f.startswith(f\"{prefix}_batch_\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc_path = os.path.join(self.batch_dir, f\"{self.prefix}_batch_{idx}.npy\")\n",
    "        label_path = os.path.join(self.batch_dir, \"encoded_labels\", f\"label_batch_{idx}.npy\")\n",
    "\n",
    "        mfcc_data = np.load(mfcc_path, allow_pickle=True)\n",
    "        label_data = np.load(label_path)\n",
    "\n",
    "        # 리스트 형태일 경우 numpy 배열로 변환\n",
    "        if isinstance(mfcc_data, list):\n",
    "            mfcc_data = np.array(mfcc_data)\n",
    "\n",
    "        # 2D 배열인지 확인 (time, n_mfcc)\n",
    "        if mfcc_data.ndim != 2:\n",
    "            raise ValueError(f\"[{mfcc_path}] shape 오류: (time, n_mfcc) 형식이 아님 → 실제 shape: {mfcc_data.shape}\")\n",
    "\n",
    "        return mfcc_data, label_data\n",
    "\n",
    "\n",
    "# 패딩을 위한 collate_fn 정의\n",
    "def collate_fn(batch):\n",
    "    # 각 샘플은 (sequence_len, n_mfcc)\n",
    "    seq_lens = [sample[0].shape[0] for sample in batch]\n",
    "    max_len = max(seq_lens)\n",
    "\n",
    "    padded_batch = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc_data, label_data in batch:\n",
    "        # mfcc_data shape: (time, n_mfcc)\n",
    "        time_len = mfcc_data.shape[0]\n",
    "        n_mfcc = mfcc_data.shape[1]\n",
    "\n",
    "        # (time, n_mfcc) → (max_len, n_mfcc)\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:time_len, :] = mfcc_data\n",
    "\n",
    "        padded_batch.append(padded)\n",
    "        labels.append(label_data)\n",
    "\n",
    "    # (batch, 1, time, n_mfcc)\n",
    "    X = torch.tensor(padded_batch).unsqueeze(1)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# 데이터셋 로딩\n",
    "train_dataset = MFCCDataset(batch_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\", prefix=\"mfcc\")\n",
    "val_dataset = MFCCDataset(batch_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\", prefix=\"mfcc\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# ============================\n",
    "# 3. 모델 정의\n",
    "# ============================\n",
    "class AudioEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioEmotionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 모델과 손실 함수, 옵티마이저 설정\n",
    "model = AudioEmotionCNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "# ============================\n",
    "# 4. 학습 루프\n",
    "# ============================\n",
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 5. 검증 루프\n",
    "    # ============================\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == targets).sum().item()\n",
    "            val_total += targets.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"🔵 Epoch {epoch+1}: Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # ============================\n",
    "    # 6. 모델 저장\n",
    "    # ============================\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"💾 Best model saved with Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 에러\n",
    "allow_pickle=True 옵션으로 불러온 데이터를 np.load() 하면, 원래는 List[np.ndarray] 혹은 (time, n_mfcc) 구조여야 합니다.\n",
    "\n",
    "만약 이전에 이 mfcc_batch_1.npy를 배치 단위 리스트 형태로 저장했었다면:\n",
    "\n",
    "지금처럼 __getitem__에서 개별 .npy를 꺼낼 경우 배치 전체가 한 개의 1D 배열로 저장되어 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해결 방법: 각 샘플을 개별 .npy 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 원본 다중샘플 npy 경로\n",
    "input_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/mfcc_batch_1.npy\"\n",
    "\n",
    "# 저장할 경로\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "data = np.load(input_path, allow_pickle=True)\n",
    "\n",
    "# 각 샘플 저장\n",
    "for i, sample in enumerate(data):\n",
    "    save_path = os.path.join(output_dir, f\"sample_{i:04d}.npy\")\n",
    "    np.save(save_path, sample)\n",
    "\n",
    "print(f\"✅ 총 {len(data)}개 샘플 저장 완료: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 분할 저장 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 레이블 경로\n",
    "label_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels/label_batch_1.npy\"\n",
    "labels = np.load(label_path)\n",
    "\n",
    "# 저장할 디렉토리\n",
    "label_output_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\"\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# 분할 저장\n",
    "for i, label in enumerate(labels):\n",
    "    save_path = os.path.join(label_output_dir, f\"label_{i:04d}.npy\")\n",
    "    np.save(save_path, label)\n",
    "\n",
    "print(f\"✅ 총 {len(labels)}개 레이블 저장 완료: {label_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCSampleDataset 정의 (샘플 단위)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "class MFCCSampleDataset(Dataset):\n",
    "    def __init__(self, sample_dir, label_dir):\n",
    "        self.sample_paths = sorted([\n",
    "            os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mfcc = np.load(self.sample_paths[idx])          # shape: (time, n_mfcc)\n",
    "        label = np.load(self.label_paths[idx])          # shape: ()\n",
    "\n",
    "        # 텐서로 변환 (채널 추가)\n",
    "        mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0)  # (1, time, n_mfcc)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return mfcc_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collate_fn 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    seq_lens = [x[0].shape[0] for x in batch]\n",
    "    max_len = max(seq_lens)\n",
    "\n",
    "    # n_mfcc 추정 시 더 안전하게\n",
    "    n_mfcc = None\n",
    "    for mfcc_data, _ in batch:\n",
    "        if isinstance(mfcc_data, np.ndarray) and mfcc_data.ndim == 2:\n",
    "            n_mfcc = mfcc_data.shape[1]\n",
    "            break\n",
    "\n",
    "    if n_mfcc is None:\n",
    "        raise ValueError(\"모든 샘플에서 유효한 2D MFCC 데이터를 찾을 수 없습니다.\")\n",
    "\n",
    "    padded_batch = []\n",
    "    labels = []\n",
    "\n",
    "    for mfcc_data, label_data in batch:\n",
    "        time_len = mfcc_data.shape[0]\n",
    "        padded = np.zeros((max_len, n_mfcc), dtype=np.float32)\n",
    "        padded[:time_len, :] = mfcc_data\n",
    "        padded_batch.append(padded)\n",
    "        labels.append(label_data)\n",
    "\n",
    "    X = torch.tensor(padded_batch).unsqueeze(1)  # (batch, 1, time, n_mfcc)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  기본 설정 및 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"✅ Using device: {device}\")\n",
    "\n",
    "# 모델 정의 (이전에 정의한 AudioEmotionCNN 사용)\n",
    "model = AudioEmotionCNN(num_classes=8).to(device)  # 클래스 수에 맞게 수정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_pt.pth\"\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"🟢 Epoch {epoch+1}: Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 샘플 단위 .npy 파일을 위한 DataGenerator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class SampleMFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32, shuffle=True):\n",
    "        self.mfcc_paths = sorted([\n",
    "            os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = [], []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            mfcc = np.load(self.mfcc_paths[i])  # (time, n_mfcc)\n",
    "            label = np.load(self.label_paths[i])  # 정수 인코딩 레이블\n",
    "\n",
    "            X.append(mfcc)\n",
    "            y.append(label)\n",
    "\n",
    "        # Zero-padding\n",
    "        max_len = max(x.shape[0] for x in X)\n",
    "        X_pad = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            X, maxlen=max_len, padding='post', dtype='float32'\n",
    "        )\n",
    "        X_pad = np.expand_dims(X_pad, -1)  # (batch, time, n_mfcc, 1)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return X_pad, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1  validation 데이터도 split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "val_input_path = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/mfcc_batch_0.npy\"\n",
    "val_label_path = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/label_batch_0.npy\"\n",
    "\n",
    "# 저장할 폴더\n",
    "val_sample_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\"\n",
    "os.makedirs(val_sample_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 로드\n",
    "mfcc_data = np.load(val_input_path, allow_pickle=True)\n",
    "label_data = np.load(val_label_path)\n",
    "\n",
    "# 저장\n",
    "for i, (sample, label) in enumerate(zip(mfcc_data, label_data)):\n",
    "    np.save(os.path.join(val_sample_dir, f\"sample_{i:04d}.npy\"), sample)\n",
    "    np.save(os.path.join(val_label_dir, f\"label_{i:04d}.npy\"), label)\n",
    "\n",
    "print(f\"✅ validation용 {len(mfcc_data)}개 샘플 및 레이블 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 콜백 설정 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# ===============================\n",
    "# [1] 학습 및 검증용 DataGenerator 정의\n",
    "# ===============================\n",
    "train_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "val_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# [2] 입력 형태 확인 및 모델 생성\n",
    "# ===============================\n",
    "sample_input, _ = train_generator[0]\n",
    "input_shape = sample_input.shape[1:]  # (time, n_mfcc, 1)\n",
    "\n",
    "# 클래스 수 확인\n",
    "import glob\n",
    "label_paths = sorted(glob.glob(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels/*.npy\"))\n",
    "all_labels = [int(np.load(p)) for p in label_paths]\n",
    "num_classes = len(set(all_labels))\n",
    "\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# ===============================\n",
    "# [3] 콜백 설정\n",
    "# ===============================\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_tf.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# GPU 초기화를 위한 예열용 더미 실행 (CPU에서 실행)\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    model(tf.random.normal((1,) + input_shape))\n",
    "\n",
    "# ===============================\n",
    "# [4] 모델 학습 실행\n",
    "# ===============================\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"✅ 모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpu 사용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cpu로 학습 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. GPU 완전 비활성화 (가장 먼저 실행)\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# 1. 필수 라이브러리 임포트\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "\n",
    "# 2. 사용자 정의 DataGenerator\n",
    "class SampleMFCCDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32, shuffle=True):\n",
    "        self.mfcc_paths = sorted([\n",
    "            os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.label_paths = sorted([\n",
    "            os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.endswith(\".npy\")\n",
    "        ])\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_mfcc = [np.load(self.mfcc_paths[i]) for i in batch_indexes]\n",
    "        batch_label = [np.load(self.label_paths[i]).item() for i in batch_indexes]  # .item() 추가\n",
    "\n",
    "        batch_mfcc = [np.expand_dims(x, axis=-1) for x in batch_mfcc]  # (time, n_mfcc, 1)\n",
    "\n",
    "        max_len = max(x.shape[0] for x in batch_mfcc)\n",
    "        padded_mfcc = np.array([\n",
    "            np.pad(x, ((0, max_len - x.shape[0]), (0, 0), (0, 0)), mode='constant')\n",
    "            for x in batch_mfcc\n",
    "        ])\n",
    "\n",
    "        labels = np.array(batch_label, dtype=np.int32)\n",
    "        return padded_mfcc, labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# 3. CNN 모델 생성 함수\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. DataGenerator 설정\n",
    "train_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "val_generator = SampleMFCCDataGenerator(\n",
    "    mfcc_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_samples\",\n",
    "    label_dir=\"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/split_labels\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# 5. 입력 형상 및 클래스 수 확인\n",
    "sample_input, _ = train_generator[0]\n",
    "input_shape = sample_input.shape[1:]\n",
    "\n",
    "label_paths = sorted(glob.glob(\"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_labels/*.npy\"))\n",
    "all_labels = [np.load(p).item() for p in label_paths]  # .item()으로 스칼라 추출\n",
    "num_classes = len(set(all_labels))\n",
    "print(f\"클래스 수: {num_classes}\")\n",
    "\n",
    "# 6. 모델 생성 및 콜백 설정\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_tf.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 모델 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"모델 학습 완료 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 머신 러닝 시도\n",
    "## 작업 순서\n",
    "1. 데이터 로딩 및 통합\n",
    "    - metadata_cleaned (train)\n",
    "    - metadata_cleaned_val (validation)\n",
    "\n",
    "2. 특징(X)과 레이블(y) 분리\n",
    "    - MFCC는 X\n",
    "    - 감정 레이블은 y\n",
    "\n",
    "3. 레이블 인코딩\n",
    "    - 문자열 레이블(Happy, Sad 등)을 숫자로 변환\n",
    "\n",
    "4. 머신러닝 모델 선택 및 학습\n",
    "    - 예: RandomForestClassifier, SVC, GradientBoosting, LogisticRegression\n",
    "\n",
    "5. 검증 및 평가\n",
    "    - accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로딩 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 경로\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/metadata_cleaned\"\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/metadata_cleaned_val\"\n",
    "\n",
    "# 파일 불러오기\n",
    "train_mfcc_paths = sorted(glob(os.path.join(train_dir, \"*.npy\")))\n",
    "val_mfcc_paths = sorted(glob(os.path.join(val_dir, \"*.npy\")))\n",
    "\n",
    "# 데이터 로딩\n",
    "train_data = [np.load(f, allow_pickle=True).item() for f in train_mfcc_paths]\n",
    "val_data = [np.load(f, allow_pickle=True).item() for f in val_mfcc_paths]\n",
    "\n",
    "# 분리\n",
    "X_train = [d[\"mfcc\"] for d in train_data]\n",
    "y_train = [d[\"emotion\"] for d in train_data]\n",
    "\n",
    "X_val = [d[\"mfcc\"] for d in val_data]\n",
    "y_val = [d[\"emotion\"] for d in val_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 특징(X)과 레이블(y) 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 학습용 데이터 로딩\n",
    "train_path = \"/media/usou/PortableSSD/mldl_project/data/metadata_cleaned.csv\"\n",
    "metadata_cleaned = pd.read_csv(train_path)\n",
    "\n",
    "# 검증용 데이터 로딩\n",
    "val_path = \"/media/usou/PortableSSD/mldl_project/data/validation/metadata_cleaned_val.csv\"\n",
    "metadata_cleaned_val = pd.read_csv(val_path)\n",
    "\n",
    "# X: MFCC 특징, y: 감정 레이블\n",
    "X_train = metadata_cleaned[\"mfcc\"]\n",
    "y_train = metadata_cleaned[\"emotion\"]\n",
    "\n",
    "X_val = metadata_cleaned_val[\"mfcc\"]\n",
    "y_val = metadata_cleaned_val[\"emotion\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadata_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/split_samples\"\n",
    "\n",
    "def load_mfcc_from_path(path_series):\n",
    "    mfcc_list = []\n",
    "    for rel_path in path_series:\n",
    "        fname = os.path.splitext(os.path.basename(rel_path))[0]\n",
    "        mfcc_path = os.path.join(base_mfcc_dir, f\"{fname}.npy\")\n",
    "        if not os.path.exists(mfcc_path):\n",
    "            print(f\"⚠️ 누락된 MFCC 파일: {mfcc_path}\")\n",
    "            continue\n",
    "        mfcc = np.load(mfcc_path)\n",
    "        mfcc_list.append(mfcc.flatten())  # 머신러닝용 1D 벡터로\n",
    "    return np.array(mfcc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X (특징) 로딩\n",
    "X_train = load_mfcc_from_path(metadata_cleaned[\"wav_path\"])\n",
    "X_val = load_mfcc_from_path(metadata_cleaned_val[\"wav_path\"])\n",
    "\n",
    "# y (레이블) 추출\n",
    "y_train = metadata_cleaned[\"emotion\"].values\n",
    "y_val = metadata_cleaned_val[\"emotion\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 이후 부터 딥러닝 다시 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 로딩 및 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 파일 경로 정렬\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 로딩\n",
    "X_raw = [np.load(p, allow_pickle=True) for p in mfcc_paths]\n",
    "y_raw = [np.load(p) for p in label_paths]\n",
    "\n",
    "# 리스트로 되어 있는 MFCC들을 한 리스트로 합치기\n",
    "X_all = [sample for batch in X_raw for sample in batch]\n",
    "y_all = np.concatenate(y_raw)\n",
    "\n",
    "print(f\"총 MFCC 샘플 수: {len(X_all)}\")\n",
    "print(f\"총 레이블 수: {len(y_all)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 샘플 길이 정규화(패딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# MFCC의 각 샘플은 (time, 13) 형태 → 시퀀스 길이 맞추기\n",
    "max_len = max([x.shape[0] for x in X_all])\n",
    "print(\"가장 긴 MFCC 시퀀스 길이:\", max_len)\n",
    "\n",
    "# (샘플 수, time, n_mfcc)\n",
    "X_padded = pad_sequences(X_all, maxlen=max_len, padding='post', dtype='float32')\n",
    "print(\"패딩된 X shape:\", X_padded.shape)\n",
    "\n",
    "# 마지막 차원을 명시적으로 추가: (샘플 수, time, n_mfcc, 1)\n",
    "X_padded = np.expand_dims(X_padded, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증용 MFCC 데이터 로딩\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data/validation/mfcc_batches/encoded_labels\"\n",
    "\n",
    "val_mfcc_paths = sorted(glob(os.path.join(val_mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "val_label_paths = sorted(glob(os.path.join(val_label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "X_val_raw = [np.load(p, allow_pickle=True) for p in val_mfcc_paths]\n",
    "y_val_raw = [np.load(p) for p in val_label_paths]\n",
    "\n",
    "X_val_all = [sample for batch in X_val_raw for sample in batch]\n",
    "y_val = np.concatenate(y_val_raw)\n",
    "\n",
    "print(f\"검증용 MFCC 샘플 수: {len(X_val_all)}\")\n",
    "print(f\"검증용 레이블 수: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 기반 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_padded.shape[1:]  # (157, 13, 1)\n",
    "num_classes = len(np.unique(y_all))\n",
    "\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 설정 & 모델 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 저장 경로\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_cnn.h5\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 커널 재시작 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MFCC 및 레이블 로딩\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 경로\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 데이터 로딩\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "X_raw = [np.load(p, allow_pickle=True) for p in mfcc_paths]\n",
    "y_raw = [np.load(p) for p in label_paths]\n",
    "\n",
    "X_all = [sample for batch in X_raw for sample in batch]\n",
    "y_all = np.concatenate(y_raw)\n",
    "\n",
    "# 시퀀스 패딩\n",
    "max_len = 157  # 고정\n",
    "X_padded = pad_sequences(X_all, maxlen=max_len, padding='post', dtype='float32')\n",
    "X_padded = np.expand_dims(X_padded, -1)\n",
    "\n",
    "# 훈련/검증 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_padded, y_all, test_size=0.12, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "print(\"✅ 데이터 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 상황은 매우 자주 발생하는 Jupyter Notebook의 커널 메모리 한계 문제\n",
    "\n",
    "- 위 방법으로 해결 예저\n",
    "1. generator 정의\n",
    "2. gc.collect()\n",
    "3. model.fit(generator, validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치 제너레이터 정의(훈련용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  # ✅ 반드시 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.mfcc_paths = mfcc_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(self.mfcc_paths))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.mfcc_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_idx = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_idx:\n",
    "            mfcc = np.load(self.mfcc_paths[i], allow_pickle=True)\n",
    "            label = np.load(self.label_paths[i])\n",
    "\n",
    "            # 유효한 MFCC만 처리\n",
    "            if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "                padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                    [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "                )[0]\n",
    "                X_batch.append(padded)\n",
    "                y_batch.append(label)\n",
    "\n",
    "        X_batch = np.expand_dims(np.array(X_batch), -1)  # (batch, time, n_mfcc, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제너레이터 생성 및 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 학습용 제너레이터\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=64, max_len=157, shuffle=True)\n",
    "\n",
    "# 가비지 컬렉션 실행 (메모리 확보)\n",
    "gc.collect()\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# 콜백 정의\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 검증용 데이터는 메모리 적재 방식으로 유지\n",
    "# 이 부분은 이전에 분리한 X_val, y_val을 사용해야 합니다\n",
    "# 혹시 없다면 validation set 따로 만들 수 있도록 알려주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 레이블 로딩\n",
    "all_labels = [np.load(p) for p in label_paths]\n",
    "y_all = np.concatenate(all_labels)\n",
    "\n",
    "# 전체 MFCC 로딩 (메모리 작은 검증셋만 로딩)\n",
    "val_size = 112157  # 예: 전체의 약 13%\n",
    "X_val_paths = mfcc_paths[-val_size:]\n",
    "y_val_paths = label_paths[-val_size:]\n",
    "\n",
    "# 검증 데이터 로딩\n",
    "X_val_list = []\n",
    "for path in X_val_paths:\n",
    "    mfcc = np.load(path, allow_pickle=True)\n",
    "    padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "    )[0]\n",
    "    X_val_list.append(padded)\n",
    "\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.concatenate([np.load(p) for p in y_val_paths])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_list = []\n",
    "valid_y_list = []\n",
    "\n",
    "for mfcc_path, label_path in zip(X_val_paths, y_val_paths):\n",
    "    mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    \n",
    "    # (time, 13) 형식인지 확인\n",
    "    if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "        padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "            [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "        )[0]\n",
    "        X_val_list.append(padded)\n",
    "\n",
    "        label = np.load(label_path)\n",
    "        valid_y_list.append(label)\n",
    "    else:\n",
    "        print(\"❌ 잘못된 MFCC:\", mfcc_path)\n",
    "\n",
    "# 최종 배열로 변환\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.array(valid_y_list)\n",
    "\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 경로\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "# 배치 파일 리스트\n",
    "mfcc_batch_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_batch_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 검증용 비율 기준으로 뒤에서 N개 배치만 선택\n",
    "val_batch_count = 10  # 예: 마지막 10개 배치만 사용\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "\n",
    "for mfcc_batch_path, label_batch_path in zip(mfcc_batch_paths[-val_batch_count:], label_batch_paths[-val_batch_count:]):\n",
    "    mfcc_batch = np.load(mfcc_batch_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_batch_path)\n",
    "\n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=157, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "\n",
    "# 배열로 변환\n",
    "X_val = np.expand_dims(np.array(X_val_list), -1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"✅ 검증용 X shape:\", X_val.shape)\n",
    "print(\"✅ 검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),  # 이 부분이 메모리에 있어야 해요!\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 정리 커널 재시작 후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 데이터 재구성 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# 검증용 샘플 수 고정\n",
    "val_sample_size = 112157\n",
    "\n",
    "X_val_list = []\n",
    "y_val_list = []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "\n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and len(mfcc.shape) == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "# numpy 배열로 변환 (꼭 확인!)\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"✅ 검증 데이터 재구성 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.mfcc_paths = mfcc_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 전체 샘플을 flatten\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m78\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 09:50:44.377105: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 81640000 exceeds 10% of free system memory.\n",
      "2025-04-06 09:50:45.212650: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.45GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-04-06 09:50:45.222291: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
      "%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_6_1/conv2d_22_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "\n",
      "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n",
      "\n",
      "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_8598/2395834495.py\", line 1, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_6_1/conv2d_22_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_341542]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mUnknownError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n\n  File \"/tmp/ipykernel_8598/2395834495.py\", line 1, in <module>\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.9 = (f32[10000,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[10000,1,157,13]{3,2,1,0} %bitcast.5974, f32[32,1,3,3]{3,2,1,0} %bitcast.5981, f32[32]{0} %bitcast.6957), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_6_1/conv2d_22_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2629257216 bytes. [tf-allocator-allocation-error='']\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_341542]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 검증 데이터 준비 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n",
      "✅ 유효한 학습용 샘플 수: 810992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-04-06 09:51:07.415378: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[16,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,157,13]{3,2,1,0} %bitcast.5956, f32[32,1,3,3]{3,2,1,0} %bitcast.5963, f32[32]{0} %bitcast.6887), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_7_1/conv2d_25_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-06 09:51:07.445784: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[16,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,78,6]{3,2,1,0} %bitcast.7052, f32[64,32,3,3]{3,2,1,0} %bitcast.6038, f32[64]{0} %bitcast.7112), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_7_1/conv2d_26_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-06 09:51:07.520998: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[16,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,39,3]{3,2,1,0} %bitcast.7278, f32[128,64,3,3]{3,2,1,0} %bitcast.6113, f32[128]{0} %bitcast.7348), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_7_1/conv2d_27_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2013/50687\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 4ms/step - accuracy: 0.3611 - loss: 1.8136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 131\u001b[39m\n\u001b[32m    128\u001b[39m gc.collect()\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# 8. 학습 시작\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1. 기본 라이브러리\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "# 2. 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 3. 검증 데이터 구성\n",
    "val_sample_size = 112157\n",
    "X_val_list, y_val_list = [], []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "    \n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "print(\"✅ 검증 데이터 준비 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n",
    "\n",
    "# 4. 학습용 제너레이터 정의 및 생성\n",
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "                [mfcc], maxlen=self.max_len, padding='post', dtype='float32'\n",
    "            )[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=16)\n",
    "print(\"✅ 유효한 학습용 샘플 수:\", len(train_generator) * 16)\n",
    "\n",
    "# 5. 모델 정의\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 생성 및 콜백 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 가비지 컬렉션\n",
    "gc.collect()\n",
    "\n",
    "# 8. 학습 시작\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장된 모델 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "model = load_model(model_path)\n",
    "print(\"✅ 모델 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred_classes)\n",
    "print(f\"✅ 검증 정확도: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"📊 분류 리포트:\")\n",
    "print(classification_report(y_val, y_pred_classes))\n",
    "\n",
    "print(\"🌀 혼동 행렬:\")\n",
    "print(confusion_matrix(y_val, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 로그 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 학습 직후 저장\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/models/history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 로그 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 로그 불러 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/models/history.pkl\", \"rb\") as f:\n",
    "    history_dict = pickle.load(f)\n",
    "\n",
    "print(\"✅ 학습 로그 불러오기 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict[\"accuracy\"]\n",
    "val_acc = history_dict[\"val_accuracy\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoch 300 으로 accuracy 더 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 준비 완료\n",
      "검증용 X shape: (112157, 157, 13, 1)\n",
      "검증용 y shape: (112157,)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.shuffle:\n\u001b[32m     82\u001b[39m             np.random.shuffle(\u001b[38;5;28mself\u001b[39m.indices)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m train_generator = \u001b[43mMFCCBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m유효한 학습용 샘플 수:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_generator) * \u001b[32m16\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# 5. CNN 모델 정의 함수\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mMFCCBatchGenerator.__init__\u001b[39m\u001b[34m(self, mfcc_paths, label_paths, batch_size, max_len, shuffle)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mself\u001b[39m.y_all = []\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mfcc_path, label_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(mfcc_paths, label_paths):\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     mfcc_batch = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfcc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     label_batch = np.load(label_path)\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m mfcc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(mfcc_batch, label_batch):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/npyio.py:456\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    453\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    454\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/format.py:800\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    798\u001b[39m     pickle_kwargs = {}\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m     array = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    802\u001b[39m     \u001b[38;5;66;03m# Friendlier error message\u001b[39;00m\n\u001b[32m    803\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnpickling a python object failed: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    804\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mYou may need to pass the encoding= option \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    805\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mto numpy.load\u001b[39m\u001b[33m\"\u001b[39m % (err,)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "# 1. 기본 라이브러리 불러오기 및 GPU 설정\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, gc\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# GPU 메모리 과도할당 방지 설정\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 2. MFCC 및 레이블 파일 경로 설정\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/encoded_labels\"\n",
    "mfcc_paths = sorted(glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "label_paths = sorted(glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 3. 검증 데이터셋 구성 (112157개 샘플)\n",
    "val_sample_size = 112157\n",
    "X_val_list, y_val_list = [], []\n",
    "loaded = 0\n",
    "\n",
    "for mfcc_path, label_path in zip(reversed(mfcc_paths), reversed(label_paths)):\n",
    "    mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "    label_batch = np.load(label_path)\n",
    "    \n",
    "    for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "        if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "            padded = pad_sequences([mfcc], maxlen=157, padding='post', dtype='float32')[0]\n",
    "            X_val_list.append(padded)\n",
    "            y_val_list.append(label)\n",
    "            loaded += 1\n",
    "            if loaded >= val_sample_size:\n",
    "                break\n",
    "    if loaded >= val_sample_size:\n",
    "        break\n",
    "\n",
    "X_val = np.array(X_val_list).reshape(-1, 157, 13, 1)\n",
    "y_val = np.array(y_val_list)\n",
    "\n",
    "print(\"검증 데이터 준비 완료\")\n",
    "print(\"검증용 X shape:\", X_val.shape)\n",
    "print(\"검증용 y shape:\", y_val.shape)\n",
    "\n",
    "# 4. 학습용 데이터 제너레이터 정의\n",
    "class MFCCBatchGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, mfcc_paths, label_paths, batch_size=16, max_len=157, shuffle=True):\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "\n",
    "        for mfcc_path, label_path in zip(mfcc_paths, label_paths):\n",
    "            mfcc_batch = np.load(mfcc_path, allow_pickle=True)\n",
    "            label_batch = np.load(label_path)\n",
    "            for mfcc, label in zip(mfcc_batch, label_batch):\n",
    "                if isinstance(mfcc, np.ndarray) and mfcc.ndim == 2 and mfcc.shape[1] == 13:\n",
    "                    self.X_all.append(mfcc)\n",
    "                    self.y_all.append(label)\n",
    "\n",
    "        self.indices = np.arange(len(self.X_all))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X_all) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch, y_batch = [], []\n",
    "        for i in batch_indices:\n",
    "            mfcc = self.X_all[i]\n",
    "            padded = pad_sequences([mfcc], maxlen=self.max_len, padding='post', dtype='float32')[0]\n",
    "            X_batch.append(padded)\n",
    "            y_batch.append(self.y_all[i])\n",
    "        X_batch = np.array(X_batch).reshape(-1, 157, 13, 1)\n",
    "        y_batch = np.array(y_batch)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = MFCCBatchGenerator(mfcc_paths, label_paths, batch_size=16)\n",
    "print(\"유효한 학습용 샘플 수:\", len(train_generator) * 16)\n",
    "\n",
    "# 5. CNN 모델 정의 함수\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 구성 및 콜백 정의\n",
    "input_shape = (157, 13, 1)\n",
    "num_classes = 8\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\"\n",
    "callbacks = [\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# 7. 불필요한 메모리 수거\n",
    "gc.collect()\n",
    "\n",
    "# 8. 모델 학습 (epoch 300으로 확장)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=300,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 11:30:53.196941: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "2025-04-04 11:30:54.313232: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 915649748 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743733855.058142    8477 service.cc:152] XLA service 0x79e7ec0029d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743733855.058176    8477 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-04-04 11:30:55.079536: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743733855.180731    8477 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-04-04 11:30:55.615828: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,157,13]{3,2,1,0} %bitcast.352, f32[32,1,3,3]{3,2,1,0} %bitcast.359, f32[32]{0} %bitcast.361), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:30:55.704393: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,78,6]{3,2,1,0} %bitcast.389, f32[64,32,3,3]{3,2,1,0} %bitcast.396, f32[64]{0} %bitcast.398), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:30:55.844944: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,39,3]{3,2,1,0} %bitcast.426, f32[128,64,3,3]{3,2,1,0} %bitcast.433, f32[128]{0} %bitcast.435), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  26/3505\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 7ms/step "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743733856.306102    8477 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3498/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 11:31:06.529920: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[29,32,157,13]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,1,157,13]{3,2,1,0} %bitcast.352, f32[32,1,3,3]{3,2,1,0} %bitcast.359, f32[32]{0} %bitcast.361), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:31:06.591286: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[29,64,78,6]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,32,78,6]{3,2,1,0} %bitcast.389, f32[64,32,3,3]{3,2,1,0} %bitcast.396, f32[64]{0} %bitcast.398), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-04 11:31:06.689536: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[29,128,39,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,39,3]{3,2,1,0} %bitcast.426, f32[128,64,3,3]{3,2,1,0} %bitcast.433, f32[128]{0} %bitcast.435), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3505/3505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (8,) and arg 1 with shape (7,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m plt.figure(figsize=(\u001b[32m8\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m     22\u001b[39m bar_width = \u001b[32m0.25\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbar_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m plt.bar(x + bar_width, recall, width=bar_width, label=\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m plt.bar(x + \u001b[32m2\u001b[39m*bar_width, f1, width=bar_width, label=\u001b[33m'\u001b[39m\u001b[33mf1-score\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/matplotlib/pyplot.py:2979\u001b[39m, in \u001b[36mbar\u001b[39m\u001b[34m(x, height, width, bottom, align, data, **kwargs)\u001b[39m\n\u001b[32m   2968\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.bar)\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbar\u001b[39m(\n\u001b[32m   2970\u001b[39m     x: \u001b[38;5;28mfloat\u001b[39m | ArrayLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2977\u001b[39m     **kwargs,\n\u001b[32m   2978\u001b[39m ) -> BarContainer:\n\u001b[32m-> \u001b[39m\u001b[32m2979\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2984\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2986\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2987\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:2583\u001b[39m, in \u001b[36mAxes.bar\u001b[39m\u001b[34m(self, x, height, width, bottom, align, **kwargs)\u001b[39m\n\u001b[32m   2580\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2581\u001b[39m         yerr = \u001b[38;5;28mself\u001b[39m._convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m.convert_yunits)\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m x, height, width, y, linewidth, hatch = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[32m   2588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orientation == \u001b[33m'\u001b[39m\u001b[33mvertical\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:540\u001b[39m, in \u001b[36mbroadcast_arrays\u001b[39m\u001b[34m(subok, *args)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[32m    536\u001b[39m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[32m    538\u001b[39m args = [np.array(_m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m, subok=subok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m shape = \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array.shape == shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[32m    543\u001b[39m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/stride_tricks.py:422\u001b[39m, in \u001b[36m_broadcast_shape\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[33;03msupplied arrays against each other.\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m b = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[32m31\u001b[39m):\n\u001b[32m    425\u001b[39m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[32m    426\u001b[39m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[32m    427\u001b[39m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (8,) and arg 1 with shape (7,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# 예시: 모델 예측값이 있다고 가정\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 레이블 디코더 로딩 (있다면)\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred_labels)\n",
    "x = np.arange(len(class_names))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_width = 0.25\n",
    "plt.bar(x, precision, width=bar_width, label='precision')\n",
    "plt.bar(x + bar_width, recall, width=bar_width, label='recall')\n",
    "plt.bar(x + 2*bar_width, f1, width=bar_width, label='f1-score')\n",
    "plt.xticks(x + bar_width, class_names)\n",
    "plt.title(\"Precision / Recall / F1-score by Class\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# history 객체를 JSON으로 저장\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(log_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     json.dump(\u001b[43mhistory\u001b[49m.history, f)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ 학습 로그 저장 완료\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 시각화\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 로그 저장 경로\n",
    "log_path = \"/media/usou/PortableSSD/mldl_project/models/train_history_log.json\"\n",
    "\n",
    "# history 객체를 JSON으로 저장\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(history.history, f)\n",
    "print(\"✅ 학습 로그 저장 완료\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# 손실 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .keras 포맷 으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"/media/usou/PortableSSD/mldl_project/models/best_model_generator.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_model_generator.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .keras -> .h5 로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 변환 완료: .keras → .h5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. 기존 .keras 모델 경로\n",
    "keras_path = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/ai/models//voice_emotion_model.keras\"\n",
    "\n",
    "# 2. 저장할 .h5 모델 경로\n",
    "h5_path = \"/home/usou/dev_ws/superbad/deeplearning-repo-3/ai/models//voice_emotion_model.h5\"\n",
    "\n",
    "# 3. 모델 로드 후 저장\n",
    "model = load_model(keras_path, compile=False)\n",
    "model.save(h5_path)\n",
    "\n",
    "print(\"✅ 변환 완료: .keras → .h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m4a → wav 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "def convert_to_wav(input_path, output_path=None):\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일이 존재하지 않아요: {input_path}\")\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "\n",
    "    audio = AudioSegment.from_file(input_path, format=\"m4a\")\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "    print(\"✅ 변환 완료:\", output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## m4a, mp3, mp4 -> wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_to_wav(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    오디오 또는 비디오 파일을 WAV로 변환합니다.\n",
    "    지원 포맷: .wav, .m4a, .mp3, .mp4 등\n",
    "    내부적으로 ffmpeg가 설치되어 있어야 합니다.\n",
    "\n",
    "    :param input_path: 입력 파일 경로\n",
    "    :param output_path: 출력 파일 경로 (None이면 자동 생성)\n",
    "    :return: 변환된 WAV 파일 경로\n",
    "    \"\"\"\n",
    "    if not os.path.exists(input_path):\n",
    "        raise FileNotFoundError(f\"파일이 존재하지 않아요: {input_path}\")\n",
    "\n",
    "    ext = os.path.splitext(input_path)[1].lower()\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".wav\"\n",
    "\n",
    "    # pydub이 ffmpeg를 통해 모든 형식 처리함\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        audio.export(output_path, format=\"wav\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"오디오 변환 실패: {e}\")\n",
    "\n",
    "    print(\"변환 완료:\", output_path)\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC 추출(모델 입력 준비)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc(file_path, sr=16000, n_mfcc=40):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc = np.expand_dims(mfcc, axis=-1)  # CNN 입력을 위해 채널 차원 추가\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 유효 레이블 개수 (nan 제외): 530280\n",
      "인코딩된 클래스 목록: ['Angry' 'Anxious' 'Embarrassed' 'Happy' 'Hurt' 'Neutrality' 'Sad']\n",
      "유효 배치 수: 82\n",
      "nan 제거 및 레이블 인코딩 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================\n",
    "# 1. 설정\n",
    "# ============================\n",
    "# 레이블 배치가 저장된 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches\"\n",
    "\n",
    "# 인코딩된 레이블 저장 경로\n",
    "encoded_label_dir = os.path.join(label_dir, \"encoded_labels\")\n",
    "os.makedirs(encoded_label_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 2. 모든 배치 레이블 수집 및 'nan' 제거\n",
    "# ============================\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "all_labels = []\n",
    "batch_label_data = []\n",
    "valid_indices_per_batch = []\n",
    "\n",
    "for label_file in label_files:\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    \n",
    "    # 'nan' 문자열 제거\n",
    "    valid_indices = [i for i, l in enumerate(labels) if str(l).lower() != 'nan']\n",
    "    valid_labels = [labels[i] for i in valid_indices]\n",
    "\n",
    "    all_labels.extend(valid_labels)\n",
    "    batch_label_data.append(valid_labels)\n",
    "    valid_indices_per_batch.append(valid_indices)\n",
    "\n",
    "# ============================\n",
    "# 3. 레이블 인코딩\n",
    "# ============================\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 인코더 저장\n",
    "with open(os.path.join(label_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# ============================\n",
    "# 4. 인코딩된 레이블 배치별로 저장\n",
    "# ============================\n",
    "for i, labels in enumerate(batch_label_data):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    save_path = os.path.join(encoded_label_dir, f\"label_batch_{i}.npy\")\n",
    "    np.save(save_path, encoded)\n",
    "\n",
    "print(f\"총 유효 레이블 개수 (nan 제외): {len(all_labels)}\")\n",
    "print(f\"인코딩된 클래스 목록: {label_encoder.classes_}\")\n",
    "print(f\"유효 배치 수: {len(label_files)}\")\n",
    "print(\"nan 제거 및 레이블 인코딩 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감정 분석 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 모델 로드\n",
    "model_path = \"best_model_generator_voice_emotion_analyze.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# LabelEncoder 로드\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "def predict_emotion(mfcc_data):\n",
    "    # 입력 형태 맞추기 (1, time, freq, 1)\n",
    "    X = np.expand_dims(mfcc_data, axis=0)\n",
    "    pred = model.predict(X)\n",
    "    idx = np.argmax(pred)\n",
    "    label = le.inverse_transform([idx])[0]\n",
    "    confidence = float(np.max(pred))\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 파이프라인 실행 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 완료: /media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000011.wav\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bb037ece200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
      "\n",
      " 감정 분석 결과: Happy (100.00% 확신)\n"
     ]
    }
   ],
   "source": [
    "# 1. 파일 변환\n",
    "m4a_path = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000011.wav\"\n",
    "\n",
    "wav_path = convert_to_wav(m4a_path)\n",
    "\n",
    "# 2. MFCC 추출\n",
    "mfcc = extract_mfcc(wav_path)\n",
    "\n",
    "# 3. 감정 예측\n",
    "emotion, score = predict_emotion(mfcc)\n",
    "print(f\"\\n 감정 분석 결과: {emotion} ({score:.2%} 확신)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/venv/test_super/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 34 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2025-04-02 12:21:20.363584: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[1,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,10,75]{3,2,1,0} %bitcast.440, f32[128,64,3,3]{3,2,1,0} %bitcast.447, f32[128]{0} %bitcast.449), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/venv/test_super/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694ms/step\n",
      "Softmax 확률 분포: [6.35206882e-17 7.89071120e-13 1.22968635e-10 1.00000000e+00\n",
      " 3.78825990e-27 1.18888200e-12 5.54563053e-27 1.00396704e-16]\n",
      "예측된 감정: Happy\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "# 설정\n",
    "wav_path = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1/1.감정/5.상처/0005_G1A3E5S0C0_LJB/0005_G1A3E5S0C0_LJB_000011.wav\"  # 예: ./val_data/sample_001.wav\n",
    "label_encoder_path = \"/media/usou/PortableSSD/mldl_project/data/mfcc_batches/label_encoder.pkl\"  # 예: ./label_encoder.pkl\n",
    "model_path = \"best_model_generator_voice_emotion_analyze.keras\"\n",
    "\n",
    "\n",
    "# 1. 모델 및 라벨 인코더 로드\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "with open(label_encoder_path, \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# 2. wav 파일에서 MFCC 추출\n",
    "def extract_mfcc(wav_path, sr=16000, n_mfcc=40, max_len=300):\n",
    "    y, sr = librosa.load(wav_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    \n",
    "    # 길이 고정 (짧으면 패딩, 길면 자름)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "# 3. 예측\n",
    "mfcc = extract_mfcc(wav_path)\n",
    "mfcc_input = mfcc[np.newaxis, ..., np.newaxis]  # (1, 40, 300, 1) 형태로 reshape\n",
    "\n",
    "y_pred = model.predict(mfcc_input)\n",
    "\n",
    "# 4. 결과 출력\n",
    "pred_index = np.argmax(y_pred)\n",
    "pred_emotion = label_encoder.inverse_transform([pred_index])[0]\n",
    "\n",
    "print(\"Softmax 확률 분포:\", y_pred[0])\n",
    "print(\"예측된 감정:\", pred_emotion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 재학습\n",
    "\n",
    "-  감정 클래스 7 -> 4개 축소\n",
    "- 행복, 슬픔, 분노, 중립\n",
    "- 데이터 증강 및 개선 모델 필요\n",
    "- 모델 성능 향상 전략\n",
    "    - 데이터 증강 + 하이퍼 파라미터 튜닝 + 과적합 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 흐름 요약\n",
    "✅ 전체 흐름 요약\n",
    "\n",
    "| 단계         | 설명                                              |\n",
    "|--------------|---------------------------------------------------|\n",
    "| 1단계 (완료) | JSON → `metadata_cleaned.csv` 생성               |\n",
    "| 2단계        | 4개 감정만 필터링 → `metadata_4class.csv` 저장   |\n",
    "| 3단계        | MFCC 추출 + 증강 적용                             |\n",
    "| 4단계        | 인코딩 → 배치 분할 저장                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1단계: JSON → DataFrame 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 수집된 샘플: 300584\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 라벨링 JSON이 위치한 최상위 폴더 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "\n",
    "# 실제 wav 파일이 존재하는 원천 데이터 경로\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 결과 CSV 및 로그를 저장할 폴더 경로\n",
    "save_dir = \"./data/usou\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 사용할 감정 4개만 필터링 대상\n",
    "target_classes = ['Happy', 'Sad', 'Angry', 'Neutrality']\n",
    "\n",
    "# 정제된 데이터와 누락 파일 로그를 담을 리스트\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# 모든 하위 폴더를 순회하며 JSON 파일 탐색\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if not file_name.endswith(\".json\"):\n",
    "            continue  # JSON 파일만 처리\n",
    "\n",
    "        json_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            # JSON 파일 로딩\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                content = json.load(f)\n",
    "\n",
    "            # 감정 정보 추출 및 필터링\n",
    "            emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "            if emotion not in target_classes:\n",
    "                continue  # 지정된 감정이 아닌 경우 제외\n",
    "\n",
    "            # 그 외 부가 정보 추출\n",
    "            style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "            sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "            wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "            # 경로 변환 (TL → TS로 수정하여 wav 경로 재구성)\n",
    "            relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "            relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "            wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "            # wav 파일 존재 여부 확인 후 저장\n",
    "            if os.path.exists(wav_path):\n",
    "                data.append({\n",
    "                    \"wav_path\": wav_path,\n",
    "                    \"emotion\": emotion,\n",
    "                    \"style\": style,\n",
    "                    \"sensitivity\": sensitivity\n",
    "                })\n",
    "            else:\n",
    "                broken_files.append(wav_path)\n",
    "        except Exception as e:\n",
    "            # JSON 로딩 실패 또는 파싱 오류 발생 시 경로 저장\n",
    "            broken_files.append(json_path)\n",
    "\n",
    "# 수집된 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 CSV 저장\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_4class.csv\"), index=False)\n",
    "\n",
    "# 누락된 경로 저장\n",
    "with open(os.path.join(save_dir, \"broken_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# 최종 처리 결과 출력\n",
    "print(\"총 수집된 샘플:\", len(df))\n",
    "print(\"에러 발생 수:\", len(broken_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출 + 증강\n",
    "\n",
    "- metadata_4class.csv에서 경로와 감정 읽기\n",
    "\n",
    "- audiomentations로 증강 (2배)\n",
    "\n",
    "- MFCC 추출 (40 x 300)\n",
    "\n",
    "- mfcc_data.npy, labels.npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4643/3246010131.py:20: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "MFCC 추출 및 증강:   0%|          | 335/300584 [00:25<7:26:13, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 0 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   0%|          | 669/300584 [00:52<7:05:35, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 1 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   0%|          | 1003/300584 [01:19<6:33:32, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 2 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   0%|          | 1339/300584 [01:45<5:59:34, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 3 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 1672/300584 [02:12<7:22:27, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 4 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 2005/300584 [02:39<7:08:27, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 5 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 2339/300584 [03:09<9:13:48,  8.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 6 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 2673/300584 [03:38<7:00:54, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 7 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 3007/300584 [04:06<7:00:46, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 8 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 3341/300584 [04:36<10:25:53,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 9 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|          | 3675/300584 [05:06<8:14:35, 10.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 10 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|▏         | 4011/300584 [05:34<5:49:34, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 11 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   1%|▏         | 4343/300584 [06:02<6:37:31, 12.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 12 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 4678/300584 [06:30<6:45:41, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 13 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 5012/300584 [06:59<6:58:11, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 14 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 5345/300584 [07:27<7:35:58, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 15 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 5680/300584 [07:54<6:02:02, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 16 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 6014/300584 [08:21<6:38:06, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 17 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 6349/300584 [08:48<6:16:18, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 18 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 6683/300584 [09:15<6:27:29, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 19 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 7015/300584 [09:42<7:19:14, 11.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 20 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   2%|▏         | 7350/300584 [10:09<6:11:35, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 21 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 7685/300584 [10:36<6:33:22, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 22 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 8018/300584 [11:03<7:40:19, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 23 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 8351/300584 [11:28<7:38:08, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 24 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 8686/300584 [11:55<5:35:51, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 25 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 9020/300584 [12:22<4:54:02, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 26 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 9354/300584 [12:48<7:11:23, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 27 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 9689/300584 [13:14<5:33:36, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 28 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 10022/300584 [13:41<6:44:33, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 29 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   3%|▎         | 10357/300584 [14:08<6:08:25, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 30 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▎         | 10689/300584 [14:34<6:47:13, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 31 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▎         | 11023/300584 [15:00<6:32:27, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 32 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 11357/300584 [15:27<6:18:30, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 33 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 11693/300584 [15:55<7:05:06, 11.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 34 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 12024/300584 [16:23<6:30:57, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 35 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 12360/300584 [16:51<6:31:45, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 36 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 12693/300584 [17:17<6:25:28, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 37 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 13027/300584 [17:44<8:38:10,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 38 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   4%|▍         | 13362/300584 [18:11<6:04:20, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 39 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 13696/300584 [18:39<7:36:52, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 40 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 14029/300584 [19:06<7:31:44, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 41 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 14363/300584 [19:33<6:59:13, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 42 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▍         | 14699/300584 [20:01<6:29:44, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 43 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 15031/300584 [20:29<7:42:30, 10.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 44 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 15364/300584 [20:57<6:24:02, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 45 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 15698/300584 [21:24<6:33:22, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 46 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 16034/300584 [21:51<5:45:14, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 47 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   5%|▌         | 16368/300584 [22:18<6:55:04, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 48 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 16701/300584 [22:47<6:55:37, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 49 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 17034/300584 [23:16<7:40:21, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 50 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 17370/300584 [23:43<7:05:24, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 51 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 17703/300584 [24:09<7:04:26, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 52 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 18037/300584 [24:39<6:26:37, 12.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 53 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 18371/300584 [25:08<8:10:08,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 54 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▌         | 18706/300584 [25:34<5:56:39, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 55 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▋         | 19039/300584 [26:03<6:39:39, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 56 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   6%|▋         | 19374/300584 [26:30<7:01:24, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 57 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 19707/300584 [26:58<5:38:40, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 58 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 20041/300584 [27:25<6:55:44, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 59 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 20375/300584 [27:52<9:08:28,  8.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 60 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 20708/300584 [28:24<11:21:42,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 61 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 21043/300584 [28:53<6:35:56, 11.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 62 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 21378/300584 [29:20<6:21:37, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 63 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 21713/300584 [29:45<5:36:24, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 64 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 22047/300584 [30:11<5:27:02, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 65 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   7%|▋         | 22381/300584 [30:38<6:23:49, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 66 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 22715/300584 [31:03<6:10:05, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 67 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 23048/300584 [31:31<6:14:15, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 68 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 23382/300584 [31:59<7:04:44, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 69 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 23716/300584 [32:25<6:20:27, 12.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 70 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 24050/300584 [32:52<5:44:22, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 71 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 24383/300584 [33:19<6:53:25, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 72 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 24719/300584 [33:45<5:48:29, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 73 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 25051/300584 [34:12<7:25:22, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 74 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   8%|▊         | 25386/300584 [34:40<5:18:55, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 75 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▊         | 25719/300584 [35:07<6:28:26, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 76 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▊         | 26053/300584 [35:34<7:16:49, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 77 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 26386/300584 [36:04<6:30:50, 11.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 78 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 26723/300584 [36:30<5:33:30, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 79 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 27054/300584 [36:58<8:05:43,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 80 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 27389/300584 [37:29<8:02:09,  9.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 81 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 27725/300584 [37:55<6:48:43, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 82 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 28058/300584 [38:21<5:41:57, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 83 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:   9%|▉         | 28392/300584 [38:47<6:44:39, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 84 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 28725/300584 [39:13<5:37:48, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 85 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 29059/300584 [39:40<5:58:31, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 86 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 29395/300584 [40:07<5:41:57, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 87 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|▉         | 29727/300584 [40:33<6:23:40, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 88 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 30062/300584 [40:59<5:44:52, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 89 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 30395/300584 [41:27<8:33:38,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 90 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 30728/300584 [41:58<6:32:35, 11.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 91 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 31062/300584 [42:26<8:10:57,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 92 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  10%|█         | 31397/300584 [42:56<8:03:38,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 93 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 31732/300584 [43:26<7:46:42,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 94 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 32064/300584 [43:54<7:16:46, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 95 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 32401/300584 [44:22<5:59:09, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 96 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 32732/300584 [44:49<6:10:44, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 97 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 33068/300584 [45:18<6:16:20, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 98 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 33401/300584 [45:46<7:26:32,  9.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 99 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█         | 33736/300584 [46:15<5:53:52, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 100 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█▏        | 34070/300584 [46:43<6:17:56, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 101 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  11%|█▏        | 34403/300584 [47:10<6:59:45, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 102 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 34738/300584 [47:37<7:14:55, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 103 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 35073/300584 [48:05<6:38:47, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 104 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 35404/300584 [48:32<5:53:39, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 105 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 35739/300584 [49:00<6:34:12, 11.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 106 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 36073/300584 [49:28<7:33:03,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 107 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 36408/300584 [49:56<6:51:10, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 108 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 36742/300584 [50:25<7:42:21,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 109 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 37077/300584 [50:53<6:37:57, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 110 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  12%|█▏        | 37410/300584 [51:24<7:01:46, 10.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 111 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 37744/300584 [51:53<6:54:57, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 112 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 38077/300584 [52:21<6:13:23, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 113 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 38412/300584 [52:49<8:07:04,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 114 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 38747/300584 [53:18<6:17:29, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 115 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 39079/300584 [53:45<8:45:32,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 116 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 39413/300584 [54:11<6:43:02, 10.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 117 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 39748/300584 [54:35<6:34:44, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 118 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 40082/300584 [55:01<5:41:57, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 119 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  13%|█▎        | 40416/300584 [55:25<6:54:30, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 120 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▎        | 40749/300584 [55:53<6:15:25, 11.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 121 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▎        | 41085/300584 [56:20<5:37:39, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 122 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 41419/300584 [56:47<6:52:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 123 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 41751/300584 [57:12<6:04:29, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 124 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 42085/300584 [57:38<7:05:15, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 125 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 42420/300584 [58:03<6:33:10, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 126 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 42754/300584 [58:29<6:14:19, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 127 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 43088/300584 [58:58<7:13:24,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 128 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  14%|█▍        | 43422/300584 [59:27<6:35:31, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 129 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 43758/300584 [59:53<5:46:19, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 130 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 44089/300584 [1:00:23<7:26:08,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 131 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 44423/300584 [1:00:54<7:04:34, 10.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 132 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▍        | 44757/300584 [1:01:28<9:09:55,  7.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 133 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 45092/300584 [1:02:04<6:15:40, 11.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 134 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 45424/300584 [1:02:36<13:53:21,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 135 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 45759/300584 [1:03:16<9:04:47,  7.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 136 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 46093/300584 [1:03:47<6:46:32, 10.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 137 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  15%|█▌        | 46426/300584 [1:04:20<6:45:12, 10.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 138 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 46760/300584 [1:04:54<7:23:27,  9.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 139 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 47096/300584 [1:05:25<6:48:10, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 140 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 47431/300584 [1:05:56<6:27:59, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 141 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 47763/300584 [1:06:22<6:02:19, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 142 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 48099/300584 [1:06:50<5:00:54, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 143 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 48432/300584 [1:07:17<5:43:21, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 144 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▌        | 48766/300584 [1:07:43<5:45:38, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 145 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▋        | 49100/300584 [1:08:09<6:57:47, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 146 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  16%|█▋        | 49434/300584 [1:08:37<6:23:28, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 147 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 49768/300584 [1:09:04<6:40:14, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 148 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 50102/300584 [1:09:33<6:23:46, 10.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 149 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 50435/300584 [1:10:00<5:48:35, 11.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 150 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 50770/300584 [1:10:29<5:57:33, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 151 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 51104/300584 [1:10:59<6:21:36, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 152 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 51439/300584 [1:11:29<5:59:10, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 153 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 51772/300584 [1:11:56<7:16:43,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 154 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 52106/300584 [1:12:25<6:47:22, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 155 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  17%|█▋        | 52438/300584 [1:12:53<6:14:11, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 156 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 52775/300584 [1:13:23<5:11:48, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 157 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 53108/300584 [1:13:53<5:45:59, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 158 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 53442/300584 [1:14:26<6:29:56, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 159 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 53776/300584 [1:14:56<6:44:11, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 160 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 54108/300584 [1:15:25<7:19:08,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 161 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 54444/300584 [1:15:57<7:44:17,  8.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 162 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 54777/300584 [1:16:27<7:33:52,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 163 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 55112/300584 [1:16:57<7:29:39,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 164 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  18%|█▊        | 55446/300584 [1:17:27<6:01:05, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 165 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▊        | 55780/300584 [1:17:57<8:08:32,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 166 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▊        | 56113/300584 [1:18:27<6:50:55,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 167 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 56447/300584 [1:18:57<5:27:02, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 168 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 56782/300584 [1:19:26<5:48:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 169 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 57116/300584 [1:19:51<5:34:26, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 170 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 57449/300584 [1:20:17<5:10:20, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 171 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 57785/300584 [1:20:43<6:08:23, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 172 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 58117/300584 [1:21:08<5:32:21, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 173 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  19%|█▉        | 58453/300584 [1:21:34<5:10:34, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 174 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 58785/300584 [1:22:00<5:49:39, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 175 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 59120/300584 [1:22:27<5:39:20, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 176 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 59454/300584 [1:22:53<5:10:38, 12.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 177 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|█▉        | 59789/300584 [1:23:17<5:00:42, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 178 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 60121/300584 [1:23:43<6:06:59, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 179 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 60455/300584 [1:24:07<5:23:11, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 180 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 60790/300584 [1:24:33<5:39:15, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 181 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 61125/300584 [1:25:02<5:48:50, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 182 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  20%|██        | 61458/300584 [1:25:28<6:04:02, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 183 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 61791/300584 [1:25:54<5:44:17, 11.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 184 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 62127/300584 [1:26:21<5:26:07, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 185 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 62458/300584 [1:26:53<10:27:15,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 186 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 62792/300584 [1:27:26<7:45:13,  8.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 187 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 63127/300584 [1:27:55<9:00:55,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 188 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 63461/300584 [1:28:24<6:29:54, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 189 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██        | 63794/300584 [1:28:53<5:50:52, 11.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 190 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██▏       | 64129/300584 [1:29:25<6:05:26, 10.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 191 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  21%|██▏       | 64463/300584 [1:29:56<6:40:46,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 192 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 64797/300584 [1:30:22<5:29:50, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 193 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 65132/300584 [1:30:47<5:54:34, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 194 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 65464/300584 [1:31:12<6:21:28, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 195 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 65799/300584 [1:31:36<4:24:49, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 196 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 66133/300584 [1:32:01<5:01:06, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 197 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 66468/300584 [1:32:22<4:04:16, 15.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 198 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 66804/300584 [1:32:43<3:49:20, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 199 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 67135/300584 [1:33:05<5:10:15, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 200 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  22%|██▏       | 67469/300584 [1:33:27<5:13:52, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 201 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 67804/300584 [1:33:49<4:14:17, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 202 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 68137/300584 [1:34:13<4:06:39, 15.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 203 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 68472/300584 [1:34:36<4:15:29, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 204 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 68807/300584 [1:34:57<4:22:59, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 205 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 69140/300584 [1:35:19<4:30:31, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 206 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 69472/300584 [1:35:41<5:08:33, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 207 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 69809/300584 [1:36:02<4:11:58, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 208 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 70142/300584 [1:36:24<3:44:43, 17.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 209 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  23%|██▎       | 70476/300584 [1:36:44<3:44:15, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 210 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▎       | 70812/300584 [1:37:04<4:01:13, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 211 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▎       | 71145/300584 [1:37:25<4:31:36, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 212 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 71477/300584 [1:37:45<6:41:12,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 213 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 71812/300584 [1:38:06<3:58:55, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 214 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 72146/300584 [1:38:29<6:14:31, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 215 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 72481/300584 [1:38:52<4:20:51, 14.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 216 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 72814/300584 [1:39:14<5:04:47, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 217 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 73149/300584 [1:39:35<3:26:51, 18.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 218 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  24%|██▍       | 73480/300584 [1:39:57<5:04:41, 12.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 219 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 73817/300584 [1:40:18<3:20:04, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 220 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 74149/300584 [1:40:41<5:14:40, 11.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 221 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 74486/300584 [1:41:01<3:29:21, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 222 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▍       | 74819/300584 [1:41:22<4:17:38, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 223 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 75153/300584 [1:41:42<3:49:47, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 224 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 75485/300584 [1:42:04<5:33:40, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 225 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 75821/300584 [1:42:25<3:05:27, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 226 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 76156/300584 [1:42:46<3:19:16, 18.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 227 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  25%|██▌       | 76488/300584 [1:43:07<3:14:00, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 228 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 76821/300584 [1:43:29<5:32:30, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 229 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 77156/300584 [1:43:51<3:53:18, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 230 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 77490/300584 [1:44:13<5:59:30, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 231 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 77824/300584 [1:44:36<4:39:51, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 232 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 78159/300584 [1:44:58<4:25:26, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 233 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 78494/300584 [1:45:20<3:53:16, 15.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 234 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▌       | 78825/300584 [1:45:43<4:02:14, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 235 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▋       | 79161/300584 [1:46:04<5:04:26, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 236 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  26%|██▋       | 79495/300584 [1:46:26<4:44:33, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 237 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 79830/300584 [1:46:48<3:44:16, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 238 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 80160/300584 [1:47:10<4:33:14, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 239 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 80496/300584 [1:47:32<3:42:58, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 240 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 80830/300584 [1:47:56<4:17:38, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 241 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 81165/300584 [1:48:18<4:35:53, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 242 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 81498/300584 [1:48:40<4:02:10, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 243 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 81833/300584 [1:49:04<4:28:43, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 244 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 82167/300584 [1:49:26<4:12:07, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 245 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  27%|██▋       | 82500/300584 [1:49:49<5:29:21, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 246 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 82835/300584 [1:50:10<5:09:16, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 247 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 83169/300584 [1:50:30<3:43:05, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 248 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 83504/300584 [1:50:51<3:42:11, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 249 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 83836/300584 [1:51:12<4:01:33, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 250 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 84170/300584 [1:51:32<4:36:59, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 251 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 84503/300584 [1:51:52<4:40:47, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 252 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 84839/300584 [1:52:15<4:30:41, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 253 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 85173/300584 [1:52:36<3:55:54, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 254 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  28%|██▊       | 85506/300584 [1:52:57<4:11:08, 14.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 255 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▊       | 85841/300584 [1:53:19<3:35:13, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 256 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▊       | 86175/300584 [1:53:42<4:30:28, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 257 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 86507/300584 [1:54:04<5:03:18, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 258 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 86844/300584 [1:54:25<3:01:38, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 259 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 87175/300584 [1:54:45<3:30:41, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 260 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 87511/300584 [1:55:08<4:28:13, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 261 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 87844/300584 [1:55:30<3:58:19, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 262 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 88177/300584 [1:55:52<4:17:27, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 263 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  29%|██▉       | 88511/300584 [1:56:14<3:48:21, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 264 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 88846/300584 [1:56:35<4:41:21, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 265 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 89181/300584 [1:56:57<3:09:24, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 266 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 89513/300584 [1:57:19<5:09:11, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 267 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|██▉       | 89847/300584 [1:57:42<3:59:50, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 268 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 90183/300584 [1:58:07<5:12:29, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 269 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 90516/300584 [1:58:32<3:57:18, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 270 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 90850/300584 [1:58:54<5:18:26, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 271 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 91184/300584 [1:59:16<3:35:56, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 272 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  30%|███       | 91519/300584 [1:59:37<4:00:02, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 273 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 91852/300584 [2:00:00<4:29:04, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 274 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 92187/300584 [2:00:24<4:04:46, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 275 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 92521/300584 [2:00:46<3:49:19, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 276 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 92853/300584 [2:01:08<5:29:33, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 277 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 93187/300584 [2:01:30<3:40:42, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 278 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 93524/300584 [2:01:53<3:42:45, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 279 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███       | 93856/300584 [2:02:15<3:15:40, 17.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 280 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███▏      | 94190/300584 [2:02:39<3:58:11, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 281 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  31%|███▏      | 94524/300584 [2:03:01<4:28:58, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 282 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 94859/300584 [2:03:24<3:58:18, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 283 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 95192/300584 [2:03:46<4:41:13, 12.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 284 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 95528/300584 [2:04:12<4:14:14, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 285 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 95861/300584 [2:04:41<4:58:48, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 286 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 96193/300584 [2:05:08<4:28:02, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 287 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 96526/300584 [2:05:37<7:14:53,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 288 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 96862/300584 [2:06:04<3:51:11, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 289 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 97195/300584 [2:06:29<4:57:17, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 290 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  32%|███▏      | 97530/300584 [2:06:55<4:29:48, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 291 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 97864/300584 [2:07:22<4:28:48, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 292 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 98197/300584 [2:07:48<5:14:29, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 293 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 98531/300584 [2:08:15<6:08:32,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 294 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 98864/300584 [2:08:43<5:13:33, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 295 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 99198/300584 [2:09:14<5:54:05,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 296 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 99532/300584 [2:09:44<5:26:52, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 297 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 99866/300584 [2:10:13<6:02:04,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 298 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 100201/300584 [2:10:44<6:50:08,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 299 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  33%|███▎      | 100536/300584 [2:11:16<4:08:11, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 300 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▎      | 100872/300584 [2:11:42<4:28:46, 12.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 301 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▎      | 101203/300584 [2:12:09<7:23:45,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 302 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 101537/300584 [2:12:36<4:37:54, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 303 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 101871/300584 [2:13:04<4:43:39, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 304 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 102205/300584 [2:13:33<5:00:15, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 305 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 102540/300584 [2:14:01<4:18:28, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 306 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 102875/300584 [2:14:27<4:00:07, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 307 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 103207/300584 [2:14:53<4:54:52, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 308 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  34%|███▍      | 103542/300584 [2:15:21<4:52:44, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 309 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 103876/300584 [2:15:48<5:16:08, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 310 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 104210/300584 [2:16:18<5:46:32,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 311 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 104543/300584 [2:16:46<10:10:12,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 312 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▍      | 104879/300584 [2:17:20<4:52:49, 11.14it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 313 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 105211/300584 [2:17:53<7:03:48,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 314 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 105546/300584 [2:18:25<4:05:32, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 315 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 105879/300584 [2:18:56<7:43:28,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 316 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 106212/300584 [2:19:27<4:49:17, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 317 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  35%|███▌      | 106548/300584 [2:19:59<4:29:53, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 318 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 106881/300584 [2:20:25<5:11:04, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 319 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 107217/300584 [2:20:50<5:17:11, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 320 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 107550/300584 [2:21:16<5:11:42, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 321 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 107884/300584 [2:21:44<5:30:36,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 322 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 108218/300584 [2:22:11<4:25:07, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 323 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 108552/300584 [2:22:38<4:38:24, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 324 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▌      | 108885/300584 [2:23:04<4:48:45, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 325 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▋      | 109220/300584 [2:23:30<5:58:15,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 326 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  36%|███▋      | 109553/300584 [2:23:57<4:37:28, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 327 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 109887/300584 [2:24:24<6:13:12,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 328 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 110222/300584 [2:24:50<4:18:20, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 329 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 110556/300584 [2:25:17<4:25:11, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 330 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 110889/300584 [2:25:43<3:45:15, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 331 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 111224/300584 [2:26:10<4:02:07, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 332 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 111558/300584 [2:26:36<3:40:20, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 333 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 111893/300584 [2:27:06<6:02:06,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 334 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 112225/300584 [2:27:38<6:34:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 335 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  37%|███▋      | 112560/300584 [2:28:08<3:58:33, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 336 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 112894/300584 [2:28:38<4:19:15, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 337 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 113227/300584 [2:29:08<4:45:10, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 338 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 113563/300584 [2:29:38<4:41:38, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 339 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 113895/300584 [2:30:08<6:42:32,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 340 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 114231/300584 [2:30:40<5:24:33,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 341 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 114565/300584 [2:31:11<5:17:55,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 342 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 114898/300584 [2:31:38<4:43:30, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 343 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 115231/300584 [2:32:07<4:57:58, 10.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 344 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  38%|███▊      | 115565/300584 [2:32:34<4:27:11, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 345 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▊      | 115900/300584 [2:33:02<3:42:18, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 346 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▊      | 116232/300584 [2:33:31<5:20:55,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 347 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 116567/300584 [2:34:05<5:21:50,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 348 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 116901/300584 [2:34:42<8:26:47,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 349 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 117236/300584 [2:35:16<5:48:12,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 350 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 117570/300584 [2:35:49<4:52:50, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 351 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 117903/300584 [2:36:23<5:44:05,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 352 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 118239/300584 [2:37:00<5:25:34,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 353 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  39%|███▉      | 118572/300584 [2:37:33<5:14:15,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 354 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 118906/300584 [2:38:03<5:53:42,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 355 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 119240/300584 [2:38:27<3:42:36, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 356 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 119572/300584 [2:38:48<3:13:43, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 357 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|███▉      | 119907/300584 [2:39:14<4:42:18, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 358 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 120241/300584 [2:39:38<5:49:25,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 359 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 120577/300584 [2:40:02<3:46:50, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 360 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 120910/300584 [2:40:26<4:47:32, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 361 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 121244/300584 [2:40:49<3:32:20, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 362 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  40%|████      | 121578/300584 [2:41:11<5:51:05,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 363 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 121912/300584 [2:41:34<4:14:45, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 364 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 122246/300584 [2:41:57<3:40:12, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 365 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 122579/300584 [2:42:21<4:14:19, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 366 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 122914/300584 [2:42:45<5:16:19,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 367 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 123249/300584 [2:43:08<3:32:56, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 368 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 123584/300584 [2:43:33<4:25:21, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 369 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████      | 123916/300584 [2:43:58<4:16:05, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 370 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████▏     | 124250/300584 [2:44:21<3:18:26, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 371 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  41%|████▏     | 124584/300584 [2:44:46<4:19:28, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 372 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 124918/300584 [2:45:12<4:37:41, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 373 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 125253/300584 [2:45:37<3:46:26, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 374 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 125585/300584 [2:46:01<4:37:19, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 375 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 125921/300584 [2:46:25<2:54:51, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 376 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 126255/300584 [2:46:48<4:27:38, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 377 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 126587/300584 [2:47:13<5:33:05,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 378 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 126922/300584 [2:47:37<3:28:45, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 379 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 127256/300584 [2:48:01<4:35:02, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 380 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  42%|████▏     | 127591/300584 [2:48:25<4:19:50, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 381 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 127924/300584 [2:48:50<3:41:20, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 382 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 128257/300584 [2:49:14<4:01:30, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 383 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 128591/300584 [2:49:40<3:59:05, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 384 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 128927/300584 [2:50:03<2:33:02, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 385 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 129260/300584 [2:50:26<4:33:55, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 386 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 129593/300584 [2:50:52<4:08:05, 11.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 387 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 129928/300584 [2:51:17<4:01:35, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 388 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 130261/300584 [2:51:41<4:28:27, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 389 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  43%|████▎     | 130596/300584 [2:52:05<2:36:55, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 390 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▎     | 130931/300584 [2:52:26<2:56:20, 16.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 391 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▎     | 131264/300584 [2:52:47<3:24:57, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 392 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 131598/300584 [2:53:07<2:22:58, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 393 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 131933/300584 [2:53:29<2:44:53, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 394 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 132266/300584 [2:53:50<4:06:35, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 395 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 132601/300584 [2:54:12<3:10:51, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 396 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 132935/300584 [2:54:33<2:51:52, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 397 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 133267/300584 [2:54:53<3:21:25, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 398 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  44%|████▍     | 133604/300584 [2:55:12<2:30:32, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 399 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 133936/300584 [2:55:33<3:13:17, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 400 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 134270/300584 [2:55:53<2:52:42, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 401 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 134603/300584 [2:56:13<2:49:38, 16.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 402 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▍     | 134938/300584 [2:56:34<3:11:37, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 403 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 135273/300584 [2:56:54<3:31:50, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 404 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 135608/300584 [2:57:14<2:47:28, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 405 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 135939/300584 [2:57:35<3:09:57, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 406 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 136274/300584 [2:57:55<3:08:44, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 407 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  45%|████▌     | 136610/300584 [2:58:17<2:46:35, 16.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 408 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 136943/300584 [2:58:37<3:02:09, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 409 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 137276/300584 [2:58:59<3:06:36, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 410 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 137610/300584 [2:59:19<3:00:21, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 411 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 137945/300584 [2:59:39<3:20:54, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 412 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 138279/300584 [3:00:00<2:53:22, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 413 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 138612/300584 [3:00:20<3:15:49, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 414 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▌     | 138947/300584 [3:00:42<3:30:07, 12.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 415 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▋     | 139280/300584 [3:01:01<2:44:24, 16.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 416 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  46%|████▋     | 139614/300584 [3:01:22<2:28:04, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 417 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 139948/300584 [3:01:41<2:39:52, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 418 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 140282/300584 [3:02:01<3:10:47, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 419 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 140617/300584 [3:02:20<3:03:09, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 420 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 140949/300584 [3:02:39<2:37:38, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 421 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 141284/300584 [3:02:59<2:58:47, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 422 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 141618/300584 [3:03:18<2:06:28, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 423 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 141952/300584 [3:03:38<2:45:51, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 424 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 142286/300584 [3:03:58<2:59:25, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 425 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  47%|████▋     | 142618/300584 [3:04:20<3:20:57, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 426 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 142955/300584 [3:04:42<3:16:48, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 427 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 143287/300584 [3:05:03<3:13:38, 13.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 428 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 143622/300584 [3:05:24<2:43:55, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 429 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 143957/300584 [3:05:45<2:47:32, 15.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 430 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 144289/300584 [3:06:04<3:08:00, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 431 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 144625/300584 [3:06:25<3:17:30, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 432 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 144957/300584 [3:06:46<3:07:40, 13.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 433 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 145294/300584 [3:07:06<2:35:12, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 434 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  48%|████▊     | 145626/300584 [3:07:25<2:38:41, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 435 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▊     | 145960/300584 [3:07:47<2:59:46, 14.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 436 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▊     | 146294/300584 [3:08:08<3:19:57, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 437 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 146629/300584 [3:08:28<2:45:18, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 438 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 146963/300584 [3:08:48<2:23:30, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 439 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 147297/300584 [3:09:09<2:19:16, 18.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 440 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 147630/300584 [3:09:32<3:24:57, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 441 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 147963/300584 [3:09:58<4:58:54,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 442 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 148298/300584 [3:10:24<3:39:18, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 443 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  49%|████▉     | 148634/300584 [3:10:46<2:44:52, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 444 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 148965/300584 [3:11:10<2:59:00, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 445 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 149300/300584 [3:11:33<3:46:43, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 446 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 149635/300584 [3:11:55<3:12:52, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 447 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|████▉     | 149968/300584 [3:12:16<3:08:00, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 448 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 150303/300584 [3:12:37<2:54:13, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 449 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 150635/300584 [3:12:57<2:45:13, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 450 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 150970/300584 [3:13:18<2:51:01, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 451 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 151304/300584 [3:13:39<2:26:25, 16.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 452 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  50%|█████     | 151637/300584 [3:13:59<2:53:25, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 453 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 151972/300584 [3:14:20<3:17:08, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 454 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 152307/300584 [3:14:41<2:23:06, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 455 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 152640/300584 [3:15:00<2:20:58, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 456 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 152975/300584 [3:15:21<2:45:23, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 457 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 153309/300584 [3:15:42<2:25:12, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 458 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 153643/300584 [3:16:02<2:33:11, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 459 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████     | 153975/300584 [3:16:24<2:51:30, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 460 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████▏    | 154310/300584 [3:16:45<2:32:14, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 461 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  51%|█████▏    | 154644/300584 [3:17:06<2:37:08, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 462 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 154978/300584 [3:17:29<2:44:00, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 463 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 155314/300584 [3:17:49<2:02:30, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 464 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 155647/300584 [3:18:10<2:15:34, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 465 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 155979/300584 [3:18:30<3:03:55, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 466 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 156313/300584 [3:18:50<2:39:16, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 467 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 156648/300584 [3:19:10<2:50:57, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 468 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 156983/300584 [3:19:30<2:19:08, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 469 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 157317/300584 [3:19:49<2:02:29, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 470 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  52%|█████▏    | 157649/300584 [3:20:10<3:08:53, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 471 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 157984/300584 [3:20:32<3:27:44, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 472 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 158318/300584 [3:20:54<2:36:01, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 473 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 158649/300584 [3:21:15<1:54:07, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 474 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 158988/300584 [3:21:36<2:25:02, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 475 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 159320/300584 [3:22:00<2:25:49, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 476 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 159653/300584 [3:22:22<3:16:00, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 477 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 159989/300584 [3:22:43<2:59:41, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 478 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 160323/300584 [3:23:05<2:38:35, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 479 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  53%|█████▎    | 160656/300584 [3:23:26<2:34:19, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 480 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▎    | 160989/300584 [3:23:46<2:33:39, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 481 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▎    | 161323/300584 [3:24:08<2:55:59, 13.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 482 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 161659/300584 [3:24:29<2:42:37, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 483 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 161992/300584 [3:24:52<2:35:32, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 484 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 162326/300584 [3:25:17<3:16:19, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 485 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 162660/300584 [3:25:39<3:28:13, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 486 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 162993/300584 [3:26:02<3:22:31, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 487 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 163328/300584 [3:26:25<2:17:21, 16.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 488 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  54%|█████▍    | 163661/300584 [3:26:47<2:36:50, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 489 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 163997/300584 [3:27:08<2:18:42, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 490 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 164329/300584 [3:27:29<1:58:02, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 491 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 164664/300584 [3:27:49<2:03:03, 18.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 492 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▍    | 164997/300584 [3:28:08<2:21:02, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 493 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 165334/300584 [3:28:29<1:58:17, 19.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 494 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 165665/300584 [3:28:49<2:28:25, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 495 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 166000/300584 [3:29:11<2:32:08, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 496 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 166335/300584 [3:29:31<2:39:00, 14.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 497 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  55%|█████▌    | 166668/300584 [3:29:51<1:57:30, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 498 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 167002/300584 [3:30:12<2:13:36, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 499 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 167336/300584 [3:30:33<2:51:30, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 500 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 167672/300584 [3:30:54<2:13:19, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 501 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 168005/300584 [3:31:13<2:03:43, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 502 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 168338/300584 [3:31:34<2:10:35, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 503 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 168672/300584 [3:31:56<2:40:38, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 504 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▌    | 169007/300584 [3:32:20<2:33:36, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 505 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▋    | 169340/300584 [3:32:42<2:46:08, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 506 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  56%|█████▋    | 169674/300584 [3:33:08<3:34:35, 10.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 507 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 170008/300584 [3:33:35<3:58:30,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 508 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 170343/300584 [3:34:01<2:49:24, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 509 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 170675/300584 [3:34:26<2:37:54, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 510 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 171009/300584 [3:34:54<3:03:14, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 511 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 171343/300584 [3:35:20<2:40:22, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 512 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 171677/300584 [3:35:47<2:58:00, 12.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 513 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 172011/300584 [3:36:14<3:42:54,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 514 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 172345/300584 [3:36:40<2:42:39, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 515 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  57%|█████▋    | 172679/300584 [3:37:07<3:25:43, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 516 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 173013/300584 [3:37:37<4:20:06,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 517 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 173348/300584 [3:38:09<2:48:36, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 518 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 173683/300584 [3:38:38<2:43:21, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 519 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 174017/300584 [3:39:04<2:32:43, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 520 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 174349/300584 [3:39:32<3:25:18, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 521 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 174683/300584 [3:40:02<3:24:20, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 522 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 175018/300584 [3:40:30<3:22:23, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 523 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 175351/300584 [3:40:59<3:04:19, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 524 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  58%|█████▊    | 175687/300584 [3:41:29<3:03:16, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 525 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▊    | 176019/300584 [3:41:58<2:55:55, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 526 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▊    | 176354/300584 [3:42:26<2:55:48, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 527 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 176688/300584 [3:42:52<2:39:03, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 528 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 177024/300584 [3:43:19<2:30:54, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 529 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 177356/300584 [3:43:44<2:38:48, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 530 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 177690/300584 [3:44:11<3:18:37, 10.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 531 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 178024/300584 [3:44:38<3:12:02, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 532 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 178357/300584 [3:45:04<3:40:42,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 533 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  59%|█████▉    | 178692/300584 [3:45:31<3:51:42,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 534 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 179026/300584 [3:45:57<3:00:18, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 535 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 179358/300584 [3:46:22<2:48:43, 11.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 536 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 179695/300584 [3:46:50<2:30:04, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 537 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|█████▉    | 180026/300584 [3:47:18<2:41:23, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 538 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 180361/300584 [3:47:45<3:43:36,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 539 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 180696/300584 [3:48:14<3:51:10,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 540 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 181029/300584 [3:48:40<3:20:15,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 541 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 181364/300584 [3:49:06<3:12:32, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 542 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  60%|██████    | 181696/300584 [3:49:34<3:54:50,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 543 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 182031/300584 [3:50:02<2:58:23, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 544 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 182364/300584 [3:50:30<6:00:51,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 545 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 182702/300584 [3:50:58<3:06:15, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 546 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 183033/300584 [3:51:25<3:18:11,  9.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 547 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 183369/300584 [3:51:52<3:11:43, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 548 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 183703/300584 [3:52:22<3:34:21,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 549 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████    | 184036/300584 [3:52:51<4:01:59,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 550 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████▏   | 184370/300584 [3:53:21<3:33:51,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 551 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  61%|██████▏   | 184704/300584 [3:53:52<3:35:45,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 552 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 185037/300584 [3:54:20<4:13:52,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 553 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 185371/300584 [3:54:50<3:37:42,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 554 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 185705/300584 [3:55:22<3:43:37,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 555 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 186039/300584 [3:55:51<2:09:02, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 556 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 186374/300584 [3:56:18<2:16:37, 13.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 557 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 186708/300584 [3:56:45<2:45:59, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 558 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 187043/300584 [3:57:12<2:15:04, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 559 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 187376/300584 [3:57:37<2:26:04, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 560 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  62%|██████▏   | 187711/300584 [3:58:04<2:19:41, 13.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 561 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 188044/300584 [3:58:31<2:20:16, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 562 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 188378/300584 [3:58:57<2:07:10, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 563 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 188711/300584 [3:59:23<3:03:54, 10.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 564 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 189046/300584 [3:59:48<2:21:13, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 565 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 189378/300584 [4:00:13<2:47:51, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 566 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 189714/300584 [4:00:40<2:11:35, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 567 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 190048/300584 [4:01:04<1:54:16, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 568 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 190382/300584 [4:01:30<2:23:23, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 569 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  63%|██████▎   | 190717/300584 [4:01:59<1:53:42, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 570 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▎   | 191049/300584 [4:02:25<3:03:17,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 571 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▎   | 191386/300584 [4:02:50<2:14:04, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 572 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 191718/300584 [4:03:19<2:47:13, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 573 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 192051/300584 [4:03:48<3:37:16,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 574 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 192387/300584 [4:04:17<2:24:42, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 575 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 192721/300584 [4:04:45<2:19:23, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 576 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 193053/300584 [4:05:11<2:39:13, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 577 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 193387/300584 [4:05:37<2:31:19, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 578 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  64%|██████▍   | 193722/300584 [4:06:05<2:32:16, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 579 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 194056/300584 [4:06:30<2:16:10, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 580 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 194388/300584 [4:06:56<2:35:46, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 581 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 194722/300584 [4:07:26<2:08:48, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 582 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▍   | 195056/300584 [4:07:55<3:30:22,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 583 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 195391/300584 [4:08:22<2:42:12, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 584 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 195726/300584 [4:08:51<2:48:38, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 585 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 196060/300584 [4:09:18<2:07:17, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 586 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 196393/300584 [4:09:42<2:01:34, 14.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 587 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  65%|██████▌   | 196726/300584 [4:10:07<2:10:40, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 588 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 197062/300584 [4:10:32<2:18:29, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 589 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 197397/300584 [4:10:55<1:52:08, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 590 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 197731/300584 [4:11:16<1:55:14, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 591 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 198063/300584 [4:11:39<2:07:59, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 592 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 198398/300584 [4:12:00<2:12:27, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 593 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 198731/300584 [4:12:19<2:20:20, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 594 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▌   | 199066/300584 [4:12:39<1:50:07, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 595 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▋   | 199400/300584 [4:13:01<2:16:37, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 596 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  66%|██████▋   | 199736/300584 [4:13:20<1:40:11, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 597 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 200068/300584 [4:13:42<2:26:57, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 598 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 200403/300584 [4:14:01<1:51:50, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 599 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 200738/300584 [4:14:19<1:54:25, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 600 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 201070/300584 [4:14:37<1:37:35, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 601 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 201403/300584 [4:14:56<2:23:07, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 602 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 201739/300584 [4:15:16<1:38:44, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 603 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 202074/300584 [4:15:37<1:51:14, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 604 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 202406/300584 [4:15:57<2:05:58, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 605 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  67%|██████▋   | 202739/300584 [4:16:18<2:01:45, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 606 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 203075/300584 [4:16:41<1:53:30, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 607 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 203408/300584 [4:17:02<2:10:01, 12.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 608 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 203742/300584 [4:17:26<2:02:05, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 609 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 204077/300584 [4:17:48<1:51:54, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 610 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 204410/300584 [4:18:12<2:04:11, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 611 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 204745/300584 [4:18:34<1:40:41, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 612 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 205077/300584 [4:18:55<2:18:20, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 613 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 205411/300584 [4:19:19<2:16:48, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 614 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  68%|██████▊   | 205745/300584 [4:19:43<2:38:53,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 615 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▊   | 206080/300584 [4:20:06<2:08:05, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 616 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▊   | 206415/300584 [4:20:32<1:41:22, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 617 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 206748/300584 [4:20:52<1:37:12, 16.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 618 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 207084/300584 [4:21:12<2:06:39, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 619 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 207415/300584 [4:21:32<2:11:09, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 620 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 207749/300584 [4:21:54<1:44:08, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 621 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 208083/300584 [4:22:15<1:50:46, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 622 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 208419/300584 [4:22:37<1:34:25, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 623 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  69%|██████▉   | 208751/300584 [4:22:56<1:18:22, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 624 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 209086/300584 [4:23:17<1:48:30, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 625 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 209420/300584 [4:23:42<2:05:08, 12.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 626 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 209752/300584 [4:24:07<1:28:08, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 627 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|██████▉   | 210087/300584 [4:24:32<2:14:56, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 628 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 210422/300584 [4:24:58<2:44:32,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 629 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 210756/300584 [4:25:23<2:47:45,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 630 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 211089/300584 [4:25:45<2:38:01,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 631 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 211425/300584 [4:26:08<1:48:35, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 632 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  70%|███████   | 211757/300584 [4:26:34<2:16:54, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 633 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 212092/300584 [4:27:03<2:22:31, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 634 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 212425/300584 [4:27:28<1:42:44, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 635 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 212759/300584 [4:27:50<1:48:20, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 636 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 213095/300584 [4:28:10<1:21:51, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 637 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 213429/300584 [4:28:31<1:30:11, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 638 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 213761/300584 [4:28:53<1:45:39, 13.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 639 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████   | 214098/300584 [4:29:15<1:26:30, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 640 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████▏  | 214429/300584 [4:29:38<2:06:55, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 641 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  71%|███████▏  | 214766/300584 [4:29:59<1:15:39, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 642 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 215099/300584 [4:30:20<1:29:04, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 643 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 215430/300584 [4:30:43<2:02:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 644 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 215766/300584 [4:31:06<2:07:54, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 645 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 216101/300584 [4:31:28<1:32:15, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 646 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 216434/300584 [4:31:52<1:29:22, 15.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 647 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 216767/300584 [4:32:13<1:27:09, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 648 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 217104/300584 [4:32:33<1:27:12, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 649 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 217434/300584 [4:32:58<1:46:32, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 650 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  72%|███████▏  | 217769/300584 [4:33:23<1:49:50, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 651 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 218105/300584 [4:33:47<1:50:48, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 652 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 218437/300584 [4:34:12<1:55:14, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 653 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 218771/300584 [4:34:36<1:54:51, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 654 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 219105/300584 [4:35:02<2:06:10, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 655 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 219440/300584 [4:35:33<1:55:53, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 656 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 219773/300584 [4:36:00<2:28:42,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 657 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 220107/300584 [4:36:26<1:44:18, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 658 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 220441/300584 [4:36:54<2:08:20, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 659 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  73%|███████▎  | 220775/300584 [4:37:19<1:36:44, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 660 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▎  | 221109/300584 [4:37:42<1:33:01, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 661 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▎  | 221443/300584 [4:38:08<1:39:49, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 662 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 221779/300584 [4:38:31<1:16:28, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 663 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 222111/300584 [4:38:54<2:01:45, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 664 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 222446/300584 [4:39:19<1:23:42, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 665 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 222779/300584 [4:39:39<1:46:12, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 666 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 223114/300584 [4:40:03<1:37:10, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 667 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 223447/300584 [4:40:26<1:29:31, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 668 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  74%|███████▍  | 223784/300584 [4:40:49<1:12:55, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 669 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 224117/300584 [4:41:11<1:06:19, 19.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 670 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 224450/300584 [4:41:35<1:32:56, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 671 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 224784/300584 [4:41:57<1:36:33, 13.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 672 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▍  | 225118/300584 [4:42:18<1:24:45, 14.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 673 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 225452/300584 [4:42:42<1:18:18, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 674 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 225785/300584 [4:43:06<1:44:41, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 675 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 226119/300584 [4:43:29<2:02:59, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 676 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 226454/300584 [4:43:52<1:15:57, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 677 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  75%|███████▌  | 226789/300584 [4:44:13<1:18:58, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 678 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 227121/300584 [4:44:33<1:40:48, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 679 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 227455/300584 [4:44:57<1:43:14, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 680 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 227790/300584 [4:45:22<1:25:29, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 681 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 228125/300584 [4:45:46<1:27:52, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 682 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 228458/300584 [4:46:09<1:15:47, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 683 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 228795/300584 [4:46:28<55:43, 21.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 684 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▌  | 229126/300584 [4:46:47<1:11:25, 16.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 685 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▋  | 229461/300584 [4:47:09<1:19:27, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 686 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  76%|███████▋  | 229794/300584 [4:47:30<1:04:11, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 687 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 230130/300584 [4:47:50<1:22:49, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 688 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 230462/300584 [4:48:14<1:19:20, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 689 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 230796/300584 [4:48:35<1:22:06, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 690 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 231130/300584 [4:48:57<1:25:19, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 691 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 231464/300584 [4:49:21<1:40:40, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 692 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 231798/300584 [4:49:44<1:32:05, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 693 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 232131/300584 [4:50:10<1:28:13, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 694 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 232466/300584 [4:50:34<1:20:49, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 695 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  77%|███████▋  | 232800/300584 [4:50:55<1:16:47, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 696 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 233133/300584 [4:51:17<1:38:09, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 697 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 233467/300584 [4:51:42<1:33:16, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 698 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 233801/300584 [4:52:05<1:34:31, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 699 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 234135/300584 [4:52:30<1:48:14, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 700 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 234470/300584 [4:52:56<1:32:33, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 701 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 234803/300584 [4:53:17<1:27:26, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 702 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 235138/300584 [4:53:39<1:12:27, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 703 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 235473/300584 [4:54:04<1:03:35, 17.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 704 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  78%|███████▊  | 235805/300584 [4:54:28<1:16:59, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 705 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▊  | 236138/300584 [4:54:52<1:24:46, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 706 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▊  | 236473/300584 [4:55:15<1:10:33, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 707 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 236808/300584 [4:55:35<1:12:35, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 708 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 237142/300584 [4:55:57<1:25:00, 12.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 709 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 237477/300584 [4:56:21<1:04:49, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 710 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 237810/300584 [4:56:43<1:06:04, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 711 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 238142/300584 [4:57:09<1:17:52, 13.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 712 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 238477/300584 [4:57:32<58:45, 17.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 713 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  79%|███████▉  | 238811/300584 [4:57:51<1:08:41, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 714 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 239147/300584 [4:58:12<59:59, 17.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 715 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 239479/300584 [4:58:36<1:33:38, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 716 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 239815/300584 [4:58:59<1:08:42, 14.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 717 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|███████▉  | 240148/300584 [4:59:24<1:27:17, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 718 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 240481/300584 [4:59:47<1:17:51, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 719 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 240816/300584 [5:00:08<1:21:32, 12.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 720 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 241150/300584 [5:00:31<1:07:28, 14.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 721 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 241482/300584 [5:00:56<1:28:56, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 722 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  80%|████████  | 241818/300584 [5:01:21<58:53, 16.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 723 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 242152/300584 [5:01:46<1:14:22, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 724 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 242486/300584 [5:02:11<1:10:38, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 725 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 242820/300584 [5:02:33<1:09:00, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 726 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 243153/300584 [5:02:58<1:28:33, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 727 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 243487/300584 [5:03:25<1:27:40, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 728 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 243823/300584 [5:03:49<1:02:27, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 729 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████  | 244156/300584 [5:04:16<1:18:16, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 730 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████▏ | 244491/300584 [5:04:38<54:40, 17.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 731 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  81%|████████▏ | 244826/300584 [5:04:58<52:21, 17.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 732 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 245157/300584 [5:05:18<1:04:46, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 733 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 245492/300584 [5:05:40<56:47, 16.17it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 734 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 245827/300584 [5:06:02<55:52, 16.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 735 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 246159/300584 [5:06:25<1:15:16, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 736 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 246493/300584 [5:06:47<52:32, 17.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 737 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 246829/300584 [5:07:08<46:09, 19.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 738 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 247161/300584 [5:07:29<1:14:44, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 739 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 247495/300584 [5:07:53<1:08:55, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 740 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  82%|████████▏ | 247830/300584 [5:08:14<1:01:41, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 741 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 248163/300584 [5:08:38<1:16:49, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 742 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 248499/300584 [5:08:58<57:10, 15.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 743 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 248832/300584 [5:09:17<56:10, 15.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 744 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 249166/300584 [5:09:37<51:13, 16.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 745 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 249499/300584 [5:10:00<57:11, 14.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 746 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 249833/300584 [5:10:21<1:04:26, 13.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 747 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 250168/300584 [5:10:45<1:06:43, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 748 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 250503/300584 [5:11:07<52:38, 15.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 749 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  83%|████████▎ | 250837/300584 [5:11:28<1:03:03, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 750 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▎ | 251170/300584 [5:11:49<1:03:25, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 751 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▎ | 251504/300584 [5:12:13<1:11:33, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 752 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 251837/300584 [5:12:35<1:03:58, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 753 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 252171/300584 [5:13:00<1:45:20,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 754 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 252505/300584 [5:13:35<2:08:59,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 755 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 252840/300584 [5:14:03<1:00:41, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 756 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 253174/300584 [5:14:29<1:05:46, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 757 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 253508/300584 [5:14:57<1:00:06, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 758 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  84%|████████▍ | 253841/300584 [5:15:24<1:25:51,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 759 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 254176/300584 [5:15:52<1:10:30, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 760 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 254509/300584 [5:16:17<59:16, 12.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 761 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 254843/300584 [5:16:41<1:05:26, 11.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 762 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▍ | 255179/300584 [5:17:06<1:55:08,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 763 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 255511/300584 [5:17:32<1:06:32, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 764 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 255845/300584 [5:17:58<1:40:52,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 765 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 256180/300584 [5:18:25<1:12:04, 10.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 766 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 256515/300584 [5:18:52<1:12:34, 10.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 767 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  85%|████████▌ | 256848/300584 [5:19:18<1:17:23,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 768 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 257181/300584 [5:19:45<1:13:30,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 769 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 257516/300584 [5:20:15<1:15:46,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 770 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 257850/300584 [5:20:44<1:18:00,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 771 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 258183/300584 [5:21:14<1:08:51, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 772 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 258519/300584 [5:21:42<53:09, 13.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 773 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 258851/300584 [5:22:09<1:05:11, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 774 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▌ | 259186/300584 [5:22:39<1:05:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 775 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▋ | 259519/300584 [5:23:09<1:34:41,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 776 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  86%|████████▋ | 259852/300584 [5:23:38<1:16:29,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 777 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 260187/300584 [5:24:09<1:17:27,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 778 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 260520/300584 [5:24:39<55:38, 12.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 779 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 260855/300584 [5:25:10<1:28:39,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 780 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 261189/300584 [5:25:39<1:01:52, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 781 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 261524/300584 [5:26:08<50:14, 12.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 782 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 261860/300584 [5:26:36<55:48, 11.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 783 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 262191/300584 [5:27:04<1:34:47,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 784 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 262525/300584 [5:27:37<1:24:19,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 785 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  87%|████████▋ | 262859/300584 [5:28:10<1:19:51,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 786 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 263193/300584 [5:28:42<52:01, 11.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 787 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 263528/300584 [5:29:08<44:30, 13.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 788 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 263862/300584 [5:29:31<42:19, 14.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 789 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 264196/300584 [5:29:55<48:25, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 790 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 264531/300584 [5:30:21<51:21, 11.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 791 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 264864/300584 [5:30:47<43:41, 13.63it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 792 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 265198/300584 [5:31:12<41:53, 14.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 793 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 265533/300584 [5:31:36<58:07, 10.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 794 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  88%|████████▊ | 265867/300584 [5:32:00<47:09, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 795 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▊ | 266202/300584 [5:32:23<44:17, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 796 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▊ | 266533/300584 [5:32:46<43:55, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 797 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 266869/300584 [5:33:08<38:54, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 798 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 267204/300584 [5:33:30<36:15, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 799 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 267537/300584 [5:33:50<39:56, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 800 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 267869/300584 [5:34:09<36:10, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 801 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 268204/300584 [5:34:30<46:38, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 802 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 268538/300584 [5:34:54<54:13,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 803 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  89%|████████▉ | 268873/300584 [5:35:17<38:54, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 804 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 269207/300584 [5:35:40<38:17, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 805 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 269540/300584 [5:36:02<36:20, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 806 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 269875/300584 [5:36:24<36:54, 13.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 807 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|████████▉ | 270209/300584 [5:36:46<40:28, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 808 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 270541/300584 [5:37:07<37:54, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 809 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 270876/300584 [5:37:28<28:54, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 810 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 271212/300584 [5:37:49<33:43, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 811 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 271543/300584 [5:38:08<32:56, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 812 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  90%|█████████ | 271879/300584 [5:38:28<29:22, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 813 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 272211/300584 [5:38:49<37:31, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 814 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 272544/300584 [5:39:14<53:17,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 815 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 272879/300584 [5:39:37<37:00, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 816 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 273214/300584 [5:39:58<27:15, 16.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 817 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 273549/300584 [5:40:19<41:27, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 818 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 273881/300584 [5:40:40<32:19, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 819 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████ | 274217/300584 [5:41:00<28:45, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 820 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████▏| 274551/300584 [5:41:19<29:21, 14.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 821 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  91%|█████████▏| 274885/300584 [5:41:42<39:14, 10.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 822 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 275218/300584 [5:42:05<26:48, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 823 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 275552/300584 [5:42:28<36:45, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 824 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 275887/300584 [5:42:53<29:00, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 825 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 276220/300584 [5:43:15<29:27, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 826 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 276554/300584 [5:43:38<28:51, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 827 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 276887/300584 [5:44:02<29:02, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 828 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 277222/300584 [5:44:25<30:20, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 829 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 277555/300584 [5:44:51<29:21, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 830 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  92%|█████████▏| 277889/300584 [5:45:15<33:05, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 831 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 278223/300584 [5:45:37<30:45, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 832 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 278559/300584 [5:45:59<27:02, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 833 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 278892/300584 [5:46:21<24:11, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 834 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 279226/300584 [5:46:44<33:05, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 835 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 279560/300584 [5:47:05<24:00, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 836 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 279895/300584 [5:47:25<22:42, 15.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 837 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 280228/300584 [5:47:45<20:18, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 838 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 280563/300584 [5:48:05<21:07, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 839 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  93%|█████████▎| 280894/300584 [5:48:26<21:17, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 840 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▎| 281230/300584 [5:48:49<24:32, 13.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 841 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▎| 281564/300584 [5:49:13<31:13, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 842 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 281898/300584 [5:49:36<21:39, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 843 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 282233/300584 [5:49:58<20:02, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 844 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 282567/300584 [5:50:19<19:26, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 845 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 282899/300584 [5:50:43<21:15, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 846 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 283232/300584 [5:51:08<33:27,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 847 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 283567/300584 [5:51:34<22:27, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 848 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  94%|█████████▍| 283901/300584 [5:51:58<26:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 849 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 284236/300584 [5:52:23<28:45,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 850 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 284569/300584 [5:52:47<22:25, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 851 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 284905/300584 [5:53:08<17:46, 14.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 852 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▍| 285238/300584 [5:53:28<16:48, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 853 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 285573/300584 [5:53:49<16:12, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 854 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 285906/300584 [5:54:08<17:41, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 855 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 286240/300584 [5:54:28<14:58, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 856 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 286574/300584 [5:54:47<17:08, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 857 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  95%|█████████▌| 286907/300584 [5:55:08<15:47, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 858 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 287241/300584 [5:55:31<21:13, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 859 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 287577/300584 [5:55:53<12:43, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 860 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 287910/300584 [5:56:14<18:05, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 861 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 288244/300584 [5:56:35<12:00, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 862 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 288577/300584 [5:56:54<13:46, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 863 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 288913/300584 [5:57:16<14:42, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 864 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▌| 289246/300584 [5:57:38<13:29, 14.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 865 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▋| 289580/300584 [5:58:00<14:15, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 866 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  96%|█████████▋| 289915/300584 [5:58:22<12:19, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 867 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 290250/300584 [5:58:43<10:16, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 868 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 290582/300584 [5:59:04<10:17, 16.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 869 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 290917/300584 [5:59:25<10:19, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 870 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 291251/300584 [5:59:46<08:43, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 871 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 291584/300584 [6:00:08<10:29, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 872 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 291918/300584 [6:00:28<08:03, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 873 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 292252/300584 [6:00:49<10:11, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 874 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 292586/300584 [6:01:10<10:18, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 875 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  97%|█████████▋| 292921/300584 [6:01:31<07:51, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 876 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 293253/300584 [6:01:51<08:14, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 877 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 293589/300584 [6:02:12<06:47, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 878 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 293923/300584 [6:02:32<06:43, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 879 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 294257/300584 [6:02:52<06:36, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 880 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 294591/300584 [6:03:12<07:03, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 881 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 294922/300584 [6:03:36<06:22, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 882 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 295258/300584 [6:04:00<07:26, 11.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 883 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 295592/300584 [6:04:23<05:22, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 884 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  98%|█████████▊| 295927/300584 [6:04:42<03:58, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 885 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▊| 296259/300584 [6:05:01<04:19, 16.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 886 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▊| 296596/300584 [6:05:20<03:36, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 887 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 296927/300584 [6:05:42<04:29, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 888 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 297261/300584 [6:06:03<04:17, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 889 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 297596/300584 [6:06:25<03:35, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 890 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 297929/300584 [6:06:46<02:31, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 891 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 298265/300584 [6:07:07<02:55, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 892 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 298598/300584 [6:07:28<02:20, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 893 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강:  99%|█████████▉| 298931/300584 [6:07:50<01:47, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 894 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 299266/300584 [6:08:12<01:28, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 895 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 299600/300584 [6:08:35<01:12, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 896 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 299934/300584 [6:08:57<00:41, 15.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 897 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|█████████▉| 300268/300584 [6:09:19<00:24, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 898 저장 완료 - 1002개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 및 증강: 100%|██████████| 300584/300584 [6:09:40<00:00, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막 배치 899 저장 완료 - 954개\n",
      "전체 MFCC 추출 및 저장 작업 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 입력 및 출력 경로 설정\n",
    "csv_path = \"./data/usou/metadata_4class.csv\"\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. 오디오 및 MFCC 관련 설정\n",
    "n_mfcc = 40                     # 추출할 MFCC 계수 수\n",
    "max_len = 300                  # MFCC 길이 고정값\n",
    "n_augment = 2                  # 증강 횟수 (원본 포함 총 3배)\n",
    "batch_size = 1000              # 배치 저장 단위\n",
    "\n",
    "# 3. 데이터프레임 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 4. 증강 파이프라인 설정\n",
    "augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.7),\n",
    "    TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    Shift(min_shift=-0.2, max_shift=0.2, p=0.5)\n",
    "])\n",
    "\n",
    "# 5. MFCC 추출 함수 정의\n",
    "def extract_mfcc(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "\n",
    "# 6. 배치별로 데이터를 저장하기 위한 변수 초기화\n",
    "mfcc_batch = []\n",
    "label_batch = []\n",
    "batch_index = 0\n",
    "\n",
    "# 7. tqdm을 이용해 전체 진행 상황 표시\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"MFCC 추출 및 증강\"):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    emotion = row[\"emotion\"]\n",
    "\n",
    "    try:\n",
    "        # 원본 로딩\n",
    "        y, sr = librosa.load(wav_path, sr=16000)\n",
    "\n",
    "        # 원본 MFCC 저장\n",
    "        mfcc_batch.append(extract_mfcc(y, sr))\n",
    "        label_batch.append(emotion)\n",
    "\n",
    "        # 증강 MFCC 저장\n",
    "        for _ in range(n_augment):\n",
    "            y_aug = augment(samples=y, sample_rate=sr)\n",
    "            mfcc_batch.append(extract_mfcc(y_aug, sr))\n",
    "            label_batch.append(emotion)\n",
    "\n",
    "        # 일정 크기의 배치가 모이면 저장 후 초기화\n",
    "        if len(mfcc_batch) >= batch_size:\n",
    "            np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "            np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "            print(f\"배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "            batch_index += 1\n",
    "            mfcc_batch.clear()\n",
    "            label_batch.clear()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {wav_path} → {e}\")\n",
    "        continue\n",
    "\n",
    "# 8. 마지막에 남은 배치도 저장\n",
    "if mfcc_batch:\n",
    "    np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "    np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "    print(f\"마지막 배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "\n",
    "print(\"전체 MFCC 추출 및 저장 작업 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 수집된 검증 샘플 수: 300584\n",
      "에러 발생 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 검증 데이터의 JSON 폴더 경로 (변경 필요)\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "wav_root   = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "save_dir = \"./data/usou\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "target_classes = ['Happy', 'Sad', 'Angry', 'Neutrality']\n",
    "\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "for folder_path, _, files in os.walk(label_root):\n",
    "    for file_name in files:\n",
    "        if not file_name.endswith(\".json\"):\n",
    "            continue\n",
    "        json_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                content = json.load(f)\n",
    "\n",
    "            emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "            if emotion not in target_classes:\n",
    "                continue\n",
    "\n",
    "            style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "            sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "            wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "            relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "            relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "            wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "            if os.path.exists(wav_path):\n",
    "                data.append({\n",
    "                    \"wav_path\": wav_path,\n",
    "                    \"emotion\": emotion,\n",
    "                    \"style\": style,\n",
    "                    \"sensitivity\": sensitivity\n",
    "                })\n",
    "            else:\n",
    "                broken_files.append(wav_path)\n",
    "        except Exception as e:\n",
    "            broken_files.append(json_path)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_4class_val.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(save_dir, \"broken_files_val.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(\"총 수집된 검증 샘플 수:\", len(df))\n",
    "print(\"에러 발생 수:\", len(broken_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검증용 MFCC 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# ✅ CNN 모델 정의 함수 호출\n",
    "model = build_cnn_model()\n",
    "\n",
    "# ✅ 하이퍼파라미터\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 30\n",
    "\n",
    "# ✅ 학습 데이터 경로\n",
    "train_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "train_label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "\n",
    "# ✅ 검증 데이터 배치 파일들이 저장된 경로\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"\n",
    "val_mfcc_files = sorted(glob.glob(os.path.join(val_dir, \"mfcc_val_batch_*.npy\")))\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "# ✅ 검증 데이터 로딩\n",
    "val_x = np.concatenate([np.load(f) for f in val_mfcc_files], axis=0)\n",
    "val_y = np.concatenate([np.load(f) for f in val_label_files], axis=0)\n",
    "\n",
    "# ✅ 학습용 배치 제너레이터\n",
    "def data_generator(mfcc_dir, label_dir, batch_size):\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)\n",
    "            y = np.load(label_file)\n",
    "            for i in range(0, len(x), batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "# ✅ 콜백 설정\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/model_ckpt/best_model_voice_emotion_analysis.keras\"\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_accuracy', save_best_only=True)\n",
    "]\n",
    "\n",
    "# ✅ 전체 학습 스텝 계산\n",
    "train_steps = sum([np.load(f).shape[0] for f in glob.glob(os.path.join(train_label_dir, \"label_batch_*.npy\"))]) // BATCH_SIZE\n",
    "\n",
    "# ✅ 모델 학습 시작\n",
    "model.fit(\n",
    "    data_generator(train_mfcc_dir, train_label_dir, BATCH_SIZE),\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train, Validation 라벨 인코딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터의 모든 배치 레이블을 모아서 LabelEncoder를 fit 합니다.\n",
    "- label_encoder.pkl로 저장하여 나중에 복원 가능하게 합니다.\n",
    "- 학습 데이터와 검증 데이터 모두 동일한 인코더로 인코딩하여 일관성 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 레이블 수집:   0%|          | 0/900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 레이블 수집: 100%|██████████| 900/900 [00:00<00:00, 6233.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder 저장 완료: /media/usou/PortableSSD/mldl_project/data4class_batches/voice_label_encoder.pkl\n",
      "클래스 목록: [0 1 2 3]\n",
      "학습용 레이블 인코딩 완료\n",
      "검증 배치 0는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 1는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 2는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 3는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 4는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 5는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 6는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 7는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 8는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 9는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 10는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 11는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 12는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 13는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 14는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 15는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 16는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 17는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 18는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 19는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 20는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 21는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 22는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 23는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 24는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 25는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 26는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 27는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 28는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 29는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 30는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 31는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 32는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 33는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 34는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 35는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 36는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 37는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 38는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 39는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 40는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 41는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 42는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 43는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 44는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 45는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 46는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 47는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 48는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 49는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 50는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 51는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 52는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 53는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 54는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 55는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 56는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 57는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 58는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 59는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 60는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 61는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 62는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 63는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 64는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 65는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 66는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 67는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 68는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 69는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 70는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 71는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 72는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 73는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 74는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 75는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 76는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 77는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 78는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 79는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 80는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 81는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 82는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 83는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 84는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 85는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 86는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 87는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 88는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 89는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 90는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 91는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 92는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 93는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 94는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 95는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 96는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 97는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 98는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 99는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 100는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 101는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 102는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 103는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 104는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 105는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 106는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 107는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 108는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 109는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 110는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 111는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 112는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 113는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 114는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 115는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 116는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 117는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 118는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 119는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 120는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 121는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 122는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 123는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 124는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 125는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 126는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 127는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 128는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 129는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 130는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 131는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 132는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 133는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 134는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 135는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 136는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 137는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 138는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 139는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 140는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 141는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 142는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 143는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 144는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 145는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 146는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 147는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 148는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 149는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 150는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 151는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 152는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 153는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 154는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 155는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 156는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 157는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 158는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 159는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 160는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 161는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 162는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 163는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 164는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 165는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 166는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 167는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 168는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 169는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 170는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 171는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 172는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 173는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 174는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 175는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 176는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 177는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 178는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 179는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 180는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 181는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 182는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 183는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 184는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 185는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 186는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 187는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 188는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 189는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 190는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 191는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 192는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 193는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 194는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 195는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 196는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 197는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 198는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 199는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 200는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 201는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 202는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 203는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 204는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 205는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 206는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 207는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 208는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 209는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 210는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 211는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 212는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 213는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 214는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 215는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 216는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 217는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 218는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 219는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 220는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 221는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 222는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 223는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 224는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 225는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 226는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 227는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 228는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 229는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 230는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 231는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 232는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 233는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 234는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 235는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 236는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 237는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 238는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 239는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 240는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 241는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 242는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 243는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 244는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 245는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 246는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 247는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 248는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 249는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 250는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 251는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 252는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 253는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 254는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 255는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 256는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 257는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 258는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 259는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 260는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 261는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 262는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 263는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 264는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 265는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 266는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 267는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 268는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 269는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 270는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 271는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 272는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 273는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 274는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 275는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 276는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 277는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 278는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 279는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 280는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 281는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 282는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 283는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 284는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 285는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 286는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 287는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 288는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 289는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 290는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 291는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 292는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 293는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 294는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 295는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 296는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 297는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 298는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 299는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증 배치 300는 이미 숫자형으로 인코딩되어 있어 건너뜀\n",
      "검증용 레이블 인코딩 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "train_label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"\n",
    "encoder_save_path = os.path.join(train_label_dir, \"voice_label_encoder.pkl\")\n",
    "\n",
    "# 학습용 레이블 로딩\n",
    "label_files = sorted([\n",
    "    f for f in os.listdir(train_label_dir)\n",
    "    if f.startswith(\"label_batch_\") and f.endswith(\".npy\")\n",
    "])\n",
    "\n",
    "all_labels = []\n",
    "label_batches = []\n",
    "\n",
    "for f in tqdm(label_files, desc=\"학습 레이블 수집\"):\n",
    "    labels = np.load(os.path.join(train_label_dir, f), allow_pickle=True)\n",
    "    label_batches.append(labels)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# LabelEncoder 학습 및 저장\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "with open(encoder_save_path, \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"LabelEncoder 저장 완료:\", encoder_save_path)\n",
    "print(\"클래스 목록:\", label_encoder.classes_)\n",
    "\n",
    "# 학습용 인코딩 저장\n",
    "for i, labels in enumerate(label_batches):\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    np.save(os.path.join(train_label_dir, f\"label_batch_{i}.npy\"), encoded)\n",
    "\n",
    "print(\"학습용 레이블 인코딩 완료\")\n",
    "\n",
    "# 검증용 인코딩\n",
    "val_label_files = sorted([\n",
    "    f for f in os.listdir(val_label_dir)\n",
    "    if f.startswith(\"label_val_batch_\") and f.endswith(\".npy\")\n",
    "])\n",
    "\n",
    "for i, f in enumerate(val_label_files):\n",
    "    path = os.path.join(val_label_dir, f)\n",
    "    labels = np.load(path, allow_pickle=True)\n",
    "\n",
    "    # 배열 전체의 dtype으로 판단 (보다 안전하게 처리)\n",
    "    if np.issubdtype(labels.dtype, np.str_):\n",
    "        try:\n",
    "            encoded = label_encoder.transform(labels)\n",
    "            np.save(path, encoded)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 검증 배치 {i} 인코딩 중 오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"검증 배치 {i}는 이미 숫자형으로 인코딩되어 있어 건너뜀\")\n",
    "\n",
    "print(\"검증용 레이블 인코딩 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 및 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import glob\n",
    "\n",
    "# GPU 메모리 과도할당 방지 설정\n",
    "# GPU 메모리를 사용할 만큼만 점진적으로 할당하도록 설정하여 OOM 방지\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 64           # 한 배치에 들어가는 샘플 수\n",
    "EPOCHS = 300              # 학습 반복 횟수\n",
    "PATIENCE = 30             # EarlyStopping이 참조할 patience 값\n",
    "\n",
    "# 데이터 디렉토리 경로 설정\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"           # 학습 데이터 배치 경로\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"         # 검증 데이터 배치 경로\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/model_ckpt/best_model_voice_emotion_analysis.keras\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow CNN 모델 정의 및 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 300, 1), num_classes=4):\n",
    "    \"\"\"\n",
    "    CNN 기반 음성 감정 분류 모델을 정의합니다.\n",
    "\n",
    "    Parameters:\n",
    "        input_shape (tuple): 입력 데이터 형태 (MFCC의 높이, 너비, 채널 수)\n",
    "        num_classes (int): 분류할 감정 클래스 수\n",
    "\n",
    "    Returns:\n",
    "        model (tf.keras.Model): 컴파일된 CNN 모델\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 첫 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 두 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 세 번째 컨볼루션 블록\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # 완전 연결층\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # 과적합 방지용 드롭아웃\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "model = build_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습용 데이터 제너레이터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def data_generator(mfcc_dir, label_dir, batch_size):\n",
    "    \"\"\"\n",
    "    학습 데이터를 배치 단위로 로드하는 제너레이터 함수입니다.\n",
    "\n",
    "    Parameters:\n",
    "        mfcc_dir (str): MFCC 배치 파일 디렉토리\n",
    "        label_dir (str): 라벨 배치 파일 디렉토리\n",
    "        batch_size (int): 배치 크기\n",
    "\n",
    "    Yields:\n",
    "        Tuple of (x_batch, y_batch): 배치 단위의 입력과 정답\n",
    "    \"\"\"\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)\n",
    "            y = np.load(label_file)\n",
    "\n",
    "            # 데이터 길이 맞추기 (불일치 방지)\n",
    "            min_len = min(len(x), len(y))\n",
    "            x = x[:min_len]\n",
    "            y = y[:min_len]\n",
    "\n",
    "            # 채널 차원 추가\n",
    "            x = x[..., np.newaxis]  # (batch, 40, 300, 1)\n",
    "\n",
    "            for i in range(0, min_len, batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 shape: (3000, 40, 300, 1) (3000,)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# 셀 4. 안정적인 검증 데이터 로딩\n",
    "\n",
    "val_mfcc_files = sorted(glob.glob(os.path.join(val_dir, \"mfcc_val_batch_*.npy\")))\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "val_x_list, val_y_list = [], []\n",
    "\n",
    "# 너무 많은 파일을 한 번에 로드하지 않도록 제한\n",
    "max_files = 3  # 우선 3개 파일로 테스트 → 점진적으로 늘릴 수 있음\n",
    "\n",
    "for mfcc_file, label_file in zip(val_mfcc_files[:max_files], val_label_files[:max_files]):\n",
    "    x = np.load(mfcc_file, mmap_mode='r')[..., np.newaxis]  # 메모리 매핑으로 로딩 효율 개선\n",
    "    y = np.load(label_file, allow_pickle=True)\n",
    "    \n",
    "    val_x_list.append(x)\n",
    "    val_y_list.append(y)\n",
    "\n",
    "val_x = np.concatenate(val_x_list, axis=0)\n",
    "val_y = np.concatenate(val_y_list, axis=0)\n",
    "\n",
    "print(\"검증 데이터 shape:\", val_x.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743682332.209154   26837 service.cc:152] XLA service 0x7fd1dc002220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743682332.209578   26837 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-04-03 21:12:12.298548: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743682332.669803   26837 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-04-03 21:12:13.096315: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[64,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,40,300]{3,2,1,0} %bitcast.6075, f32[32,1,3,3]{3,2,1,0} %bitcast.6082, f32[32]{0} %bitcast.7058), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:13.184354: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[64,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,32,20,150]{3,2,1,0} %bitcast.7223, f32[64,32,3,3]{3,2,1,0} %bitcast.6157, f32[64]{0} %bitcast.7283), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:13.569306: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[64,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,10,75]{3,2,1,0} %bitcast.7449, f32[128,64,3,3]{3,2,1,0} %bitcast.6232, f32[128]{0} %bitcast.7509), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:14.212689: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:14.379634: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    5/14089\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:36\u001b[0m 37ms/step - accuracy: 0.6218 - loss: 1.2386 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743682337.550856   26837 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   15/14089\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:25\u001b[0m 32ms/step - accuracy: 0.8168 - loss: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:12:18.649738: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[42,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[42,1,40,300]{3,2,1,0} %bitcast.6075, f32[32,1,3,3]{3,2,1,0} %bitcast.6082, f32[32]{0} %bitcast.7058), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:18.662184: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[42,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[42,32,20,150]{3,2,1,0} %bitcast.7223, f32[64,32,3,3]{3,2,1,0} %bitcast.6157, f32[64]{0} %bitcast.7283), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:18.922032: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[42,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[42,64,10,75]{3,2,1,0} %bitcast.7449, f32[128,64,3,3]{3,2,1,0} %bitcast.6232, f32[128]{0} %bitcast.7509), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:12:19.432696: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:19.592934: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:20.383662: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:20.653420: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:12:20.911935: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12765/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m37s\u001b[0m 28ms/step - accuracy: 0.4891 - loss: 4.3896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:18:18.906775: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[58,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,1,40,300]{3,2,1,0} %bitcast.6075, f32[32,1,3,3]{3,2,1,0} %bitcast.6082, f32[32]{0} %bitcast.7058), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:18:18.940993: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[58,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,32,20,150]{3,2,1,0} %bitcast.7223, f32[64,32,3,3]{3,2,1,0} %bitcast.6157, f32[64]{0} %bitcast.7283), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:18:19.274469: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[58,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,64,10,75]{3,2,1,0} %bitcast.7449, f32[128,64,3,3]{3,2,1,0} %bitcast.6232, f32[128]{0} %bitcast.7509), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:18:19.867075: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:20.035184: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:20.911919: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:21.185970: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:21.458632: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:21.506758: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.3 = (f32[58,32,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,64,20,150]{3,2,1,0} %bitcast.7287, f32[64,32,3,3]{3,2,1,0} %bitcast.6157), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/sequential_1/conv2d_1_2/convolution/Conv2DBackpropInput\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-04-03 21:18:21.729967: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.004842: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.274539: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.550212: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:22.820847: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:23.093690: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:23.366832: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-04-03 21:18:23.383539: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.876351237s\n",
      "Trying algorithm eng4{k11=1} for conv %cudnn-conv-bw-input.3 = (f32[58,32,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[58,64,20,150]{3,2,1,0} %bitcast.7287, f32[64,32,3,3]{3,2,1,0} %bitcast.6157), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", metadata={op_type=\"Conv2DBackpropInput\" op_name=\"gradient_tape/sequential_1/conv2d_1_2/convolution/Conv2DBackpropInput\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4829 - loss: 4.2140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 21:19:03.321099: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,40,300]{3,2,1,0} %bitcast.658, f32[32,1,3,3]{3,2,1,0} %bitcast.665, f32[32]{0} %bitcast.667), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:03.330652: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,20,150]{3,2,1,0} %bitcast.695, f32[64,32,3,3]{3,2,1,0} %bitcast.702, f32[64]{0} %bitcast.704), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:03.527905: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,10,75]{3,2,1,0} %bitcast.732, f32[128,64,3,3]{3,2,1,0} %bitcast.739, f32[128]{0} %bitcast.741), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:04.471919: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.9 = (f32[24,32,40,300]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,1,40,300]{3,2,1,0} %bitcast.658, f32[32,1,3,3]{3,2,1,0} %bitcast.665, f32[32]{0} %bitcast.667), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:04.487801: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.10 = (f32[24,64,20,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,32,20,150]{3,2,1,0} %bitcast.695, f32[64,32,3,3]{3,2,1,0} %bitcast.702, f32[64]{0} %bitcast.704), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-04-03 21:19:04.650035: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.11 = (f32[24,128,10,75]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,64,10,75]{3,2,1,0} %bitcast.732, f32[128,64,3,3]{3,2,1,0} %bitcast.739, f32[128]{0} %bitcast.741), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 29ms/step - accuracy: 0.4829 - loss: 4.2138 - val_accuracy: 0.0000e+00 - val_loss: 1.1736\n",
      "Epoch 2/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 28ms/step - accuracy: 0.4244 - loss: 1.3382 - val_accuracy: 0.3333 - val_loss: 1.1441\n",
      "Epoch 3/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 28ms/step - accuracy: 0.4067 - loss: 1.3278 - val_accuracy: 0.6667 - val_loss: 1.1410\n",
      "Epoch 4/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 27ms/step - accuracy: 0.3746 - loss: 1.3312 - val_accuracy: 0.0000e+00 - val_loss: 1.2207\n",
      "Epoch 5/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3768 - loss: 1.3111 - val_accuracy: 0.0000e+00 - val_loss: 1.3933\n",
      "Epoch 6/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3552 - loss: 1.3110 - val_accuracy: 0.0000e+00 - val_loss: 1.3153\n",
      "Epoch 7/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.4015 - loss: 1.2857 - val_accuracy: 0.3333 - val_loss: 1.2338\n",
      "Epoch 8/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3956 - loss: 1.2785 - val_accuracy: 0.3333 - val_loss: 1.1687\n",
      "Epoch 9/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3812 - loss: 1.2776 - val_accuracy: 0.3333 - val_loss: 1.0949\n",
      "Epoch 10/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 26ms/step - accuracy: 0.3686 - loss: 1.2852 - val_accuracy: 0.3333 - val_loss: 1.0227\n",
      "Epoch 11/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 26ms/step - accuracy: 0.3472 - loss: 1.3216 - val_accuracy: 0.3333 - val_loss: 1.0150\n",
      "Epoch 12/300\n",
      "\u001b[1m14089/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 27ms/step - accuracy: 0.3830 - loss: 1.2876 - val_accuracy: 0.6667 - val_loss: 1.0011\n",
      "Epoch 13/300\n",
      "\u001b[1m11298/14089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:24\u001b[0m 30ms/step - accuracy: 0.3823 - loss: 1.2551"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     10\u001b[39m callbacks = [\n\u001b[32m     11\u001b[39m     EarlyStopping(\n\u001b[32m     12\u001b[39m         monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,          \u001b[38;5;66;03m# 검증 정확도를 기준으로\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     )\n\u001b[32m     21\u001b[39m ]\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 모델 학습 시작\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# → 배치 제너레이터로 학습 데이터를 공급하고, 메모리에 올린 검증 데이터를 사용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습 데이터 제너레이터\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# 에폭당 스텝 수\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                     \u001b[49m\u001b[38;5;66;43;03m# 총 에폭 수\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# 검증 데이터\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# 조기 종료 및 체크포인트\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 전체 학습 스텝 수 계산\n",
    "# → 각 배치 파일의 샘플 수를 모두 더한 후, 배치 크기로 나누어 steps_per_epoch 계산\n",
    "train_steps = sum([\n",
    "    np.load(f).shape[0] \n",
    "    for f in glob.glob(os.path.join(train_dir, \"label_batch_*.npy\"))\n",
    "]) // BATCH_SIZE\n",
    "\n",
    "# 콜백 정의\n",
    "# → 성능이 개선되지 않으면 조기 종료, 최고 성능 모델만 저장\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',          # 검증 정확도를 기준으로\n",
    "        patience=PATIENCE,               # patience 기간 설정\n",
    "        restore_best_weights=True        # 가장 좋은 성능의 가중치 복원\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,        # 모델 저장 경로\n",
    "        monitor='val_accuracy',          # 모니터링 기준\n",
    "        save_best_only=True              # 최고 성능만 저장\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델 학습 시작\n",
    "# → 배치 제너레이터로 학습 데이터를 공급하고, 메모리에 올린 검증 데이터를 사용\n",
    "model.fit(\n",
    "    data_generator(train_dir, train_dir, BATCH_SIZE),  # 학습 데이터 제너레이터\n",
    "    steps_per_epoch=train_steps,                       # 에폭당 스텝 수\n",
    "    epochs=EPOCHS,                                     # 총 에폭 수\n",
    "    validation_data=(val_x, val_y),                    # 검증 데이터\n",
    "    callbacks=callbacks                                # 조기 종료 및 체크포인트\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제 발생\n",
    "\n",
    "- val_accuracy가 0.3333, 0.6667에서 반복됨 → 특정 클래스만 예측되고 있는 문제 가능성\n",
    "\n",
    "- loss는 줄긴 하지만 전체적으로 정체 상태\n",
    "\n",
    "- accuracy가 점점 낮아지는 경향도 보임\n",
    "\n",
    "- 약 80분 투자했지만, EarlyStopping 조건을 만족하지 못하고 긴 학습 예상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불균형 확인용 코드\n",
    "- 데이터셋의 감정 라벨 분포를 확인해서, 특정 감정이 너무 많거나 적은 경우 모델이 그 감정으로만 예측할 가능성이 있기 때문에 반드시 체크해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 분포: Counter({0: 245001, 1: 235755, 3: 228996, 2: 192000})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 라벨 배치 파일 경로 설정\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 전체 라벨 수집\n",
    "all_labels = []\n",
    "\n",
    "for file in label_files:\n",
    "    labels = np.load(file, allow_pickle=True)\n",
    "    all_labels.extend(labels.tolist())\n",
    "\n",
    "# 라벨 분포 확인\n",
    "label_counts = Counter(all_labels)\n",
    "print(\"라벨 분포:\", label_counts)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(label_counts.keys(), label_counts.values())\n",
    "plt.title(\"Emotion Label Distribution (Train Set)\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정 클래스 불균형 확인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# 라벨 배치 경로\n",
    "label_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "# 모든 라벨 로딩\n",
    "all_labels = []\n",
    "for file in label_files:\n",
    "    labels = np.load(file, allow_pickle=True)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 라벨 분포 확인\n",
    "label_counter = Counter(all_labels)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(label_counter.keys(), label_counter.values())\n",
    "plt.title(\"Training Label Distribution\")\n",
    "plt.xlabel(\"Emotion Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class_weight 적용\n",
    "\n",
    "- 증강 재조정\n",
    "\n",
    "- 또는 RandomUnderSampler, SMOTE 등 대안 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. class-weight 적용\n",
    "- 클래스 불균형 문제를 완화하기 위해 각 클래스에 역비례 가중치를 적용할 수 있습니다. 아래는 전체 라벨을 분석하고 class_weight을 자동으로 계산하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용할 class_weight: {0: 0.9201513463210355, 1: 0.9562384679009989, 2: 1.17415625, 3: 0.9844626107006236}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# 전체 라벨을 숫자로 인코딩한 리스트라고 가정 (예: [0, 1, 0, 2, 3, 1, ...])\n",
    "all_labels_array = np.array(all_labels)\n",
    "\n",
    "# 고유 클래스 목록\n",
    "classes = np.unique(all_labels_array)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=all_labels_array)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "print(\"적용할 class_weight:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 학습 코드 개선\n",
    "- 지금까지 개선사항을 반영하여, 각 셀에 맞게 구성해드립니다. (class_weight 적용 포함)\n",
    "\n",
    "### 셀 1. 환경 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 23:59:16.882290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743692356.950121   44334 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743692356.973294   44334 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743692357.116733   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743692357.116793   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743692357.116796   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743692357.116799   44334 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-03 23:59:17.135814: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# GPU 메모리 점진적 할당\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# 하이퍼파라미터\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 300\n",
    "PATIENCE = 30\n",
    "\n",
    "# 경로 설정\n",
    "train_dir = \"/media/usou/PortableSSD/mldl_project/data4class_batches\"\n",
    "val_dir = \"/media/usou/PortableSSD/mldl_project/data4class_val_batches\"\n",
    "checkpoint_path = \"/media/usou/PortableSSD/mldl_project/model_ckpt/best_model_voice_emotion_analysis.keras\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 2. CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-04-03 23:59:22.700145: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1743692362.700595   44334 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4738 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def build_cnn_model(input_shape=(40, 300, 1), num_classes=4):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 3. 데이터 제너레이터 및 클래스 가중치 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적용할 클래스 가중치: {0: 0.9201513463210355, 1: 0.9562384679009989, 2: 1.17415625, 3: 0.9844626107006236}\n"
     ]
    }
   ],
   "source": [
    "def data_generator(mfcc_dir, label_dir, batch_size):\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(mfcc_dir, \"mfcc_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(label_dir, \"label_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)\n",
    "            y = np.load(label_file, allow_pickle=True)\n",
    "\n",
    "            min_len = min(len(x), len(y))\n",
    "            x = x[:min_len][..., np.newaxis]\n",
    "            y = y[:min_len]\n",
    "\n",
    "            for i in range(0, min_len, batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "# 전체 라벨을 모아서 class_weight 계산\n",
    "all_labels = []\n",
    "for f in glob.glob(os.path.join(train_dir, \"label_batch_*.npy\")):\n",
    "    labels = np.load(f, allow_pickle=True)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "classes = np.unique(all_labels)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=all_labels)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "print(\"적용할 클래스 가중치:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀 4. 검증 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 shape: (5000, 40, 300, 1) (5000,)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 검증 데이터 배치 파일 목록\n",
    "val_mfcc_files = sorted(glob.glob(os.path.join(val_dir, \"mfcc_val_batch_*.npy\")))\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "# 최대 로딩할 샘플 수 제한 (예: 5000개)\n",
    "max_samples = 5000\n",
    "loaded = 0\n",
    "\n",
    "val_x_list, val_y_list = [], []\n",
    "\n",
    "for mfcc_file, label_file in zip(val_mfcc_files, val_label_files):\n",
    "    # 각 배치 파일 로딩\n",
    "    x = np.load(mfcc_file)[..., np.newaxis]  # (배치, 40, 300, 1)\n",
    "    y = np.load(label_file, allow_pickle=True)\n",
    "\n",
    "    # 남은 개수 계산 후 일부만 사용 (과도한 메모리 사용 방지)\n",
    "    remaining = max_samples - loaded\n",
    "    if len(x) > remaining:\n",
    "        x = x[:remaining]\n",
    "        y = y[:remaining]\n",
    "\n",
    "    val_x_list.append(x)\n",
    "    val_y_list.append(y)\n",
    "    loaded += len(x)\n",
    "\n",
    "    if loaded >= max_samples:\n",
    "        break\n",
    "\n",
    "# 최종 배열로 병합\n",
    "val_x = np.concatenate(val_x_list, axis=0)\n",
    "val_y = np.concatenate(val_y_list, axis=0)\n",
    "\n",
    "print(\"검증 데이터 shape:\", val_x.shape, val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 문자열을 숫자로 매핑 (예: 감정 레이블이 str인 경우)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val_y.dtype.type \u001b[38;5;129;01mis\u001b[39;00m np.str_ \u001b[38;5;129;01mor\u001b[39;00m val_y.dtype.type \u001b[38;5;129;01mis\u001b[39;00m np.object_:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     unique_labels = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     label_to_index = {label: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_labels)}\n\u001b[32m      5\u001b[39m     val_y = np.array([label_to_index[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m val_y])\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# 문자열을 숫자로 매핑 (예: 감정 레이블이 str인 경우)\n",
    "if val_y.dtype.type is np.str_ or val_y.dtype.type is np.object_:\n",
    "    unique_labels = sorted(set(val_y))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    val_y = np.array([label_to_index[label] for label in val_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m classes = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m class_weights = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(compute_class_weight(\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, classes=classes, y=val_y)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/arraysetops.py:274\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    272\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/numpy/lib/arraysetops.py:336\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[39m\n\u001b[32m    334\u001b[39m     aux = ar[perm]\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     aux = ar\n\u001b[32m    338\u001b[39m mask = np.empty(aux.shape, dtype=np.bool_)\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(val_y)\n",
    "class_weights = dict(enumerate(compute_class_weight('balanced', classes=classes, y=val_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 가중치: {0: 25.048666666666666, 1: 2.087388888888889, 2: 0.6288341889782888, 3: 0.8134664826391708, 4: 0.8491073446327684, 5: 0.6739672460492565}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 검증 라벨 배치 파일 경로\n",
    "val_label_files = sorted(glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "# 클래스 가중치 계산용 라벨만 메모리에 점진적으로 로딩\n",
    "val_labels = []\n",
    "\n",
    "for label_file in val_label_files:\n",
    "    y = np.load(label_file, allow_pickle=True)\n",
    "    val_labels.extend(y)\n",
    "\n",
    "val_y_raw = np.array(val_labels)\n",
    "\n",
    "# 문자열 라벨이면 숫자 인덱스로 인코딩\n",
    "if val_y_raw.dtype.type is np.str_ or val_y_raw.dtype.type is np.object_:\n",
    "    unique_labels = sorted(set(val_y_raw))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    val_y = np.array([label_to_index[label] for label in val_y_raw])\n",
    "else:\n",
    "    val_y = val_y_raw.copy()\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "classes = np.unique(val_y)\n",
    "class_weights = dict(enumerate(compute_class_weight(class_weight='balanced', classes=classes, y=val_y)))\n",
    "\n",
    "# 결과 출력\n",
    "print(\"클래스 가중치:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def val_data_generator(val_mfcc_dir, val_label_dir, batch_size):\n",
    "    \"\"\"\n",
    "    검증 데이터를 배치 단위로 불러오는 제너레이터 함수입니다.\n",
    "    - 메모리 이슈를 피하기 위해 배치 단위로 불러옵니다.\n",
    "    \n",
    "    Parameters:\n",
    "        val_mfcc_dir (str): MFCC 검증 배치 파일 경로\n",
    "        val_label_dir (str): 라벨 검증 배치 파일 경로\n",
    "        batch_size (int): 배치 크기\n",
    "\n",
    "    Yields:\n",
    "        Tuple[np.ndarray, np.ndarray]: (x_batch, y_batch)\n",
    "    \"\"\"\n",
    "    mfcc_files = sorted(glob.glob(os.path.join(val_mfcc_dir, \"mfcc_val_batch_*.npy\")))\n",
    "    label_files = sorted(glob.glob(os.path.join(val_label_dir, \"label_val_batch_*.npy\")))\n",
    "\n",
    "    while True:\n",
    "        for mfcc_file, label_file in zip(mfcc_files, label_files):\n",
    "            x = np.load(mfcc_file)[..., np.newaxis]  # (batch, 40, 300, 1)\n",
    "            y_raw = np.load(label_file, allow_pickle=True)\n",
    "\n",
    "            # 문자열 레이블이면 숫자로 변환\n",
    "            if y_raw.dtype.type is np.str_ or y_raw.dtype.type is np.object_:\n",
    "                unique_labels = sorted(set(y_raw))\n",
    "                label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "                y = np.array([label_to_index[label] for label in y_raw])\n",
    "            else:\n",
    "                y = y_raw.copy()\n",
    "\n",
    "            min_len = min(len(x), len(y))\n",
    "            x = x[:min_len]\n",
    "            y = y[:min_len]\n",
    "\n",
    "            for i in range(0, min_len, batch_size):\n",
    "                yield x[i:i+batch_size], y[i:i+batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 제너레이터 인스턴스 생성\n",
    "val_generator = val_data_generator(val_dir, val_dir, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `class_weight` is not supported for Python generator inputs. Received: class_weight={0: 25.048666666666666, 1: 2.087388888888889, 2: 0.6288341889782888, 3: 0.8134664826391708, 4: 0.8491073446327684, 5: 0.6739672460492565}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     17\u001b[39m callbacks = [\n\u001b[32m     18\u001b[39m     EarlyStopping(\n\u001b[32m     19\u001b[39m         monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     )\n\u001b[32m     28\u001b[39m ]\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 모델 학습 실행\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 학습용 제너레이터\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# 검증용 제너레이터\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# 클래스 가중치 적용\u001b[39;49;00m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/__init__.py:113\u001b[39m, in \u001b[36mget_data_adapter\u001b[39m\u001b[34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[39m\n\u001b[32m    109\u001b[39m         raise_unsupported_arg(\n\u001b[32m    110\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msample_weights\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mthe sample weights\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPyDataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m         )\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    114\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArgument `class_weight` is not supported for Python \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    115\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgenerator inputs. Received: class_weight=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_weight\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    116\u001b[39m         )\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Argument `class_weight` is not supported for Python generator inputs. Received: class_weight={0: 25.048666666666666, 1: 2.087388888888889, 2: 0.6288341889782888, 3: 0.8134664826391708, 4: 0.8491073446327684, 5: 0.6739672460492565}"
     ]
    }
   ],
   "source": [
    "# 검증 제너레이터 인스턴스 생성\n",
    "val_generator = val_data_generator(val_dir, val_dir, BATCH_SIZE)\n",
    "\n",
    "# 학습 스텝 수 계산 (전체 학습 샘플 수 / 배치 크기)\n",
    "train_steps = sum([\n",
    "    np.load(f).shape[0]\n",
    "    for f in glob.glob(os.path.join(train_dir, \"label_batch_*.npy\"))\n",
    "]) // BATCH_SIZE\n",
    "\n",
    "# 검증 스텝 수 계산 (전체 검증 샘플 수 / 배치 크기)\n",
    "val_steps = sum([\n",
    "    np.load(f, allow_pickle=True).shape[0]\n",
    "    for f in glob.glob(os.path.join(val_dir, \"label_val_batch_*.npy\"))\n",
    "]) // BATCH_SIZE\n",
    "\n",
    "# 콜백 정의\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# 모델 학습 실행\n",
    "history = model.fit(\n",
    "    data_generator(train_dir, train_dir, BATCH_SIZE),  # 학습용 제너레이터\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,                    # 검증용 제너레이터\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights                        # 클래스 가중치 적용\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오류의 원인은 class_weight 인자는 Python 제너레이터 기반 입력에 사용할 수 없기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 4클래스 필터링 완료: 0개 → ./data/usou/metadata_4class.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 설정\n",
    "json_dir = \"/media/usou/PortableSSD/mldl_project/json_data\"\n",
    "output_csv_path = \"./data/usou/metadata_4class.csv\"\n",
    "target_emotions = {\"angry\", \"happy\", \"neutrality\", \"sad\"}\n",
    "\n",
    "data = []\n",
    "for root, _, files in os.walk(json_dir):\n",
    "    for fname in files:\n",
    "        if fname.endswith(\".json\"):\n",
    "            with open(os.path.join(root, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                content = json.load(f)\n",
    "                if content[\"emotion\"] in target_emotions:\n",
    "                    data.append({\"wav_path\": content[\"wav_path\"], \"emotion\": content[\"emotion\"]})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"✅ 4클래스 필터링 완료: {len(df)}개 → {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class_weight 효과를 반영한 데이터 오버샘플링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5428/2753053002.py:20: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "오버샘플링된 MFCC 추출:   0%|          | 12/326668 [00:01<12:16:51,  7.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     y, sr = librosa.load(row[\u001b[33m\"\u001b[39m\u001b[33mwav_path\u001b[39m\u001b[33m\"\u001b[39m], sr=\u001b[32m16000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     mfcc = \u001b[43mextract_mfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     mfcc_batch.append(mfcc)\n\u001b[32m     54\u001b[39m     label_batch.append(row[\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mextract_mfcc\u001b[39m\u001b[34m(y, sr)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_mfcc\u001b[39m(y, sr):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     mfcc = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmfcc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_mfcc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mfcc.shape[\u001b[32m1\u001b[39m] < max_len:\n\u001b[32m     38\u001b[39m         pad_width = max_len - mfcc.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/feature/spectral.py:1993\u001b[39m, in \u001b[36mmfcc\u001b[39m\u001b[34m(y, sr, S, n_mfcc, dct_type, norm, lifter, mel_norm, **kwargs)\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mel-frequency cepstral coefficients (MFCCs)\u001b[39;00m\n\u001b[32m   1847\u001b[39m \n\u001b[32m   1848\u001b[39m \u001b[33;03m.. warning:: If multi-channel audio input ``y`` is provided, the MFCC\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1989\u001b[39m \u001b[33;03m>>> fig.colorbar(img2, ax=[ax[1]])\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1992\u001b[39m     \u001b[38;5;66;03m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1993\u001b[39m     S = power_to_db(\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1995\u001b[39m fft = get_fftlib()\n\u001b[32m   1996\u001b[39m M: np.ndarray = fft.dct(S, axis=-\u001b[32m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m=dct_type, norm=norm)[\n\u001b[32m   1997\u001b[39m     ..., :n_mfcc, :\n\u001b[32m   1998\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/feature/spectral.py:2135\u001b[39m, in \u001b[36mmelspectrogram\u001b[39m\u001b[34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[39m\n\u001b[32m   2013\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmelspectrogram\u001b[39m(\n\u001b[32m   2014\u001b[39m     *,\n\u001b[32m   2015\u001b[39m     y: Optional[np.ndarray] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2025\u001b[39m     **kwargs: Any,\n\u001b[32m   2026\u001b[39m ) -> np.ndarray:\n\u001b[32m   2027\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[32m   2028\u001b[39m \n\u001b[32m   2029\u001b[39m \u001b[33;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2133\u001b[39m \u001b[33;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[32m   2134\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2135\u001b[39m     S, n_fft = \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2136\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2147\u001b[39m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[32m   2148\u001b[39m     mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/core/spectrum.py:2945\u001b[39m, in \u001b[36m_spectrogram\u001b[39m\u001b[34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[39m\n\u001b[32m   2939\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2940\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[32m   2941\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2942\u001b[39m         )\n\u001b[32m   2943\u001b[39m     S = (\n\u001b[32m   2944\u001b[39m         np.abs(\n\u001b[32m-> \u001b[39m\u001b[32m2945\u001b[39m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2946\u001b[39m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2947\u001b[39m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2948\u001b[39m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2949\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2950\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2951\u001b[39m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2952\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2953\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2954\u001b[39m         )\n\u001b[32m   2955\u001b[39m         ** power\n\u001b[32m   2956\u001b[39m     )\n\u001b[32m   2958\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/librosa/core/spectrum.py:387\u001b[39m, in \u001b[36mstft\u001b[39m\u001b[34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, y_frames.shape[-\u001b[32m1\u001b[39m], n_columns):\n\u001b[32m    385\u001b[39m     bl_t = \u001b[38;5;28mmin\u001b[39m(bl_s + n_columns, y_frames.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     stft_matrix[..., bl_s + off_start : bl_t + off_start] = \u001b[43mfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfft_window\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43my_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbl_s\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbl_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_backend.py:28\u001b[39m, in \u001b[36m_ScipyBackend.__ua_function__\u001b[39m\u001b[34m(method, args, kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:91\u001b[39m, in \u001b[36mrfft\u001b[39m\u001b[34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrfft\u001b[39m(x, n=\u001b[38;5;28;01mNone\u001b[39;00m, axis=-\u001b[32m1\u001b[39m, norm=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     90\u001b[39m          overwrite_x=\u001b[38;5;28;01mFalse\u001b[39;00m, workers=\u001b[38;5;28;01mNone\u001b[39;00m, *, plan=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_1D\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrfft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:32\u001b[39m, in \u001b[36m_execute_1D\u001b[39m\u001b[34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[32m     31\u001b[39m     x = np.asarray(x)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m norm = _validate_fft_args(workers, plan, norm)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[33m'\u001b[39m\u001b[33mfft\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:61\u001b[39m, in \u001b[36mr2c\u001b[39m\u001b[34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid number of data points (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp.shape[axis]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Note: overwrite_x is not utilised\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 경로 설정\n",
    "csv_path = \"./data/usou/metadata_4class.csv\"\n",
    "output_dir = \"/media/usou/PortableSSD/mldl_project/data4class_oversampled_batches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 2. MFCC 설정\n",
    "n_mfcc = 40\n",
    "max_len = 300\n",
    "batch_size = 1000\n",
    "\n",
    "# 3. 데이터 불러오기\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 4. 클래스별 분포 확인\n",
    "label_counts = df['emotion'].value_counts()\n",
    "max_count = label_counts.max()\n",
    "\n",
    "# 5. 오버샘플링 수행\n",
    "oversampled_df = pd.DataFrame()\n",
    "\n",
    "for emotion, group in df.groupby('emotion'):\n",
    "    # 클래스별로 최대 수만큼 오버샘플링\n",
    "    group_oversampled = resample(group, replace=True, n_samples=max_count, random_state=42)\n",
    "    oversampled_df = pd.concat([oversampled_df, group_oversampled])\n",
    "\n",
    "# 6. MFCC 추출 함수\n",
    "def extract_mfcc(y, sr):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    if mfcc.shape[1] < max_len:\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    return mfcc\n",
    "\n",
    "# 7. 배치 저장\n",
    "mfcc_batch = []\n",
    "label_batch = []\n",
    "batch_index = 0\n",
    "\n",
    "for _, row in tqdm(oversampled_df.iterrows(), total=len(oversampled_df), desc=\"오버샘플링된 MFCC 추출\"):\n",
    "    try:\n",
    "        y, sr = librosa.load(row[\"wav_path\"], sr=16000)\n",
    "        mfcc = extract_mfcc(y, sr)\n",
    "        mfcc_batch.append(mfcc)\n",
    "        label_batch.append(row[\"emotion\"])\n",
    "\n",
    "        if len(mfcc_batch) >= batch_size:\n",
    "            np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "            np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "            print(f\"배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "            batch_index += 1\n",
    "            mfcc_batch.clear()\n",
    "            label_batch.clear()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"오류: {row['wav_path']} → {e}\")\n",
    "        continue\n",
    "\n",
    "# 8. 마지막 배치 저장\n",
    "if mfcc_batch:\n",
    "    np.save(os.path.join(output_dir, f\"mfcc_batch_{batch_index}.npy\"), np.array(mfcc_batch))\n",
    "    np.save(os.path.join(output_dir, f\"label_batch_{batch_index}.npy\"), np.array(label_batch, dtype=object))\n",
    "    print(f\"마지막 배치 {batch_index} 저장 완료 - {len(mfcc_batch)}개\")\n",
    "\n",
    "print(\"오버샘플링 기반 MFCC 추출 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라벨 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "전체 라벨 로딩:   0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "전체 라벨 로딩: 100%|██████████| 327/327 [00:01<00:00, 321.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LabelEncoder 학습 및 저장 완료: /media/usou/PortableSSD/mldl_project/models/label_encoder_4class.pkl\n",
      "클래스 목록: ['Angry' 'Happy' 'Neutrality' 'Sad']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 경로 설정\n",
    "label_path = \"/media/usou/PortableSSD/mldl_project/data4class_oversampled_batches/label_batch_*.npy\"\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 2. 전체 라벨 수집\n",
    "all_labels = []\n",
    "for label_file in tqdm(sorted(glob(label_path)), desc=\"전체 라벨 로딩\"):\n",
    "    labels = np.load(label_file, allow_pickle=True)\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# 3. 라벨 인코더 학습 및 저장\n",
    "le = LabelEncoder()\n",
    "le.fit(all_labels)\n",
    "\n",
    "encoder_path = os.path.join(save_dir, \"label_encoder_4class.pkl\")\n",
    "with open(encoder_path, \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"✅ LabelEncoder 학습 및 저장 완료:\", encoder_path)\n",
    "print(\"클래스 목록:\", le.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 제너레이터 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 17:24:28.947118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743755068.995799    5428 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743755069.009420    5428 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743755069.127231    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743755069.127250    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743755069.127251    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743755069.127253    5428 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 17:24:29.142424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class MFCCBatchGenerator(Sequence):\n",
    "    def __init__(self, data_dir, encoder_path, batch_size=32, shuffle=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # 파일 목록\n",
    "        self.mfcc_files = sorted([f for f in os.listdir(data_dir) if f.startswith(\"mfcc_batch_\")])\n",
    "        self.label_files = sorted([f for f in os.listdir(data_dir) if f.startswith(\"label_batch_\")])\n",
    "        self.indexes = np.arange(len(self.mfcc_files))\n",
    "\n",
    "        # 라벨 인코더 로드\n",
    "        with open(encoder_path, \"rb\") as f:\n",
    "            self.encoder = pickle.load(f)\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.indexes[idx]\n",
    "        mfcc_path = os.path.join(self.data_dir, self.mfcc_files[i])\n",
    "        label_path = os.path.join(self.data_dir, self.label_files[i])\n",
    "\n",
    "        X = np.load(mfcc_path)\n",
    "        y = np.load(label_path, allow_pickle=True)\n",
    "        y_encoded = self.encoder.transform(y)\n",
    "\n",
    "        return X[..., np.newaxis], y_encoded\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구조 추천 (성능 좋은 CNN 기반)\n",
    "- 기존보다 조금 더 깊고, BatchNormalization, Dropout 등을 넣어서 일반화 성능을 높이는 구조입니다.\n",
    "\n",
    "- 커널 과부하를 막기 위해 파라미터 수를 100만 이하로 제한했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 300, 1), num_classes=4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MFCCBatchGenerator.__init__() missing 1 required positional argument: 'encoder_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m history_save_path = \u001b[33m\"\u001b[39m\u001b[33m./ai/models/history_4class.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 배치 제너레이터 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m train_generator = \u001b[43mMFCCBatchGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 모델 빌드\u001b[39;00m\n\u001b[32m     14\u001b[39m model = build_cnn_model(input_shape=(\u001b[32m40\u001b[39m, \u001b[32m300\u001b[39m, \u001b[32m1\u001b[39m), num_classes=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: MFCCBatchGenerator.__init__() missing 1 required positional argument: 'encoder_path'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pickle\n",
    "\n",
    "# 경로 설정\n",
    "train_data_dir = \"/media/usou/PortableSSD/mldl_project/data4class_oversampled_batches\"\n",
    "model_save_path = \"./ai/models/voice_emotion_model_4class.keras\"\n",
    "history_save_path = \"./ai/models/history_4class.pkl\"\n",
    "\n",
    "# 배치 제너레이터 생성\n",
    "train_generator = MFCCBatchGenerator(data_dir=train_data_dir, batch_size=64, shuffle=True)\n",
    "\n",
    "# 모델 빌드\n",
    "model = build_cnn_model(input_shape=(40, 300, 1), num_classes=4)\n",
    "\n",
    "# 콜백 설정\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='loss', patience=60, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint(model_save_path, monitor='loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=300,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 학습 이력 저장\n",
    "with open(history_save_path, \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 완료 및 모델/이력 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 시작 \n",
    "# JSON -> DataFrame 변환(4개 감정만 필터링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON 파일 탐색: 449it [02:39,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정상 처리된 데이터 수: 236584\n",
      "⚠️ 오류 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 사용할 감정 4종\n",
    "target_emotions = {\"neutral\", \"angry\", \"happy\", \"sad\"}\n",
    "\n",
    "# JSON 및 WAV 최상위 경로\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "\n",
    "# 결과 저장 경로: 외장 하드 mldl_4class 폴더\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 수집 리스트\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# JSON 탐색 및 처리\n",
    "for folder_path, _, files in tqdm(os.walk(label_root), desc=\"JSON 파일 탐색\"):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                if emotion.lower() not in target_emotions:\n",
    "                    continue\n",
    "\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root).replace(\"TL\", \"TS\")\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion.lower(),\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"[WAV 없음] {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[JSON 오류] {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# DataFrame 저장\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_cleaned.csv\"), index=False)\n",
    "\n",
    "# 오류 로그 저장\n",
    "with open(os.path.join(save_dir, \"broken_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"✅ 정상 처리된 데이터 수: {len(df)}\")\n",
    "print(f\"⚠️ 오류 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/4277833996.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n",
      "/tmp/ipykernel_5551/4277833996.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_df = df.groupby('emotion', group_keys=False).apply(lambda x: x.sample(min_class_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 균형 샘플 수: 76332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 중: 100%|██████████| 228996/228996 [44:48<00:00, 85.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장된 MFCC 배치 수: 23\n",
      "⚠️ 실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ============================\n",
    "# 1. 메타데이터 로드 및 클래스 균형 맞춤\n",
    "# ============================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 클래스별 개수 파악\n",
    "min_class_count = df['emotion'].value_counts().min()\n",
    "\n",
    "# 클래스별 균형 맞춤\n",
    "balanced_df = df.groupby('emotion', group_keys=False).apply(lambda x: x.sample(min_class_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "print(\"각 클래스 균형 샘플 수:\", min_class_count)\n",
    "\n",
    "# ============================\n",
    "# 2. 설정값 정의\n",
    "# ============================\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_interval = 10000\n",
    "\n",
    "# 저장 디렉토리\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# 3. MFCC 추출 루프 (제너레이터 스타일)\n",
    "# ============================\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "error_files = []\n",
    "save_counter = 0\n",
    "\n",
    "for idx, row in tqdm(balanced_df.iterrows(), total=len(balanced_df), desc=\"MFCC 추출 중\"):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ============================\n",
    "# 4. 에러 로그 저장\n",
    "# ============================\n",
    "error_path = \"/media/usou/PortableSSD/mldl_4class/broken_audio_files.txt\"\n",
    "with open(error_path, \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ============================\n",
    "# 5. 요약 출력\n",
    "# ============================\n",
    "print(f\"✅ 저장된 MFCC 배치 수: {save_counter + 1}\")\n",
    "print(f\"⚠️ 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 레이블 인코딩(Train 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5551/2700387088.py:12: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 레이블 인코딩 완료 및 저장\n",
      "📦 저장 경로: /media/usou/PortableSSD/mldl_4class/mfcc_batches/encoded_labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================\n",
    "# 1. 메타데이터 로드\n",
    "# ===============================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ===============================\n",
    "# 2. 레이블 인코딩\n",
    "# ===============================\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(df[\"emotion\"])  # 'happy' → 0, ...\n",
    "\n",
    "# ===============================\n",
    "# 3. 인코더 저장 (나중에 검증 데이터에 동일하게 적용)\n",
    "# ===============================\n",
    "encoder_path = \"./label_encoder.pkl\"  # 현재 코드 폴더에 저장\n",
    "with open(encoder_path, \"wb\") as f:\n",
    "    pickle.dump(encoder, f)\n",
    "\n",
    "# ===============================\n",
    "# 4. 라벨을 MFCC 배치 기준으로 분리 저장\n",
    "# ===============================\n",
    "\n",
    "# 학습 데이터의 MFCC 배치 수 확인\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "mfcc_batches = sorted([f for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "label_save_dir = os.path.join(mfcc_dir, \"encoded_labels\")\n",
    "os.makedirs(label_save_dir, exist_ok=True)\n",
    "\n",
    "start_idx = 0\n",
    "for i, batch_name in enumerate(mfcc_batches):\n",
    "    mfcc_path = os.path.join(mfcc_dir, batch_name)\n",
    "    batch_mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    end_idx = start_idx + len(batch_mfcc)\n",
    "    batch_labels = encoded_labels[start_idx:end_idx]\n",
    "    \n",
    "    # 저장\n",
    "    np.save(os.path.join(label_save_dir, f\"label_batch_{i}.npy\"), batch_labels)\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(\"✅ 레이블 인코딩 완료 및 저장\")\n",
    "print(\"📦 저장 경로:\", label_save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation 전처리 (Train 과 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation JSON 탐색: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation JSON 탐색: 88it [00:05, 15.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 데이터 수: 36207\n",
      "⚠️ 오류 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class/validation\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 2. 필터링 감정 정의 및 리스트 초기화\n",
    "# ========================================\n",
    "\n",
    "target_emotions = {\"neutral\", \"angry\", \"happy\", \"sad\"}\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 탐색 및 필터링 처리\n",
    "# ========================================\n",
    "\n",
    "for folder_path, _, files in tqdm(os.walk(label_root), desc=\"Validation JSON 탐색\"):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"].lower()\n",
    "                if emotion not in target_emotions:\n",
    "                    continue\n",
    "\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"JSON 읽기 오류: {json_path}, 에러: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 결과 저장\n",
    "# ========================================\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_dir, \"metadata_cleaned_val.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(save_dir, \"broken_val_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"✅ Validation 데이터 수: {len(df)}\")\n",
    "print(f\"⚠️ 오류 파일 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC 추출 (Validation용, 클래스 불균형 조정 없이 전체 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MFCC 추출 중 (Validation): 100%|██████████| 36207/36207 [10:14<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장된 MFCC 배치 수: 4\n",
      "⚠️ 실패한 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드\n",
    "# ========================================\n",
    "\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. 설정값 정의\n",
    "# ========================================\n",
    "\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_interval = 10000\n",
    "\n",
    "# 저장 디렉토리\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 3. MFCC 추출 루프 (제너레이터 방식)\n",
    "# ========================================\n",
    "\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "error_files = []\n",
    "save_counter = 0\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"MFCC 추출 중 (Validation)\"):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 남은 데이터 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# ========================================\n",
    "# 4. 에러 로그 저장\n",
    "# ========================================\n",
    "\n",
    "with open(\"/media/usou/PortableSSD/mldl_4class/validation/broken_audio_val.txt\", \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# 5. 결과 출력\n",
    "# ========================================\n",
    "\n",
    "print(f\"✅ 저장된 MFCC 배치 수: {save_counter + 1}\")\n",
    "print(f\"⚠️ 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 레이블 인코딩 (학습용 인코더 재사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 라벨 인코딩 완료 및 저장\n",
      "📦 저장 경로: /media/usou/PortableSSD/mldl_4class/validation/mfcc_batches/encoded_labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. LabelEncoder 로드\n",
    "# ========================================\n",
    "encoder_path = \"./label_encoder.pkl\"  # Train 3번 셀에서 저장한 인코더\n",
    "with open(encoder_path, \"rb\") as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# ========================================\n",
    "# 2. Validation 메타데이터 로드\n",
    "# ========================================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_4class/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ========================================\n",
    "# 3. 레이블 인코딩 적용\n",
    "# ========================================\n",
    "encoded_labels = encoder.transform(df[\"emotion\"])\n",
    "\n",
    "# ========================================\n",
    "# 4. MFCC 배치 기준으로 라벨 분리 저장\n",
    "# ========================================\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "mfcc_batches = sorted([f for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "label_save_dir = os.path.join(mfcc_dir, \"encoded_labels\")\n",
    "os.makedirs(label_save_dir, exist_ok=True)\n",
    "\n",
    "start_idx = 0\n",
    "for i, batch_name in enumerate(mfcc_batches):\n",
    "    mfcc_path = os.path.join(mfcc_dir, batch_name)\n",
    "    batch_mfcc = np.load(mfcc_path, allow_pickle=True)\n",
    "    end_idx = start_idx + len(batch_mfcc)\n",
    "    batch_labels = encoded_labels[start_idx:end_idx]\n",
    "    \n",
    "    # 저장\n",
    "    np.save(os.path.join(label_save_dir, f\"label_batch_{i}.npy\"), batch_labels)\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(\"✅ Validation 라벨 인코딩 완료 및 저장\")\n",
    "print(\"📦 저장 경로:\", label_save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 모델 정의 (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 22:04:02.463416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743771842.481758   21737 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743771842.487580   21737 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743771842.501105   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743771842.501129   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743771842.501130   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743771842.501131   21737 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-04 22:04:02.505074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-04 22:04:05.800758: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-04-04 22:04:05.800780: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-04-04 22:04:05.800784: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: usou-GP75-Leopard-10SEK\n",
      "2025-04-04 22:04:05.800787: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: usou-GP75-Leopard-10SEK\n",
      "2025-04-04 22:04:05.800876: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.144.3\n",
      "2025-04-04 22:04:05.800887: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.144.3\n",
      "2025-04-04 22:04:05.800889: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.144.3\n",
      "/home/usou/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7680</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">983,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7680\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m983,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,077,252</span> (4.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,077,252\u001b[0m (4.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,076,804</span> (4.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,076,804\u001b[0m (4.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# GPU 메모리 점진 할당\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def build_cnn_model(input_shape=(40, 100, 1), num_classes=4):  # ← 줄인 입력\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = build_cnn_model(input_shape=(40, 100, 1), num_classes=4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2027 - loss: 3.1182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 4s/step - accuracy: 0.2051 - loss: 3.0772 - val_accuracy: 0.3149 - val_loss: 1.2610\n",
      "Epoch 2/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 5s/step - accuracy: 0.3663 - loss: 1.1645 - val_accuracy: 0.3414 - val_loss: 1.3809\n",
      "Epoch 3/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3615 - loss: 1.1496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 5s/step - accuracy: 0.3599 - loss: 1.1505 - val_accuracy: 0.3349 - val_loss: 1.1638\n",
      "Epoch 4/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3368 - loss: 1.1462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 5s/step - accuracy: 0.3373 - loss: 1.1459 - val_accuracy: 0.2621 - val_loss: 1.1333\n",
      "Epoch 5/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - accuracy: 0.3099 - loss: 1.1686 - val_accuracy: 0.2642 - val_loss: 1.1390\n",
      "Epoch 6/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4517 - loss: 1.1090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 5s/step - accuracy: 0.4465 - loss: 1.1123 - val_accuracy: 0.3261 - val_loss: 1.1330\n",
      "Epoch 7/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2651 - loss: 1.1654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.2664 - loss: 1.1652 - val_accuracy: 0.2822 - val_loss: 1.1324\n",
      "Epoch 8/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3532 - loss: 1.1339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3524 - loss: 1.1342 - val_accuracy: 0.2450 - val_loss: 1.1249\n",
      "Epoch 9/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3006 - loss: 1.1394 - val_accuracy: 0.3115 - val_loss: 1.1345\n",
      "Epoch 10/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.4110 - loss: 1.0952 - val_accuracy: 0.1949 - val_loss: 1.1297\n",
      "Epoch 11/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3814 - loss: 1.1115 - val_accuracy: 0.1884 - val_loss: 1.1356\n",
      "Epoch 12/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3903 - loss: 1.1074 - val_accuracy: 0.2793 - val_loss: 1.1410\n",
      "Epoch 13/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3617 - loss: 1.1145 - val_accuracy: 0.2570 - val_loss: 1.1457\n",
      "Epoch 14/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3680 - loss: 1.1364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 5s/step - accuracy: 0.3656 - loss: 1.1376 - val_accuracy: 0.2433 - val_loss: 1.1226\n",
      "Epoch 15/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3630 - loss: 1.1103"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3618 - loss: 1.1107 - val_accuracy: 0.3411 - val_loss: 1.1187\n",
      "Epoch 16/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3613 - loss: 1.1172 - val_accuracy: 0.3214 - val_loss: 1.1275\n",
      "Epoch 17/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3556 - loss: 1.1164 - val_accuracy: 0.3163 - val_loss: 1.1356\n",
      "Epoch 18/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3601 - loss: 1.1171 - val_accuracy: 0.2519 - val_loss: 1.1342\n",
      "Epoch 19/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3586 - loss: 1.1072 - val_accuracy: 0.3008 - val_loss: 1.1405\n",
      "Epoch 20/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3168 - loss: 1.1444 - val_accuracy: 0.2285 - val_loss: 1.1235\n",
      "Epoch 21/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3062 - loss: 1.1207 - val_accuracy: 0.2825 - val_loss: 1.1190\n",
      "Epoch 22/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3809 - loss: 1.1091 - val_accuracy: 0.2540 - val_loss: 1.1246\n",
      "Epoch 23/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 5s/step - accuracy: 0.3396 - loss: 1.1154 - val_accuracy: 0.1686 - val_loss: 1.1221\n",
      "Epoch 24/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3956 - loss: 1.1021 - val_accuracy: 0.1889 - val_loss: 1.1284\n",
      "Epoch 25/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3629 - loss: 1.1064 - val_accuracy: 0.2572 - val_loss: 1.1326\n",
      "Epoch 26/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3005 - loss: 1.1222 - val_accuracy: 0.2399 - val_loss: 1.1288\n",
      "Epoch 27/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3474 - loss: 1.1167 - val_accuracy: 0.1613 - val_loss: 1.1311\n",
      "Epoch 28/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3800 - loss: 1.1024 - val_accuracy: 0.2122 - val_loss: 1.1373\n",
      "Epoch 29/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3673 - loss: 1.1005 - val_accuracy: 0.2523 - val_loss: 1.1351\n",
      "Epoch 30/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3406 - loss: 1.0992 - val_accuracy: 0.1660 - val_loss: 1.1370\n",
      "Epoch 31/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3578 - loss: 1.0996 - val_accuracy: 0.1874 - val_loss: 1.1347\n",
      "Epoch 32/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 4s/step - accuracy: 0.3675 - loss: 1.0999 - val_accuracy: 0.1350 - val_loss: 1.1443\n",
      "Epoch 33/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.2945 - loss: 1.1164 - val_accuracy: 0.2314 - val_loss: 1.1370\n",
      "Epoch 34/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3202 - loss: 1.1106 - val_accuracy: 0.1958 - val_loss: 1.1325\n",
      "Epoch 35/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3428 - loss: 1.1012 - val_accuracy: 0.1536 - val_loss: 1.1376\n",
      "Epoch 36/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3612 - loss: 1.1013 - val_accuracy: 0.2322 - val_loss: 1.1390\n",
      "Epoch 37/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3865 - loss: 1.0886 - val_accuracy: 0.1668 - val_loss: 1.1576\n",
      "Epoch 38/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3492 - loss: 1.1005 - val_accuracy: 0.1624 - val_loss: 1.1365\n",
      "Epoch 39/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3546 - loss: 1.0961 - val_accuracy: 0.1607 - val_loss: 1.1570\n",
      "Epoch 40/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.4010 - loss: 1.0841 - val_accuracy: 0.1990 - val_loss: 1.1483\n",
      "Epoch 41/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.4465 - loss: 1.0725 - val_accuracy: 0.1493 - val_loss: 1.1424\n",
      "Epoch 42/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3413 - loss: 1.1071 - val_accuracy: 0.1608 - val_loss: 1.1376\n",
      "Epoch 43/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3419 - loss: 1.0985 - val_accuracy: 0.2479 - val_loss: 1.1485\n",
      "Epoch 44/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3719 - loss: 1.0842 - val_accuracy: 0.1405 - val_loss: 1.1616\n",
      "Epoch 45/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3s/step - accuracy: 0.3283 - loss: 1.1023 - val_accuracy: 0.1554 - val_loss: 1.1648\n",
      "✅ 학습 완료 및 저장됨\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# =============================\n",
    "# 1. 제너레이터 정의 (샘플 개수 맞춤 처리 포함)\n",
    "# =============================\n",
    "class MFCCGenerator(Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32):\n",
    "        self.mfcc_paths = sorted([os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "        self.label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.startswith(\"label_batch\")])\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.mfcc_paths[idx], allow_pickle=True)\n",
    "        y = np.load(self.label_paths[idx])\n",
    "\n",
    "        # 오류 방지: 길이 맞춤\n",
    "        min_len = min(len(x), len(y))\n",
    "        x = x[:min_len]\n",
    "        y = y[:min_len]\n",
    "\n",
    "        # Padding & Shape 변환\n",
    "        x = np.stack([\n",
    "            np.pad(sample, ((0, max(0, 40 - sample.shape[0])), (0, 0)), mode='constant')[:40]\n",
    "            for sample in x\n",
    "        ])\n",
    "        x = np.transpose(x, (0, 2, 1))            # (batch, 13, 40)\n",
    "        x = x[..., np.newaxis]                    # (batch, 13, 40, 1)\n",
    "        x = np.transpose(x, (0, 2, 1, 3))         # → (batch, 40, 13, 1)\n",
    "        return x, y\n",
    "\n",
    "# =============================\n",
    "# 2. 경로 설정\n",
    "# =============================\n",
    "train_mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "train_label_dir = os.path.join(train_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "val_label_dir = os.path.join(val_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "# =============================\n",
    "# 3. 제너레이터 준비\n",
    "# =============================\n",
    "train_gen = MFCCGenerator(train_mfcc_dir, train_label_dir, batch_size=32)\n",
    "val_gen = MFCCGenerator(val_mfcc_dir, val_label_dir, batch_size=32)\n",
    "\n",
    "# =============================\n",
    "# 4. 모델 불러오기 (4번 셀에서 정의된 함수 사용)\n",
    "# =============================\n",
    "model = build_cnn_model(input_shape=(40, 13, 1), num_classes=4)\n",
    "\n",
    "# =============================\n",
    "# 5. 콜백 설정\n",
    "# =============================\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=30, restore_best_weights=True, monitor='val_loss'),\n",
    "    ModelCheckpoint(\"voice_emotion_analyze.h5\", save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "# =============================\n",
    "# 6. 학습 실행\n",
    "# =============================\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=300,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# 7. 학습 기록 저장 (.pkl)\n",
    "# =============================\n",
    "with open(\"voice_emotion_analyze_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 완료 및 저장됨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd4VGX2wPHvzGTSO2kkBJKQ0HvvoIAUQWmChQUEUVdxZUX3p+uqqOzi2tZd17YqYEFFAbHQBREUpPdOIIT0AultMnN/f0xJQtokmbTJ+TxPniR37r3zztxJ5t4z55xXpSiKghBCCCGEEEIIIYQQDUjd2AMQQgghhBBCCCGEEC2PBKWEEEIIIYQQQgghRIOToJQQQgghhBBCCCGEaHASlBJCCCGEEEIIIYQQDU6CUkIIIYQQQgghhBCiwUlQSgghhBBCCCGEEEI0OAlKCSGEEEIIIYQQQogGJ0EpIYQQQgghhBBCCNHgJCglhBBCCCGEEEIIIRqcBKWEEELYRFhYGJMmTWrsYQghhBBC2ExMTAwqlYrXX3+9sYcihF2SoJQQduLdd99FpVIxcODAxh6KqCdhYWGoVKoKv8aPH9/YwxNCCCFahFWrVqFSqTh06FBjD8UumIM+lX298sorjT1EIUQ9cmjsAQghbGP16tWEhYVx4MABLl26RGRkZGMPSdSDXr16sWTJknLLg4ODG2E0QgghhBC2cc899zBx4sRyy3v37t0IoxFCNBQJSglhB65cucLevXtZv349Dz30EKtXr+aFF15o7GFVKDc3Fzc3t8YeRpNUXFyMwWDA0dGx0nVCQkKYPXt2A45KCCGEEKJurDn/69Onj5zjCNECSfmeEHZg9erV+Pj4cPvttzNjxgxWr15d4XoZGRn8+c9/JiwsDCcnJ9q0acOcOXNIS0uzrFNQUMDSpUvp0KEDzs7OtG7dmmnTphEdHQ3Arl27UKlU7Nq1q8y+zanXq1atsiybN28e7u7uREdHM3HiRDw8PLjvvvsA2LNnD3fddRdt27bFycmJ0NBQ/vznP5Ofn19u3OfOnWPmzJn4+/vj4uJCx44defbZZwH4+eefUalUfPvtt+W2++KLL1CpVOzbt6/K5+/y5cvcdddd+Pr64urqyqBBg9i4caPl9uTkZBwcHHjxxRfLbXv+/HlUKhX//e9/yzzPixcvJjQ0FCcnJyIjI/nnP/+JwWAo93y9/vrrvPXWW7Rv3x4nJyfOnDlT5VitYX7eL1++zLhx43BzcyM4OJiXXnoJRVHKrJubm8uSJUssY+3YsSOvv/56ufUAPv/8cwYMGICrqys+Pj6MGDGCbdu2lVvv119/ZcCAATg7OxMREcGnn35a5nadTseLL75IVFQUzs7OtGrVimHDhrF9+/Y6P3YhhBCiqTh69CgTJkzA09MTd3d3Ro8eze+//15mHWveE5OSkrj//vtp06YNTk5OtG7dmjvvvJOYmJhqx7Bz506GDx+Om5sb3t7e3HnnnZw9e9Zy+9q1a1GpVPzyyy/ltv3ggw9QqVScOnXKsuzcuXPMmDEDX19fnJ2d6devH99//32Z7czljb/88guPPPIIAQEBtGnTxtqnrUrm/pXbtm2jV69eODs706VLF9avX19u3erO78yqO/ct7X//+5/lnK1///4cPHiwzO11OVZCtFSSKSWEHVi9ejXTpk3D0dGRe+65h/fee4+DBw/Sv39/yzo5OTkMHz6cs2fPMn/+fPr06UNaWhrff/89cXFx+Pn5odfrmTRpEjt27ODuu+/m8ccfJzs7m+3bt3Pq1Cnat29f47EVFxczbtw4hg0bxuuvv46rqysA33zzDXl5efzxj3+kVatWHDhwgLfffpu4uDi++eYby/YnTpxg+PDhaLVaHnzwQcLCwoiOjuaHH37g73//O6NGjSI0NJTVq1czderUcs9L+/btGTx4cKXjS05OZsiQIeTl5fGnP/2JVq1a8cknn3DHHXewdu1apk6dSmBgICNHjuTrr78ul4G2Zs0aNBoNd911FwB5eXmMHDmS+Ph4HnroIdq2bcvevXt55plnSExM5K233iqz/cqVKykoKODBBx/EyckJX1/fKp9PnU5XJoho5ubmhouLi+V3vV7P+PHjGTRoEK+++ipbtmzhhRdeoLi4mJdeegkARVG44447+Pnnn1mwYAG9evVi69atPPXUU8THx/Ovf/3Lsr8XX3yRpUuXMmTIEF566SUcHR3Zv38/O3fu5LbbbrOsd+nSJWbMmMGCBQuYO3cuK1asYN68efTt25euXbsCsHTpUpYvX84DDzzAgAEDyMrK4tChQxw5coSxY8dW+fiFEEKI5uD06dMMHz4cT09P/vKXv6DVavnggw8YNWoUv/zyi6UHqDXvidOnT+f06dM89thjhIWFkZKSwvbt24mNjSUsLKzSMfz0009MmDCBiIgIli5dSn5+Pm+//TZDhw7lyJEjhIWFcfvtt+Pu7s7XX3/NyJEjy2y/Zs0aunbtSrdu3SyPaejQoYSEhPD000/j5ubG119/zZQpU1i3bl2587BHHnkEf39/nn/+eXJzc6t9zvLy8io8x/H29sbBoeSy9eLFi8yaNYuHH36YuXPnsnLlSu666y62bNliec6sOb8DanTu+8UXX5Cdnc1DDz2ESqXi1VdfZdq0aVy+fBmtVlunYyVEi6YIIZq1Q4cOKYCyfft2RVEUxWAwKG3atFEef/zxMus9//zzCqCsX7++3D4MBoOiKIqyYsUKBVDefPPNStf5+eefFUD5+eefy9x+5coVBVBWrlxpWTZ37lwFUJ5++uly+8vLyyu3bPny5YpKpVKuXr1qWTZixAjFw8OjzLLS41EURXnmmWcUJycnJSMjw7IsJSVFcXBwUF544YVy91Pa4sWLFUDZs2ePZVl2drYSHh6uhIWFKXq9XlEURfnggw8UQDl58mSZ7bt06aLceuutlt9ffvllxc3NTblw4UKZ9Z5++mlFo9EosbGxiqKUPF+enp5KSkpKlWM0a9eunQJU+LV8+XLLeubn/bHHHrMsMxgMyu233644OjoqqampiqIoyoYNGxRAWbZsWZn7mTFjhqJSqZRLly4piqIoFy9eVNRqtTJ16lTL81F6vzePb/fu3ZZlKSkpipOTk7JkyRLLsp49eyq33367VY9ZCCGEaGpWrlypAMrBgwcrXWfKlCmKo6OjEh0dbVmWkJCgeHh4KCNGjLAsq+498caNGwqgvPbaazUeZ69evZSAgAAlPT3dsuz48eOKWq1W5syZY1l2zz33KAEBAUpxcbFlWWJioqJWq5WXXnrJsmz06NFK9+7dlYKCAssyg8GgDBkyRImKirIsMz8/w4YNK7PPypjPiSr72rdvn2Vd87nGunXrLMsyMzOV1q1bK71797Yss/b8zppzX/P4WrVqpVy/ft1y+3fffacAyg8//KAoSt2OlRAtmZTvCdHMrV69msDAQG655RYAVCoVs2bN4quvvkKv11vWW7duHT179iz3KZZ5G/M6fn5+PPbYY5WuUxt//OMfyy0rndWTm5tLWloaQ4YMQVEUjh49CkBqaiq7d+9m/vz5tG3bttLxzJkzh8LCQtauXWtZtmbNGoqLi6vtTbBp0yYGDBjAsGHDLMvc3d158MEHiYmJsZTTTZs2DQcHB9asWWNZ79SpU5w5c4ZZs2ZZln3zzTcMHz4cHx8f0tLSLF9jxoxBr9eze/fuMvc/ffp0/P39qxxjaQMHDmT79u3lvu65555y6y5atMjys0qlYtGiRRQVFfHTTz9ZHrtGo+FPf/pTme2WLFmCoihs3rwZgA0bNmAwGHj++edRq8u+bdz8uujSpQvDhw+3/O7v70/Hjh25fPmyZZm3tzenT5/m4sWLVj9uIYQQornQ6/Vs27aNKVOmEBERYVneunVr7r33Xn799VeysrKA6t8TXVxccHR0ZNeuXdy4ccPqMSQmJnLs2DHmzZtXJgu7R48ejB07lk2bNlmWzZo1i5SUlDKtGdauXYvBYLCc41y/fp2dO3cyc+ZMsrOzLec36enpjBs3josXLxIfH19mDAsXLkSj0Vg95gcffLDCc5wuXbqUWS84OLjM+aynpydz5szh6NGjJCUlAdaf39Xk3HfWrFn4+PhYfjef75jPcWp7rIRo6SQoJUQzptfr+eqrr7jlllu4cuUKly5d4tKlSwwcOJDk5GR27NhhWTc6OtqSfl2Z6OhoOnbsWCZFuq4cHBwq7CMQGxtrOVFyd3fH39/fkjaemZkJlLzJVzfuTp060b9//zK9tFavXs2gQYOqnYXw6tWrdOzYsdzyzp07W24H8PPzY/To0Xz99deWddasWYODgwPTpk2zLLt48SJbtmzB39+/zNeYMWMASElJKXM/4eHhVY7vZn5+fowZM6bcV7t27cqsp1ary5wIA3To0AHA0tfg6tWrBAcH4+HhUeVjj46ORq1WlzsprMjNwUMAHx+fMidnL730EhkZGXTo0IHu3bvz1FNPceLEiWr3LYQQQjQHqamp5OXlVXp+YTAYuHbtGlD9e6KTkxP//Oc/2bx5M4GBgYwYMYJXX33VEnypjPk9vLIxpKWlWUrqxo8fj5eXV5kP3tasWUOvXr0s5w6XLl1CURSee+65cuc45tYGdT3HiYqKqvAcx9PTs8x6kZGR5QJGFZ3jWHN+V5Nz35vPccwBKvM5Tm2PlRAtnQSlhGjGdu7cSWJiIl999RVRUVGWr5kzZwJU2vC8LirLmCqdlVWak5NTuewavV7P2LFj2bhxI//3f//Hhg0b2L59u6VJeumG4NaaM2cOv/zyC3FxcURHR/P777/bfAaXu+++mwsXLnDs2DEAvv76a0aPHo2fn59lHYPBwNixYyv8pG/79u1Mnz69zD5LZ4zZg8o+EVVKNU4fMWIE0dHRrFixgm7duvHRRx/Rp08fPvroo4YaphBCCNEkWPOeuHjxYi5cuMDy5ctxdnbmueeeo3PnzpbM8rpycnJiypQpfPvttxQXFxMfH89vv/1WJhPcfG725JNPVnqOc/MHgS3xHKe+j5UQ9kganQvRjK1evZqAgADeeeedcretX7+eb7/9lvfffx8XFxfat29fZvaUirRv3579+/ej0+ksDRtvZv5UKCMjo8xy8ydO1jh58iQXLlzgk08+Yc6cOZblN8++Zs70qW7cYAwYPfHEE3z55Zfk5+ej1WrLnExVpl27dpw/f77c8nPnzlluN5syZQoPPfSQ5ZPECxcu8Mwzz5TZrn379uTk5FgyoxqLwWDg8uXLlk8OwThewNJos127dvz0009kZ2eXyZa6+bG3b98eg8HAmTNn6NWrl03G5+vry/3338/9999PTk4OI0aMYOnSpTzwwAM22b8QQgjRWPz9/XF1da30/EKtVhMaGmpZZs17Yvv27VmyZAlLlizh4sWL9OrVizfeeIPPP/+8wjGY38MrG4Ofnx9ubm6WZbNmzeKTTz5hx44dnD17FkVRypxHmc/JtFpto5/jmLO2Sn9QWtE5jjXnd9ac+9ZUTY+VEC2dZEoJ0Uzl5+ezfv16Jk2axIwZM8p9LVq0iOzsbMs0vdOnT+f48eN8++235fZl/oRn+vTppKWl8d///rfSddq1a4dGoynXG+ndd9+1euzmT5pKf7KkKAr//ve/y6zn7+/PiBEjWLFiBbGxsRWOx8zPz48JEybw+eefs3r1asaPH18mg6kyEydO5MCBA+zbt8+yLDc3l//973+EhYWVKVnz9vZm3LhxfP3113z11Vc4OjoyZcqUMvubOXMm+/btY+vWreXuKyMjg+Li4mrHZCulj6OiKPz3v/9Fq9UyevRowPjY9Xp9ueP9r3/9C5VKxYQJEwBjME6tVvPSSy+Vy2K7+ThYIz09vczv7u7uREZGUlhYWON9CSGEEE2NRqPhtttu47vvvrOUk4FxRrgvvviCYcOGWUrSqntPzMvLo6CgoMw67du3x8PDo8r3zdatW9OrVy8++eSTMh8knjp1im3btjFx4sQy648ZMwZfX1/WrFnDmjVrGDBgQJnyu4CAAEaNGsUHH3xAYmJiuftLTU2t+kmxoYSEhDLns1lZWXz66af06tWLoKAgwPrzO2vOfa1V22MlREsnmVJCNFPff/892dnZ3HHHHRXePmjQIPz9/Vm9ejWzZs3iqaeeYu3atdx1113Mnz+fvn37cv36db7//nvef/99evbsyZw5c/j000954oknOHDgAMOHDyc3N5effvqJRx55hDvvvBMvLy/uuusu3n77bVQqFe3bt+fHH38s10egKp06daJ9+/Y8+eSTxMfH4+npybp16ypsCvmf//yHYcOG0adPHx588EHCw8OJiYlh48aNljI6szlz5jBjxgwAXn75ZavG8vTTT/Pll18yYcIE/vSnP+Hr68snn3zClStXWLduXbnSw1mzZjF79mzeffddxo0bh7e3d5nbn3rqKb7//nsmTZrEvHnz6Nu3L7m5uZw8eZK1a9cSExNjVbCsMvHx8RV+0ubu7l4mQObs7MyWLVuYO3cuAwcOZPPmzWzcuJG//vWvlsbqkydP5pZbbuHZZ58lJiaGnj17sm3bNr777jsWL15smQY5MjKSZ599lpdffpnhw4czbdo0nJycOHjwIMHBwSxfvrxGj6FLly6MGjWKvn374uvry6FDh1i7dm2ZxuxCCCFEU7dixQq2bNlSbvnjjz/OsmXL2L59O8OGDeORRx7BwcGBDz74gMLCQl599VXLutW9J164cIHRo0czc+ZMunTpgoODA99++y3JycncfffdVY7vtddeY8KECQwePJgFCxaQn5/P22+/jZeXF0uXLi2zrlarZdq0aXz11Vfk5uby+uuvl9vfO++8w7Bhw+jevTsLFy4kIiKC5ORk9u3bR1xcHMePH6/Fs1jiyJEjFZ7jtG/fnsGDB1t+79ChAwsWLODgwYMEBgayYsUKkpOTWblypWUda8/vrDn3tVZdjpUQLVojzPgnhLCByZMnK87Ozkpubm6l68ybN0/RarVKWlqaoiiKkp6erixatEgJCQlRHB0dlTZt2ihz58613K4oipKXl6c8++yzSnh4uKLVapWgoCBlxowZZaY0Tk1NVaZPn664uroqPj4+ykMPPaScOnVKAZSVK1da1ps7d67i5uZW4djOnDmjjBkzRnF3d1f8/PyUhQsXKsePHy+3D0VRlFOnTilTp05VvL29FWdnZ6Vjx47Kc889V26fhYWFio+Pj+Ll5aXk5+db8zQqiqIo0dHRyowZMyz7HzBggPLjjz9WuG5WVpbi4uKiAMrnn39e4TrZ2dnKM888o0RGRiqOjo6Kn5+fMmTIEOX1119XioqKFEUpmV64JtMGm6dBruirXbt2lvXMz3t0dLRy2223Ka6urkpgYKDywgsvWKZALj3WP//5z0pwcLCi1WqVqKgo5bXXXrNMg1zaihUrlN69eytOTk6Kj4+PMnLkSGX79u1lxlfRtNYjR45URo4cafl92bJlyoABAxRvb2/FxcVF6dSpk/L3v//d8twIIYQQTdnKlSsrfT8GlGvXrimKoihHjhxRxo0bp7i7uyuurq7KLbfcouzdu7fMvqp7T0xLS1MeffRRpVOnToqbm5vi5eWlDBw4UPn666+tGutPP/2kDB06VHFxcVE8PT2VyZMnK2fOnKlw3e3btyuAolKpLI/hZtHR0cqcOXOUoKAgRavVKiEhIcqkSZOUtWvXlnt+Dh48aNUYzedElX3NnTvXsq75XGPr1q1Kjx49FCcnJ6VTp07KN998U+FYrTm/q+7ct6pzNkB54YUXFEWp+7ESoqVSKUotai+EEKIJKi4uJjg4mMmTJ/Pxxx839nAazbx581i7di05OTmNPRQhhBBCCJsJCwujW7du/Pjjj409FCGEjUhPKSGE3diwYQOpqallmqcLIYQQQgghhGiapKeUEKLZ279/PydOnODll1+md+/ejBw5srGHJIQQQgghhBCiGpIpJYRo9t577z3++Mc/EhAQwKefftrYwxFCCCGEEEIIYQXpKSWEEEIIIYQQQgghGpxkSgkhhBBCCCGEEEKIBidBKSGEEEIIIYQQQgjR4KTReQUMBgMJCQl4eHigUqkaezhCCCGEaEIURSE7O5vg4GDU6pb7+Z6cLwkhhBCiMtaeL0lQqgIJCQmEhoY29jCEEEII0YRdu3aNNm3aNPYwGo2cLwkhhBCiOtWdL0lQqgIeHh6A8cnz9PS0+f51Oh3btm3jtttuQ6vV2nz/wrbkeDUfcqyaFzlezYscrxJZWVmEhoZazhdaKjlfEqXJ8Wpe5Hg1H3Ksmhc5XiWsPV+SoFQFzCnonp6e9XaS5erqiqenZ4t/oTYHcryaDzlWzYscr+ZFjld5Lb1kTc6XRGlyvJoXOV7Nhxyr5kWOV3nVnS+13EYIQgghhBBCCCGEEKLRSFBKCCGEEEIIIYQQQjQ4CUoJIYQQQgghhBBCiAYnPaXqQK/Xo9PparydTqfDwcGBgoIC9Hp9PYxM2FJDHS9HR8cWPbW4EEIIIYQQwv7V9jq6OWhJ1/parRaNRlPn/UhQqhYURSEpKYmMjIxabx8UFMS1a9dafJPU5qChjpdarSY8PBxHR8d6uw8hhBBCCCGEaAx1vY5uDlratb63tzdBQUF1eqwSlKoF8x9SQEAArq6uNT4ABoOBnJwc3N3dJTOmGWiI42UwGEhISCAxMZG2bdu2iH9gQgghhBBCiJajrtfRzUFLudZXFIW8vDxSUlIAaN26da33JUGpGtLr9ZY/pFatWtVqHwaDgaKiIpydne36hWovGup4+fv7k5CQQHFxsUwfKoQQQgghhLAbtriObg5a0rW+i4sLACkpKQQEBNS6lM++n6V6YK59dXV1beSRCHtjLtuz99pjIYQQQgghRMsi19H2yXw869IjTIJStWSPqYaicclrSgghhBBCCGHP5JrHvtjieEpQSgghhBBCCCGEEEI0OAlKiVoLCwvjrbfeauxhCCGEEEIIIYQQzYJcR5clQakWQKVSVfm1dOnSWu334MGDPPjggzYZ45dffolGo+HRRx+1yf6EEEIIIYQQQojaasrX0aNGjWLx4sV12kdTIbPvtQCJiYmWn9esWcPzzz/P+fPnLcvc3d0tPyuKgl6vx8Gh+peGv7+/zcb48ccf85e//IUPPviAN954A2dnZ5vtu6aKioosTceFEEIIIYQQQrQ8tbmOtmbGPVteR9sDyZRqAYKCgixfXl5eqFQqy+/nzp3Dw8ODzZs307dvX5ycnPj111+Jjo7mzjvvJDAwEHd3d/r3789PP/1UZr83px2qVCo++ugjpk6diqurK1FRUXz//ffVju/KlSvs3buXp59+mg4dOrB+/fpy66xYsYKuXbvi5ORE69atWbRokeW2jIwMHnroIQIDA3F2dqZbt278+OOPACxdupRevXqV2ddbb71FWFiY5fd58+YxZcoU/v73vxMcHEzHjh0B+Oyzz+jXrx9eXl507NiR++67j5SUlDL7On36NJMmTcLT0xMPDw+GDx9OdHQ0u3fvRqvVkpSUVGb9xYsXM3z48GqfEyGEEEIIIYQQjae219H33nsvrVu3rvfr6KqsW7fOcv0cFhbGG2+8Ueb2d999l6ioKJydnQkMDGTGjBmW29auXUv37t1xcXGhVatWjBkzhtzc3DqNpyoSlLIBRVHIKyqu0Vd+kb7G29z8pSiKzR7D008/zSuvvMLZs2fp0aMHOTk5TJw4kR07dnD06FHGjx/P5MmTiY2NrXI/L774IjNnzuTEiRNMnDiR++67j+vXr1e5zcqVK7n99tvx8vJi9uzZfPzxx2Vuf++993j00Ud58MEHOXnyJN9//z2RkZEAGAwGJkyYwG+//cbnn3/OmTNneOWVV9BoNDV6/Dt27OD8+fNs377dEtDS6XS8/PLLHD16lM8//5yrV68yb948yzbx8fGMGDECJycndu7cyeHDh5k/fz7FxcWMGDGCiIgIPvvsM8v6Op2O1atXM3/+/BqNTQghBGQX6DgVn9nYwxANJK+omG1nkjmWLrM0CSGEParNNbStvur7Onrs2LFs37693q+jK3P48GFmzpzJ3XffzcmTJ1m6dCnPPfccq1atAuDQoUP86U9/4qWXXuL8+fNs2bKFESNGAMbssHvuuYf58+dz9uxZdu3axbRp02z6nN1MyvdsIF+np8vzWxv8fs+8NA5XR9scwpdeeomxY8dafvf19aVnz56W319++WW+/fZbvv/++zJZSjebN28e99xzDwD/+Mc/+M9//sOBAwcYP358hesbDAZWrVrF22+/DcDdd9/NkiVLuHLlCuHh4QAsW7aMJUuW8Pjjj1u269+/PwA//fQTBw4c4OzZs3To0AGAiIiIGj9+Nzc3PvroozJle+bgkcFgwM/Pj7feeouBAweSk5ODu7s777zzDl5eXnz11VdotVoAyxgAFixYwMqVK3nqqacA+OGHHygoKGDmzJk1Hp8QQrR0L/5whrWH4/hwTj/Gdgls7OGIenY9t4hHvzyOg0rNXxt7MEIIIWyusa6hoX6vo729vQkPD8fT0xO1Wl1v19FVefPNNxk9ejTPPfccYLxGPXPmDK+99hrz5s0jNjYWNzc3Jk2ahIeHB+3ataN3796AMShVXFzMtGnTaNeuHQDdu3ev8RhqQjKlBAD9+vUr83tOTg5PPvkknTt3xtvbG3d3d86ePVtthLdHjx6Wn93c3PD09CxX8lba9u3byc3NZeLEiQD4+fkxduxYVqxYAUBKSgoJCQmMHj26wu2PHTtGmzZtygSDaqN79+7l+kgdPnyYyZMnExYWRmhoKLfccguA5Tk4duwYw4cPtwSkbjZv3jwuXbrE77//DsCqVauYOXMmbm5udRqrEEK0RCfiMgBYc7Dq9yFhH5y1xoznYkVVr5/OCiGEEHVR0XX0c889R9euXev1OroqZ8+eZejQoWWWDR06lIsXL6LX6xk7dizt2rUjIiKCP/zhD6xevZq8vDwAevbsyejRo+nevTt33XUXH374ITdu3KjVOKwlmVI24KLVcOalcVavbzAYyM7KxsPTw6pGaFXdr63cHCh58skn2b59O6+//jqRkZG4uLgwY8YMioqKqtzPzQEalUqFwWCodP2PP/6Y69ev4+LiYllmMBg4ceIEL774YpnlFanudrVaXe5kVqfTlVvv5sefm5vLuHHjGDduHJ999hkuLi5cv36dCRMmWJ6D6u47ICCAyZMns3LlSsLDw9m8eTO7du2qchshhBDlKYpC/I18AHadT+VGbhE+bjIhhT1zLnWOU1hsQOYfEUII+1LTa2hb37et3Hwd+dRTT7Ft2zZef/11OnToUG/X0XXh4eHBkSNH2LVrF9u2beP5559n6dKlHDx4EG9vb7Zv387evXvZtm0bb7/9Ns8++yz79++3VDLZmgSlbEClUtUo/c9gMFDsqMHV0aFOQan69NtvvzFv3jymTp0KGCO+MTExNr2P9PR0vvvuO7766iu6du1qWa7X6xk2bBjbtm1j/PjxhIWFsWPHDkumUmk9evQgLi6OCxcuVJgt5e/vT1JSEoqioFIZ+1IcO3as2rGdO3eO9PR0XnnlFUJCQsjKyirXbK5Hjx588skn6HS6SrOlHnjgAe655x7atGlD+/bty0WshRBCVC+roJjcIj0AxQaFzaeSuHdg20YelahPTg4l50cFOgMejTgWIYQQtlfTa+jmYu/evdx7771MnToVtVpdL9fR1encuTO//fZbmWW//fYbHTp0sPRednBwYMyYMYwZM4YXXngBb29vdu7cybRp01CpVAwdOpShQ4fy/PPP065dO7799lueeOKJehmv/b0KhE1ERUWxfv16Jk+ejEql4rnnnrN5pPazzz6jVatWzJw50xIwMps4cSIff/wx48ePZ+nSpTz88MMEBAQwYcIEsrOz+e2333jssccYOXIkI0aMYPr06bz55ptERkZy7tw5VCoV48ePZ9SoUaSmpvLqq68yY8YMtmzZwubNm/H09KxybG3btsXR0ZG3336bBx98kAMHDvD3v/+9zDqLFi3i7bff5u677+aZZ57By8uL33//nQEDBlhm8Bs3bhyenp4sW7aMl156yabPnxBCtBQJGfllft9wLF6CUnZOq1GjUavQGxQKivWNPRwhhBDCKpGRkfzwww9Mnz4djUZTL9fRZqmpqeUSLlq3bs2SJUvo378/L7/8MrNmzWLfvn3897//5d133wXgxx9/5PLly4wYMQIfHx82bdqEwWCgY8eO7N+/nx07dnDbbbcREBDA/v37SU1NpXPnzvXyGEB6SolKvPnmm/j4+DBkyBAmT57MuHHj6NOnj03vY8WKFUydOrVcQApg+vTpfP/996SlpTF37lzeeust3n33Xbp27cqkSZO4ePGiZd1169bRv39/7rnnHrp06cJf/vIX9HrjCWznzp159913eeedd+jZsycHDhzgySefrHZs/v7+rFq1im+++YZu3brx1ltv8eqrr5ZZp1WrVuzcuZOcnBxGjhxJ3759+fDDD8tkTanVaubNm4der2fOnDm1faqEEKJFMwelAj2dUKngwJXr5QJVwv44m7KlCnX1czIvhBBC2Nobb7yBt7c3w4YNq7fraLMvvviC3r17l/n68MMP6dOnD19//TVfffUV3bp14/nnn+ell16yzCTv7e3N+vXrufXWW+ncuTPvv/8+X375JV27dsXT05Pdu3czceJEOnTowN/+9jfeeOMNJkyYUC+PAUClSPfIcrKysvDy8iIzM7NcRk1BQYFlZjhnZ+da7d9gMJCVlWXpyC+atroerwULFpCamlqu/O9mtnhttXQ6nY5NmzYxceLESksqRdMhx6t5aczj9dm+GJ777jRjuwSSla9j/5XrPDOhEw+NbN+g4zCr6jyhJanv56HPy9u4nqtj46LBdG3ja/P9C9uS/+nNixyv5sNejlVLudZpadf6VR1Xa88T7P9ZEqKRZGZm8uuvv/LFF1/w2GOPNfZwhBCi2YrPKAAgxNuFO3uFAPDdsYTGHJJoAM4Oxr4XBZIpJYQQQtgtCUoJUU/uvPNObrvtNh5++GHGjh3b2MMRQohmy1yqF+ztzIRuQWg1Ks4kZnExObuRRybqk7PWeJoqPaWEEEII+yWNzoWoJ7t27WrsIQghhF0oCUq54OPmyMgO/vx0NoXvjiXw5LiOjTw6UV8cTZlS0lNKCCGEsF+SKSWEEEKIJq10UAooKeE7Ho+0xrRflkwpCUoJIYQQdkuCUkIIIYRosor1BpKySnpKAYzpHIiro4Zr1/M5ei2jEUcn6pNl9j0p3xNCCCHslgSlhBBCCNFkJWcXYlBAq1Hh7+4EgIujhnFdgwD47mh8Yw5P1CMnranRebFkSgkhhBD2SoJSQgghhGiyzKV7QV7OqNUqy/I7ewUD8OOJRIr1ErSwR5ZMKZ1kSgkhhBD2SoJSQgghhGiyLP2kvFzKLB8a6UcrN0fSc4v4LTq9MYYm6pmTg2RKCSGEEPZOglJCCCFEI1AUha8PXuNgzPXGHopVMvJ05BU3/P3Gm4JS5n5SZlqNmtt7tAbgu2NSwmePpNG5EEIIYf8kKCWsNmrUKBYvXtzYwxBCCLuw9nAcf1l3gvmrDpJf1LTLk9JzChn3n1955biGrHxdg953YoaxyXnwTUEpKCnh23oqqck/h6LmzD2lpHxPCCFEcybX0VWToFQLMHnyZMaPH1/hbXv27EGlUnHixAmb3V9+fj6+vr74+flRWFhos/0KIYS9yMgrYvnmcwBkFxTz44mERh5R1d7/JZrruToyi1R8sOdKg963pXyvgqBUn7Y+tPFxIbdIz45zyQ06LlH/Smbfk0wpIYQQDa+hrqNXrVqFt7d3nffTXElQqgVYsGAB27dvJy4urtxtK1eupF+/fvTo0cNm97du3Tq6du1Kp06d2LBhg832WxuKolBc3Aj1JkIIUYVXt57nem4RGlPj7i8OxNps31tOJTLh33s4EZdhk/0lZxXw6b6rlt9X7Yu1lNQ1hHhLUMq53G0qlcqSLfXdsaYd2BM1ZynfK5ZMKSGEEA2voa+jWyoJSrUAkyZNwt/fn1WrVpVZnpOTwzfffMOCBQtIT0/nnnvuISQkBFdXV7p3786XX35Zq/v7+OOPmT17NrNnz+bjjz8ud/vp06eZNGkSnp6eeHh4MHz4cKKjoy23r1ixgq5du+Lk5ETr1q1ZtGgRADExMahUKo4dO2ZZNyMjA5VKxa5duwDYtWsXKpWKzZs307dvX5ycnPj111+Jjo7mzjvvJDAwEHd3d/r3789PP/1UZlyFhYX83//9H6GhoTg5OREZGcnHH3+Moij06dOHN954o8z6x44dQ6VScenSpVo9T0KIlunYtQy+NAWh/nN3bxzUKo7GZnA2MavO+y7WG3j5x7OcTczi/9adRG9Q6rzPd36+RGGxgT5tvYn0VCgqNvDGtvN13q+1EirpKWV2Z68QAHadTyEzr2FLC0X9sjQ6l55SQgghGkFtrqN79uzJ2rVrbTqO2NhY7rzzTtzd3fH09GTmzJkkJ5dkiB8/fpxbbrkFDw8PPD096du3L4cOHQLg6tWrTJ48GR8fH9zc3OjatSubNm2y6fjqSoJStqAoUJRbsy9dXs23uflLse5iw8HBgTlz5rBq1SqUUtt888036PV67rnnHgoKCujbty8bN27k1KlTPPjgg/zhD3/gwIEDNXoqoqOj2bdvHzNnzmTmzJns2bOHq1dLPmGPj49nxIgRODk5sXPnTg4fPsz8+fMt2Uzvvfcejz76KA8++CAnT57k+++/JzIyskZjAHj66ad55ZVXOHv2LD169CAnJ4eJEyeyY8cOjh49yvjx45k8eTKxsSXZCXPmzOHLL7/kP//5D2fPnuWDDz7A3d0dlUrFfffdV+6f0cqVKxkxYkStxieEaJn0BoW/bTiJosC0PiHc3qM1Y7sEAlgCVXWx5XSSJbPobGIWXx2s2z7jbuRZxvXn0ZHc0c6YsfLt0XhOJ2TWbbBWyC7QkVVgfH9oXUlQqkOgB52CPNDpFTadSqz3MYmG42TKlCqUoJQQQtif2lxD2+qrHq+jFy5cyMMPP1zj6+jKGAwG7rzzTq5fv84vv/zC9u3buXz5MrNmzbKsc99999GmTRsOHjzI4cOHefrpp9FqtQA8+uijFBYWsnv3bk6ePMk///lP3N3dbTI2W3Fo7AHYBV0e/CPY6tXVgLct7vevCeDoZtWq8+fP57XXXuOXX35h1KhRgDGoMn36dLy8vPDy8uLJJ5+0rP/YY4+xdetWvv76awYMGGD1kFasWMGECRPw8fEBYNy4caxcuZKlS5cC8M477+Dl5cVXX31l+UPp0KGDZftly5axZMkSHn/8ccuy/v37W33/Zi+99BJjx461/O7r60vPnj0tv7/88st8++23fP/99yxatIgLFy7w9ddfs337dsaMGQNAREQEYPxHcO+997J8+XIOHDjAgAED0Ol0fPHFF7z++us1HpsQouX6Yv9VTsVn4eHswDMTOgNw78C2bD6VxLdH4nl6QidcHWv31qwoCh+a+j1FBbhzMSWH17eeZ1L3YLxctbXa59s7LqHTKwxp34pBEb5cPwe3dw9i48kklm86x2cLBqBSqWq1b2skZhqbnHu5aHF3qvx5mdI7hFc2n+O7Y/HcM6BtvY1HNCxnc6aUlO8JIYT9qeE1tE3V43X0okWL2LhxI9988w2DBg2q81B37NjByZMnuXLlCqGhoQB8+umndO3alYMHD9K/f39iY2N56qmn6NSpEwBRUVGW7WNjY5k+fTrdu3cHSq5xmxLJlGohOnXqxJAhQ1ixYgUAly5dYs+ePSxYsAAAvV7Pyy+/TPfu3fH19cXd3Z2tW7eWySSqjl6v55NPPmH27NmWZbNnz2bVqlUYDMZPOY8dO8bw4cMtAanSUlJSSEhIYPTo0XV5qAD069evzO85OTk8+eSTdO7cGW9vb9zd3Tl79qzl8R07dgyNRsPIkSMr3F/r1q2ZOHGi5fn74YcfKCws5K677qrzWIUQLUNqdiGvbjWWvf1lXEf8PZwAGNrej7a+rmQXFvPjidpn+hyJvcHxaxk4Oqj5/IGBRAW4cyNPx793XKzV/mLScll7xNhDYcltJR8eLBkbiaNGza+X0th9Ma3W47VGfBVNzkub3NN4Urv/ynUSMxuu35WoX+aeUtLoXAghRGOp6XW0p6cnO3furNF1dFXOnj1LaGioJSAF0KVLF7y9vTl79iwATzzxBA888ABjxozhlVdeKdMa509/+hPLli1j6NChvPDCCzad4MxWJFPKFrSuxmirlQwGA1nZ2Xh6eKBW1yEuqHWt0eoLFizgscce45133mHlypW0b9/eEoR57bXX+Pe//81bb71F9+7dcXNzY/HixRQVFVm9/61btxIfH18mlRCMf6g7duxg7NixuLhUfmFR1W2A5bkqnTqp01XcP8TNrWzk+8knn2T79u28/vrrREZG4uLiwowZMyyPr7r7BuPzN3fuXP71r3+xcuVKZs2ahatrzY6BEKLlWr7pLNkFxXQP8eLege0sy9VqFXcPCOXVLef5Yn8sM/uFVrGXyn38qzFLamqvEAI9nXl+chf+8PEBPt0Xw70DQ4kM8KjR/v694yJ6g8ItHf3p287X8v821MeVOYPb8dGvV1i+6SzDIv0sDdttraSfVPkm56WFeLswIMyXAzHX+fF4IgtHNL1PAUXNOZlm3yvQSaaUEELYnRpeQ9v8vmugJtfRLi4uPPbYYzW6jq6rpUuXcu+997Jx40Y2b97MCy+8wFdffcXUqVN54IEHGDduHBs3bmTbtm0sX76cN954g8cee6zBxlcdyZSyBZXKmP5Xky+ta823ufmrhiUTM2fORK1W88UXX/Dpp58yf/58S9nFb7/9xp133sns2bPp2bMnERERXLhwoUb7//jjj7n77rs5duxYma+7777b0vC8R48e7Nmzp8JgkoeHB2FhYezYsaPC/fv7+wOQmFiSSVC66XlVfvvtN+bNm8fUqVPp3r07QUFBxMTEWG7v3r07BoOBX375pdJ9TJw4ETc3N9577z22bNnC/PnzrbpvIYT4/XI664/Go1LBy1O6lQvi3NU3FAe1imPXMjiTUPOG59eu57HlVBIAC4aHAzA8yp8xnQMpNii89OPZMgH96lxMzmbDsXgAnhjbsdzti26NxNPZgXNJ2aw7Un5GGltJsDJTCuDO3qZZ+I7H19t4RMNy1hrL9yRTSggh7FBtrqFt9VXP19GlM5XqqnPnzly7do1r165Zlp05c4aMjAy6dOliWdahQwf+/Oc/s23bNqZNm8bKlSstt4WGhvLwww+zfv16lixZwocffmiz8dmCBKVaEHd3d2bNmsUzzzxDYmIi8+bNs9wWFRXF9u3b2bt3L2fPnuWhhx4q09G/Oqmpqfzwww/MnTuXbt26lfmaM2cOGzZs4Pr16yxatIisrCzuvvtuDh06xMWLF/nss884f95Y0rJ06VLeeOMN/vOf/3Dx4kWOHDnC22+/DRizmQYNGmRpYP7LL7/wt7/9zarxRUVFsX79eo4dO8bx48e59957LSWFAGFhYcydO5f58+ezYcMGrly5wq5du/j6668t62g0GubNm8czzzxDVFQUgwcPtvr5EUK0XDq9gec2nALgngFt6RXqXW4dfw8nxnUNAmrX8HzlbzEYFBjRwZ8OgSUZUX+7vTNajYrdF1L5+XyK1fv7108XUBQY1zWQ7m28yt3u7erIoluNkzy8ue0C+UX1k8mSkGHsKWVNUGpit9Y4qFWcis/iUkpOvYxHNCzJlBJCCNEU1OQ6+uGHHyYlxfpzLjO9Xl8uuePs2bOMGTOG7t27c99993HkyBEOHDjAnDlzGDlyJP369SM/P59Fixaxa9curl69ym+//cbBgwfp3NnYu3Tx4sVs3bqVK1eucOTIEX7++WfLbU2FBKVamAULFnDjxg3GjRtHcHBJY7m//e1v9OnTh3HjxjFq1CiCgoKYMmWK1fv99NNPcXNzq7Af1OjRo3FxceHzzz+nVatW7Ny5k5ycHEaOHEnfvn358MMPLT2m5s6dy1tvvcW7775L165dmTRpEhcvlvRDWbFiBcXFxfTt25fFixezbNkyq8b35ptv4uPjw5AhQ5g8eTLjxo2jT58+ZdZ57733mDFjBo888gidOnVi4cKF5ObmlllnwYIFFBUVcf/991v93AghWrYVv17hYkoOvm6O/GVc+awjM3OD7g1H48krKrZ6/1kFOtaYZtl7YFh4mdvC/NyYb1r28o9nKbIi4+RUfCabTiahUsGfx3aodL05g8MI8XYhKauAFb9dsXq8NWFtTykAHzdHRnYwZtR+f0yypeyBOVOqQGbfE0II0chqch19++2313j/OTk59O7du8zX5MmTUalUfPfdd/j4+DBixAjGjBlDREQEa9asAYyJE+np6cyZM4cOHTowc+ZMJkyYwIsvvggYg12PPvoonTt3Zvz48XTo0IF3333XNk+KjUhPqRZm8ODBFZZw+Pr6smHDhiq33bVrV6W3LVmyhCVLllR4m6OjIzdu3LD83qNHD7Zu3Vrpvh566CEeeuihCm/r3Lkze/fuLbOs9OMZNWpUhY8vLCyMnTt3lln26KOPlvnd2dmZN998kzfffLPM8tIZVfHx8Wi1WubMmVPp+IUQwiwhI9/SaPyZCZ3wdnWsdN0h7VvRrpUrV9Pz+OF4ArP6WzeL3JoD18gt0tMh0J3hUX7lbl90SyTrDsdzJS2XVXuv8OCI9lXu71/bjaXbk3sE0ynIs9L1nLUa/jK+I49/dYz3dkUzq38ofu5OVo3ZWtb2lDK7o1cwO86l8N3xBP48tkO9zgwo6p85U0rK94QQQjQ2a6+jDQYDWVlZeHqWnENVdR0NMG/evDLZVzdr27Yt3333XYW3OTo68uWXX1a6rbnqqCmTTCkhrFBYWEhcXBxLly7lrrvuIjAwsLGHJIRoBl7+8Qx5RXr6tfNhep82Va6rVqss2VJfHLhW5bpmxXoDK01ZSg8Mi6gwCOPhrOX/xhsztP6z4xKp2YWV7u9I7A12nEtBrYLFY6IqXc9sco9guoV4klNYzNu1nOWvMnqDQlKm9eV7AGO7BOLqqOFqeh7H4zJtOh7R8Ep6Skn5nhBCCGGvJCglhBXWrVtHeHg4GRkZvPrqq409HCFEM7DrfAqbTyWhUat4eUo31FbMUDejbxu0GhXHr2VwOqH6oMrmU0kkZBbg5+7IHb2CK11vep829GjjRU5hMa9vPV/peuYsqel92hDh717t/avVKv460diXYPX+WC6n2q6XU2p2IcUGBY1aRYCHdZlSro4O3NbF+KHBhqNSwtfcOWvNPaUkU0oIIYSwVxKUEsIK9957LzqdjsOHDxMSEtLYwxFCNHEFOj0vfH8agHlDwujcuvIyuNL83J24zcqG54qi8NGvxiyp2YPaWbJKKqJWq3hhclcAvj58jZMVZBH9fjmdPRfT0GpU/Gl09VlSZkPa+3FrpwCKDQqvbqk84FVT5n5SQZ7O5WYrrMqdvYz/o388kUixXoIZzZlzqfK9msweKYQQQojmQ4JSQgghhI29/0s0V9PzCPR0sqoMrrT7LA3PE8gtrLzh+ZHYGxy/loGjg5rZg9pVu9++7XyY0isYRYEXfzhd5iJfURTe3GbMkprVP5RQX9cajfnpCZ1Qq2DL6SQOxVyv0baVKeknZV3pntmwKD983RxJyynk98u2GYtoHI4OJYFW6SslhBBC2CcJSgkhhBA2dDU9l3d3RQPwt9u74OGsrdH2gyJaEdbKlZzCYn44nlDpeh/tMWZJTesdYnWD8f+b0AkXrYZDV2/wfal977mYxoGY6zg6qFl0S82CaAAdAj2Y2S8UgH9sOmuTrJYEy8x71pXumWk1al6Y3IUvFw5icPtWdR6HaDzm8j0wZh8KIYQQwv5IUKqWSs/IJoQtSGmCEBXTGxT+svY4/9xyrrGHUi1FUXjuu9MUFRsYFunHpB6ta7yP0g3PKyvhi03PY+vpJADmDwu3et+tvVx4ZJRx9r1XNp8jr6gYRVF4Y5ux7O4Pg9oR5FWzIJDZE2M74KLVcCQ2gy2nkmq1j9JKglI1y5QCYwnf4PatalT2J5oerUaNGuN7o2RKCSGEfZDraPtii+PpYINxtCiOjo6o1WoSEhLw9/fH0dGxxlNOGwwGioqKKCgoQK2WuGBT1xDHS1EUUlNTUalUaLU1y6oQwt6diMvg60NxADx2aySujk33revDPZfZfSEVR42aF+/sWuP3B7MZfdvw+rbzHI/L5FR8Jt1CvMrcvnLvFQwKjOjgT4dAjxrte+GICNYcukbcjXze/+Uy3UO8OB6XiYtWwx9NAavaCPB0ZuGICP6z4yL/3HKO0Z0DcXSo/f/M+Iyazbwn7JNWDYUGyZQSQojmzhbX0c1BS7nWVxSFoqIiUlNTUavVODo61npfTffMvolSq9WEh4eTmJhIQkLlZRVVURSF/Px8XFxc7PIP0d401PFSqVS0adMGjabyZsVCtET7Lqdbfo67kV/jIExDORhznX+aGn0/N7kL7a2Yva4yrdydGNc1iB9PJPLlgVj+PrW75bbMfB1fH7wGwAM1yJIyc9ZqeHZiZ/64+ggf/BJt6dk0b2iY1WWAlXlwRARf7I8lJj2PL/ZfZd7Qmo/PrLY9pYR9KQlKySfrQgjRnNniOro5aGnX+q6urrRt27ZOATgJStWCo6Mjbdu2pbi4GL2+5p/c6XQ6du/ezYgRIyQrphloqOOl1WolICWaJEVROJuYTWSAe50yX2prX3RJUOra9bwmGZRKyylk0RdH0BsU7ugZzOyBbeu8z3sHtuXHE4l8dyyBv07sjJuT8S17zcFYcov0dAh0Z3iUX632Pb5bEIMifPn98nUup+Xi4eTAQyMi6jxmdycHHh8dyXPfnebLA9fqFpTKrH35nrAf5n85kiklhBDNX12vo5uDlnStr9FocHBwqHPwTYJStWQus6rNC02j0VBcXIyzs7Pdv1DtgRwv0dIt33yO/+2+zNTeIfxrVq8Gve+iYgOHYm5Yfr92Pa9B798aeoPC418dJTmrkMgAd5ZP626TT8YGR7Qi3M+NK2m5fH88gXsGtKVYb2DVbzEAPDAsotb3o1KpeH5SVya9vQeDAguGh+PtWvu069LGdAnkue9Ocyk1hwKdHmdtzYPtuYXFZOTpgJo3Ohf2xVGCUkIIYVfqch3dHMi1Y83Zb5GjEEKIOlvx6xX+t/syAN8ejef3UqV0DeFEXAb5pS5G427kN+j9W+PfOy7y26V0XLQa3ruvjyWjqa5UKhX3DDDOaGdueL75VBIJmQX4uTtyR6/gOu2/S7Anz0/qwuSewTwwvO5ZUmZBns74ujmiNyicS8qu1T4STVlSHs4ONZ69UNgX8wR80uhcCCGEsE8SlBJCCFGhTScTeXnjGQAi/N0AeOG70xTrG+7i0Fy6Z55E7dqNppUp9cuFVN7eeRGA5dO6E2Xj0sIZfUNx1Kg5YWp4/tEeY4Bw9qB2tcpAutm8oeG8fU9v3G0USANjMK1rsCcApxMya7UPc5Nz6ScltJIpJYQQQtg1CUoJYSM6vYHY9KZ1wSxEbR24cp3Fa46hKPCHQe1Y/8ch+LhqOZ+czWe/X22wcZibnI/s4A/AtetNJ1MqISOfxV8dRVHgvoFtmdI7xOb34evmyPhuQQA8++1Jjsdl4uigZvagdja/L1vqYglKZdVqe3OTc+knJbRqBYACyZQSQggh7JIEpYSwAUVRePizw4x47We+Oxbf2MNp8gwGhW8OXeNUfO2yKET9upiczQOfHKSo2MBtXQJZekdXvF0deWpcJwDe3HaB1OzCeh9HYbGew1eN/aRm9jOWsTWVTKmiYgOPfnGEG3k6uoV48tykLvV2X/cMMDZNPx5n/HuZ1jukzrPk1beuwV6ALYJS0k+qpZNMKSGEEMK+SVBKCBv4/Per7DiXAsDS709zPbeokUfUtH15MJan1p7gyW+ON/ZQxE2SswqYt/IgWQXF9GnrzX/u6Y3GVDs3q38o3UO8yC4s5tUt5+p9LEdjMygsNuDv4cTIjsZMqeyCYjJNDbAb0yubz3E0NgNPZwfeu6+vTUrpKjMowtdSPgkwf1jtZ7RrKObyvXOJWbUq94yXTClhYp59r1CCUkIIIYRdkqCUEHUUnZrD3zedBYzTod/I0/H3jWcbeVRNV1aBjje2XQDgUkpOg/YnElXLLtAxd8UB4jPyifBz4+O5/csEWzRqFS/e2RWAbw7HcST2RmW7sglzP6lBEa1wdXTAz904O1xjZ0ttPpnIit+uAPDGzF6E+rrW6/2pVCr+YCrXu6WjPx1s3LeqPoS3csPVUUNhsYHLabk13t6cKSU9pURJppS8VwghhBD2qEkEpd555x3CwsJwdnZm4MCBHDhwoNJ1169fT79+/fD29sbNzY1evXrx2WeflVln3rx5qFSqMl/jx4+v74chmglFUfjyQGytG/CWptMbeGLNMQp0BoZF+vHJ/P6oVLDuSBx7L6XZYLT25787L1kyyYoNCgmmhsaicRUVG3j488OcS8rGz92JT+YPwMfNsdx6fdr6MKNvG8DY9FxvUOptTOZ+UoMifAFo42MM/sQ1YlDqSlouT609AcBDIyMY2yWwQe537uAw3p/dh3/N6tUg91dXarWKzq1r3+zc/H9BMqWst3z5cvr374+HhwcBAQFMmTKF8+fPV7vdN998Q6dOnXB2dqZ79+5s2rSpAUZrPUfL7HuSKSWEEELYo0YPSq1Zs4YnnniCF154gSNHjtCzZ0/GjRtHSkpKhev7+vry7LPPsm/fPk6cOMH999/P/fffz9atW8usN378eBITEy1fX375ZUM8HNEM/Hw+hWfWn+Su9/dx/FpGnfb1zs+XOB6XiaezA6/d1YO+7XyZPdCY0fDXb09KD4ybxKTlstKUYeJs+vj7SnrNsyiaqtTsQuauOMBXB2Ibeyg1oigK/7fuBL9dSsfVUcPKef2rzP75v/Gd8HBy4GR8JmsOXquXMRXo9ByLzQBgcEQrANr4GAMUjdXsvECn54+fHyansJgBYb48dVvHBrtvtVrF+G6t8XYtHyhsqswlfGdq2FfKYFBIzJTyvZr65ZdfePTRR/n999/Zvn07Op2O2267jdzcyv/H7t27l3vuuYcFCxZw9OhRpkyZwpQpUzh16lQDjrxqkiklhBBC2LdGD0q9+eabLFy4kPvvv58uXbrw/vvv4+rqyooVKypcf9SoUUydOpXOnTvTvn17Hn/8cXr06MGvv/5aZj0nJyeCgoIsXz4+Pg3xcEQzsOt8KgB5RXrmrTzApZScWu3n2LUM3t55CYBlU7vT2st48fTU+I4EeDgRk57Hf023C6Plm8+i0yuM6ODPiChjj6CYWpT2NFUrf7vCLxdSeXr9STYcbT4N71/dep5vj8ajUat4974+dG/jVeX6/h5O/HlsB9O257hRDz3Ujly9QZHeQKCnE+F+xn5K5kBZY5XvPf/dKVMmmSNv39sbB02jv4U2aV1rOQNfWk4hOr2CWgWBHk27oXtTsmXLFubNm0fXrl3p2bMnq1atIjY2lsOHD1e6zb///W/Gjx/PU089RefOnXn55Zfp06cP//3vfxtw5FWTRudCCCGEfXNozDsvKiri8OHDPPPMM5ZlarWaMWPGsG/fvmq3VxSFnTt3cv78ef75z3+WuW3Xrl0EBATg4+PDrbfeyrJly2jVqpXNH4NofvZcNJbV+bo5cj23iLkrDrD2j4MtQSVr5BfpeWLNMfQGhck9g7mjZ7DlNk9nLS/d2ZWHPz/C+79EM7lnMB2Dmn4PmPq2NzqNraeT0ahV/O32zqw7HAcYy6Hsgd6gsP5ISSDqyW+O4+vmyIgO/o04qup9ti+G93ZFA/DKtO6M6hhg1XZzBrdjzcFrnE/O5o3t51k2pbtNx2Uu3Rsc0QqVythoPdRUvnftesMHpdYdjuPrQ3GoVfCfu3sT6CmzwlWn9Ax8iqJYjmN1zE3OgzydJfBXB5mZxrJJX1/fStfZt28fTzzxRJll48aNY8OGDRWuX1hYSGFhycybWVnGgKNOp0Ons/0EBDqdztLoPK+ofu5D2I75+Mhxah7keDUfcqyaFzleJax9Dho1KJWWloZerycwsGxPjsDAQM6dq3xmp8zMTEJCQigsLESj0fDuu+8yduxYy+3jx49n2rRphIeHEx0dzV//+lcmTJjAvn370GjKz5DUGCdZpb+LhhN3I58rablo1Cq+eXAAD3x6hCvpecz5eD9fLBiAt6u23DYVHa+/bzzL5bRcAj2deH5ix3LH8tYOrRjdyZ8d51J5Zv0JvlzQH7Xaugsye6Q3KLz0wxkA7unfhnBfZ9qYpnq/kpZjs7+Fxvzb2n0xjaSsArxdtAxp78umU8n88fPDfD6/P91CPBt8PNbYdiaZ578/DcDjt7ZnSs+gGj13z93ekdkrDvHF/lhm9A62ZMZYq6rjZe7JNiDM23J7a09j6Vrs9bwGPcY6vYFXtxrfk/50ayT923m1yP/fNf37CvN1xkGtIjNfx9W0bKubll9LN2avtvZybrLPc1Mdl5nBYGDx4sUMHTqUbt26VbpeUlJShedgSUlJFa6/fPlyXnzxxXLLt23bhqtr/TT815reOy9diWXTpph6uQ9hW9u3b2/sIYgakOPVfMixal7keEFennUfJDdqUKq2PDw8OHbsGDk5OezYsYMnnniCiIgIRo0aBcDdd99tWbd79+706NGD9u3bs2vXLkaPHl1uf41xkgXyQm0Me5NVgIa2bgZO/b6LOe3grSwNF1NyuevtnTzaRY9jJTO7m4/X2RsqPj9nXGlaSB57d1V8HIe7wq9qDUdiM/jbqi0MC6q/htBN3b5kFeeSNLhoFDrrr7Bp0xWSM43H4kxsqs0b6zbG39aqC2pATXevQka7xXPJS82FTPjDx/v4czc9fk0ssSajEJYd1aAoKgYHGAjPO8+mTdU3Rb5Zn1ZqjqSr+fPn+3i8qx4rk2HKuPl4Ferh2DUNoCL/6gk2JRsbi6fmAzgQm57Dxo2banVftXEsXUVylgYPrUJozjk2bar8Q5OWoCZ/X4HOGuLzVHz24y56+Fr3P3BngvF/g5J7vck13Taz9iSrsTz66KOcOnWqXGuDunrmmWfKZFZlZWURGhrKbbfdhqen7YPvOp2OXZ/+BIB/UDATJ/aw+X0I29HpdGzfvp2xY8ei1Zb/kE80LXK8mg85Vs2LHK8S5mSf6jRqUMrPzw+NRkNycnKZ5cnJyQQFBVW6nVqtJjIyEoBevXpx9uxZli9fbglK3SwiIgI/Pz8uXbpUYVCqMU6yGvOF+s3hOJKzCnl0VITV5RT2YvNXx4FkJvePZOIt7QEYMCSbez46SExOMT9mBPHevb3QlioZKX28cnQKf//vPqCQOYPa8sTtnaq8v+KgqyzbdJ7NCU48PmNIiyz5yS4o5qW3fgWK+PNtnZg5xNgIPjGzgP+e2c2NIjW3jRtrkzKdxvrbysjT8eSBXYDCkqlD6BrsyS1jirnv44OcTcrmk6sefL1wAK3cm05/nG8Ox6M7cprOQR6seHhgrZ//3kMLGPfvX7mSbUAX0ospvYKr38iksuO151Ia+gNHCPZy5g9Th1v+TxUWG/j78Z/QGVQMHDkavwZ6Pld/fBC4wR+GtOeOMZENcp9NUW3+vn4pOMX6owm4tI5i4mjrnrvDG8/B1Vj6dYlg4m0d6jLkemPtSVZjWLRoET/++CO7d++mTZs2Va4bFBRUo3MwJycnnJzK/91ptdp6+59rnn2vSK+0+JP75qI+Xw/C9uR4NR9yrJoXOV5Y/fgbNSjl6OhI37592bFjB1OmTAGMKec7duxg0aJFVu/HYDCUKb+7WVxcHOnp6bRu3brC2xvjJKsh9l+RjLwi/vbdGQwKTOoZQlRgy+l1pDco7Lt8HYCRHQMtz33XNr6smNef2R/v55cLafztu7O8flfPcuV2Dg4OLP32JCnZhbT3d+Ovt3dBq60krcrk/mHt+eFEEsfjMvnHlgu8e1/f+nlwTdj/foomPbeICD835g2NQGtqENLG1wEnBzWFxQZScotp18rNZvfZ0H9bm8/Eo9MrdAryoGdbX1QqFb5aLZ8sGMD09/YSez2fhZ8f46sHB+Hm1DQSVI9cM/abuaVTAC7OtQ/utPXT8tjoKF7dcp5/br3I+O7BeDjX7Lm/+XgdvGoc2+D2fjg6OpZaz9hnKDGzgMRsHa193Gs9bmudT8rmQMwNNGoVfxgS1uJPLqBmf1/d23iz/mgC55JzrN4mKcv4fh7q69Zkn++mOC5FUXjsscf49ttv2bVrF+Hh4dVuM3jwYHbs2MHixYsty7Zv387gwYPrcaQ1I43OhRBCCPvW6B1En3jiCT788EM++eQTzp49yx//+Edyc3O5//77AZgzZ06ZRujLly9n+/btXL58mbNnz/LGG2/w2WefMXv2bABycnJ46qmn+P3334mJiWHHjh3ceeedREZGMm7cuEZ5jE3J7otpGEwVFLWdda65OhmfSWa+Dg9nB3reNLtYvzBf3r2vDxq1ivVH41m++Wy57b8/nsimk0k4qFW8Nas3ztUEpAA0ahX/mNYdjVrFppNJ7DibXO02Tc0/Np1l8PId/HSm5mOPTc9jxa9XAHj29s44OpT8y1GrVYSZAlHNvdn5N4eMTdvv6hdaJvswwMOZT+4fgK+bIyfjM3n488MUFTeNac0PxRgDtP3DKm+CbK0Fw8IJ93MjLaeQf/90sc772xdtanLevvzkFA3d7PzTfTEA3NYlsEaTIQij0s3OrZWQaWx0HmxlDyph9Oijj/L555/zxRdf4OHhQVJSEklJSeTn51vWufmc6vHHH2fLli288cYbnDt3jqVLl3Lo0KEafTBY38xvG4W6pvG/UwghhBC21ehBqVmzZvH666/z/PPP06tXL44dO8aWLVssjTdjY2NJTEy0rJ+bm8sjjzxC165dGTp0KOvWrePzzz/ngQceAECj0XDixAnuuOMOOnTowIIFC+jbty979uypMBuqpdl1LsXy8+VmHgioqT0XUgEY2t6vwlKlWzsF8up0Y7+KD/dc4YNfoi23XS+EFzca+8g8PjqK7jcFtarSNdiLB4YZP7F+bsMpcguLa/0YGlp2gY5Ve2NIzCzggU8P8drWc+gN1vfGWr75LEV6A8Oj/Li1U/lZ3cL8jAGGmGb8WjyXlMXJ+Ewc1KoKS9ci/N1ZMa8/LloNey6m8X/rTmCowXNYH1KyC4hJz0Olgj7tfOq8PycHDS9M7gLAyr0xXEjOrvW+cgqLORlvzpQqH5Rq42sMVMTdyC93m61lFej49qhxRsU5g8Pq/f7sUefWxmzcxMwCrucWWbVNQkYBIEGpmnrvvffIzMxk1KhRtG7d2vK1Zs0ayzo3n1MNGTKEL774gv/973/07NmTtWvXsmHDhiqbozc0S6ZUsWRKCSGEEPaoSdSRLFq0qNJP5Xbt2lXm92XLlrFs2bJK9+Xi4sLWrVttOTy7YTAo7DIFZgCiW1im1B7TbF7DovwqXWd63zak5xbyj03nWL75HD5ujtzZPZAvLqnJLiimd1tv/jiqfY3v+/ExUWw8mUjcjXze2HaB500X8E3djrMpFBUbcNFqyNfpeefnaI5fy+Tfd/eqtj/S75fT2XwqCbUK/nZ7lwr7l5kzpWLSm3bT4KqYs6RGdw6o9DnpFerNu7P78MAnh/j2aDwBnk48M6FzQw6zjEMxNwDoGOiBl4ttypBGdQxgbJdAtp9JZun3p1n9wMBa9aw7eOU6eoNCW1/XCmdra8hMqXWH48gr0tMh0J1BEXXPKGuJPJy1hLVyJSY9j9MJmQyP8q9y/fwivSV4JUGpmlGU6oPdN59TAdx1113cdddd9TAi25DyPSGEEMK+NXqmlGg4J+Izy3xSHd2Ms1NqKqewmCNXjRfiI6q5KHpwRHseGhEBwDPrT/LENye5mKXGRavmXzN71aohtKujA8umGD95XrX3CifiMmq8j8bw4wnjJ+oLR0Tw77t74aLV8OulNCa//StHY29Uup3eoPDyj2cAuHdgWzoGVdy7LMzPHJRqnq9Fnd7ABlMmzV19Q6tc95aOAbwyrTsAH/xy2VLW2BgO2rB0r7TnJ3XB0UHN3uh0tpyqeEr56uy7bCrdiyifJQUQ6msMStV3ppTBoPDZvqsA/GFwWIubFMKWalLCZy7dc3dywNO5SXxuJhqZo9oYbCtsIqXPQgghhLAtCUq1ID+bSvciA4zNgS+n5Fj1yao92H85nWKDQrtWrrRt5Vrt+k9P6MT0Pm3QGxQ2mi6u/zqhkyWIUhujOgZwR89gDAo8ve4kxfqmfYKdVaBjtymzblKP1tzZK4TvFg0lws+NhMwCZn6wj8/2xVT4Glp3OI7TCVl4ODvw5zGVz55lyZRqpgHSnedSSM8tws/diVEdqw52grHn1FPjOgLw8sYz/HA8ob6HWCFzplT/cNsGpUJ9XS0B3de3na9RqadZVf2kANr4GLNnrt2o30ypXy+lcTktFw8nB6b1DqnX+7J3XYKNs9haFZTKMPeTcpZAoAAkU0oIIYSwdxKUakF+Pm8MSs0bEoZaBdmFxaRmVz5roT3Zc9FUuhdZeeleaSqVilemd7f0QeribWBWv7pfmD43qQuezg6cScxi5W8xdd5fffrpTDJFegNRAe50MM3S2CHQg+8WDWV81yB0eoXnvjvNE18fJ7+o5GIhp7CYV7eeB4z9t6oq8ws3Bfmu3chH18SDdBUxl+5N6xNidQbdI6PaM3dwOxQFlnx9nMNXr9fnEMvJKSzmdIKxZ1P/sLr3k7rZwhEReLloiU7NtfRjslZmvs4ytsqCUuZMqYSM/FoFvaz1qSlLanrfNk1mxsTmqqslKJVZ7bolQSkp3RNGJUGp5vceIYQQQojqSVCqhUjNLuREnPGC4LYugZYLu+jU5pmhUlO7LxozfqrrZ1KaVqPm/dl9+WReXxZ0NNjkU3t/Dyeevd3YS+jN7Re4YWXj38aw0VS6d3uP1mWWezhreW92H56d2BmNWsW3R+OZ+u5vlhn03v35Emk5hYS1cq22OXSAhxPOWjV6g0J8AzSutqXU7EJLoPeuvm2s3k6lUvH85K6M7xpEkd7AWzaYra4mjsbewKBAiLdLvcwm5+ms5eGRxr5rb/10oUazDR64ch2DAhF+bgR6Ole4TpCnM1qNCp1eISmrwCZjvtm163nsOGecbfIPg9vVy320JObyvStpudVO9BAvTc7FTRxMb72SKSWEEELYJwlKtRC/mMqwuoV4EuDpTIQpQyU61f6bncdn5HM5NReNWlVp9kVlHB3UDGnfyjIltS3M7BdKhL8b+To9B2IaNkvGWpn5Oksg7/burcvdrlKpWDgigtUPDMTP3YlzSdnc8favfLovho9MvZKevd3YX6gqarXKUsJ3pZn1ldpwNB69QaFnqDdRgRX3zKqMRq3i2ds7o1IZs/ga8u/woKl0b4CNS/dKmzukHX7uTsTdyGfNoWtWb2cu3RtUxd+pRq2yBCzqq9n55/uvoigwPMqP9v7u9XIfLYm/hxMBHk4oinG2yqqYM6UqanIvWiZzplRhsaHFtBwQQgghWhIJSjVlRblwci3kZ9R5V+aMjls6GsvRzBdal1tAptSvpuBKzzZeNptprC5UKhUDw40X3ebm603N9jPJ6PQKHQM9qgy4DIpoxcY/DaNfOx+yC4t5/rvTFBUbGBrZijGdA6y6r+bYV0pRFL45bAy21CRLqrRQX1dGm8pDzQ21G8LBK8ZAaL96KN0zc3V0YNEtxmyp/+68aHWGg7nJ+aBKmpybmWfgq49m5wU6PV8fNB7b6jL9hPW6WtlXqnRPKSEAHEudqUqzcyGEEML+SFCqKfvt37BuAXw0Bm7E1Ho3xXqDpWH1KHNQytTsvCVkSu029ZOqSelefevbzhgQOGTLoFRGLPynDxz4sM67+vGEsQH3zaV7FQn0dObLBwcxf2g4AGoV/O32LlaXO7bzMwYYmlNQ6kRcJheSc3ByUDO5Z3Ct92MOeqw7HFdtWZMt6PQGjl4zNTm38cx7N7tnYFtCvF1Iziq0Kuh2I7eIs4nGgMWgiKrHFupbf5lSPxxP4EaejhBvF0tPOVF3lhn44q0MStVDaalonrSlg1LSV0oIIYSwOxKUasoubDF+T78IH42FhGO12s2R2AyyC4rxcdXSK9QbwFK+dznNvoNSeoPCb5fMQSnrmpw3hH6moNTJuEwKi23UJ+PidrgeDT//A4pr36sqI6+IX02BPGuCUmDsv/X85C6sfXgw3zw8hM6tPa2+v3BzplR6/c6mZkvmLKlxXYPqlH03LNKPCD83sguLa9wUvDZOJ2RRoDPg7aolsp7L0pwcNDw+OgqAd3ddIrtAV+X6+68Ys6QiA9wJ8Kg6S6aNKVPK1jPwKYrCJ/tiAJg9qB0atcz+ZiuWTKnEypudGwwKCZnSU0qUpVFj+VsssNX7pRBCCCGaDAlKNVW5aZB43PizfyfITYFVt8Oln2q8K3Pp3sgO/pYTO3OmVNyNfLtuHno6IZOMPB0eTg70NAXkmoJ2rVxp5eZIkd7AqfjqZ6SySv71ku8Xt9V6N9tOJ1NsUOjc2rPG/XT6hflassCsFeZnDko1bKZUsd5ATi2ykwp0er4/Zswku6tf7Ur3zNRqFbMHGRtpf7ovpt77pVhK99r5oG6AgMu0PiFE+LlxI0/Hil9jqlzX3E9qcDWlewBtfIwBi7jrti3fO3otg1PxWTg6qJnVP9Sm+27pzJlSF5JyKp1pMz23iKJiAyoVBHlJ+Z4o4WTqT2jP5ytCCCFESyVBqabq8i7j98BusGAbhI+Eohz4YhYcXV2jXf18ztRPqlQpSis3RzydHVCUhg8GNKQ9poyfwe1bodU0nZe7SqWyBG8O26qEL6/Ufo5/Wevd/HjSOOveJCuzpOoq3BSUiruRX+nFqq0pisLd//udAX//iR1nk2u07bYzyWQVFBPs5cyQ9nXPvpvetw2ujhouJOfw++X6bXx/MMbcT6p+S/fMHDRqFo/tAMBHey6TkVd5Bp/5sVszGYF59lBbZ0qZywwn9wjG183Rpvtu6UJ9XfBwdqBIb+BicsUZuubSvUAP5yb1/1o0vpKglJTvCSGEEPZGzvqaquidxu/tbwFnL7hvLXSfCYZi+O4R2P0aWJFVkZCRz7mkbFQqGFGqp5JKpSrpK5Viz0EpYy+tplS6Z2bpKxVjo6BUfqmAxoWtkFfzAMeN3CJLuePECmbdqw8BHk64aDXoDUq9zaZ2s1PxWRy6eoO8Ij0PfnaYb2owQ5x53el929ikvMvLRcvU3iGAMVuqviiKYulhVt/9pEqb1L01nYI8yC4s5v1fLle4TnpuEeeTs4Hqm5xDSaPzpKwCm5W/pmYXsvGEMSA7d0g7m+xTlFCpVHRpbW52XnF2qDQ5F5Vx1moAbFfuLoQQQogmQ4JSTZGilApK3Wr87uAIUz+AoYuNv+9cBj/+GfRVlx/tOm8MyvQO9cbnpk/+I/zMM/DZZ1+p3MJiSxZSU2pybmae/exI7A3blG2VDkIZdHBqXY13sfV0EnqDQtdgT0sGU31TqVS0a2UMMlxtoL5Sa009oTycHdAbFJ5ae4L3dkVXexwSMvL51RS0m1HLWfcqYm54vu1MMomZtp9RDiA6NZfruUU4OajpFmJ9z6+6UqtVPHlbRwBW7b1CSnZBuXUOmMoKOwV5WJWh5OfuiLNWjaJAYkb5/dXGmoOxFOkN9Az1pkcbb5vsU5RlaXZeyQx88ZaglPSTEmU5S6aUEEIIYbckKNUUpZyF7ERwcIa2Q0qWq9Uw9kWY+DqggsMrYc1sKKr8Qt7cT+qWjuVnkWofYAw62OsMfPuvpKPTK4T6uliCHk1J12AvHDVq0nKKbBOMMWdKtRtm/F6LEr6NptI9axuc24o5AHalAWbgKyzW891xY0+ot+/pzUMjIwD455ZzLNt4FoOh8sDU+iNxKAoMCPelXSvbBe06BnkwMNwXvUHhi/2xNttvaYdMpXs9Q71xctDUy31UZnTnAHqFelOgM/Duz9Hlbv/dFJSyJksKjIFMWzY7L9YbWG163ucOliyp+mJudn6mkqBUginAGCJBKXETJ1OmlPSUEkIIIeyPBKWaInOWVLuhoK2gjGHAQpj1mTFodWEzfDLZ2Bj9JoXFeksp1i0VTG1uzpSKTrXP8j1zP6lhkf6oVE1vFi1nrcaSsWKTvlLmTKkBC0GlgfjDkHrB6s3TcwrZa2o2fXsDle6ZtWvVcM3Od55NISNPR6CnE8Oj/HlmQmf+dntnAD7+9Qp//voYRcXlP41XFIW1h+MAuMuGWVJmc4eEAfDlgdh6KVE5YApKDWjA0j0zlUrFU+OM2VJf7I+1ZMSY/X7Z+Pq3pp+UWaip2fk1GzQ7/+lsMomZBbRyc2ywstWWqKvp/92ZxKwKg78JkiklKuGslUbnQgghhL2SoFRTdHPpXkU6T4Y534GLD8Qfgo9vg+tl+7UcvGLsmRPg4WT5hLq0SFOm1OXUnHqf9asxmINSI5pgPykzc8PpQ7YISpkzpfw7QtRY4881yJbaYird6x7iZdMsIGuE+xmzXmIaoHxv3RFjYGlq75KeUA8Mj+Bfs3rioFbx3bEEFnxykNybZuY7GHODmPQ8XB019RK4GNslkCBPZ9JyithyKsnm+zf3LjOXjTa0oZF+DI5oRZHewH9+umhZnlkEl9NyUalgUHgNglI2bHb+yV5jg/NZ/UMtvWuE7bX3d8fRQU1OYTGxFfSPS8iUoJSomKXReQUfGAghhBCieZOgVFOjK4Crvxl/riooBdB2EMzfBl5t4Xq0MTCVXTKTmLl0b1THijOF2vq6oVGryC3Sk5xVaLOH0BQkZuZzKSUHtQqbzJBWX/q0NfWVqmtQyqCH/Azjzy6+0PMe488n1oDBupN4c5Pnhi7dAwgzZ0rVc/leanYhP5v6rM3oG1Lmtqm92/DR3H64aDXsuZjGvR/+TnpOyd+FucH57d1b4+bkYPOxaTVq7h3YFoBP9sbYdN/JWQXEXs9DpYI+7RonKAXwpClbau2ROEsvu0tZxv9NXVp74uWqtXpf5mbndW2OfzE5m32X01Gr4L5BUrpXn7QaNZ2CPICK+0pJo3NRGWcHKd8TQggh7JUEpZqa2H1QXADuQRDQufr1/TvAA9vBNwJyU+HiVstNP5+rvJ8UgKODmrambAN7a3ZuzpLq0ca7Rhe6Dc08A9+FlGwy83W131FBJmDKdnPxgQ7jjbM2ZsVDzJ5qN0/NLuT3y41TugcQZuopFXcjr8LSOVv57lg8eoNCr1BvIgM8yt0+qmMAXywciI+rluNxmcx4fx/XrueRW1hs6bd1V7/Qehvf3QNC0WpUHInN4GRcxTOU1cZBU+le5yBPPJ0b7++hbzsfRncKQG9Q+JcpW+pipjEoNdjKflJmob7GbJq4G3Ur3/t0nzFLamyXQOll1ADMWbs3z8BXoNOTllMESE8pUZ6TqXyvUDKlhBBCCLsjQammpnTpnrV9kDyCoJ2pIbopUyomLZfLabk4qFUMraJ8rb2/fTY7bw6lewD+Hk60a+WKosDR2DpkS5n6SRVp3IjJ0Bl7kXWdZrzNihK+LaeTMCjQs42XpSyqIQV4OOHqqMGg2KYcqyKle0JVNXNe77Y+fPPwEEK8XbiSlsv09/bynx0XySvSE9bKlf71WP4W4OFsKQ38dF+MzfZrLt2rz7Fb64nbOgDww/EEziVlc9GUKVWTflKApdF5XB1eL9kFOtabyjnNMyCK+tWlkhn4EjONTc5dHTV4uTTdDxJE4zBnShVKppQQQghhdyQo1dRE/2z8Xl3p3s08TNkt2cZsjl2m0r1+YT5VZkZE+DftZuevbD7Hra/vKvepelUMBsXS4H1YlH99Dc1mzNlSdSrhM/WTSta5Mv29vcYgo7mE78z3UFh10HHjCeNsdJN6BNd+DHWgUqksfayu1lOz89MJWZxLysbRQc3kah5nZIA76/44hI6BHqRkF/LBbmO/thl929R70/w5ptnfvj+ewI3cIpvs05wp1a8RmpzfrGuwl6VE9Lnvz5BWoEKtgv7hNRubuXwvLaeIvKLiatau2IZjCeQW6Wnv78aQGgbFRO2UZEqVDUqVbnLeFCemEI1LGp0LIYQQ9kuCUk1JdjIknzT+HDGqZtu6Bxq/5xgzpcx9cyor3TNryplSiqKwev9VLqflMvuj/ZxPyrZquzOJWVzPLcLNUUPvtt71O0gbMAel6tTs3JQpdQN30nOL+MNH+4n36G4s69TlwrkfK900JbuA/VeM20/oHlT7MdSRudn5lbT6yZQyZ0mN7RJoVUlnkJczXz802JJdpFLBtD62n3XvZn3a+tA12JPCYgNfm/pY1UV2gY6zicYAQP8mEJQC+POYDqhVcOyaMdjcLbjmZYVerlo8nI29vWpbwveLpb9YqARCGkjnIE/UKkjLKSQlq8CyPF5m3hNVsDQ610n5nhBCCGFvJCjVlFzeZfwe1APca5jhUypTKr9Izz5Tf6BbOlUdlDJnSl1ugplS167nk11gzIC4kafjvo9+51JK9cGz3ReNF5qD2/uh1TT9l3i/dsZAwbFrGRTra3fCnX3DGIzMUNwJ9XUhIbOAP3x8gNzOdxlXOPZFpdtuOZWEokDvtt6WkqjG0K4em50XFRv47lg8UHXp3s28XLV8tmAgC4eH8+IdXRvkglmlUjHXVEr22e9X0RvqNjPmkdgMDIqxB1OQV9NoIB0Z4M70UgG+ATXMkjKrS7Nzg0GxZJDVtHRQ1J6Lo8byvlM6W8qcKRUiTc5FBZy00uhcCCGEsFdN/4q9JYneYfweObrm23qYMlyyk9l3OY2iYgMh3i5EBbhXuVl708VBfEY++UVN62TvlKlkLzLAnS6tPUnLKeLeD3+vNmjxq6mf1PAm3k/KLCrAHQ9nB/KK9JyzMhvsZhdiYgFQXH1Z8+BgQrxduJyWy2OnoowrXNkNmXEVbvvjcdOse43Q4Ly0cHNQqh7K93aeS+FGno4ADyeGR9bsdeGs1fDs7V0atOfQHb2C8XbVEncj3zJhQW0dMgVe+rdrGllSZn8aHYVWY8xOGhReu15X5mbntQlKnU82Ti7g6qihm6mkTDSMipqdW8r3vCRTSpTn7CCNzoUQQgh7JUGppsJgqH0/KSgJSuUkseusMWvmlk7+1Zak+Lo54m0qZbpSDxkqdWG+YOkf5sPnDwy09Pe598PfK70IzSsqtjR1bi5BKbVaRZ+2xovyw7Us4bsWbww4+foFEeztwmcLBuDn7sjOZFfOaLsDCpz4utx2SZkFHLxqDFpMbOSglHkGvvoISq0zNbOe2jsEh2aQPees1TDTNMvfp79frdO+DphKM2vas6m+hfq68s9p3RgdbGBYDQOFln1Ymp3XvHzP/Lz0befTLF4T9qSivlIJGcZSPinfExVxlkwpIYQQwm7JmXhTkXIaclNA6wqhA2u+vZupTM9QzOFz0UD1/aTM2luanTetvlKn4o0XLF2DvfB1c+TzBwbS3t+NhMwC7vnwd8sn66Xtv3KdIr0xSyzcFORoDurSVyo9p5C8DGPJYtsQY0lUhL87n8wfgIezAyvzBgOgHPsSlLKlYJtPJaIoxvtv7IvBsFbGAEP8jXyKbPhpeFpOoSXbaHoNSvca2+yB7VCpYPeFVC7X8m+zqNjAsWsZQNOYee9mk3u05o52BjTq2vVzMs8UWZsZG81BqYFNLFjXEnStYAa+BOkpJargZG50LplSQgghhN2RoFRTEb3T+D1sGDg41Xx7B0dwNWYbGLIScXRQW90npSk2O1cUhVPxpibIIcYLGH8PJ75YOIiwVq7E3cjn3g9/J7lUo1woW7rXnBoX96vDDHzbziTjhbHsz6tVoGV512AvVs7rz071IAoULar0C+jjjpTZduOJplG6B8bj6+aowaBAbC3KsSrz3bEEig0KPdt40SHQw2b7rW9tW7lyqymw/Fkts6VOJWRSWGzAx1VrCT7bkzY+5vK9mmVKKYrC/ivGvnsDI6SfVEMzZ0rFXs8jq0CHoiiWRuchEpQSFXB2kEwpIYQQwl5JUKqpMAelalO6Z2Yq4QtQZTAoohWujg5WbdYUm50nZxWSnluERq2iU1BJICHQ05kvFg6ijY8LMel53Pvh76RmF1pu32Nqcj48qoaN4htZz1Bv1Cpjb6/EzJpdYG86mYgPpoCiS9msj35hvrwxezjblf4AHNjwDoopWyoxM9+SmdXYpXtgbPBtbnZ+1YYlfOtMs+41pywpsz8MbgcYZw7MLSyu8fYHTdlA/cJ8m1WQ1lq1zZS6nJZLWk4Rjg5qerTxqo+hiSp4uzpagk9nEoyzpRYWG1CpINCrFh/KCLtXMvueBKWEEEIIeyNBqaagKA+u7jP+bJOg1A1u6Wh9UKYplu+Z+0lF+rtbekmYBXu78OXCQQR7OROdmsvsj/ZzPbeIpMwCLiTnoFLBkGY2m5abkwOdWxuzB2rSV+p6bhF7o9PxVpmCOK7lS7RGdQwgYPj9AHRM28rrm08BsOlkEmAs62oqs7KF+RmDDLbqb3Y6IZMziVk4atRM7hFsk302pBFR/oS1ciW7oJgNptkDa+Kgqb9aUyzdswVzplR2QTGZeTqrtzOX7vUO9cbJQVPN2qI+dCnVV8rcT8rf3UmOh6iQs6l8r1An5XtCCCGEvZGgVFMQuxf0heAZAn4dar0bnYux1CeADKv7SQFEmMr3LqfmYqjl9PNX0nIZ/9ZuS1ZKXVn6SYVUPCtWqK8rXywcRICHE+eTs5n90X42njSWovUI8cLHzdEm42hI5hI+c6N2a2w/k4TeoOCvMQVxXCrujzPw1mnkOfnjq8rh4q/reP+XaDaeSABgUhMK1oTZeAa+dYeNgZwxXQKa5WtCrVbxB9Osf5/uvWrJcrOGwaBw6GpJppQ9cnV0wM/deFxrki21/7KU7jW20jPwxUs/KVENJ9OHU4XFkiklhBBC2BsJSjUFlln3boE6lNjE6own+VGu2ZaZzKzR1tcVB7WKfJ2epJt6NFnr2z3HWJj+Kvt+/qFW29/slClTytwQtyJhfm58sXAQfu6OnEnM4uUfzwDNr3TPrI+5r1Ss9UGpjaZsJ2+VsacUrpUEHzQOuPa9G4Bpml95ZfM5jsRmoFLBhG5BtR+0jZlft1fT695TSqc38J0pu2hGMyzdM5vRtw0uWg3nk7NZW4Ogb3RqDhl5Opy1arpV8XfU3LWxzMBn3WvG2E9Kmpw3NvP/9jMJWZYm59JPSlTG2VK+J5lSQgghhL2RoFRTYIt+UsCJTGMJVke3ml3QazVq2ppmPqttXynt+e+YrtnDlKzPyS6wvoymMqfNTc6DK86UMosMcGf1A4PwcdValg2Lqt308o3NnM1yOiGLvKLq+wdl5BWx91IaThShNZj6alWSKQVAz3sAGOtwFG9TY/QBYb4EeDaN0j3AMmOiLcr3dp1PJT23CD93J0Y000AlgJeLloXDwwF4Zv1Jy0yC1TGX7vUK9cbRwX7/1Vv6SlnZ7DzuRj6JmQU4qFX0butdjyMTVTFnSl1MybH8vQd7N53/RaJpMZfxF0imlBBCCGF37PdKpbnISoSUM4AKIm6p9W4URWFvirGMJUSTUePt69JXKj4jH8ccYwZHlCqOo7E1v//SrucWkZBpzNjqUk1QCqBjkAefLRiIj6uWEG8X+rRtnv1zgr2cCfJ0Rm9QOH4ts9r1t51Jptig0D/AVNKldgCnKmaXC+wKQT3QKMX8PfI8APcNameLodtMO1NwNCEjv85lGmsPXwNgau9gHDTN+1/d4jEdmNIrmGKDwh9XH7aq79jBGGM2UH87Ld0zs8zAZ2WmlDlLqkcbL6sngxC219rLGR9XLXqDws/njYFWKd8TlZFG50IIIYT9at5XavbAnCUV3Lvy0isrnE7I4lKeMcvEQ5de4+1L+krVPCi163wKISrjfQaqMjh5KabG+yjN3OQ83M8ND2dtNWsbdQvxYvdfbmHbn0c026wQlUpF3zDrS/g2mXpo3d7eNFuVi2/15Z+mbKnblV84ufQ27ujZdPpJgbHRsZujBoMC167XvoQvPbeIHWeNF7rNcda9m6nVKl67qyejOvpToDMwf9VBLiRnV7lNSwlKhfqYM6Wse70cuGL8XzUgXPpJNSaVSmUp4Yu7IT2lRNWcpHxPCCGEsFvN8+rdntiodG/X+RSSFWNAQ5WTDDVoiAylM6VqXjb1y/lUglVplt9TL5+o8T5KMzc5tyZLqjQPZy1uTs0786FvW3Oz8+tVrpeZp+O3S8bnfESoabYqa4Ka3WeASgPxh/HIvlKnsdYHlUpl6SsVk1b7oNSPJxIpNih0D/GiU1DNXkdNlVaj5t37+tC7rTeZ+TrmfHzA0iD6ZomZ+cTdyEetwu5L1EJ9zZlS1pXvHZB+Uk1G15v+x0tPKVEZZ2l0LoQQQtgtCUo1JsUAl81NzusWlNobnU4q3sZfDDrIqzqocTNzUKqmmVJFxQZ+u5RGsKokO8uQcg6dvvafZpozpey5OXNl+lkypTKqnAlx+9lkdHqFjoEehDiZLsZdrChbdA+AyDHGn49/Wdfh1gtbzMD37THjzILT+4TYZExNhaujAyvm9icywJ2krALmfLyf67lF5dYz95Pq3NrT6mzD5iq0VKPz6mYnTM4qICY9D7UKS1aiaDw3f/AgmVKiMs7akkypmsxCKoQQQoimT4JSjSnpJOSlg6M7tOlfp11dSM5BhwPFzqZP/7MTa7R9e1P5XkJmAbmF1TfZNjt09TpFRYUEqDIsy9oZrnE2MatG91/a6QTjtt1C7CPDpSY6t/bERashM19XZX8vc+nexO6tSwKQVTU5L62XsYSPE2vA0PRKIcL8jEGG2jY7j8+F0wnZaDUq7uhlX0EpAB83Rz6dP4DWXs5Ep+Zy/6qD5f5mD7WQ0j0wBjJUKuPFalpO+QBdaeZ+Ul2CPfG082Bdc1B6dlVnrbrMhBVClObkoLH8XFjc9N63hBBCCFF7EpRqROoru4w/hA0HB8da7+dGbhFpOcbZ19QeQcaFOUk12oe3qyOt3IxjqEkw4JcLqQSqrqOm5JPLKFUch2Kq74lUkewCneX+u7bATCmtRk3PUOPjrqyZdWa+jj0XUwGY2D0I8k1BKVcrMz86TAAnL8iKh3M/1nnMtmbOlLqaXrvyvQOpxn9rozsF4utW+7+rpizY24XPFgzA21XL8WsZ/HH1EYpKXaiZM6VaQlDK0UFNkGkGyeqanVv6SYVJP6mmINzPDRdTWZYxuFhNTzzRYjmV6hVZKH2lhBBCCLsiQalGpLJR6d4lU0ZNiLcLas/WxoXZNQtKQUmz85rMwPfL+VRCKNtYPUodz6GrNSsfNDtjypIK9nK224BCdfq2M/WVqiQotcNUuhcV4E5UoAfkmdazNlNK6ww9Zhp//mYu7HgZ9Lq6Dttmwk09pWqTKaXTGziUZrywtYcG51WJDPBg5bz+uGg17L6QypPfHMdgUMjM13Euyfh31L+FlKhZ2+x8/2VTP6kI+w/WNQcatYrOrY0zhko/KVEVrUaF2hSzLJC+UkIIIYRdkaBUI9HoC1Fd22/8pa5BqRRjEKl9gDuYM6VqEZSqabPzxMx8ziVlE6I2NTlv3cv4TXWds1fiatX3wVy61zWk5WVJmfVrZ7xgPlJJUKpM6R6UypSqwYX2mBegx93GvmZ7XoePxkDq+VqP2ZbatTKXkubXePrvPZfSydGp8HXTMqqjf30Mr0np3daH92b3wUGt4vvjCbz04xmOXL2BokC7Vq4EmDKI7F0bU7PzuCqanafnFHLR9L+yJWSQNRfdTP/rg70kKCUqp1KpSpqdS6aUEEIIYVckKNVIWuWcQ2XQgVdbaNW+Tvu6mGy80IqqY1DKnCllbbPz3ReMJWR9vU1BrMBuKB7GQIl37hWuXbduNqzSTrXgJudm5tnSLqflkm4qyzTLKtCx+4IxCGgJStW0pxSAkwdM+wDuWgXO3pB4DD4YAfs/aPQ+U37ujrg7OaAo1We+3OzrQ3EA3NkzGK2mZfx7G9UxgDdm9gRg1d4YXvzhNFAS3GwJrMmUMpc0dgh0b7FZmE3RfQPbMbKDP/cMbNvYQxFNnDkoJZlSQgghhH1pGVdtTVBA9knjD5G3Qh37aJjL96IC3MG9dj2loOaZUrvOG4NSPTyyjQu82qDy7wRAZC1L+E7HmzKlgltek3Mzb1dHIgOMx+JIbEaZ23aeTaFIb6C9vxsdAo3r1CpTyqzrVHhknzFbr7gANv8FVk+HrIQ6PIK6UalUlmbnMTXoK3UlLZedptfkzL721+C8Knf2CuH5SV2AkuespZTuAYT6mmfgqzwQvt/UT2pguPSTako6BnnwyfwB9Ar1buyhiCbO2cE8A58EpYQQQgh7IkGpRhKQfcr4Qx1L9wAuJRuDQpFlMqWSa7yfCFNQ6kpaDgZD1aV3Or2BXy8aM3baOZiCIl5twBSU6qCKq7QnUmUKdHpLgK1bCy7fA+hn6it1c7PzjabSvdu7ty5pClybTKnSPINh9nqY8Bo4OEP0Tnh3MJxaX7v92YC5hC+mBn2lPv71MooCXbwNlqBeSzJ/WDiP3lKSddk/vCVlShlLv6pqdH7ANPPegBb0vAhhTyyZUlK+J4QQQtgVh8YeQIuUFY9HQQKKSo0qfESddpVTWExCZgFgCkql1758L9THBa1GRYHOQEJmPm1MJTEVORqbQXZhMT6uWjwKTQEwrzZgME5NH6WK55uYmmVKnUvKRm9Q8HN3JNDTqcbjtyd92vnw1cFrHC6VbZZdoOMXU8nkBHPpHtQtU8pMpYKBD0LEKFi/0FjOt/Z+uLAFJrwKLt6133cthJuCUlfSrQtK3cgtYu1hY+nercE172VmL568rSMezlr0BsWS+dgStDFlSiVk5KM3KGjUZbNPswp0nEk0ZmEOlKCUEM2So2RKCSGEEHZJMqUagXnWPSW4D7jUrcQm2tS418/dCW9Xx5JMqZwkqGGjcQeNmrBW5r5SVQcDdp1PAWBElB+qTGMwAK9QCOgMGMv3LiTnkJln/axup+KN/aS6BHu1+KnBzZlSx+MyKSo2fiq881wKRcUGIvzc6BRknLEKgx7yM4w/1zZTqjT/DvDATzDiKVCp4cQaeG8oXNld933XQJhpBr6rVgalPv/9KgU6A11aexDp2XKDUiqViodHtufRWyIbeygNKsjTGa1GhU6vkJRVUO72QzHXURTjzI4tpfm7EPamJFNKglJCCCGEPZGgVCNQm4NS4aPqvC/zbFJR5nIl90Djd30R5NesfA5Kmp1HV9Ps3JyxMzbCCYpM63qFgF8HANqo0nAjn8Ox1mdLnbY0OW+5/aTMwv3c8HVzpKjYYGn+XnrWPUvQriATMAVh6hjgtNBo4da/wfyt4BMOWXHw2VRIj7bN/q0Q1srUUyqt+p5SBTo9n+y7CsCCoWF1bdEmmiGNWkWwt6mEr4Jm5/vNpXsy654QzZaz1njKWlgs5XtCCCGEPZGgVEMz6FHFGLNOlIhb6ry7S+aglLnptYNTScZMLUr4zCU/VWVKpWQXcDrBWAoz1N+UleDqB1oXYwmZKTAWqYrnUIz1gTHzPlt6PykwZrz0aWsMMh25eoPcwmJLY/kJ3YNKVjT3k3L0AAcbzygWOgAe/hUCuxnLMuMP23b/VTBnSiVk5lf7qfh3x+JJyymktZczE7oFNsTwRBNU1Qx80k9KiOZPMqWEEEII+yRBqYaWeAxV/g10ahdj+V4dXUop1eTczNLsPLHG+4uwzMBXeabUL+ZZ99p44aMzlvHh1aZkBVOz8yh1vNXNznV6A+cSjY+lW7AEpQD6mkr4DsXcYMe5FAqLDYS1cqVL61KZZJZ+UvU005qTOwR1N/5sLtNsAK3cHPFwckBRILaCIIOZoih8tOcKAPcPDUOrkX9pLVWorzFT6uYZ+PKKijkZZ8w2HBghQSkhmitnB1NQSjKlhBBCCLsiV3ANLf0yioMLaR5djGVSdWQu36swKJVT8xn42ltRvmcu3RvZwb8kUFFBUCpSFc/xaxmWnkhVuZicQ5HegIezg+XisqXrF2aagS/2BptOVFC6B3Wfec8aniHG71nx9XcfN1GpVJZsqapm4Nt1IZWLKTm4Ozlw94C2DTU80QSZJ2a4eQa+I1czKDYohHi7VDl5gxCiaXMyl+9JppQQQghhVyQo1dB63EXxkoucCJ1T510V6PSWUpUyQSn3umdKJWcVklNYXO72Yr2BPRfTABjV0R8yrxlv8AotWcm/IwBdHeIpLNUTqSrmflJdgz1bfJNzs+4hXmg1KlKzC9l+1hhgnFh61j2wzcx71fEyBaUyGy4oBdDO3FeqimbnH+25DMCs/qF4Otc9yCuarzY+pkyp62UzpQ5cSQekdE+I5s6SKSVBKSGEEMKuSFCqMTg4U6Cte7nV5dRcDAp4uWjxd3cqucFSvlfzTCkvFy1+pn1driBb6nhcBpn5OrxctPRs411lplQnB2NQ7FBM9c3OLf2kpHTPwlmrsfTX0hsU2vq60vXmJvANminVcOV7YGz2DnClkmbnpxMy+e1SOhq1ivuHhjXgyERTFOpbcabU76Z+UgMlKCVEsyaNzoUQQgj7JEGpZuxSasnMe2Wyi+rQUwpKZuCrqNm5uZ/UsCg/HDTqioNSAZ0B8C9OwoUCq5qdn4o3ZUqF1GHmPUUxftmRvm1LgpflSvegYTKlLEGphPq7jwqEtTK+Dq9Wkin1samX1MTuraUsS1ganSdlFVBYbMykKNDpOXYtA5BMKSGaO2l0LoQQQtgnCUo1Y5eSK2hyDnXqKQUlM/BV1Fdql6mf1KgO/sYFlqBUqfI9V19wM94eqUrg8NUbKFUEi/QGhTOJdcyUMhhg1e3w6R12FZgy95UCmFh61j2zhsiUMpfv5aWDLr/qdW0ozM9UvldBT6nEzHy+P24Mki0cHt5gYxJNl5+7Iy5aDYoCiRnGWUFPxGVSVGzAz93JknknhGienCxBKcmUEkIIIeyJBKWasQqbnEOdekpBSbPzmzOl0nIKOWGaxWpkB3/Q60ruo3SmFFhK+Do7JJCeW8SVKppVx6Tnklekx1mrtvS0qrHsRLj6G1zZDQXV97BqLgZFtKKVmyM9Q73pHlJBwK4hMqWcvUFruqBvwGwpc6ZUQmZBuU/GV+2NodigMCDclx5tvBtsTKLpUqlUlr5S5hK+/ZeN/aQGRvhKrzohmjlz+Z5kSgkhhBD2RYJSzdilyoJSpXtK1SJrqLJMqT0XjVlSXVp7EuDpbAwEKQbQOFoyoyxMQakhnsZtDl2tvITPXLrXpbUnGnUtLxxLB0vsKCjl7erI7r/cwpoHB1V8Ud0QmVIqValm5w3XV8rXzREPZwcArqaX9AnKKSzmi/2xACwcHtFg4xFNnyUoZWp2fiBG+kkJYS+czI3OpaeUEEIIYVckKNVM6fQGS/ZRVKBH2RvdA43f9YWQX30/p5uZg1JX0nLRG0qCWrtM/aRGdbypdM8zBNQ3vZTMM/Bpk4Cqm52bm5x3rUuT86xSM8PZUVAKwM3JwdJLoxzz8XWte+P8Kln6SjXcDHwqlcqSLVV6Br6vD14ju6CYCD83RncKaLDxiKavdLNznd7AYVMwXPpJCdH8SaaUEEIIYZ8kKNVMXU3Po9ig4OaoIdjLueyNWmdwMQUpatFXKsTHBUcHNYXFBhIyjBkHeoPCblM/qZHl+km1Kb8TU6ZUiC4GsC5TqltdmpzbaaZUtRoiUwpKglKZDReUAggz9QEy95Uq1htY8ZuxwfmC4eGoa5tZJ+ySudn5tet5nIrPJK9Ij7erlg4BHtVsKYRo6pxNmVIy+54QQghhXyQo1UxdSjE2OW9/88x7ZnXoK6VRqwg3ZaiYS/hOxmdyI0+Hh5MDfdqZAl6Z14zfSzc5NzMFpVxy43CmkMupuaTnFJZbTVEUyZSqi4boKQUl5XsNmCkFEN7K1OzclCm19XQycTfy8XVzZHqfCoKhokUL9TX3lMrnwBXj30b/MF8JXgphB2T2PSGEEMI+SVCqmbqYXEk/KbPSfaVqIcLfHJQyBgN2nU8BYFiUH1qN6WVTVaaUuz+4tkKFwqhWGQCWUprS4m7kk5mvQ6tR0eHmMsSaaImZUkV5UGycZazBMqUaOChVkimVh6Io/G/PZQBmD2pXeUmjaLHamDKl4m/kWYJS0k9KCPtgLt8rlKCUEEIIYVckKNVMXUq1NihV2xn4yjY7/+Xm0j2oOigFlmypW3yNM2BVFJQ6nWAMIHUI9MDRoQ4vx5YYlDJnSakdwKmey5O8Gqd8r12pnlKHrt7g+LUMHB3UzBncrkHHIZoHc0+ptJwifjfPvBfeqjGHJISwEUujc52U7wkhhBD2RIJSzZQ5Uyqqsl4p5qBULXpKQUmm1OXUHG7kFnHsWgYAIzvWJChlbHbe08k4hoMVNDs3l+51q0vpHkB2CwxKle4nVd/T3XuajnFWw82+BxBuypRKzCzg7Z2XAJjeJwQ/d6cGHYdoHrxctJYZG3OL9Lg7OdC5tfSTEsIeWBqdF0umlBBCCGFPJCjVDOkNiiWDKaqyTKk69JSC0plSuey+mIqiQMdAD1p7uZSsZAlKVdBTCiyZUm31sQCcis8q1wvCJk3ODQbIKvU4W0pQqqH6SUFJplRBJhTm1P/9mfi4avE0BRnMjfYXDItosPsXzY+52TlA33Y+OGjkbU60DLt372by5MkEBwejUqnYsGFDtdusXr2anj174urqSuvWrZk/fz7p6en1P9haMJdsF0qmlBBCCGFX5Gy9GYq/kU9hsQFHB7WlXKUcG/WUSs0u5McTxoDPqNJZUgWZUGjMcrIELG5mbnaeeQk/dyeK9AZOxpcNGJ0yZUp1qUumVF4aGHQlv5vHZe8aauY9MJYHOpkCh6VLJeuZSqWy9JUCuLVTQOUlq0JQ0uwcYGCE9JMSLUdubi49e/bknXfesWr93377jTlz5rBgwQJOnz7NN998w4EDB1i4cGE9j7R2JFNKCCGEsE8SlGqGLppm3ovwc0NT2axSdewp5eGsJcDDWCL101ljYKvC0j0XX3B0u3lzI1NQSnXjCoNCjeuULuFLySogNbsQtYq6ldjc3HxbMqXqh6XZecOW8IW1Knl9PTA8vEHvWzQ/pTOlpMm5aEkmTJjAsmXLmDp1qlXr79u3j7CwMP70pz8RHh7OsGHDeOihhzhw4EA9j7R2SnpKSVBKCCGEsCcSlGqGLqVU0+QcyvaUUpRa3Y+5hE9RwM1RQ792pS7wqusnBeAeAM7eoBi41T8DgMMxJc3Ozf2k2vu74+roUKsxAuUzd1pKUCrP9Fy6+DTM/TVSs3Nz1l7XYE8GR0jTalE1c/aos1ZN9xDvxh2MEE3Y4MGDuXbtGps2bUJRFJKTk1m7di0TJ05s7KFVyFy+V6AzoNTyvEYIIYQQTU8dIgGisVxMqabJOZT0lCougIKMWgUuIvzd2GeawWpIpF/Z2fEyrxm/V9ZPCozNtwM6Q+w++rimAH4cjr2BwaCgVqss/aS6BtehnxSUBKUc3aEox/h4W4JGy5Rq2KDUvQPaEns9jwXDwlHVd0N30ez1busNGEs96zSjpxB2bujQoaxevZpZs2ZRUFBAcXExkydPrrL8r7CwkMLCQsvvWVnGD5d0Oh06na6yzWrNvE+dToem1PLc/EKctJqKNxKNpvTxEk2fHK/mQ45V8yLHq4S1z0GTCEq98847vPbaayQlJdGzZ0/efvttBgwYUOG669ev5x//+AeXLl1Cp9MRFRXFkiVL+MMf/mBZR1EUXnjhBT788EMyMjIYOnQo7733HlFRUQ31kOqVVZlSWmdjllJBhrGvVC2CUuZMKYCRHfzL3mhNphQYZ+CL3Udo8VWctQFk5OmITs0hKtCDUwnmJud1nHnPHCTx7wTxh1pQplQD9pSCkmOd2bDlewGezrw5s1eD3qdovnq08eanJ0YQVHpSBiFEOWfOnOHxxx/n+eefZ9y4cSQmJvLUU0/x8MMP8/HHH1e4zfLly3nxxRfLLd+2bRuurpX0uLSB7du3U2wA82nrD5u34tokzmBFRbZv397YQxA1IMer+ZBj1bzI8YK8vDyr1mv0t/Q1a9bwxBNP8P777zNw4EDeeustxo0bx/nz5wkICCi3vq+vL88++yydOnXC0dGRH3/8kfvvv5+AgADGjRsHwKuvvsp//vMfPvnkE8LDw3nuuecYN24cZ86cwdnZuaEfok0pimIJSkUFVtPw2SPIFJRKhIBONb4vc9kU3NTkHGoQlDLerybtPL1Cx/L75escunqDqEAPS/le17o0OYeSTKmAzi0rKNXgmVLBxu+2ypTKv2Fsnq6WT7uFbUVWlUUqhACMAaahQ4fy1FNPAdCjRw/c3NwYPnw4y5Yto3Xr1uW2eeaZZ3jiiScsv2dlZREaGsptt92Gp2cds54roNPp2L59O2PHjsXBwYGnDmzHoMCIW0Zb+l6KpqP08dJqtY09HFENOV7Nhxyr5kWOVwlzRnV1Gj0o9eabb7Jw4ULuv/9+AN5//302btzIihUrePrpp8utP2rUqDK/P/7443zyySf8+uuvjBs3DkVReOutt/jb3/7GnXfeCcCnn35KYGAgGzZs4O677673x1SfkrIKyCksRqNWlWkAXSGPIEg9Z+wrVQu9Q33wc3ekc2tP2vjc9AloTTKlAFLP06+DL79fvs7BmOtM6BZE3I18ALrYqnwvoLPxe0EWGAygtvPSnYbOlLKU79lg9r2MWHi7H3S4DWZ9Xvf9CSGEqJG8vDwcHMqeBmo0xg8JKuvZ5OTkhJNT+WCQVqut1xNv8/6dtRryivToFXWLP9Fvyur79SBsS45X8yHHqnmR44XVj79Rg1JFRUUcPnyYZ555xrJMrVYzZswY9u3bV+32iqKwc+dOzp8/zz//+U8Arly5QlJSEmPGjLGs5+XlxcCBA9m3b1+FQanG7JFQU+dMJW/tfF1QKXp0VcxCo3ELQA3oM+Ix1OK+XLWw58kRKBWM1SHjGiqg2L01SlX79olECyjXL9Mn2JildijmOsdjjQGVUB8XXB3qVnPrkBlnHItvB9MLWkGXewOcbfOpbVOtC3bISzc+bkfPqo+BrbgFGo9lZhzFdbw/1ZXfcNAXosTur/O+Smuqx0pUTI5X8yLHq0RTfA5ycnK4dOmS5fcrV65w7NgxfH19adu2Lc888wzx8fF8+umnAEyePJmFCxfy3nvvWcr3Fi9ezIABAwgODm6sh1Elc1CqoFhm4BNCCCHsRaMGpdLS0tDr9QQGBpZZHhgYyLlz5yrdLjMzk5CQEAoLC9FoNLz77ruMHTsWgKSkJMs+bt6n+babNWaPhJralagCNLgbcti0aVOV63ZJziUKiDn1O6cyIms3yAqoFD2TshJQATsOnafgeErlKysKEzWuaPV5FJ74ARVhxF7PZ9XWg4CaVqrcah9HlRSFSRlxaICfj1/lVpUWjaLj5y0byHf0q/1+K9DU6oInZKXgCOw+eIrsUzeqXb+uNIZCJgGqohy2/bCWYk3t/zY6Jm6hE0BuKps3/oCism0JX1M7VqJqcryaFzle1vdIaEiHDh3illtusfxuLrObO3cuq1atIjExkdjYWMvt8+bNIzs7m//+978sWbIEb29vbr31VsuHfE2Rk2nygoIqPpATQgghRPPS6OV7teHh4cGxY8fIyclhx44dPPHEE0RERJQr7bNWY/ZIqGlK377vz0BMHEO7tWfi2Kobt6sPXIPtGwn3c6GtLad4zopHfcyAotZy6x33gKrqMjlNaleIP8jYbgF0SPHgfHIOh284AsWM7tOBiSMjaj+WvOtojhk/sR41+W7UV/8JuSncMrgPBHar/X5LaZJ1wQY9DkeNF0XDx90J7uX7r9UH5cJfUOXf4LaBXUvKJWtBs2EDJIEKhQnD+4Fn+d4ltdEkj5WolByv5kWOVwlreyQ0pFGjRlVadgewatWqcssee+wxHnvssXoclW05m2bcK9AZGnkkQgghhLCVRg1K+fn5odFoSE4u2/MoOTmZoKCgSrdTq9VERhozf3r16sXZs2dZvnw5o0aNsmyXnJxcpklncnIyvXr1qnB/jd0joSYupxoDER1be1W/rbexB5A6NwW1LR9HrjHjTOUZjNbRikajAZ0g/iAO1y/RP7wz55NzyCooBqB7qE/dnuN8U5aWqx9aF3dw9oLcFLTFuWDjY9ek6oJzswDjxYfWMwA0DTQuzzaQfwNtXjJoe9R+P9cvW37UFqRBq7Y2GFyJJnWsRLXkeDUvcrys75EgbMucKVUo5XtCCCGE3WjUTtCOjo707duXHTt2WJYZDAZ27NjB4MGDrd6PwWCw9IQKDw8nKCiozD6zsrLYv39/jfbZVF1MyQYgMqCamfcA3E2BvexE2w7C0uQ81Lr1zRk1qefo165sU26bzbxnnhnO2bQ/e5+BzzzznpNnwwWkoOR5Nr8GakNRID265PfsistqhRBCiNIkU0oIIYSwP41evvfEE08wd+5c+vXrx4ABA3jrrbfIzc21zMY3Z84cQkJCWL58OWDs/9SvXz/at29PYWEhmzZt4rPPPuO9994DQKVSsXjxYpYtW0ZUVBTh4eE899xzBAcHM2XKlMZ6mDaRnlPIjTwdKhW097ciKOVhDkolGwMBKpVtBpJ5zfi9upn3zMwz8KWco99YH8viIE9n/Os6pXNWvPG7eWa4lhKUssy851P1erbmZYMZ+HJSoCi75HdbB02FEELYJWet9JQSQggh7E2jB6VmzZpFamoqzz//PElJSfTq1YstW7ZYGpXHxsaiVpckdOXm5vLII48QFxeHi4sLnTp14vPPP2fWrFmWdf7yl7+Qm5vLgw8+SEZGBsOGDWPLli04Ozs3+OOzpYspOQC08XHBxdGKxtDmoFRxvjFI4+Jtm4FYMqWsDUp1Mn6/Hk2Ih4YgT2eSsgroGmyDfl0tPVPK1bfq9WzNHPwzBwNrI/1S2d9zkiteTwghhCilJFNKglJCCCGEvWj0oBTAokWLWLRoUYW37dq1q8zvy5YtY9myZVXuT6VS8dJLL/HSSy/ZaohNwiVTUCrSmiwpAK2LMUhTkGm88G+soJRnCDh6QFE2qutXGBDuy/fHE+jRxgbjyTJl2ZQLSjW9JrQ2ZcmUauCglPmY16V87+aglGRKCSGEsIJl9r1iKd8TQggh7EWj9pQSNWMOSkUFeli/UX30lappTymVqqSEL/UsT0/oxOIxUSwYHl73sbTU8j17yJRyNL2OpaeUEEIIK5gzpQolU0oIIYSwGxKUakZq1OTcrHRfKVupaU8pKCnhSz1PsLcLi8d0wN3JBol6LbV8r9EypUxBqcx4Y5+y2jA3OW9nmnhAglJCCCGs4OxgCkpJppQQQghhNyQo1YxYyvdqFZSyUaZUQVZJwMccoLCGJVPqnG3GYWYJSt2cKZVh2/tpahorU8rDFPwrzof8G7XbhzlTqt1Q43cJSgkhhLCCNDoXQggh7I8EpZqJrAIdyVn/z959h7dZnn0f/2pZ8p7xyl5kL8hgz4RZNpRC30Ip3eXpSMdTOlgdjEJLaWn7AAVK2W0pu5CQEsIOkL13nDi2k3jbsmWt949LtyTbkq1xa9nn5zh83LIs3bpiKU50+jx/lwOIsSilV5i0NrZlKwJrFGOE5dPU8ch2fdYBqkCm7eJWUOVbl3RKJZTFBjll6nIsI3weNzTtUZfHnaKOnUfA7dJnfUIIIYYsCToXQgghhh4pSmUIrUuqosBKgc0S+R31zpSKNk9Ko3VKHd0Jbqc+a9G6pGxFkJUbuAxDvyildSklu1MKeo/wRaulBjxOMFmhag4YzYAXOg/rukQhhBBDjz/o3Cnje0IIIcRQIUWpDLGrwRdyXh5FdxJAfoU66pUpFUueFEDBKLDkqoJE01591tI35BzAVqCOQ70o5e+UKk7+Yxf4nvu2GHbg0/KkSiaAyQx52utTduATQggxMKt0SgkhhBBDjhSlMkRMIecA+b6xNt07paIsShmNMOIYdVmvXKm+IecwfMb3UpUpBfF1Sml5UqUT1dGfeSa5UkIIIQbm331Pgs6FEEKIIUOKUhkippBzCHSidDTEvltasFiLUgAjtFypJBSlHG3gGaL/afV6U5cpBYHvdyyZUv6i1CR1zJOilBBCiMhI0LkQQggx9EhRKkPsPKyN70XbKeV70++0q0JNvOIqSum8A59/fC9EUcrrgZ4OfR4n3Tjt4Fah9ynplNLG92LplGryje9pRSnplBJCCBEhm9k3viedUkIIIcSQIUWpDGDvcVHb0gXE0CmVlQtWX86SHrlS/kypKIPOAUZMVUe9duAL1SlltoEpS10eqiN8WpeU0QJZUb4e9KCN7+nRKaX3eKkQQoghyyqdUkIIIcSQI0WpDLDnSCdeL5TkZlGaZ43+BPk67cDncQcKQbF0SpX7ilJHd4LbFd9aIHRRymAY+rlSwXlSBkPyH18Llm87FN1IqLMbWnxFTX9RKmi8VAghhBiA1inlkKKUEEIIMWRIUSoDxBxyrsnT6Y1/RwN4XGAwBQpd0SgcA+ZsNXrWvC++tUDo3fdg6BelUpknBb4ioEE9j51HI79f817AC9ZCyC1T10mnlBBCiAhJ0LkQQggx9EhRKgPEHHKu0euNv5YnVTASjKbo76/nDnw9ndDd4ltPde+vDfWiVCp33gMwWQKFzraDkd8veOc9rcNLMqWEEEJESILOhRBCiKFHilIZYGdDjCHnGm1EKt5MKX+eVAyjexp/rlScRak2X4EtKy+QmaUZ6kUpf6dUcerWoBUCowk775snBYHd9zqPgtupz9qEEEIMSVqnVLdTOqWEEEKIoUKKUhlg15E065RKi6JU0M57fXOVtKKUHrsNpqOuZnVMVacUxBZ2HqoolVMKRjPghY7Dui1PCCHE0OPvlHJJp5QQQggxVEhRKs05XG72N9oBmFyeH9tJ9MqUSqeilFZg6zu6B8OoUyqFRakC32sgqqLUbnUsnRi4zmgMdEvJCJ8QQogBWM1ap5QUpYQQQoihQopSaW7fUTtuj5c8q5mKghh23oM065Saoo5Hd6rd/GIVLuQchn5RKp06peId34OgHfikKCWEECI8qz9TyoM3mt1fhRBCCJG2pCiV5oJDzg19x9Qi5Q+TboB4/hPnz5QaHfs5iseB2QaubmjZH/t52g6p44CdUi2xnz+ddaVDp1SU43tdLdB5RF0O7pQC2YFPCCFERLRMKYAet+RKCSGEEEOBFKXS3M7D7UAcIecQGN9zdoKjPfbz6NEpZTRB2WR1+XAcI3wRFaWGaKeUPcW770HgNRBpp1STb3QvrxKsfcZQddyBz7DuSRZv/gEc2R73uYQQQqQXmzlQlJKwcyGEEGJokKJUmgvulIqZNQ+yfIWAWHOlHB2BsbF4ilIQyJU6vCX2cww0vmcd4kWptOiU8hUD2w9FNoYZKk9Ko2OmlHHjM+T2HMa4/sm4zyWEECK9WEwGjL6mcYfkSgkhhBBDghSl0pxWlJpcEUdRCoK6UWIckdKKQNZCsBXEt5bKWepYvyH2c0inVGo7pfIqwWAEjyuyXfP8eVIhilJ6dko1q5FQ4/534z6XEEKI9GIwGILCzqVTSgghhBgKpCiVxlxuD3uOdAIwaUSMO+9pgnOlYuHPk4qzSwqgao461q2P7f4uRyCfaLgFnXvcgT9XKjulTOZAFpRWIBxIuJBzCMqUirMo5ewOFF3rNwY6+4QQQgwZNi3s3CWdUkIIIcRQIEWpNHaguYsetwebxcjI4uz4ThZvp5SWJ1UUR8i5pnK2OjbvUwHY0dL+DGYbZBf3/3qqilIed6CLKVG6WgBfWH2oP3sy+cPODw5+2wGLUjrtvtdSg8H3vTHghf3vx3c+IYQQaUcLO3dIp5QQQggxJEhRKo3tbFCh5BNH5GEyxrjznkYLO481U0qPkHNNTgkUjVGX6zdGf3+tMye/CkLtSBhclErmltErboPfTIJ97yXuMbQ8KWuh6lZKpUJfUWqwsHOvNyhTaoBOqc4j4HbGvp7mfb0/37sq9nMJIYRIS1pRSjqlhBBCiKFBilJpbFu9KkrFFXKu8Y9IxdkppUdRCuIb4fPnSYUY3YNAUcrrgZ6O6M8fq5oPweuGTx9L3GP486RS3CUFQZ1SgxSlOhrU82AwQvG4/l/PLgGjJXDbWDXvBcBlzFKf730n9nMJIYRIS1azb3xPgs6FEEKIISHqotS4ceO4/fbbqampScR6hI/X6+WFderN/qLxpfGfMO5MKa0opcP4HsRZlNJ23gsRcg5gyQ4UOZI5wmdvVMcdr6vcq0RIh533NFpRqnWQ8T1tdK9oDJit/b9uNAY6+WJ9fYK/U+pQ0UL1+eHN0Hk09vMJIYRIO/5OKRnfE0IIIYaEqItS3/3ud3n++eeZMGECS5Ys4ZlnnsHhSNAb8GHs433N7DnSSU6WiYvmhim+RCPuTCkdg84BquaqY1ydUmG+LwZDanKltKKUow32vJ2gx0iDnfc02vjeYEHnA+VJaeJ9fYK/KNWcMxHviGnqun2yC58QQgwl0iklhBBCDC0xFaXWrVvH6tWrmTZtGv/zP/9DVVUVN954I2vWrEnEGoelp1erTrSL5lSTZ9UhOyjP96Y/lvEojyeQG6T3+N7RHdDTGd19/Z1SYcb3IPlFKber925vW15MzOOkVaeU77Uw2PhesopSTWp8r9Najmfsyeq6fTLCJ4QQQ4k/6NwlnVJCCCHEUBBzptSxxx7L/fffz6FDh7jlllt4+OGHWbBgAXPnzuWRRx7Bm8yA6SGmxd7DqxvVm/OrF47R56TaDmc9HeBoj+6+HQ3gcYLBFChuxSuv3Jdz5YX6TdHdd7BOKQgqSrXFtLyoBRekALa/Gl9odzjp2CnVXqeKcuEMFHKuyY+jaAoqTN3XKWW3luPVilKSKyWEEEOKzSKdUkIIIcRQEnNRyul08txzz3HRRRfx/e9/n/nz5/Pwww9z+eWX85Of/ITPf/7zeq5zWHl+TS09Lg/TqwqYPapQn5Na8yHLF5gebW6PlhlUUK3vjm+x5kpFVZRKUqeU3ZddZC2EnFJVpErE6Fg6dUrlloPRrALlO+rD387fKTUx/G3i7ZTqOAyuLrwGI3ZLKd6xJwIGOLo9vpwqIYQQaSWQKSVFKSGEEGIoiLootWbNml4jezNmzGDTpk28++67XH/99fz85z/nzTff5N///nci1jvkeb1envlYje5dvXA0BoNBv5PH+sZf7zwpTSxFKbcT2n0FkHQa39PypPJGwNTPqMtbX0rA46RRp5TRCPm+wmBrmBE+t8s/Vjdwp5S2O+QAxa2B+Hbeo2AUXqMZsouhcpa6Tkb4hBBiyLCZZXxPCCGEGEqiLkotWLCAnTt38uc//5na2lruuecepk6d2us248eP53Of+5xuixxO1tQ0s6OhA5vFyMXzBii6xCLWXCn/zntpUJTqaAC8qkMnd0T426WqKJVTBtMvUpe3vgwenX+Tq40JZhfre95Y+cPOw+zA11qjRj9N1kAGVSh5ce4O6Rvd8xaPDVw3/lR13LsqtnMKIYRIO1YZ3xNCCCGGlKhnsfbs2cPYsWMHvE1ubi6PPvpozIsazp76SHUlXTi7mgKbRd+Tx9wplaCiVOVsdTyyFZzdYLENfp8239rzq1WnTjj+olRLXEuMWKdvfC+nFMadqh6/8wjUfAjjTtLvcdKpUwoC3WrhduDz50lNHPj5ind8z1eUoijoZ9O4U+CDP0qnlBBCDCEyvieEEEIMLVF3Sh0+fJiPPvqo3/UfffQRn3zyiS6LGq5au5y8ulG9uf+cXgHnwfxv/KMckUpUUapwlMpG8rjg8JbI7uPfeW+APClIQadUULHInAVTLlCf6z3Cl06ZUhDolAo3vhdJnhQExvfsR8HVE/06fCOC3uLxgevGngAGIzTtCb8+IYQQGcVmVv91lfE9IYQQYmiIuij1rW99iwMHDvS7vra2lm9961u6LGq4enFdLd1OD1Mq8jl2TJH+DxBzUUrLlBqt73oMhuhH+CIJOYfUBZ3nlqmjNsK35SXw6PQfZ683DTulfIXKcON7/qLUAHlSoP48Rl9nYOfh6Nehje8Fd0rZCqFqrros3VJCCDEkWKVTSgghhBhSoi5KbdmyhWOPPbbf9fPmzWPLlgi7XUQ/Xq+Xpz5KUMC5Jt0ypSCGolS6dkppmVKl6jjhDLXbYfshqP1Un8dw2sHtUJczrlNqkKKUwRB70RRCj+8BjD9FHfdKUUoIIYaCwPiedEoJIYQQQ0HURSmr1UpDQ/+iRl1dHWZz1BFVwmfdgRa21bdjNRu5dF4Cij8QW25PT2dgZCwtilJap9QgIfDJLkr5M6V8nVIWGxxzjrq89UV9HkPrkjJlQVauPueMl1YcbAtXlNqjjoMVpSD2XKkeO3SoQlav8T2QsHMhhBhibBJ0LoQQQgwpURelzj77bG666SZaWwNv9ltaWvjJT37CkiVLdF3ccPLMajUid8GsKgpzdA441+THsMOZ1gFjLQgUevSkFaUaNoPbOfjt/UWpqoFvl+pOKYDpF6vjlhfV6F28gvOkEtFJFwttfK/jcP8sKGdXYPQzkqJUXoU6Rtsp1bJfHW2FkF3U+2ujj1c7NbbWBLqphBBCZCyr2dcpJZlSQgghxJAQdVHqnnvu4cCBA4wdO5YzzjiDM844g/Hjx1NfX8+9996biDUOee3dTl5ar4otVy9KQMC5RitK9bSDoyOy+/jzpBLUvVU8XhW83A44sn3w26drp5Q/6ymoKDVpMZizoaUm8k6wSB4juzj+c+kltwxMVsDbv8Opaa+63lbY+/sSjhZ2Hm1RyhdyTvG4/l+z5sHI49RlGeETQoiMp3VKOaRTSgghhBgSoi5KjRw5kg0bNnD33Xczffp0jjvuOH7/+9+zceNGRo/WOQh7mHhx3SG6nG4mlecxf2wCCw7WfLD4xr4izZVKZJ4UgNEIlbPV5cEKNx6PymiC6DKl9OhSGojXGxR0HlR8ycqFyYvVZT124etKs5BzUB1b4Ub4gvOkIunsijVTSuuA6ju6pxnny5WSsHMhhMh4NumUEkIIIYaUmEKgcnNz+epXv6r3Woatp1ergPPPLUhQwHmw/Epo2q26WkonDn77RBelQI3w7X9XFaXmfT787TqPgMcFBmNg1CscrSjldatcLGuefuvty2kHV7e63LcjaPolsPVlNcJ35s/jG7tLx04pUK+N5r39w84jDTnXaEWpjliLUuNCf338KfDOPapTyutNn9FHIYQQUdOCzqVTSgghhBgaYk4m37JlCzU1NfT09M6Rueiii+Je1HCy8WArmw+1kWUycvmxCSz8aPxFqQjf+CerKAWDd0ppnTh5FWAaJHfLkqOyhDwu1S2VyKKUFnJusqod94JNPlsFkzfugsNboWJ67I/T1ayO6dQpBYFRyraDva9v3K2O0Ralou6UGmB8D2D0IvUctB+Cpj2RFWOFEEKkJQk6F0IIIYaWqItSe/bs4dJLL2Xjxo0YDAa8vtEorcPH7Zb/JETjKV+X1HmzKinOzUr8A0b7xt+fKZXA0UytKFW/ETxuMJpC364twtE9UN0wtkIVQN7dCoWDZFDFIzjkvG8Xjq0AJp4JO15XI3zxFKXsQUHn6UR7PsJ2SkVYBPJnSkW5+57WKVUSZnzPkg2jFqpuvL2rpCglhBAZzB907pTxPSGEEGIoiDpT6jvf+Q7jx4/n8OHD5OTksHnzZlatWsX8+fNZuXJlApY4dHU6XLy0Tr2R/9yCBAacB8uLckQqGZ1SZZNVILizM9BdE0o0RSkIjPA52uJb32C0YlFumDDv4F344pGOmVIQKPgNlCkVCe21aW/sv5NfOB4PNPt23wvXKQVqhA9UUUoIIdLIgQMHOHgw0Gm6evVqvvvd7/Lggw+mcFXpy98p5ZJfggohhBBDQdRFqQ8++IDbb7+dsrIyjEYjRqORk08+mTvuuINvf/vbiVjjkPXqxno6e9yML8vl+AlJKjRE0ynl8QQKDYksShlNUDlLXa7fEP522loG23lPk6wd+LSQ83A7zE05T40SHt4CR3fF8Tjp2inle20EF6W6mgPfl5IIO5NySsDoG8uMNIi/vU7t3Gg0B9YRij/s/N3EB98LIUQUrrnmGt566y0A6uvrWbJkCatXr+anP/0pt99+e4pXl34CmVLSKSWEEEIMBVEXpdxuN/n5+QCUlZVx6JDqXhk7dizbt2/Xd3VD3LOfqN+MXr0wCQHnmkiLUs374MMHwN2jgsW10apE8edKrQt/m1g7pRJelAoa3wsluxjGn6oub42jWyrdO6WCx/ca96hjflXkeV4GQ+B1FmlRShvdKxwNpgGmkUfNB7MNOg/DEfk5JYRIH5s2bWLhwoUAPPfcc8ycOZP333+fJ598ksceeyy1i0tD1qBOKa/8kkEIIYTIeFFnSs2cOZP169czfvx4Fi1axN13301WVhYPPvggEyZMSMQah6SDnbChtg2LyZCcgHNNuKKU2wk1H8LON2DHMjga9Ma9bMrgweLxiiTs3F+USrNOKS3oPKcs/G2mXQS7/6tG+E75fmyPk7adUr7nw34UnN1gsUU/uqfJr4DWmshzpQbbeU9jtqrA871vw753oHxqdOsSQogEcTqdWK1WAN58803/hjFTp06lri7KjL1hQOuU8nqhx+3xZ0wJIYQQIjNF3Sn1s5/9DI9HtUzffvvt7N27l1NOOYXXXnuN+++/X/cFDlXvN6hv/dkzKinNsybvgf2ZUg3QcQTWPQXPXQd3T4S/fQbe/4MqSBlMMPZkWHI7fOHfiV9XcFEq3G8+/eN70XZKtcS1tEEN1ikFMPUzquOsbn2gkBKtdO2Uyi5Wux1C4DnSilIlURaqow3iH2znvWCSKyWESEMzZszgL3/5C++88w7Lly/n3HPPBeDQoUOUlg7w78owZTUH/usqYedCCCFE5ou6U+qcc87xX540aRLbtm2jqamJ4uLi5I2gZTh7j4tPj6rv1TULkxRwrtHe9Dva4J7JQFABKKcUJi2BY85RO8ZlFyVvXSOmgilLdTW17O9fZPB6A90zkRalrAXqmKzxvXBB5wB5I2DsSapLZ+vLcOL/RPcYblfgz5FunVIGg3pOGnepolTpxDg6pbQd+CItSu1Tx3A77wUb5xuh3PeuykszRl2TF0II3d11111ceuml/OY3v+G6665jzhz1S5qXXnrJP9YnArJMRgwG9d8Ch9MN2Qnu5BZCCCFEQkVVlHI6nWRnZ7Nu3Tpmzpzpv76kJM3eJKe51zY10O02MKYkmxMmJPm3oNZ8yKvwZfZ4oXK2KkJNPgdGHqtCx1PBnAXl01WmVN36/kWprmZwdavLkeZb2YrUMdWZUpppF6mi1JaXoi9KBXd7ZRdHd99kKBipClGtfTqloi1K5VWoY7RFqUg6pUYeC5Zc1XF2eHMgXF8IIVLo9NNP5+jRo7S1tVFcHPj5/tWvfpWcnJwUriw9GQwGbGYTXU43Dpd0SgkhhBCZLqpWAYvFwpgxY3C7ZRveeGgB5589bhRGY5K7ywwG+Pw/4dIHYek2+Po7cObPYPSC1BWkNAPlSmljYbkjVD5QJJIedD5AphTAtAvV8eDq3qHgET2Gb3TPWjhwoHeqFAbtwOf1QuNu9XnMnVIR5qg0RTG+Z7LA2BPU5b3vRLcuIYRIkK6uLhwOh78gtX//fu677z62b99OeXl5ileXnmxa2LlT/j8qhBBCZLqo51d++tOf8pOf/ISmpqZErGfI21bfxroDrRgNXi6bF+EYmt6qZsOcq6AgwTvqRWvAolSUO+9BCoLOB+mUKqhSYdsA216J7jH8eVJp2CUFgbDztlrV5eTsVBlakRSLguUHZZ4NxtGuwtUh8scZ58uV2idFKSFEerj44ot5/PHHAWhpaWHRokXce++9XHLJJfz5z39O8erSkxZ2LplSQgghROaLuij1xz/+kVWrVlFdXc2UKVM49thje32IgW3y7bg3q9jLiPwkBpxngqq56nhoXf+wc61TKj/NilIetxothMGLUqBG+ECN8EUjXXfe0xT6ilKttYHRvaKxaiwzGv6g8wg6pZr3q2N2SeC5HowWdr7vPfXcCSFEiq1Zs4ZTTlE/m/75z39SUVHB/v37efzxx2UDmTD8RSmX/BwXQgghMl3Uc0CXXHJJApYxfFxx3ChOnVTMK6+/meqlpJ+K6WrXP/tRVZQI7opK106prmb8YfGR7Io3/SJY9lPY/x50HIa8CEcz0nXnPU1wp1SseVIQGN+zN4KrZ+CiVjQ772kq56gAfEcr1G+A6nnRr1EIIXRkt9vJz88HYNmyZVx22WUYjUaOP/549u/fn+LVpSdtBz4Z3xNCCCEyX9RFqVtuuSUR6xhWinOyKLWlehVpyJKtduE7vFmN8GVCUUrLk7IVqsyiwRSNUYWQQ2vVCN/8L0X4OGneKaUVpVoPxleUyi5WuzC6e9QIX9Ho8LeNZuc9jckMY0+EHa+rXCkpSgkhUmzSpEm88MILXHrppbzxxht873vfA+Dw4cMUFBSkeHXpyerrlHLI+J4QQgiR8WRPdJFewuVKaeN7WvEjEsFFqb7jgHqJNOQ8WCwjfOneKaWN73W3qA4kgNKJ0Z/HYIA8bYRvkB34otl5L9j4U9Ux1blSLodvjFDeVAkxnN1888384Ac/YNy4cSxcuJATTlAbMixbtox58yIvnK9atYoLL7yQ6upqDAYDL7zwwqD3cTgc/PSnP2Xs2LFYrVbGjRvHI488EusfJWlsWqeUjO8JIYQQGS/qopTRaMRkMoX9ECIuVbPVsV9RKo5OKY8LnPb41xZKpCHnwaZfrI57V0F7BIHekP6dUrZCyFLjJ9R8pI6xdEpB5LlS0ey8F0wLO9//Prid0d1XTx/+CR47H96+M3VrEEKk3BVXXEFNTQ2ffPIJb7zxhv/6s846i9/97ncRn6ezs5M5c+bwwAMPRHyfz372s6xYsYK//vWvbN++naeffpopU6ZEtf5UkKBzIYQQYuiIenzv3//+d6/PnU4na9eu5W9/+xu33XabbgsTw1SoTimvVwVoQ3SdUlm5KqPK64buNvW53vydUlEUpUonwqgFcPBjePe3cN5dg98n3TulQHVLHdkGbof6PN6i1GA78Pk7paIY3wOomKnGBLuaVaj+6AXRrlAfdb6OstUPwclLwSIzvUIMV5WVlVRWVnLw4EEARo0axcKFC6M6x3nnncd5550X8e1ff/113n77bfbs2UNJifq3Zdy4cVE9ZqrYLJIpJYQQQgwVURelLr744n7XXXHFFcyYMYNnn32WG264QZeFiWGqcpY6ttVCxxHIGwGONnB2qusLqiI/l8GgOni6mtQIXzT3jZTd1ymVG0VRCuCMn8LfL4FPHoETvqWypgZ8HN8Of9nFUS8xaQp8RSkAsy26AmKwSDqlPG5oqVGXo+2UMhph7Ekq02vfqtQVpbQ/X1cTbP43zL06NesQQqSUx+Phl7/8Jffeey8dHR0A5Ofn8/3vf5+f/vSnGI2JSVp46aWXmD9/PnfffTd///vfyc3N5aKLLuIXv/gF2dnZIe/jcDhwOBz+z9va2gD1C0qnU//OU+2cfc9tMRoAsDsS87giNuGeL5Ge5PnKHPJcZRZ5vgIi/R5EXZQK5/jjj+erX/2qXqcTw5U1X3XYNO6C+vUwaXFgdM9WFH23U3BRKhG0sbpoOqUAJp6hso32roKVd8Ilfxr49pnQKRU8WlkyURV/YpEfQaZUWy14nCoUPZqRTs34U1VRau87cMr3Y1tnvLTXNcDHD0lRSohh6qc//Sl//etfufPOOznppJMAePfdd7n11lvp7u7mV7/6VUIed8+ePbz77rvYbDb+/e9/c/ToUb75zW/S2NjIo48+GvI+d9xxR8iu+GXLlpGTk5OQdQIsX7681+dH6o2AkfWbtvBay+aEPa6ITd/nS6Q3eb4yhzxXmUWeL7XDcCR0KUp1dXVx//33M3JkjJ0RQgSrmqOKUnVaUSqG0T1NonfgiyXoXHPWLfDwWbD+aTjx21A+dYDHSfNMKYDCUYHLsYSca/J9HW0DFaW00b2iMWCMIctOy5U68BG4esCcFf054uH19u4Eq/1UfYw8LrnrEEKk3N/+9jcefvhhLrroIv91s2fPZuTIkXzzm99MWFHK4/FgMBh48sknKSxU/1b+9re/5YorruBPf/pTyG6pm266iaVLl/o/b2trY/To0Zx99tkJ2SnQ6XSyfPlylixZgsUS2OH241e28tGRA4ybOJnzz4pxVFzoLtzzJdKTPF+ZQ56rzCLPV4DWUT2YqItSxcXFGAwG/+der5f29nZycnJ44oknoj2dEP1VzYFN/wrkSsUScq5JdFEqlqBzzaj5MPUzqmPnrV/CVWH+/ni9GdIpFVQ0jDVPCiCvQh0jKUpFO7qnKZ8WyJU6si0QsJ8s9kZw96jLMy5V43urH4ZLpSglxHDT1NTE1Kn9fykxdepUmpqaEva4VVVVjBw50l+QApg2bRper5eDBw8yefLkfvexWq1YrdZ+11ssloT+x7vv+XOs6rLTw7D/D386SvTrQehLnq/MIc9VZpHnK/J/o6MuSv3ud7/rVZQyGo2MGDGCRYsWUVycxnk3InP0DTuPqyjl+81td0vcywpJ65TKjaFTCuDMn8G2V2Hry+E7ZXo6AwWMtO6U0qko5e+UGiBTyr/zXpQh5xqDQRXRupqh80hs54iH9prOKYPjv6WKUpv+BWf/Mvp8MiFERpszZw5//OMfuf/++3td/8c//pHZsxNXMD/ppJP4xz/+QUdHB3l5eQDs2LEDo9HIqFGjBrl3atnMEnQuhBBCDBVRh7588Ytf5LrrrvN/fOELX+Dcc8+NqyD1wAMPMG7cOGw2G4sWLWL16tVhb/vQQw9xyimnUFxcTHFxMYsXL+53+y9+8YsYDIZeH+eee27M6xNJVun7T3jzPlU0yIjxvRgLCeXTYM7n1OUVt4e+jdYlZcpKzA6CeikIHt+Lpyjly5TqagKXI/Rt4u2UgkAhUet2Syat4FZQpTrmquaoXQvX/j35a4nEwU/hN5Nh7ZOpXokQQ87dd9/NI488wvTp07nhhhu44YYbmD59Oo899hj33HNPxOfp6Ohg3bp1rFu3DoC9e/eybt06amrUphA33XQT1157rf/211xzDaWlpVx//fVs2bKFVatW8cMf/pAvfelLYYPO04XVosa2pSglhBBCZL6oi1KPPvoo//jHP/pd/49//IO//e1vUS/g2WefZenSpdxyyy2sWbOGOXPmcM4553D48OGQt1+5ciVXX301b731Fh988IE/y6C2trbX7c4991zq6ur8H08//XTUaxMpklMS2I2ufiO0aW/gY+mUKlLHhBel4uhgOv0mMFpgz0rY83aIxwjKkwrqUkw7hSPBYAIM8RWlsovB5BsP6WgIfRtdilIj1DGVnVIFI9VzuuAr6vNP/qp2Fkw3W/4NnYdVV58QQlennXYaO3bs4NJLL6WlpYWWlhYuu+wyNm/ezN//Hnmh+pNPPmHevHnMmzcPgKVLlzJv3jxuvvlmAOrq6vwFKoC8vDyWL19OS0sL8+fP5/Of/zwXXnhhv46tdGT1d0p5UrwSIYQQQsQr6vG9O+64g//7v//rd315eTlf/epXue6666I6329/+1u+8pWvcP311wPwl7/8hVdffZVHHnmEH//4x/1u/+STvX9T//DDD/Ovf/2LFStW9PoNoNVqpbKyMqq1iDRSNQdaatQIX7pmSvXYwenbUSCWoHNN8ViYfz2sfhBW3AbjV/QuPmVCnhSoLq5L/qx2xYtnBM1ggPwK9fy31wcKlMGafeN7JTGO70HgObOnsFNKG1WcdQUs/7n6M+9cBlPOS/6aBtLg290qFd8rIYaB6urqfoHm69ev569//SsPPvhgROc4/fTT8Xq9Yb/+2GOP9btu6tSpGbk7kM3XKeVwpWERXwghhBBRibooVVNTw/jx/d8Ijh07ttdv4CLR09PDp59+yk033eS/zmg0snjxYj744IOIzmG323E6nZSU9H7DvnLlSsrLyykuLubMM8/kl7/8JaWlod8oOxwOHI7AmJCWEu90OnE6nVH9mSKhnTMR5x4qjOWzMG19Gc+hdRjaajEAzpxyiPJ7ZrTkYQI8XS24Y/x+h32+2hqwAF6jBZfRFvXaejnhu5jXPoGh9lNcm1/CO+V8/5cM7UcwAx5bUcx/hqSZfpk6xrlOU14lxpYaXC21eCv7nKu7FUtXs3qYvOpejxXN3y1jdol6bbQfTvr31dRyECPgzq3A43QCZoxzrsH04QN4PnoQ94TFSV3PYMz1mzAA3o7DuHT8XsnPwswiz1eAfA9Sy+Yf35NOKSGEECLTRV2UKi8vZ8OGDYwbN67X9evXrw9b9Ann6NGjuN1uKioqel1fUVHBtm3bIjrH//7v/1JdXc3ixYE3ceeeey6XXXYZ48ePZ/fu3fzkJz/hvPPO44MPPsBk6r99/B133MFtt93W7/ply5aRk5MT1Z8pGpn428lkKW91cALQvf0tcpwtACz7cBMu056ozjOqaR/HAUcP7uaD116La019n69C+z5OB7pNeSz7z3/iOjfAtJKzOKbhZeyv3MRbuzxgUOMJ44+8y2ygvrWHj+P8M2SKBR1eqoEtH61g757eU8b+77u5gDfeXBXy/pH83RpztI55wOG9m/koyd/X4/dsoALYsO8INe3qsXMc41mMAeOe//Lf5x+h05YenZ5ZzjbO61Tj1K62Bl5LwPdKfhZmFnm+1C/EROrYLBJ0LoQQQgwVURelrr76ar797W+Tn5/PqaeeCsDbb7/Nd77zHT73uc/pvsCB3HnnnTzzzDOsXLkSm83mvz54HbNmzWL27NlMnDiRlStXctZZZ/U7z0033cTSpUv9n7e1tfmzqgoKCnRft9PpZPny5SxZsmTYbxMZVsd8+P295DhVZpM3K5ezP3N51JlKhh1G2P9/lOVZOP/88we/Qwjhni/D7v/CdrAVV8d87l66T8L7wDsUdNdywehOvLOvAsD4zmY4CJXjp+nzOBnA+MY78MnHzBhTyrQzev+ZDVtfgu2QVTGl3/cjmr9bhh0GOPAI5XnGpH9fzQ/eAe0w68RzmDnxTP/1XsfrGHa/yRn5e/As+VJS1xSOYe/bsEldtrjtnH/2WWDuvyV8LORnYWaR5ytA66gWqWEz+zqlXNIpJYQQQmS6qItSv/jFL9i3bx9nnXUWZrO6u8fj4dprr+XXv/51VOcqKyvDZDLR0NA7zLihoWHQPKh77rmHO++8kzfffHPQLZMnTJhAWVkZu3btClmUslqtWK3932RZLJaE/sc70efPaMUjVd6OL3vHUDASS1ZW9OfJU917Rkcbxji/1/2erx6VU2XILdXnebSUwcnfhTdvxfzOXTDns2DOAod6HGNeWdx/hoxRqPLDTPYjmPr+mdsOAGAsGR/2+xHR360C9TPGaG9M/vfV97o2F4+G4Mde9DXY/Sam9U9jWnxzeuy2eLR316rF2QbZMeS7DUB+FmYWXZ8vexOseVztQpqfHt2BkdDjz3/ZZZcN+PWWlpa4H2Oosvo6pRzSKSWEEEJkvKh338vKyuLZZ59l+/btPPnkkzz//PPs3r2bRx55hKwoiwZZWVkcd9xxrFixwn+dx+NhxYoVnHDCCWHvd/fdd/OLX/yC119/nfnz5w/6OAcPHqSxsZGqqqqo1idSrGpO4HIsIeeQ2KDzTl/oczwh530t/BrkVarA608fU9cF7743XGhvTrVA8GBayHk8O+8B5Pqet84kh3c7u6C7RV3u+7qetFj9uRytsLH/LqcpoYWca1KxW6EYuj75K7x5C7z/h1SvJOkKCwsH/Bg7dmyvDVxEQCBTSopSQgghRKaLulNKM3nyZCZPnhz3ApYuXcp1113H/PnzWbhwIffddx+dnZ3+3fiuvfZaRo4cyR133AHAXXfdxc0338xTTz3FuHHjqK+vB9TWxnl5eXR0dHDbbbdx+eWXU1lZye7du/nRj37EpEmTOOecc+Jer0iiqjmw43V1uWBkbOfQilKONvB6ox7/G5BdjRaSE8dOc31l5cBpP4RXvw+rfgPzPp85u+/pyV+Uqu//teZ96hjPznsAuSPU0dkJPZ3J60rSdpO05ARenxqjERZ8GZb9DFY/DMdep+9rNhYNG3t/nuwinhjaWg+qY6i/60Pco48+muolZCxtfM8h43tCCCFExou6U+ryyy/nrrvu6nf93XffzZVXXhn1Aq666iruuecebr75ZubOncu6det4/fXX/eHnNTU11NUFuiX+/Oc/09PTwxVXXEFVVZX/45577gHAZDKxYcMGLrroIo455hhuuOEGjjvuON55552QI3oijenZKeXuAVd3/GsKphWlcnXslAKYd63qluk8DB/+eZh2Svm6GgcqSsXbKZWVB2ZfFl0yCy1a91d+VeiC09zPq3U1bIQDHyVvXaG4nXBku7pc7CsCSlFK6El7PWndg0JEQILOhRBCiKEj6k6pVatWceutt/a7/rzzzuPee++NaRE33ngjN954Y8ivrVy5stfn+/btG/Bc2dnZvPHGGzGtQ6QZPYpSWXlqFzuvR43wWbL1WRuAXRvf07FTClSO1Bk/hee/Au/dHwiVHk6dUnm+HTm7msDlCHwP3E5oUZlScRelDAY1etl2UD2XxWPjO1+ktE6pcK/pnBKYdQWsfQJWPwRjjk/OukJp3KUKuln5MPJYNTppl6KU0JFWlOpqSekyRGYJjO9Jp5QQQgiR6aLulOro6AiZHWWxWGQ3GqGvgpGBgk9+jEUpgyFxuVJaB5PeRSmAmVdA+QyVLdR5WF03nDqlsovB5CtEBXdLtR4Er1t1EuXpEIqcilwprSiVP0DG3YKvqOOWF6G9IfztEq3et+1exXTILVeXJVNK6MkunVIielrQebfLjdfrTfFqhBBCCBGPqItSs2bN4tlnn+13/TPPPMP06dN1WZQQgCoonbwUxp0C406K/TyJKkp1JqhTClS20Fk/733dcOqUMhgCuVIdQUUZbXSvaKz6HsVLy5VKZqFFG98rGKAoVT0XRi0EjxPW/C0pywqpQStKzYRc3+tcxveEnrS/e13NqV2HyChWX6aU1ws9bumWEkIIITJZ1ON7P//5z7nsssvYvXs3Z555JgArVqzgqaee4p///KfuCxTD3Ik3qo94WAvUUfdOqQQEnQc75lxVmDi4Wn1uK0rM46Sr/Epo2d97Bz69dt7TpKIo5R/fGyS8f+FX1HP/yaOqOGuKeV+K2Gk771XMAKN6EyhFKaEbtzPwc7mrRf/NKMSQpWVKgQo714pUQgghhMg8UbcaXHjhhbzwwgvs2rWLb37zm3z/+9+ntraW//73v0yaNCkRaxQiPonolPJ4Arvi6R10rjEYYPEt6nLhmNQUJVIp1A58eu28p0lF909w0PlApl+sMq/aD8H2VxO/rlCCO6VyfK9zyZQSetEK+6DGcns6UrcWkVGyTEZ//VLCzoUQQojMFtP8ywUXXMB7771HZ2cne/bs4bOf/Sw/+MEPmDNnzuB3FiLZ/EWpFv3O2d2iwtMhsVlP406GL7wAVz+VuMdIV6F24NNr5z2Nv1MqmZlS2vjeIDlpZiscd526vPqhxK4plM7GQAGtYnpqusrE0Nb3tSQjfCJCBoMBm687yiFh50IIIURGizmUZdWqVVx33XVUV1dz7733cuaZZ/Lhhx/quTYh9KGNvenZKaX9ht9aqHbLS6SJZ0DlrMQ+RjrSduALLko1Zfj4nscdeacUwHHXq90j970Dh7cmdm19HfaN7hWPA2t+UCh8Y9i7CBGVvsVg2YFPREEb4ZNOKSGEECKzRVWUqq+v584772Ty5MlceeWVFBQU4HA4eOGFF7jzzjtZsGBBotYpROwSMb7nDzkfRuHjyebvlPIVcbzeoE4pvcb3klyU6jyixpQMxkDRbSBFo2HK+eryxw8ndm191QeN7kGgKNXTDs6u5K5FDE32PgVO2YFPREHLkeqWTikhhBAio0VclLrwwguZMmUKGzZs4L777uPQoUP84Q9/SOTahNBHIopSiQ45F/133+tqBkebulw0Rp/H0J6/vm+OE0ULOc8tjzwjbOFX1HH9M9Ddlph1heIPOfcVpawFYLSoyxJ2LvTQb3yvJSXLEJlJ65RyuKRTSgghhMhkERel/vOf/3DDDTdw2223ccEFF2AyyU4nIkMksiiVqJBzERR07uuU0nbey6uErBx9HiO4U8rr1eecA2mPME8q2PjToGSCCoHe905i1hWKP+R8hjoaDIHvl4SdCz30G9+TTCkROZtFOqWEEEKIoSDiotS7775Le3s7xx13HIsWLeKPf/wjR4/KGxORARJSlNLG96RTKmG0olRXMzi79d95DwJFRXdPoAsrkbROqWiKUgYDjJimLgfnayWS2xXIsNKKUpCa3QrF0NW3uCnjeyIKVn9RSjqlhBBCiEwWcVHq+OOP56GHHqKuro6vfe1rPPPMM1RXV+PxeFi+fDnt7e2JXKcQsUtIUapJHaUolTi2IjDb1OWOBv133gOwZENWvrqcjEJLNCHnwfJ8HUodh/VdTzhNu8HtAEtu7/yuVOxWKIYu7XVksqqjjO+JKNjMvqBzGd8TQgghMlrUu+/l5ubypS99iXfffZeNGzfy/e9/nzvvvJPy8nIuuuiiRKxRiPgkNOhcilIJYzD03oFP7533NMns/vF3SkVblPJ9HzqTVJTyj+5NB2PQPxM52g58SQqGF0Ob9neuZII6SqeUiIKM7wkhhBBDQ9RFqWBTpkzh7rvv5uDBgzz99NN6rUkIffmLUjqOZ0mmVHIE78Cn9857mmTuwKcVpfKjGN+DwBqT1SlV3ydPqu86JFNK6EF7HZVNUkfJlBJRsGqdUjK+J4QQQmS0uIpSGpPJxCWXXMJLL72kx+mE0Jfsvpe5gnfga96vLuveKZXEolQsQecQ6JTSdiJMtL4772kkU0roSXsdlWpFqZaULUVkHq1TyuGSTikhhBAik+lSlBIirWlFKbdDBWbrQYLOk0MrSrXUQNtBdVn3opQ2kpaM8b14i1LJGt8LV5SSTCmhE7czMK5XOlkdZXxPRMFmkU4pIYQQYiiQopQY+rLywOB7qevVLSVB58mhFaUOrAavByw5kFeu72NoOUmJHklztEOPb0OIeILOvV5919WXvSlQAKyY3vtryewqE0Ob1m1qMAZ21JTxPREFf6eUFKWEEEKIjCZFKTH0GY1g9e2wpkdRytkNPR3qshSlEksr3hxaq47F41QAup6SVWjRuqSsBWDNi+6+ub5CnKtLFbcS6fAWdSwaE+gy1CSrgCeGPq3bLrtEfYCM74mo+IPOZXxPCCGEyGhSlBLDg565Utpv+I3m/m/ahb60sTWPUx31Ht2DJBalatUx2i4pUEWsLF8hK9HrDDe6B8kddRRDm/Y6zh0B2cXqcncreKTAICIjQedCCCHE0CBFKTE86FqUCsqT0rtrR/TWt4Cj9857kLxCiz/kPIaiFATtwJfgsPP6jerYd+c9CHyvnHbo6UzsOjJZV0vy8r8yVfAOptlFviu94NBxl1QxpAXG96SQKYQQQmQyKUqJ4cFWpI56BOn6d94ri/9cYmBappQmIZ1SSSpKtR1Sx4KRsd0/WTvwDdQplZUHZpu6nM7dUonO3RrMQ2fCH45L/KhlJusMKu6brWDOVp9LrpSIkL9TyiWdUkIIIUQmk6KUGB507ZTSQs5L4j+XGJitMFAEgcSO79mPJnZ0SOuUimV8D4LCzhM4vudxw+Gt6nKoopTBkP65Ui018NtpsPLO1Dy+owOadquOn8bdqVlDJgge34OgEb6WlCxHZB5/ppSM7wkhhBAZTYpSYnjQsygV/Bt+kVgGQ+9uqZIEjO9pz6PXk9gujbY4x/eS0SnVtEeFqZuzw3+v0z1XquZDVQBc8/fUPH5n0Nie1h0n+tOKmtrrSRvhk7BzEaFAUUrG94QQQohMJkUpMTwkIug8V8b3ksLfWWSAwtH6n99kCXRpJDJE3B90Xh3b/bWiVGcCs4oaNqljxXQwmkLfJt2LUtrfz7aDqcl1Cn5M7TkX/fUt7msj1jK+JyIkQedCCCHE0CBFKTE8JCroXCSeVowpqAaLbeDbxioZI2m6BZ0nsiil5UmFCDnvu45E7wIYK228FuDQuuQ/vhSlIqMVpfzje0XqKON7IkL+TimXdEoJIYQQmUyKUmJ4SESnlASdJ4fWKZWInfc0iS60uJ2BYkW8nVKJHN8bKORcoxVj07Uo1RVclFqb/McPfn5kfC+8fuN7vm5FGd8TEbJZ1H9hHdIpJYQQQmQ0KUqJ4UGCzjNX6UR1LJ+auMdI9EhaRwPgBaM5UACLlr8olcBiUL02vjdAUcofDN+YuHXEo1en1JrkP35wsa5VOqXC8o/v+f7u6blDqhgWtE4ph3RKCSGEEBnNnOoFCJEUWlHK0Rb/uSToPLnmfh6ycmHy2Yl7DH9RKkEFn7agnfeMMf4uwL/7XgN4vSoEXk/drdBaoy5XTA9/u0R/r+IVXCw7tDYx36uB9OqUkqJUSG5noPjUL+hcMqVEZGxm2X1PCCGEGAqkU0oMDxJ0nrmycmDuNYn9fvvH9xLUKdXuG+PKjzFPCiC3XB09zsS8cW/Yoo4FowKjVCHXkeDvVbyCx/c6GgJZXsnS0Wf3Pa83uY+fCbSfoQZj4LUm43siStr4nhSlhBBCiMwmRSkxPOhVlPJ4gjKlpFNqyEh0ppSWLRRryDmokHer73WciHVqO+9VDjC6B4Fxq3QtStl9BTujRR2TnSsVXJRyO9J3zDGVtNdOdklgl0cZ3xNRsvo7pWR8TwghhMhkUpQSw4NeRSlHK3h9v5WVotTQkehMKa0oFWvIuSbP1y2ViLBzrSg10M57EPhe2Y+mZxeQ1ik15nh1TGVRCmSELxStqBrc/egf32tJ9mpEhvIHnbvceNPxZ5EQQgghIiJFKTE8WAvU0dUNzu7Yz6OFKGflg9ka/7pEeshJcE6SNkIWT6cUBIWdHx74drHw77wXYVHK1Q09HfqvIx7OLnDa1eVJZ6ljbRLDzr3eQMEw27cRguzA159/BDoo9F/rlJKilIiQ1Rd07vGC0y1FKSGEECJTSVFKDA/WAsAXdhxP2LnWSZMrXVJDin9HuUR1SmlFqZHxnccfdq5zUcrjCWRKVcwa+LZZuWDJUZfTbYRPKxobzTD+VHVZCztPBkebGtkDqJ6rjq0Hk/PYmSTUZhFappSM74kIaZ1SAN0uyZUSQgghMpUUpcTwYDQGuqXiGeGTPKmhSStKdTWrncH0pkfQOQR1Suk8vte8F5ydYLZByYTBb5/occdYaaN72SVQMVPlSnU1QUtNch5fKxZaC6B0krosnVL9DTS+52gDtyvpSxKZJ8tk9G+sKWHnQgghROaSopQYPvTIlbKH+A2/yHzZxWonMNA/mNrrDeqUirco5cuU0nvMUBvdGzEVTObBb58TlCuVTrROqZwSNV6rjSImK1dKK0rljoACX36YFKX60143vcb3CgOX9dglVQx5BoMBq9mXKyVh50IIIUTGkqKUGD78RamW2M/h75QqG/h2IrMYjYFCo94Fn65mcHWpy/F2SuUmKOg80p33/OtI8G6FsdL+fmp5TtXz1PFQknKltOclrwIKRqnLEnTeX6jxPZMFsvLUZRnhExGy+XKlHDK+J4QQQmQsKUqJ4UOPTin/m6mS+Ncj0ou/0KJz948Wcp5dDJbs+M6VqPE9f8h5pEWpNB/fy+lblEpyp1RecKeUFKX68Wfz9Snua7lSEnYuImQzq6JUt3RKCSGEEBlLilJi+NBlfM/3prfvmymR+RJVaNFG9/Kr4z+XNr7Xoff4nq9TarCd9zTpWpSyN6ujVpQaeaw6HlqvwtwTrVMrSlX0Ht+T7ep7CzW+B4Ed+Lqbk7ockbm0sHPJlBJCCCEylxSlxPChS1FKgs6HrESNpGkh5wU6FqU6j4BHpzdh3W3QvE9djrRTKl0zpYKDzkFlZJlt4GhVYe6J5h/fKw88367uQDFbKP6O076dUkXqKJ1SIkLa+J50SgkhhBCZS4pSYviQoHMxEO0Nst5FKb1CziFQOPO69St0HN6qjvnVkY+lpnumlPbnMFmgcpa6nIwRPq2DLbdcBa1r3ycZ4QtwOwOZUf3G94rUsUs6pURkrP6ilHRKCSGEEJlKilJi+NC1U0rG94YcrYCgd/eP1imlx/ieyRLoAtJGxeIV7egepPH4Xp9OKQjkStUmIew8OOgcJFcqFO1nqMEYyJDS+Mf3WpK5IpHBtN33uiXoXAghhMhYUpQSw4cuQecyvjdkJSxTShvf06FTCvQPO4925z1I36KUP+g86O9nMsPO/UHnvjFL2YGvP+01k10CRlPvr8n4noiSf/c9Gd8TQgghMpYUpcTw4S9KtcV2f5cDetrV5VwpSg05iRpJ0zPoHPQPO4925z3oPeqYTiHe9j677wFU+8LO69brl8MViscTeO34i1JBYedCsYfZeQ8CnVJSlBIRskmnlBBCCJHxpCglho94O6W0LgyDCayF+qxJpI/cBGVK6Rl0DkFFKR06pTweaNiiLscyvudxgiPGIm8ihBrfK5sMllxwdsLRnYl77O4W9f2AQIGzcKQ6tkqnlF9nmJ33IDDOJ+N7IkISdC6EEEJkPilKieEj3qJU8M57RvmrM+T4O6Ua9TunyxF43ehWlNJxfK9lv+r+M2VB6eTI72fJhqw8dTldRvjcLrXLHvTulDKaoGqOupzIET7t+bAVqZBzgAJfUUrG9wI6B9gsQsb3RJRsFl+nlASdCyGEEBlL3lmL4cNWoI4xFqUM9hB5NWLo0Lp/etrB2aXPOdt9o3sma/9Q51hpnVJ6dHRpo3sjpoLJHN190y1Xyr9jmyEwBqbx50olMOzcnydVEbhOxvf6i2h8T3bfE5GxmrVMKSlKCSGEEJlKilJi+Ii7U2qA3/CLzGctUB1DoF+hRcuTKqgCg0Gfc+bqOL4XS56UJidB446x0sZrbYX9C2zJCDvvG3IOvTul0il7K5W010uoHUy1TikZ3xMR0jqlHC4Z3xNCCCEylRSlxPChFaVcXWqsKkr+TikJOR+aDAb9Cy3a2JZeIecQlCl1OP5zNWxUx2h23tNo4472NOmU8o/XlvT/2khf2Hn9RnA7E/P4nSGKUvm+HRdd3dL9o+kcoFNK6yaU8T0RoUCmlHRKCSGEEJlKilJi+LAWBC7HsgNfV1CmlBiatDfKdp1ypdqDOqX0omtRSuuUiiLkXKMVZ9OlUypUyLmmeLzanMDVDUe2Jebxtc614PE9iy1Q6Gw9mJjHzTTa362BxvecneDqSdqSROaSoHMhhBAi80lRSgwfRlOgMBXLCJ+/EyPEmykxNPjDzvXqlNKKUnp2SvmKHvZGFe4dK0cHNO1Vl2MZ30tEMHw8ugbIfDMaoTrBYedakbDvrnLaDnySK6UMNL5nC9rVVEb4RASsZl/QuUs6pYQQQohMJUUpMbzEkStlsEun1JCnd1Gq3VeI0HN8L6cUDEbAG9/o3JHt6hx5FaG7VgZdR5plSvk3IgjRKQWBXKnaBIWdhwo6B9mBry//+N6I/l8zmgI/o2WET0RAxveEEEKIzCdFKTG8+ItSLdHfd6CxEzE05OqdKZWA8T2jKVAQiifsvHGXOpYdE9v90zVTKtT4HiQ+7DxsUUrbgU+KUridgZ+94X6OaiN80iklIuDvlJLxPSGEECJjSVFKDC/xdEp1DdKJITKfvyilV6ZUAjqlIFD4iCdXqmmPOpaMj+3+/u9VmhSl/H8/i0N/vdoXdt6wOaaNDgblDzrv0wFUION7fv6sNkMg1LwvbQc+CYaP2qpVq7jwwguprq7GYDDwwgsvRHzf9957D7PZzNy5cxO2vkTQOqUcMr4nhBBCZCwpSonhJY6ilP/Nt4zvDV16ju95PInplAJ9ws6bdqtjycTY7p9uRSm7r4gR7u9n0RjVReVxBgLe9eJxB14zMr4XXvDPUKMp9G20TikZ34taZ2cnc+bM4YEHHojqfi0tLVx77bWcddZZCVpZ4kjQuRBCCJH5zKlegBBJFWtRyusN6sSQ8b0hS8+ilL1RFUAA8irjP18wf1EqjvE9f6fUhNjuHzy+5/WCwRD7WvTQNcDue6DWVz0Pdq9QI3wjj9Xvse2N4PUAhv4/H7TxvVYpSvlHPQcagdY6qGR8L2rnnXce5513XtT3+/rXv84111yDyWSKqrsqHdgs2viedEoJIYQQmUqKUmJ4ibEoZfZ0YfD4djqTTqmhK0fH7h9tdC+3HMxZ8Z8vmB6dUo2+TqnSGDultL8HHpcqIIQbx0oW/0YEA4zX+otSa4Ab9Hts7XnIKQVTn39Wg3ffS4fiXSr5O6UGKkoVqaN0SiXFo48+yp49e3jiiSf45S9/OejtHQ4HDkdg/LWtrQ0Ap9OJ0+nUfX3aOcOd22zwAqoolYjHF9EZ7PkS6UWer8whz1VmkecrINLvgRSlxPCiFaUcbVHdzepqVxey8sBi03lRIm1oHRx6dP8kanQPAiNinTEWpexNgU6U4hgzpcxWsBaCo1UVG1JelBqkUwqCws7X6fvYWsda39E9COSJubpUTtJwzqTrjKBTyj++J5lSibZz505+/OMf884772A2R/bfwTvuuIPbbrut3/XLli0jJydH7yX6LV++POT1NR0AZlraO3nttdcS9vgiOuGeL5Ge5PnKHPJcZRZ5vsBut0d0OylKieElxk6pLK0oNZzfUA4H2ptlVzf0dIA1P/ZzJSrkHFT3FcTeKaWN7uVXQ1YcbyRzSwNFqbLJsZ8nXl5voIgxUCejNrJ3eCv02OP7swfrCBNyDqqInVOmCp1ttcP7Z0hE43tF6ijjewnldru55ppruO222zjmmMh34LzppptYunSp//O2tjZGjx7N2WefTUFBge7rdDqdLF++nCVLlmCxWPp9fWdDB/dufB+DOYvzzz9D98cX0Rns+RLpRZ6vzCHPVWaR5ytA66gejBSlxPASd1FKRveGtKxcsOSCs1PlSsVTlEpop1ScmVLx5klpckeoc+mRwRWP7lbw+jJlBir65FepbqaOBmjYBKMX6vP4/p33QnRKgcqVsh9VI3yVs/R5zEykvU4GHN/zddzJ+F5Ctbe388knn7B27VpuvPFGADweD16vF7PZzLJlyzjzzDP73c9qtWK1Wvtdb7FYEvof73Dnz8tWa3G4PMP+P/7pJNGvB6Eveb4yhzxXmUWeLyL+88vue2J4sfp+kxtlUco/vich50Nfrq/wGG+uVFsCO6XizZTy50nFWZTyZ3CluCil5UlZctVYYTha2DmosHO9+DulykN/XduBr/Wgfo+ZiaIZ35NOqYQqKChg48aNrFu3zv/x9a9/nSlTprBu3ToWLVqU6iVGJDjo3Ov1png1QgghhIiFdEqJ4UU6pcRgckdAS038RSltfC+RmVLdLeByDFyICUW3Tiktg6sxvvPEK5LRPU31PNjxOtSu0e/xtaJUbpiiVHDY+XCmvU4iGd+TTKmodXR0sGvXLv/ne/fuZd26dZSUlDBmzBhuuukmamtrefzxxzEajcycObPX/cvLy7HZbP2uT2dWiwkAjxecbi9Z5mG8kYAQQgiRoaRTSgwv8RalBnozJYaGXF8uULzdP/7xvQR0StmKwOhrh41lnU2+TqmSGHfe0+SmS6eUL+Q8J4Kw9WpfrpSunVIDBJ1D4DUw3ItSMr6XUJ988gnz5s1j3jzVDbh06VLmzZvHzTffDEBdXR01NTWpXKLurObAf2O7Xe4UrkQIIYQQsZJOKTG8SNC5GIxehZZEBp0bjap41n5IFUQKR0V3fz0zpSD+rrJ4aR04A+28p6meq45Hd4CjPb7cME2k43ttMr4HyPhegpx++ukDjrA99thjA97/1ltv5dZbb9V3UQlmNRsxGKDQ24712c/BsVfDrCtSvSwhhBBCREE6pcTwohWlnHZw9UR8N8mUGkb8OUlxFFp67IHCZyLG9yD2XCl7U2A0qmR8fGtIl0ypLq1TKoKiVF45FIwCvFC3QZ/H74y0KDWMO6XczkChKTfELoUabXzP1Q3OrkSvSmQ4g8GA1WzkctMqrHvfhHfvS/WShBBCCBGltChKPfDAA4wbNw6bzcaiRYtYvXp12Ns+9NBDnHLKKRQXF1NcXMzixYv73d7r9XLzzTdTVVVFdnY2ixcvZufOnYn+Y4hMYA3astoR2RaVIJlSw4r2htkeR1Gq3Te6Z8nt/ZrTkzYqFm1RqmmvOuZXqd0G45EumVL+8b0I/35q3VJ6jPC5nYE/fyTje8M1jFl7jjAERvRCycoHg++/JjLCJyJgs5g4wbhFfdK8d/j+HRNCCCEyVMqLUs8++yxLly7llltuYc2aNcyZM4dzzjmHw4dDv9FauXIlV199NW+99RYffPABo0eP5uyzz6a2ttZ/m7vvvpv777+fv/zlL3z00Ufk5uZyzjnn0N3dnaw/lkhXJrN60wNRjfBluTvUBSlKDX16ZEq1+X4eFVSpHd8SIc+3zqiLUjrlSUH6ZEppnVKRjO9B0A58OoSdax11BlP4x9eKUk778A3w9udJlYDRFP52RqOM8Imo5JpgkXGb+qSnI/U/j4QQQggRlZQXpX7729/yla98heuvv57p06fzl7/8hZycHB555JGQt3/yySf55je/ydy5c5k6dSoPP/wwHo+HFStWAKpL6r777uNnP/sZF198MbNnz+bxxx/n0KFDvPDCC0n8k4m05c+Vaon4LlYJOh8+cn2Fx3jG9xIZcq7xd0o1RHc/f55UnKN7ENRV1ggeT/zni5XWqRRp5ttIHcPOte9/7ghVUAnFkh0oaA/XET6t83Cg0T2Nfwe+lkStRgwhs0x7yTcEjXpqP+OEEEIIkRFSWpTq6enh008/ZfHixf7rjEYjixcv5oMPPojoHHa7HafTSUmJejOyd+9e6uvre52zsLCQRYsWRXxOMcRFG3budmJx29Vl6ZQa+vTolEpkyLkm15df1Bllp1Sjr1OqVIdOKe3vg9eT2g4ge5SdUlVz1bFpT/zrHizkXDPcd+DTiryR5PJpnVLDtatMRGUBm3tfIUUpIYQQIqOkdPe9o0eP4na7qajoncNRUVHBtm3bIjrH//7v/1JdXe0vQtXX1/vP0fec2tf6cjgcOBwO/+dtbSpryOl04nQ6I/vDREE7ZyLOLQZnsuZjBFydTXgjeA6cbQ1YAK/BiMucC/K8pS1d/m5lFavn296Iq8cRyLeJgrGlFhPgzqvAk6DXiyG7FDPgaW/AHcVjmBp3q9d/4diIXv+DMduKMHS34Gyrh6zo8rP0+llotjdhAFzWwsj+TJZ8zEXjMLTsw3VgDd7xp8b82Ia2OvU85IwY8Hkw5VdjrN+Iu3l/wl4TiRbP82Vsb8AEeLJLBn29mmyFvp/Rjbq8RhNB/v1OH8e6NwLgNtkwubsDhXchhBBCZISUFqXideedd/LMM8+wcuVKbDZbzOe54447uO222/pdv2zZMnJycuJZ4oCWL1+esHOL8Ba2OqgCNn38Lvv3Wga9fX7XAc4Eeky5vP6f1xO+PhG/eP5uGTwuLvIdl7/8T5zmvKjPsWDPWqqBzTVN7H3ttZjXMpDSjj2cDNgP72VFFI9xXsM2soB3NtfStif+tZ3pzSafFj5a8QqN+VNjOke8PwvPbj5ENvDumi20botsx7b5lDOSfWxf+Qy7tnbE/NiT699hOnCwpYe1AzwPs5udjAd2rVnFtvpBuqqSaEzjKsrat7B2zJfxGiP7L0Esz9fUQx8yBdh/tJMNg7xej2vqYhSwdc377DmYoI0C4mS321O9BAHg6mGaS3VKHRp5LqNrXpBOKSGEECLDpLQoVVZWhslkoqGhdyZKQ0MDlZWVA973nnvu4c477+TNN99k9uzZ/uu1+zU0NFBVFdiKvaGhgblz54Y810033cTSpUv9n7e1tfkD1AsK9P8PsdPpZPny5SxZsgSLZfCiiNCX6aVXYONaZk0ew4wTzh/09u5db8E2sBRWcv75g99epI5ef7e82wowONpYcuI8KJsc9f1Nj94HrTB90WKmTU3Qa6ZxMuz8Nbnezshfl13NWNZ2AnDyhV+If/c9wHT0T3CgjuNnT8I7Lbo/qy7Pl9eLecNXADhp8YVQNCaiuxk/2A3/Xc20gi6OiePvtXHZu1AHI6fMo+rM8OcxvrcdVv6XyRU5TEiXnyNeL+b7lmKwH6XqnO/inXjmgDeP5/kyvrYCGmDMtGMZderAf37jf96CNR8yfXwVU09Lk+9VH1pHtUixQ2uweR00evM5WH6GFKWEEEKIDJTSolRWVhbHHXccK1as4JJLLgHwh5bfeOONYe93991386tf/Yo33niD+fPn9/ra+PHjqaysZMWKFf4iVFtbGx999BHf+MY3Qp7ParVitVr7XW+xWBJaNEr0+UUYvu3ITc5OTBF8/w09vuyp3DJ5vjJE3H+3ckeAow2LoxliOU+7GhU2F4+O7f6RKBoJgKGnA4vXCVkRdHU2HFDH/CosuUX6rMO3C6C5uynmP2tcz1dPJ7jV+LWloDzyNYxeAICxbj3GeJ4jX4C3qaBq4J8nxapYZmyvi+/x9NR2yL9+c+u+iL93MT1fXSqM3pRfMfjP3VyVDWbqaY/oZ3QqyL8FaWLvKgA+8EwH22h1XdNe8HoTt/OpEEIIIXSV8t33li5dykMPPcTf/vY3tm7dyje+8Q06Ozu5/vrrAbj22mu56aab/Le/6667+PnPf84jjzzCuHHjqK+vp76+no4ONX5hMBj47ne/yy9/+UteeuklNm7cyLXXXkt1dbW/8CWGuSiDzg3+EGUJOR82/LvKxbADn8cd2JEtkbvvWQvA7BtbjjTs3L/z3gT91qEFV2s74CWb9vfTlAVZUYxaVs1Rx9aa+HZazOSg87oNgcuJzuHRXh+R7GDq+8WB7L4nBuUrSn3omc5Ri+/vmKM18HNBCCGEEGkv5ZlSV111FUeOHOHmm2+mvr6euXPn8vrrr/uDymtqajAGbbP95z//mZ6eHq644ope57nlllu49dZbAfjRj35EZ2cnX/3qV2lpaeHkk0/m9ddfjyt3SgwhNt9IZqS77/kKE17ZeW/40N44x7IDX8dh8LrBYBq8UBEPg0HtwNdaox6zeNzg92nyFR70LErpsVthPLqCdt6LpjPCVgClk6FxJxxaB5MXD3qXkDojLUqpzjbaatOni6N+Y+ByU4KLUrHsvtfdkqjViKHA2Q0HVgOqU6raa1F/z9pqVQE+V/7NFkIIITJByotSADfeeGPYcb2VK1f2+nzfvn2Dns9gMHD77bdz++2367A6MeRE2Snlf9MrRanhw1+UiqGDpt3XCZNXAUaTfmsKJU8rSjUMfltITKdUPN8rPWgdODkl0d+3ep6vKLUm9qKU9r3Pqxj4dlqnlNOuii1aN1Aq1a8PXG7cldjH0oqWEXVKFaljV3PCliOGgIOrwe2gzVzK7u5qup0e9bNNK0r5RnSFEEIIkd5SPr4nRNJpRamOBtWxMAiDNsIlRanhI57un7Y6dSyoGvh2etC6czoiHN/TRrRKJ+q3hpQXpYI6paJV5dsko2FzbI/t7A4UtwfrlLJkB9aYLiN8wZ1SLTXg6knM47idga4n7e/WQLROKRnfEwPZ+w4ANQXHAQYcTjeUjFdfk7BzIYQQImNIUUoMP2XHqGPdOnjthyoDaCC+N73eWDoxRGbyF6ViKLRoBYf8NCxKJTJTKmXje75umlj+fpZPU8fDW2N7bO3PbMoKFFIGoo3wtdbG9nh66m6F5n3qsikLvJ7A53rz5/sYIusQ024j43tiIL48qdpi1RHV7XQHfrZJUUoIIYTIGFKUEsNP+TQ4727AAB8/BP+8HlyOsDeXoPNhSI/xvUSGnGu0kbFIxve6mgOjqInIlIolFF4P2t/PmIpS09WxcdeAPwPC0oqBueWRZUQVBuVKpVr9JnUsHA0jpqjLicqV0op3OSWRjbT6x/daIupmFcNQTyfUfgrA4dKFAIHxPZCilBBCCJFBpCglhqdFX4Mr/gpGC2x5EZ64HLrbQt9Wgs6Hn3i6f/zje0koSkUzZqi9ScurhKxcHdeg7b7XNHjXYSJomVKxjO/lV6lxXq8bju6M/v7+kPMIRtIgvXbgq/ftvFc5C0onqcuJ2oHPHkXIOQS6zjxOVXwQoq+aD9Xro3A0jrzRAHS7pFNKCCGEyERSlBLD18zL4fP/UNvI73sHHjsf2vt0nHi9EnQ+HMWTKaV1SuWnWadUo+9Nmp55UuArBhkAb2q2Ye+Ko1PKYAh0S8UywhdpyLmmIJ06pXx5UpWzocT3mkhU2LnWcRhJnhSooqnRoi7LCJ8IxTe6x/hTsWapPXscTg8U+zKlupokKF8IIYTIEFKUEsPbxDPgi6+oN0v1G+GRs3t3CzjaMbh94b+SKTV8aG+eu5rB7YruvkkNOteKUhFkSvnzpMbruwaTOZABlIpcKXucRWN/rtSW6O+rfd8HCznXpFNRqi5Ep1TCxve0olSEz5HB0HuET4i+9qmQc8adgs2s/ivb7XKDNU91g4J0SwkhhBAZQopSQlTPgy+9AcXjVNDvI+fAoXXqa77RIJcxCyw5qVqhSLacoO6frii6f7zeoKDzZHRK+YpnHYcHz97RCg4lOndKQWpzpbri2H0P4uyUCsqUioQ2vpfqoHNXDxzZpi5XzQ50z6XL+B4E7cAn3S6ij+5WOLRWXR5/CjaLyinrdvrGh/0jfHtTsDghhBBCREuKUkKAelP2pWWqa6DzCDx2Aex+y9+F0WMuSPECRVIZTYHOuGi6fxxt4PRl4CSjU0orhri6wNE+8G0TsfOefx0p3IFPy5SKtZMxrk6pKMf3CkepY9uh1AZ4H9mq8nhsRSroXCtUttVCj13/x4t2fA8CnVIyvif62v+B2i2yZAIUjgoqSnnU1yVXSgghhMgoUpQSQpNfAV98DcadAj0d8OSV8OkjAPSY8lK8OJF0seRKaaN71kJ9w8TDseapTDQYfJ1aF4zemVIQVJRq1P/cg7H7Omli7ZQa4StKtewHR0d09412fC/fV6h0dqpuj1QJHt0zGFRBT+tMak5Ad4n22syNolNKGwmV8T3RV9DoHoBVG9/zd0r5RpSlKCWEEEJkBClKCRHMVgD/718w/WLVSbD2CQAc5vwUL0wknb8oFcVImhZynoyd9zTaOgcKO+9qDoy5FeucKQXx7VYYD1cP9Pg6xGLtlMotDXQ6Hdke3X07oyxKZeUEii2pzJXSQs6r5qijwRA0wpeAsHN/N1sUuV9akUw6pURfe99Wx/GnAvg7pXpc0iklhBBCZCIpSgnRl9kKVzwKC77sv6pHilLDj7/7J4qi1IHV6piIEblwItmBT3tzllepuqv0lqpMKS1vyGAMFDFiEesIn79TKsLxPYCCoBG+VKkP6pTSaGHniciVimd8TzKlRDB7E9RvUpd9nVI2S99OKSlKCSGEEJlEilJChGI0wfn3wBk/w2vO5kj+jFSvSCRbtN0/Xi9seFZdnnFJQpYUkj/sfIB1aoG/iSqWxZopVbeOkc0fxv64WgeOrQiMcfxzFkvYeU+nGvOF6IotWhddqjqlPJ7Am/rK2YHrSxIYdh7L+J4/6LxF79WITLb/PcALZVPUyD2BTqluf6eUrxu08wh0t6VgkUIIIYSIhhSlhAjHYIDTfojrh3s5UHpKqlcjki3aTKnaT9Vv5i05MOX8xK2rr0g6pfx5UokuSkWRKeV2YX72aubv+xM0bIrtcbWRxGjGwkKJpVNK65IyZ4M1ik7KVO/A17xXjTyarFA2OXC9Nr7XpHNRyu0MjOBFs/ueNuYo43si2N5V6ugb3QOwmfvsvmcrDLzWEpGRJoQQQghdSVFKiMEYzalegUgFrdBij7DQsuE5dZz6mcSMyIWjFaW0fKNQErnzHsQWCr/3bQy+2xuORNGhFMyuFaVizJPSxNIpFRxybjBEfr/CkeqYqvE9LU+qYjqYLIHrSxPUKaU9Rxiie57843st+q5HZLa9vpDz8YFfFAWP73m1XS1lhE8IIYTIGFKUEkKIUKIptLidsOlf6vLsqxK3plD8QecDFaV8hYaSBOy8B4GuhGgypTY/779oaN4X2+NqnVKx7rynGTFFHTvqg4oog4g25FxToBWlUtQpFSpPCgKvjc7D+o48aa+JnBI1Fh0p//ieZEoJn47DoBWwx57sv9rq65TyeMHlkaKUEEIIkWmkKCWEEKFEk5O0+y315jt3BEw4PaHL6ieaoPNEd0p1NasC3WBcPbD1Zf+nhlhHbPy7usVZlLLmQ9EYdTnSbint+x1NyDmkQVHK1ykVnCcFaufRXF+BTc8RPu3vTzSjeyDje6K/fb4uqYpZatdMH6sl8F9Z/wifv/NPilJCCCFEupOilBBChOLvlIqg+2ejb3Rv5uVgSvK4p78oFaZ41tUSKN4kqiiVXax2wIPIOo32vAXdrYHPY+2U0mt8D4JG+CLMldK+39GEnEOgKNVaq8Lxk61O65Sa3f9riRjhi2XnPZDxPdFfiNE9AKvZ6J+g7XZqYefSKSWEEEJkCilKCSFEKFqnlKMNXI7wt3O0w9ZX1OXZn038uvry777XELrIob0py6tIXNaV0RgIG4+ks2yTGt3zjFoExNEppY12xTu+B0Fh54nulPIFnTs7exfmkqHjsBpRxAAVIXYUTcQOfFpBNDfKMHptfK+7Re0YKIQWcj6ud1HKYDBgNQdypYDADnxSlBJCCCHSnhSlhBAiFFtRIOR+oG6pba+CqwtKJ0H1sUlZWi/ayJXHGTp/xz+6l6A8KU1OhOOOzm71PQM8J30XQAWeO9qjf8xEdEod2RbZ7TtizJTKygmMpiU77FzLkyqdFLpAmYgd+GIe3ytSR69H7RYohre2OvW6NBhh7In9vmyzqFwph0srSvk6pTrqoaczWasUQgghRAykKCWEEKEYDJEVWjY8q46zPhvdLmx6sdjAWqguh1pnovOkNJHuVrjrTVVkKBiJd+JZOMz56vqmGLqltMfStVNqS2RjdbEGnUNQrlSyi1JantSs0F/3j+/t0u8x/eN7URalLNlgtqnLMsI37Bn2+0b3quYECpZBAp1Svq667OJA8TeWny1CCCGESBopSgkhRDiD5Uq1N8Celery7CuTsqSQtMJIqLBzbRSrNElFqcE6pbRd92ZcCgYjnVm+tccywqftvpcT5WhYKKWTwWBS3WYDhcZrYh3fg8AIX9vB6O8bDy1PqipEnhSoDipQRSm98q7sMWZKQe8RPjGsGfe9qy70Gd3T9OuUAsmVEkIIITKEFKWEECIcf/dPmKLUpn+p8aJRCxPfiTQQf9j54f5fS1qnVATB8D122P66ujzjMnVzq7bjWwxvHPUc37PYAp1Cg4Wde72xj+9BCjultJDzMJ1Sxb4cnu7WyALrI6G9HmIpHPrDzkOMpYphxbDfV5Qaf1rIr9vMqijl75QCKUoJIYQQGUKKUkIIEY6/0BKm+0cb3UtFwHkwf9h5qKKUr1MqHTKldr6hAr6LxsJIlb/VafUV1KIdsfG4Ax00eozvAYyYqo6DhZ072sHVrS7nxlOUqo3+vrFydAS65kLtvAcq76pglLqsV65UrON7EOiUkvG9YS3HcQRDa43K+BtzfMjb2Cx9gs5BilJCCCFEhpCilBBChDPQSNqRHVC3Tr1RmnFpUpfVj79Tqs/YWVdLIHdJ240qUSLJlNoUPLqn8rfsWTF2SnW3qi41CGTHxEsLOx+sU0or/mXlq0JOtLTxvdYkFqUaNgNeyKscuLtLG/PUawe+eMb3tOdVxveGtbIO39/HkceF3UHUapFOKSGEECJTSVFKCCHC8RelQoykbXxOHSctjq0LRE9akaFv8Ux7M5ZXAdb8xK5hsEwpRzvsXKYuz7zMf3WH1inVvC+6x9PGy6wFYM6K7r7h+MPOB+mU8oecx1BoAShMwfhe/SB5UpoSHcPO3UE7Qka7+x7I+J4AoKzd9/cxTJ4UBAedh+qUkqBzIYQQIp1JUUoIIcIJl5Pk9QbtupfCgHNNbpig82TlScHgmVLbX1cjbyUTe42P2bVMqdaD4HJE/nhayLleXVIQ1Cm1DTye8LeLJ+QcUpMpNVielEYLO9djfM+fS2WILfdLxveE10tZh68oNT58USoQdB6iU6rtIDi7ErVCIYQQQsRJilJCCBFOuJykAx9BSw1k5cGU85O/rr7Cje/5i1IJzpOCoO9VmKKUtuvezMv8o3sADnMB3qxcwAvN+yN/PD1DzjUlE8CUpXKvWmvC3y6ekHMIjO/1tKsxxGSo36iO4fKkNKU6dkppo3s5JWA0RX9/Gd8TTbvJdjbjNWXB6EVhb2bzj+8FdUrllIK1UF2OthNTCCGEEEkjRSkhhAgnXPfPBt/o3rSLYssU0ptWHOkIM76X6DwpCIzvOVrB1dP7a10tsOtNdXnGZb2/ZjBAkW99zVGM2WjZVXqFnAOYzFA2RV0eaIRPK0rFEnIOkJUb6AJKRreU2wkNvlyeSDulGveojsB4aMXcWEb3IGh8ryW+dYiMZfTtuucdOR8s2WFvZ9PG91xBRSmDIfCzT3KlhBBCiLQlRSkhhAgnVE6SqyfQ9TM7DUb3oHemlCfoTZkWVl2ahE4pW5EKfYdAh4xm+2vg7lG721VM73dXbyxvHLXxvZzS6Nc6EH+u1ABh5/GO70FghC8ZYedHd4LboYLZiwcpUBaNBYNRdYv17byLVjw770HQ+J5kSg1Xhn3vAOAde/KAt7OFCjoHCTsXQgghMoAUpYQQIhytU8rVBT2d6vKuN9Wb5LwKGH9a6tYWTFun1x2U40NyM6WMxkCBqG9nmX/XvT5dUj7e4nHqQjSBxIkY34PIws61ImWs43sQFHaehKJUcJ6UcZB/9s1ZUDRGXY53hE/rZou1KKV1Ssn43vDk9WKoeV9dHCDkHMBmUa9rR/D4HkhRSgghhMgAUpQSQohwsnLBbFOXtUKEtuverCtjy8lJBJMlMMam7QzX3RroWEpGUQqCxh2DOsvsTbDnLXV5ZriiVBydUnqO70FQ2PlA43tap1QcRSktVyoZ43v+PKlBRvc0/hG+OMPO4x7f82VKyfje8HRkG4bOI7gMWXirjx3wplZziEwpkKKUEEIIkQGkKCWEEOEYDL1zpbpbYft/1OezP5u6dYXSN+xcexOWWw7W/OSsQeuU0jpkALa+DB4XVMyCssmh76d1SsWSKZWoTqmjO1QWUyjxBp1D0A58B2M/R6Tq1qtj1SAh55oSncLO9Rrfk06p4Sm/Etdn/sD2qkvAbB3wpv5OKZeM7wkhhBCZRopSQggxkOBcqa0vg6tbhWEPtotZsvUNO09mnpQmVKeUlr8145Kwd/N3SjXv752JNRC7L2dI76JU4Wi1q6K7J/QbWa83/qBzCCpKJbhTyuvtPb4XCa1TKt438lqnnva6iJZ/fK818teFGDqyi/HOuZpdFZ8Z9KYhd9+DQFGq9SC4HHqvUAghhBA6kKKUEEIMJLhTasOz6vLsz6ouqnTiL0ppnVK+rqNkje5BUAHPV4zoOAJ7V6nLYUb3AMivBlMWeJzqzWMkEjW+ZzSqQHYIHXbe1azWCZkxvtd6QBV1jBYYMS2y+5T6XjNxj+/5XgexhtFrnVKg/gxChGENF3SeVw6WXPB6oKUmBSsTQgghxGCkKCWEEAPR8nDqN8BetRMUs9Jk171g/cb3fAWFlBSlfJ1SW19Ubwar5g68DqNJ7foGkXfnJCroHAYOO9e6pGxFg44UDShZu+/V+bqkRkxVIeaR0Mb3mvaAxzPwbQcS7/ieOUsVFEBG+MSAbGb139luV59OKYNBRviEEEKINCdFKSGEGIj2hnrdU4AXxpwAxWNTuqSQtK4drSCUzJ33NDl9OqU2/VsdB+qS0mjrjCRXyusNZErp3SkFQWHnITqlOnXIk4JAp1RPO3S3xXeugWgh55HmSYHafc9oAbcjvswrbXwv1qBzCIzwdTXHfg4x5Gnje82dPf2/WBLDRgpCCCGESBopSgkhxEC08b2eDnVMt4BzTW6f8b1UZkrZj0JbHex/T30+49LB7+t/4xhBUaqnIzBCF+to2EAi6ZTSOtNiZc0DW6G6nMgRvmjzpEB1rmnPR6xh525noJAUa6YUBEb4ZAc+MYB5Y4owGGD9wVZ2H+no/UXplBJCCCHSmhSlhBBiIMFvqI0WmH5JypYyIH+m1GGVv6N1qaRqfG/Li4AXRi1QnTeDieaNoza6Z7ZBVk5MSx2Q1inVtAecXb2/5g85j6PQoknGDnxap1S0wfxa2HmsuVLac4QhvhHL7GJ1lPE9MYBRxTmcNVX9DPz7B/t7f1ErzMebkSaEEEKIhJCilBBCDCQ4D2fy2YnJMNJDcFFKK+zkloM1P3lr8IfCNwbtuhfB6B6Afwe+fYPfNpGje6C+l9klKg/r6I7eX9M60eLtlILE78Bnb1JB5wCVM6O7b0mcYedaUTS7WHVexco/vtcS+znEsPD/jldj1f/69CD2HlfgC9IpJYQQQqQ1KUoJIcRAgotS6Tq6B4Eiib0Rju5Ul5PZJQWBUbqedjjwEWCAGZdEdl//G8e9KjNqIF0JDDkHFY7sz5XqM8LXoVOmFARypRIVdq51SRWPC4wKRkrrlGqKsSjlDzmPs6PMP74nmVJiYKdOHsG40hzaHS5eWBtU6NV+trTUqLFSIYQQQqQVKUoJIcRAisaCOVu9uT7m3FSvJrycUjAYAa+vIERy86RAFT6MlsDnY04IFF4GUzRGrd/ZGSj8hGP3FSgS2bXmz5XqE3auV9A5QOEodWxLVFFKy5OKcnQP4h950gL3Y915T6N1Ssn4nhiE0Wjwd0s9/sE+vFpxO69S/Qz3ulVhSgghhBBpRYpSQggxkJwS+PKbcMNysNhSvZrwjKbALmc1H6qjFladLAZD7yJEJLvuacxZgSLNYGM2WqdUosb3IHzYua7je76CXaLG92LNkwIo8RWlmvfF1l2ijVjGG0Qv43siClceNxqbxci2+nY+3e8rXhuN0W2kIIQQQoikkqKUEEIMpnJm8gs8sdAKJQ2b1bEkyZ1SEChKGYww/eLo7uvPlRrkjaO/4JHIolS48T1fB5Ce43sNm+DIjoFvG4s6X6dUVQxFqfwqsOTE3l0i43siBQpzLFw0R/29ejw48FxypYQQQoi0JUUpIYQYKvyFEt/YSrIzpSDQrTXu5OgLN/5uhkHeOGo7u8XbhTOQ8qnq2HoAutvUZY87aCxNh6JU1VzV7dXRAH8+EZbfAo6OQe8WEWdXIKS9clb09zcag8LOd0V/f93G97Td91rjO48YNq49YRwA/9lUx5F2h7oy0p8tQgghhEg6KUoJIcRQ0bcIlIqiVPVcdTz2uujvGxx2PpBkjO9lF0O+r5PpyDZ1tDepziEM8RdbQHV6feW/KqvM44T37oMHFsLmFwYPex/M4S1qrTllquspFvHkSmm77+XE+X3yd0q1xHceMWzMHFnIvDFFON1env3Y1+UnnVJCCCFE2pKilBBCDBXBRancEWArSP4aTr8JvvUxzLoi+vsWR9splcCiFPQPO9dCznNKwGQJfZ9olYyHa56Fq59RYe9ttfCP6+DvlwZ2UYyFNrpXOUtlfcW0Nl9RKpYd+Dp9I5a6dUq1xHceMax8wRd4/uRHNbjcHilKCSGEEGlMilJCCDFUBIdvpyJPCsBshRHHxHZf7Y1jpJlSieyUgv5h53qGnPc15Tz41mo47X/BZIU9b8GfToA3b4OezujPp4Wcx5InpfF3SqVyfK9IHSVTSkTh/FlVlORmUdfazZtbDwf9bNmnxnCFEEIIkTakKCWEEENFcM5RKkb34lU8Th27mgcuQmhfS2SmFASFnfs6pTp8nVJ6hJyHYsmGM34C3/oQJp+tRvre/S38cSFseSm6kb56rVMqnqLUJHVsjKG7RO/xvZ6O2HYBHEZWrVrFhRdeSHV1NQaDgRdeeGHA2z///PMsWbKEESNGUFBQwAknnMAbb7yRnMUmmM1i4qoFowH4+4f7oGAkmLLU36nWA6ldnBBCCCF6kaKUEEIMFcHFktIMLEpZ8wJdSAPlSvnH94oTu55+nVK+opQeIecDKZkA1zwHn3sKCsdA20F47gvwxOWwY9ng+Uoed2AHxniKUlq3XesBcHZHfj+3K1A4jHv3vcLAZQk7H1BnZydz5szhgQceiOj2q1atYsmSJbz22mt8+umnnHHGGVx44YWsXbs2wStNjs8vGoPBAO/tamTX0a7Ix4OFEEIIkVTmVC9ACCGETvIyvFMK1BvHjgY1wjfy2P5fd3aD0zfOlujxvRFTAIMaRes4EjS+l+CiFKgcqKkXwIQzVLfUe7+H3SvUBwaomAFjjocxJ6iPwpGB+zbuBqcdLDmBEbxY5JaBtRAcrer5KJ4U2f208UoM8ed+mcxgLQBHmyrG6REwP0Sdd955nHfeeRHf/r777uv1+a9//WtefPFFXn75ZebNm6fz6pJvVHEOZ00t582th3niw/3cWjIBjm5XRamJZ6Z6eUIIIYTwkU4pIYQYKtIhUypegwUSazvvGUy9u2gSISs3MFJ4ZGsgJykRmVJh15ADZ/4Mvvmh2tGwZCLghYZN8PHD8K8b4HfT4b5Z8PxX4ZNHYNsr6r4VM8Boiv2xDYZAx100O/Bpo3vZxfE9vsa/A5/kSiWSx+Ohvb2dkpIEF3uT6AsnjAPgX58exFmoLg+6u6cQQgghkko6pYQQYqjILoaCUdDTDmWTU72a2JRoIzb7Qn89eOe9WHeVi0b5dNUldHhrcjul+iqdCBfdry53HIaaD6DmQ9j/vsqPaqlRHxueDdwnntE9TclEOLRWhZ1POiey+7T4MnviHd3TZBdCK7IDX4Ldc889dHR08NnPfjbsbRwOBw6Hw/95W1sbAE6nE6dT/8wv7Zyxnvv4sYWMLclhf5OdNe1FLAI8R3fhTsBaRfzPl0gueb4yhzxXmUWer4BIvwdSlBJCiKHCYICvva0CobNyU72a2ETaKZXo0T1N+TTY/qqvKJXgoPNI5ZXD9IvVB4CjHQ5+HChSHfwEXF1wzLnxP5YWdt4UYaeU2wn//aW6PGZR/I8PqtgKg2dpiZg99dRT3Hbbbbz44ouUl4d/fd9xxx3cdttt/a5ftmwZOTk5CVvf8uXLY77vvHwD+5tMPL3dwyKg48BG3nrtNf0WJ/qJ5/kSySfPV+aQ5yqzyPMFdrs9ottJUUoIIYaSTM/c0cKIm8OM2AR3SiVDcNh5soLOo2XNVxk5Wk6O26kKVXp8j7RMqkjH9z78EzRsVIWkM2+O//FBxvcS7JlnnuHLX/4y//jHP1i8ePGAt73ppptYunSp//O2tjZGjx7N2WefTUFBge5rczqdLF++nCVLlmCxWGI6x0ldTl7/zdt82l0JVsh3HuX8884FgyRY6E2P50skjzxfmUOeq8wiz1eA1lE9GClKCSGESB/a+F57HfTYVaZSMC1EO5mdUq/UAfcAADsBSURBVKB2s+vpUJeTmSkVC5NFv6JdNEWp5n3w1h3q8tm/hDy9xveK1FHG93T39NNP86UvfYlnnnmGCy64YNDbW61WrFZrv+stFktC/+Mdz/nLLBYunjOSf37ixI0Jk9uBpesIFI7SeZWRO9Bkpzg3izzr0PxveKJfD0Jf8nxlDnmuMos8X0T855dfEwkhhEgf2cWBAPPmff2/3pXkTqnSyWA0q5wuvCpgPVmPnQ60wPyO+kBRLhSvF15ZqsYGx50Ccz+v3xpkfC8iHR0drFu3jnXr1gGwd+9e1q1bR01NDaC6nK699lr/7Z966imuvfZa7r33XhYtWkR9fT319fW0tramYvkJ9YUTxuLGRI3XVygNNx6cYC63h3ve2M6pv3mLs+5dyc6G9pSsQwghhEgnUpQSQgiRPgyGwAhfqDeOdt8IV7IKQ+asQK4SqPFIPXaUyxTZRZDjGwkd6I38xn/C7hVgssJn7tM3hF4b35NOqQF98sknzJs3j3nz5gGwdOlS5s2bx803qzHKuro6f4EK4MEHH8TlcvGtb32Lqqoq/8d3vvOdlKw/kWaOLGTemCL2eXxdjikoSjW0dXPNwx/xx7d24fVCQ5uDz/7fB6w/0JL0tQghhBDpZGj2DQshhMhcJROgbl3oXKlkB52DGuE7sk1dTnXIeSqUTgT7UQxNe4Cs/l+3N8HrP1aXT/0hlE3qf5t4aON7kik1oNNPPx2v1xv264899livz1euXJnYBaWZa08Yy75/VQLr8RzdndTfyq7acYTvPbuOxs4e8qxmfv6ZaTy1+gDrD7RwzUMf8tB18zlxYobnAQohhBAxkk4pIYQQ6UXLlWoKUZTSMqWSOUJXPj1wOd1CzpPBN8JnCLcD3/Kfg/0ojJgKJyWgy8YfdN4S+X2a94HLof9aRMY6f1YVRyzVABzevzUpj6mN61336GoaO3uYXlXAy/9zMlctGMOTX17EiRNL6exx88VHP2bZ5vqkrEkIIYRIN1KUEkIIkV5KJqhjyPE9LVOqNHnr0cLOIf1DzhOhVCtKhXg+9r4Da59Qly/8vRp31JuWKRXp+J7XC89dC7+fCzUf6b8ekZGsZhPjj5kNQM+RXQl/vL7jev/v+DE8/80TGV+WC0Ce1cwjX1zA2dMr6HF5+MaTa/jXpwcTvi4hhBAi3UhRSgghRHrRMqXSZnwvqFNquI7vQf8iobMbXvmuujz/SzDm+MQ8vn98ryWy2+9cDnXrVRFLW7sQwCmLFgIwoqeWXQkMGV+14wjn//4dVu9tIs9q5g9Xz+OXl8zCZumdR2ezmPjT54/l8mNH4fZ4+f4/1vPYeyF+7gkhhBBDmBSlhBBCpBetU6rlALidvb9mT/LuewDF48BsU5eHZVFKZUT1G997515o3KW6x866JXGP7x/fiyBTyuuFVXery/O/pILphfCpHHMMboxkG3q4519v0+1063r+cON6F86pDnsfs8nIb66YzfUnjQPg1pe38Ps3dw6YDyaEEEIMJVKUEkIIkV7yK8GcDV43tAR2C8PtCoxwJbNTymhSeUna2oYbX5HQ0NWExdWhrju8Dd79nbp83t2BbqZE0M7t6ho8J2rv23DwY7UL4InfTtyaRGYyZ+EuGA1A04FtfP+59Xg8+hR/BhvXG4jRaODmz0zne4uPAeB3b+7g9le26LY2IYQQIp3J7ntCCCHSi8Ggws4Pb1Fh59oIVnCmkJYzlCyLb4HNL8Dkc5L7uOkgKxfyq6C9jjxHA3g98PJ3wOOEY86F6Rcn9vGthYAB8KoRvvwBcr1W3aOOx1038O3EsJU1YiK07WeiqYGnN9YxIt/KLRdOx2AwxHzOzYda+eKjH3Ok3UGe1cwdl80asDsqFIPBwHcWT6Yg28xtL2/h0ff20dbl4q7LZ2E2ye+QB+NwufnSY+o5eParJ1Ccm4B8OyGEyEReL3S3QtshaD8EbXX9L3/mtzB6YcqWmPJ/5R544AHGjRuHzWZj0aJFrF69OuxtN2/ezOWXX864ceMwGAzcd999/W5z6623YjAYen1MnTo1gX8CIYQQuguVK6WN7tkKwZTk36lMPBMuuh+secl93HThG+HLddRjXPs4HPgQLLlw/j2qiJhIRqN6zmHgEb79H8C+d8BoScwugGJo8L2WfzTiQ/Kw89j7+/jL2yFC/CP0we5GPvd/H3Kk3cGUivxBx/UGc/1J4/ntZ+dgMhr415qDfOPJNbqPGQ5Fd7y2jfd2NbKjoYNbXtqc6uUIIURqeDyw4w144Zvw2Gfg/mPh19Vw11j48wnwxOXw0o2w8tfw6WOw8w1o2Kh2LU6hlHZKPfvssyxdupS//OUvLFq0iPvuu49zzjmH7du3U17eP7fDbrczYcIErrzySr73ve+FPe+MGTN48803/Z+bzdIQJoQQGaXEV5QKDtdORci5UEomwL53KO3YjvG/T6vrzvo5FI1OzuNnF6lOuYF24Fv1G3Wcew0UjkrCokRGWvBl2PAcxc0b+G/F/ZzV8G3uen0bFQVWLjs2utfN65vq+PYz6+hxeVg4voSHr5tPgc0S9xIvO3YUeVYzNz69luVbGrjwD+/yy0tmsmhCEncdzSD/2VjHY+/vA8BogJfWH+K8mZWcN6sqtQsTQujH3gQe1/DM9oxEdyusfRI+fij07tWgpgzyq6GgCgqqgy6PhKo5yV1vHymt1vz2t7/lK1/5Ctdffz0Af/nLX3j11Vd55JFH+PGPf9zv9gsWLGDBggUAIb+uMZvNVFYOw9wPIYQYKvxFqeBOqUZ1TGbIuVB83SXjGleqz6vnwcKvJu/xs4vVb/HC7cB38FPYvQIMJjg5/C+thGDEFLj2RXj8YspbN/B66e84t/F7/OifGyjNs3LaMSMiOs1TH9Xwsxc24vHCOTMq+P3n5vXbXS8eZ8+o5LHrF3DjU2vZebiDqx78kMuOHclPzp9GWZ5Vt8fJdDWNdn70rw0AfO20CZiNBh54azc/e2ETC8eXUCrfKyEym6sHPvgjvH23ig9YfCss+rrqoo73vO/cA6sfgsKRMGkJTF4CoxYmvxs/Hke2w+oHYd3T4OxU11kLYd7n1f/VCqpVBEN+FWTlpHatA0jZd7ynp4dPP/2Um266yX+d0Whk8eLFfPDBB3Gde+fOnVRXV2Oz2TjhhBO44447GDNmTNjbOxwOHI5AeGpbWxsATqcTp9MZ7m4x086ZiHML/cnzlTnkucosAz1fhoIxmAFv025cvq8b2o9gBjy2YtzyHCeVoXCs/z8MXoMJ13n3gtujPpLAZC3ECLg6G/GGeO5Nb9+NEfDMvAJ3/ihI8OtDfsZkuOq5/sLUyM7NvFx0Lxe2fJ9vPPEpz371BGaNKgx7V6/Xyx/+u4vfLt8BwNULx/DLS2ZiMuo/xnrixDL++/3TuPuN7Ty9uobn19Ty5pYGfnTuVK5eOCYhj5lJelwe/ufpNbR3uzhubDE/OHsKHq+XFVsPs62+nZ+/uIkHrjk2rrwwIUQK7XkbXvsBHN0RuO6Nm2D7a3DJn2Pv1q7fCP/+hhpbA9WJX78R3v2tiguYcIYqUE1anJ4b3Hg8sHMZfPQX2PNW4PoRU2HR12D2VSoPNIOkrCh19OhR3G43FRW9g0grKirYtm1bzOddtGgRjz32GFOmTKGuro7bbruNU045hU2bNpGfnx/yPnfccQe33XZbv+uXLVtGTk7iKorLly9P2LmF/uT5yhzyXGWWUM9XjuMwSwBP415ee/UVMBiZ1PA+M4Dapi7WvPZa0tc5nOV31XKm7/KuEeewZc1B4GDSHn9+s52RwNZP32PPgd65XgX2Gs7Y+TpeDLzlOpaOJLw27HZ7wh9DJFj1XLjuJXj8YsZ1beXf+b/hsvYfcP1jq/nXN05kbGn//9C7PV5ue3kzj3+wH4BvnzmJ7y05JqFFj6KcLH596SyuPG4UP3thE5sPtfGzFzbxj08P8qtLZjJzZPgC2lB3x3+2sv5gK4XZFu6/eh4WXyD8PVfO4ZIH3uO1jfW8sqEurowvIUQKtNfDGz+FTf9Un+eOgCW/AKcdlv1M5Uf++UQ47y6Yc3Xk2ZZuJ7zzW1h1txoFzC6Bc+8ADLBrOexaoQpUW15QHwCVs9Kni6qrBdY9qbq7/JmrBphyvipGjT818TmfCZJBvWmROe+88/yXZ8+ezaJFixg7dizPPfccN9xwQ8j73HTTTSxdutT/eVtbG6NHj+bss8+moKBA9zU6nU6WL1/OkiVLsFjizx4QiSXPV+aQ5yqzDPh8eVx4t/0Yk8fJ+afMg4KRGP/7CRyC6skzqVxyfmoWPVy5nXj++nfaOjoZec0fGJeb3DfCxtdWwNrVTJ9QzdRTez/3pufVv+3e6Rdz6qWh/53Xm9ZRLTJc1Ry49iV4/CImdW3nH7l3c2XHj7jukdX88xsn9hqTc7jcLH12Pa9urMNggFsvnMF1J45L2lLnjSnmxW+dxBMf7ufeZTtYf6CFi/74Ll84fixLz55CYfYQ/jfP6+33RuuNzfU8+t4+AO69cg4ji7L9X5s5spBvnTGJ36/Yyc9f3MSiCSWU59uSuWIhRCzcLpWJ9N9fQU87YFA5gGf+TGVLAkw4Hf79dTi4Gl74Bmx7FT5zH+QNMnrdsFndr16N+zL1M/CZ3wUyquZcBR431K5RBaqdy+HQGtVBpXVRWQugcjZUzVbFqsrZaiTclMCfv24n7P4vbHhOdYg5fb8UsxXCsdeq70/xuMQ9fpKkrChVVlaGyWSioaGh1/UNDQ265kEVFRVxzDHHsGvXrrC3sVqtWK39Z84tFktC39gm+vxCX/J8ZQ55rjJL6OfLAkVjoGkPlrYDUDoOutXOa6a8EZjk+U0uiwXnV97m7dde5fzcwuT//cpVAc+mnvbez/2R7bD1JQCMp/0IY5LWJT9fhpCq2XDdy/C3i5jStZNnsu/ic43/yw2PfcxTXzmeXKuZ9m4nX/v7p7y/uxGLycDvrprLZ2Ynv/vGbDLyxZPGc/6sKn712lZeXHeIv32wn1c31vOzC6Zx8dzqzB1Vc/Wo3/wf3QmNO+HoLt9xp/r64lvg2OvAYOBAk50f/mM9AF85ZTyLp1f0O923zpjE8i0NbKlr46f/3sSDXzguc783QkSqrU4VLrqaYNQC9ZEpY1w1H8Gr3w+M1I08Di64V+UiBSudCNf/B97/Pbx1B2x7BQ58BBf+HqZe0P+8bhe89ztYeRd4nCqj8vx7YObl/buKjCYYvUB9nPET6Dii8ip3LlfHrmbY/6760JiyoHyar1g1Rx1Lj4nve+H1woHVsPE52PzvQKYqwIhpvhG9z2bOcxuBlBWlsrKyOO6441ixYgWXXHIJAB6PhxUrVnDjjTfq9jgdHR3s3r2bL3zhC7qdUwghRBIUj1c7iDTvhfGnqP8MgOy+lyoGAxjiDBaNlfYbUu01oHnnXsCrfuNZMSPZqxJDReUsNcr3t4uY3rWLp213cvXB/+WbT67hrstn8+XHP2ZTbRu5WSb+7wvzOXlyWUqXW15g4/efm8dn54/m5y9uYs+RTr777Dqe+HA/M6oLyLGayc0ykWs1k5tlJsdqUkftOquZEflW8qwpeBvQ3QaHt8KRrargpBWhmveD1x3+fi9/B/a/T8+593Dj0xtp63Yxd3QRPzp3asibZ5mN3HPlHC5+4F2Wb2ngxXWHuGTeyAT9oRLI64WWGrAVqDfTQvR1dBdse1l1DB38uPfXjGZV1BlzAow9CcYsSr/XUWcjvHkzrH1CfW4rUmHmx14XPszcZIZTvq/G6v79NTi8BZ65Bub+PzWOZ/NNOjVsUd1UdevU51MuUN1R+f0L2SHljYA5n1MfHrd6nLoNqttK66BytEHdevWx9u8AmDFwlrUcU8eTUD4Vyo6BsilQNjnw/5lQDm9ThaiN/1B/7zW5I1QRbdZnYeSxGTuiN5CUju8tXbqU6667jvnz57Nw4ULuu+8+Ojs7/bvxXXvttYwcOZI77rgDUOHoW7Zs8V+ura1l3bp15OXlMWmS2hnoBz/4ARdeeCFjx47l0KFD3HLLLZhMJq6++urU/CGFEELEpmSC+s2UtrWtvUkdZfe94cdWpI7Bu+817lb/cQM49QfJXpEYaipnqY6pxy9ihn03T1nv5JodP+a03zTicHkozc3isesX9g5B77GrAkvDRqjfpDJKqny/LS+fAZbEjoydNKmM/3znFB5+Zy/3r9jJJ/ub+WR/8+B3BLJMRq6YP4pvnDaR0SUJyE91O1XB6fAWNTZzeIt6g9haE/4+WXlqp8+yyVA6GcomqeOuN+G/v4QNz9K240Psrd+iwDaOPwTlSIUyvbqAb585mXuX7+CWlzZzwsRSKgrSfIyvrU6NDNWuUcdDa1Ux3myDE74FJ3038IZbJI+rB9wO9RpNdUHA61VFlq2vqC6hI32ymEctgMLRqnuorVYVqg5+DO/fDxjUL3DGnugrVJ2of5B3d6vaOdnRrkbNejrUz8p+lzvVh9aBBDDv/8Hi2yA3wsJ/1Wz46kp461fw3v2w7gnYuwou/gPUfgor7wR3j/o/xHl3q+6iWJ8/o8k3sjcL+Ly6zuOBln2+QtVGVayq24Cho548RwPsfEN9BMur8BWptI9J6mfjxufUOTRZeeoXbrOvhPGnZ9aOgDFI6Z/uqquu4siRI9x8883U19czd+5cXn/9dX/4eU1NDcagCumhQ4eYNy/QwnfPPfdwzz33cNppp7Fy5UoADh48yNVXX01jYyMjRozg5JNP5sMPP2TEiMi2+BVCCJEmSsarY5MvzLHLV5SSTqnhR/vNYndL4Lp3f6e2h560pH97vxCxqJzpG+W7kJn2PTyZdQef77mJEUVlPHX1eMZ0fQzvbICGTerNQ+Mu9RoMxWhWOyFVzVVFqqo56vw6j1tYzSa+dcYkLppTzeub6mnrdtLpcGPvcdHZ48bucNHhcGHvcdPZ48LucNPl6KHHYeepj2p49uMDXDynmm+eMZFJ5aE3BBpU51GoW4+xdh3H7luO+aE7VUHKE2aXyvxqNe4yYkrvIlR+Zeg3jFWzYfQiHM98kbLu/byU9TN2L7id0SXnDLq0r58+kWVbGthY28pPnt/Iw9fNT8wYX08n7P9AvSk129TznJWr3liGu+xoU0WnQ2ug1ndsr+t/boMJXN2qM3TN43D6TaqLpM+b1GWb6/n5i5sYVZzDdSeO47yZlQMW7UQYbqcq9NT6ioKH1qrCqsep/l5nF6v/h2QX9/7I8R1tRapA3d0GjlZVpOluU0dHW+/LPZ3qtZBTqn7hll0cdLlEHXNKMWQVUNa+BeOyd2HHf6D1QGC9RjOMOwWmfUZ1AhVUqeu1Lrv970PN++rYuEv9/GrYBKsfVLfLr1YjcSUT1N/H0onqWDwOzP3jbfwc7WqE/vBW9f3Sjm210X/PK2aqUb0xx0d/X7MVltwOx5yrMqNa9sPjFwe+fsy5KnNK+77oyWhU37eSCTDjEv/VzuZaVr/6N46fWIKpebf6Ph3dCe2HoKNBfex7J8T5zOr/NLOvhGPOg6zEbbiWblJecrvxxhvDjutphSbNuHHj8Hq9A57vmWee0WtpQgghUqlkgjr6O6V8M/U5palZj0gdbdxA65RqqYH1T6vLp/0oJUsSQ1TFDH9hapZ9L6vyf0aBwY3x0cbQt88doX5zXjFT/Sa9boPqYrA3Bt78rfONpWBQvxmvmqPGR4wW9SbEFHy0qGKD0aI+N2WpNZVNCT/KAowuyeErp04I/+fqsautw7e9Ctv/A4Ymmk0lbOupZPfGKp7cWE3x6Jmcc9opTDlmWujH8nqh9aAaU/F1BFC3Xr3RAkxArw3as/JV8aliuuocq5gO5dNj6nY9WDiPL3T/mtvcv+dU00ZmfvxjcG6C838z4Bs3i0mN8V34h3dZse0w/1pTyxXHjYr68ftxu1QRac9KtW39gY/CF+GiYTCqYmb1sTBynjpWzFDdYstvVkWFV5eqreCX/AKOOYcet5e7Xt/GX99Vv8BpaHPw6f5mKgtsfOGEsXxuwWhK8wYoLqQrt1MVX5r2qNedrUhlTRaNVa8hPYqLHjcc3REoPh1aqwrOru4wt3dB5xH1oZeeDuioH/AmZuCk4CssOTDpLJh6IRxzduiRPIMBiseqj7m+iaH2Bqj5QBWo9r+vfj61H1IffYskBiMUjlIFqpKJ6jwdDWrE7Mi23oWxvnLL1S+TsnLBkqv+joa7XFCt/hzxdgKNPRG+8Z7atW/N38Ba6Nud73PJ727LK+do/gw888/vnYPZ3RbIyjuyXb32GndBThnMvAxmXDpspwFSXpQSQgghQir2dUo171NvhrT27mH6D/aw5h/f870G3vu9enMw/jQYvTBlyxJDVMUMuO4V+NuFFNkPgxP1Bq10sup2qpwFFb4xjlDZJF6v6hbQcka0j/Y6OLpdfUQru0S96Rp7kjpWzlJFsIF0NsKO11Xw8a4V4Orq9eVidxMnmJo4ARWNQR3wDDgMVtxFE8ipnqaKaE57oBDVN9dNUzIRT8VMtrVYOObkSzBXz1YFBB3eDDrdHv7n6bXs7c7hdyN/xYkzP8T89h2q2HdoDVz5NxgRPlh4SmU+310ymbtf385tL2/mpEmlVBVmh719SF6vegO5Z6X62Peu6nQJVjhGZfaA6oBxtAdGlHo6faNLHepnl6Z4vMqIqT5WHStngzWv/+NPvQAmnw2fPgYr71BrefoqukedxE86ruL5ejXu9KWTxlOQbeaJD2uob+vmN29s5/crdnLJ3Gq+eOJ4plen2ehfj139G9+8VxWfmvYGLrccCJ8zZsn1Fai0j9GBy3mV6nvf1aTG/rWjvdF3udl3bFTFLm03s2DWQqieo7pwtY/cEeoXI12++3c1h/loUUVmW4HaIc3qO/ovB12fldt7rf71Nva67LU30W3vwDrtHIzTL4KJZ4IlytcwqJ9XMy4JdPV0t/py3XapkfjGXdC0Gxr3qN3vWmrUx+7/hj5fXoUqopZP630cKDcpkaz5cNH9sOjram25afZLTFuBCnAfeVyqV5J2pCglhBAiPRWPVUdHm/pPqvYfeRnfG36Cx/fa6mCNChPl1B+makViqKuYDl/5L+x/T42ZjZgW+SiFwaA6DApH9d4Nqr3BV9xZr94Mul2qu8btVD/f3E71uccV+JqjQ92nq0nlx2x7RZ3LWgCjF6kC1biT1ZigOUu9wd/2muqIqnm/93hh4RiYer5aU8VMVQA4ugOO7qC9disdtVspdRzAigOat6qPvoxm9b2omh2029RMsObjdjrZ+dprTD7mXNBxh8rfvLGdtTUt5NvM3P/5BZhLToOxx8O/vqyyqh48Xe28NfvKsOf46ikTeGNzA+sPtPDjf23ksesXDD7GZ29Sb8Z3vakKUX1H67KLYfypaov6CaerAlMkRThXjypOGU2qOBEpkwUWfkXl4rzzW9wf/Anbwff4Le9xhu1UCi64ndMWTAfgG6dP5NUNdTz63j421rby3CcHee6TgywaX8L1J41j8bQIg5711NWiugj9eVnrBu62ATUKWTxeFZ26W1WBpL0OnJ0qLP9IiNdotCy5UD23dwGqeHzobsGsXChMfmC+y+lk2Wuvcf755+u7y6ytEEbNVx/BvF7oOOwrUPmKVS37VWEuuPiUrr8krJie6hWIKElRSgghRHqyZEPBSF9Q56e+63ISHh4s0pA2muDugbfvUoGzY05Qb8aFSBRt9EUv+RWQf7Yat4mGq0e9md//ni8f5kNVrN+1XH0AmLPVGEzT7t73rZililBTL1DdVcFFk5wSGKV+Y5/v+9h/pJV/vPkuOzavZay3lgmGOgxmC7tME9ltmshB81jospJVY8RSayTLBFnmLVhMBsxGA+2NRrYt30l5YTYj8q2U5Vn9xwKbOWwhyOFy09TZQ2NHD42dPTR1Omjs6OFgcxePvb8PgN9cMTsQyj7hNPj6u/CvG9TY0fNfVtu0n3tXyH8jzCYj9145h/Pvf4e3dxzhuU8OcNWCMb1v5PGo7/OuN2HnMry1n2IILuqZbernzoTTVBGqcvbg3WqhmLPAHPubeacln984P8er9vH8wPIcl5re40JWwRvnQtu3YN4XsBaN4bJjR3HpvJGsqWnmkff28fqmej7a28RHe5sYWZTNNQtHYehUnWj96hxeL7TXqyylhk3Qdkj9HM4t8+Uclfku+z439TlBT6ca7/RnZq3p/9rU2ApVEahkgsqSDL6cV9m/OOTsVv8vaNkf6OQJ/uhoUEXbPrlM6nJx7+vyKlWGUizPY4bbe7STP6zYSY7VxJdOGs+EEUEdegaD7+dVhSp8C5FgUpQSQgiRvorHq/981n6iPpc8qeEpK0+F/XrdKisC1I57qd4FSYhkMGepMdXRC+Hk76kcnPqNvlwYX6Gqq0m96TcY1YjflPNVV1TxuKgeauyIQn5w9QXUtZ7JQ6v2ctvq/XR3B4e5O30f4Rj58PDekF/JMhsZkWelLC+Lwpws2rudNHX20NTRQ7vDFfI+mi+eOI5zZ/YJKs6vgGtfVDtsrfqNGm3bsUxtwe4f6xrrvzyprJwfnj2FX722lV+8spV5Y4oxdLfQs/1NbPtWUHnkXXKdgfFEA7DVM5q3PXP50DCXokknc+7ccZw+ZQQ2S2qKGIdaurjxqTWsqWkBRrBh4W/4zJxuLCt+rl4L79yrPkxZUDweQ+kkjiudwHFTJtE4exTP7rHy0Fo7tS1d/GbZTsDMn7a8zuLSZk7Kq2OG+SCjevaQ37IdQ1eYHLVQbIWBQpWjQ3UwhdoEoGhsYFyxep4alY2228Zi84VxTwz9da93wH8bXG4POw93sO5AC45Dbi6a66Ykd/gUpVq7nPxhxU7+9sE+nG6V1fzkRzWcM72Sr58+kbmji1K7QDEsSVFKCCFE+ioZr377fdBXlAoV5imGPoNBjfDZG9UbnepjYeJZqV6VEKlhNPnGjebCCd9UHT5Hd6gx51ELdclRqSrM5uYLp/O9JZNpaHPQ4/LgdKuPHpeHHrcHp9vrv77H7cHucLJ63SZKq8fRaHdytL2Hox0OjrQ7aHe46HF5qG3poralK+Rjmo0GinOzKM3NojQvi5JcK6W5WRxTkc+V88OEkxtNcOZP1a5dz381ENocisnKl4tGs6CggG32Atoe+BnzDDsxGQKbKLV7s3nPM5OVnjmsdM/hiLGMPKuZ1i4nbGrkhU2N5FnNLJ5WzmdmV3PKMWVYzdEXNLxeLy6PN6rd8d7adpjvPbeOFruTfJuZ31wxh3NnVqovftEXYL/qbtXd5O7pl19WCnwT+IYll5by0exxFFDYfZBx1GNu9UBr78dzY+Rw1mg6i6ZgKR1PnreTbGcz1p5mjN1NGDqPqmKo1+PbYa61dzdUXmVQXtY8qJqXnIyfoIKU1+ulrrWbdQdaWH+ghbUHWthU24q9J5BVdefr2/jcgjF85dQJjCyKIacpQ7jcHp5eXcNvl++g2a4Ky6cdMwKLycCbWw/z+uZ6Xt9cz6LxJXz9tImcPmVEYnaqFCIEKUoJIYRIXyW+sPP6DeqYrvkFIvFsRYEdGE/9oXRJCaExGlV3UPlU3U+db7OQb4ssw8bpdFJ8dCPnnz8NS595sG6nmyPtDo52ODja0UOzvYcCm4XSPF8RKtdKQXb48b5BTToLvrNO5RT1G+narzpu3Q4MjbuYC8wNege0zziGbfnHUzfiZFwjF1FRUsCVRTa+U5RNeb4NowE21rbyyoY6Xt1QR21LFy+sO8QL6w6RbzNzzoxKPjO7ipMmlfUqMjndHg61dLG/0c7+Jjs1jZ3sb7RT06Q+7D1uyvKyqCy0UVlgCzpmBz4vtGE1G7l32Q7+8rYq+MwaWcgD1xzLmNKgjDODwZcXdr7qpGs9oLKAmvb0DrFuqcHg7KTYuY3jQLWDAT1ZRdTZJrHNO4aP7FWstlex0zsKR3cWtAE1vb/dWSYjRTkWygpMjLQ5GGW1U2WxU25qpygvm8qpJzBp4mTMURTd4uXxeGlo72bPkU7WHWjxF6IOtzv63TY3y8TsUUW0dTvZfKiNx97fxxMf7ufiuSP5xukTmFSen7R1J8PbO47wy1e2sPNwBwCTyvP46QXTOGNKOQA7Gtp5cNUeXlxX6x/xnFKRz9dOm8CFc6qjKp4KEQspSgkhhEhfJb4tzt096igh58OX1iVXMQumnJfatQghomKzmBhdkhPIhEoEaz6MPyX019xOXw6RKlS5mvbjya0ga+o5jCsazbhBTj17VBGzRxXx43OnsvZAC69sOMRrG+toaHPwz08P8s9PD1KcY+GkSWW0djnZ36hG5Nwe74DnPdrRw9GOHjbVtoW9jdVsxOFSo3DXnTCWn1wwbeDuLKNJjW0WjwP6dJS6elSRrnE37ub9rN55mPkXXEdW8WjGGgyMBc4BDrd3s+VQG5sPtbHlUBu7j3TQbO+h2e70d8odbndwuB3f3o1W34fv5/T7u7BZ9jB7ZBHzxhQxd3QR88YUU1kYXyZka5eTA012DvgKewea7dQ0dXGwyc7B5i563P1HBk1GA1Mq8pnrW8fc0UVMHJGHyWjA6/Xy7q6j/Omt3Xywp5F/rTnI82sPcvb0Cr5x+qSMH2XbdbiDX726hbe2HwGgKMfC0iXHcPXCMb0KTcdU5HPPlXP4/tnH8Mi7e3nqoxq2N7Sz9Ln13PPGdm44ZQKfWzCaXKuUDkRiyCtLCCFE+ioe3/tzyZQavqpmQ+2nalRHuqSEENEwWYIKNbG/ATIaDRw3tpjjxhbz8wum8/G+Jl7ZUMd/NtVxtKOHVzb03qHPajYypiSHsaU5jCnJVcfSHMaW5FCQbaGhrZv61m7qtaPvcl1rNw2t3bQ7XDhcHvKsZu66fDYXzK4Ks7IImbOgbDKUTcbjdHK44TXIr+r3M7U830b5FBun+zppNF6vly6nCqVvsTv9harmTtX91mJ3svuIymtq73axel8Tq/c1+e9fWWBj3hitUFVMUY6F1i4nbV1O2rqdtNqdtHW7aOtyquu7nbR1uWjpclLbbKete+DsMbPRwMjibGaOLGTe6CLmjC5iZnUh2Vmhi3gGg4FTJo/glMkjWFvTzJ9X7mbZlgbe2Kw+TpxYyjdOn8jJk8qSNsrm9nhp6uzhcHs3R9rV+GtDaxfr9hupfXcv5QU5lOZlUZZr9Y25ZvXLOGux93Dfmzt54sP9uDxezEYD1504jm+fOZnCnPCdj1WF2fz0gunceMZknvhoP4++t49Drd384pUt3L9iJ2dNLWeO7/s6rSo/ptFVIUKRopQQQoj0VdK3KCWdUsPWuXfCSd/Vdzc0IYSIkdFoYNGEUhZNKOWWC6fz0d4m1tY0U15gY2xJDmNLcynPt2I0hi9mlOVZmVFdGPbrHQ4X9a3dVBbayEuDLhWDwUBOlpmcLDOjBoh49Hi87DnaydqaZtYeaGFdTQvb6tuob+vmP5vq+c+m+pjXUJZnZXRJNqOLcxhTkqMul+QwujiHqkJbzCOD88YU8+C189l1uJ0/r1SjbO/vbuT93Y3MGlnIxXOrKcy2kGs1k2s1k2c1kZNlJs/3eU6WCavZ6C9eudweOhwu2rvVh7rspMPhoq3bRUe3i7ZuJ0fbHRzpcHC4TR0bOxyEbrAz8uahnSHXnmc1+0dhS3KtfLyvSeWgAYunlfOT86f13l1vEIU5Fr51xiRuOHk8z6+p5aF39rD3aCfPr63l+bW1AFhMBqZXFagi1ShVqJpQljvg612IcFL/000IIYQIx1aouqO0LCEZ3xu+zFYpSAkh0pLZZOSkSWWcNKlM1/PmWc1MKo+8mJAujEYDk8rzmFSex5XzRwNg73Gx8WAraw+0sLammfUHWnG43BRmWyjItlBgs/gumymw+a7L9l1nM1NdlM2o4mxyshL79nVSeT73fnYOS88+hodW7eGZj2vYWNvKxtrWQe9rNhrIyTLhdKuOslgZDFCaa2VEvvooy7VwtO4gxRUjabI7aezoobHTQWNHDy6Plw6HKnrtb7T7zzGlIp+ff2Y6J0+O/TVps5i4ZtEYrlowmvd2HeXT/c2sP6iyuprtTtYfbGX9wVZgPwD5VjOzRxcye1QRk0bkMWFELhPK8gbszoqX2+PlUEsXe492sq+xkz1HOjnQZKc0L4tjx6iuxokj8tKmWNbV4+Zoh0PtPNqpNoNo73Zh73Fh73Fj73HT6VCXO/3XubA73DhcHhaOL+Gbp09kcsXQyj2TopQQQoj0VjIhUJSSTikhhBAi4+Rkmf2dZZlgZFE2t140g/85cxJPflTD9vp2OntcdDpcdDrcvS5rBSiXx9tvxNBmMZJnVYW1PJuZfJvqrsq3WcizmlXhKc/KiAJ1LM+3UpKb1avjy+l08tprNZx//qxemwh4vV7aulyqQNXZQ6NvI4HinCzOmVGhW9C8yWjg1GNGcOoxI/yPe7C5yx8mv/5gCxtrW2l3uHhvVyPv7Wrsdf+S3CzGl+UyvizXV6jKZXxZHmNLc/qNHro9XpxuDw6XJ7C7py/H7Gi7gz1HO9nnK0DtPdrJgabQWWIAz31yEIACm5ljxxb7i1RzRhfF3HmojbB2OFS3W6+j76O108Ha/Ubefn4TLV0uGju056cnrmIlwL/X1vLvtbWcO6OSG8+cxMyR4TstB9Pj8rBqxxFe3nCIX1wyk4IIN7VIBClKCSGESG/F4+Hgx+qyFKWEEEIIkSSleVa+fdbkAW/j9nhVV4tDFSusZiN5VlWESuTOdQaDgcIcC4U5FiaMSNjDhHxcbeOCC+dUA2pccUdDh79AtfeIKhrVt3X7u4I+3d/c5zxQkpOF0+3B6fbS4/YMujlAKFkmI2NKc/yFr9ElOdS3dqnOrgOttHW7WLn9CCt9ge9GA0ypLOC4sWr00Ggw+Mcr24NHLrudQaOXgfHLyJZohEOHQq/XbFS7juapccsCX6FSjcaayLGayM0yk52ljtrnTreHJz7cz3821fP6ZvVx+pQR3HjGJOaPi+z/xx6Pl4/3NfHierVZQ4tdjXmeNKmMz/q6GlNBilJCCCHSW3CulIzvCSGEECKNmIwGNXKYwk6TVDObjEyvLmB6dQFXB13f6XD5x+r2HlUfe452sudIB+3dLho7ewY8b5bJSJbZiMVkoDgni3FluYwrzWV8WY7/cnVRNqYw43lOt4dtde18ur+JNTUtfLq/mdqWLrbWtbG1ro0nqInpz2swQF6WKjxqBUjVAWcm22Kkse4gx804hvLCbEp8ofSqEGUlN8sUc3D+SZPK2NnQzp9W7ubFdbX+YtvxE0q48YzJnDSptN+5vV4v2+rbeWFdLS+vO8Sh1m7/18rzrVw4p5p5Kd5pUopSQggh0lvJhMBl6ZQSQgghhMgIuVYzM6oL+wX6e71eGjt7ONLuwGIyYjVrxSd1zDKpQlS8ux5aTEZmjSpk1qhCvniSuq6+tZs1Nc2s2d/M5kNtmE0G8m1m8q2WXiOWBbbA52rc0uQfu8y2mMLmVPnHLU+b0GvcUi+TK/L53VVz+e7iyfzl7d3889ODfLiniQ/3fMTc0UXceMYkzppWzsHmLl5af4gX19Wyo6HDf/98q5lzZ1ZyybyRHD+hNGxBL5mkKCWEECK9FUunlBBCCCHEUGEwGCjLs1KWZ036Y1cW2jh/VhXnz6pK+mPraWxpLndcNpv/OXMyD67aw9Ora1h3oIUvP/4JFQVWGtoc/ttmmYycObWci+dWc8bU8n5ZXqkmRSkhhBDpbcQxYLKCrQCsQ2u3ESGEEEIIIWJV7Qvl/9YZk/jru3v5+wf7aGhzYDDACRNKuWTuSM6ZWUlhdvqOl0pRSgghRHrLLoYb3gBLjhriF0IIIYQQQviNyLfy4/Om8o3TJvLxviZmjiykstCW6mVFRIpSQggh0l/1vFSvQAghhBBCiLRWmGNh8fSKVC8jKonbo1IIIYQQQgghhBBCiDCkKCWEEEIIIYQQQgghkk6KUkIIIYQQQgghhBAi6aQoJYQQQgghhBBCCCGSTopSQgghhBBCCCGEECLppCglhBBCCCGEEEIIIZJOilJCCCGEEEIIIYQQIumkKPX/27v/kLrqP47jr+vUO73zmj+aP3A2Y2JboZBOuyyIpuRWRC4jAonbDxhrV9Gkf6LMBYWjoB+LYUW1v9oMB65VrGW2jMbczOGycFIwaGDORmxeb7mJ9/P9Y9/dum19W/vqOffsPh9wwXvO9fq+vBRevD1eAQAAAAAAYDmWUgAAAAAAALAcSykAAAAAAABYjqUUAAAAAAAALMdSCgAAAAAAAJZjKQUAAAAAAADLsZQCAAAAAACA5VhKAQAAAAAAwHKJdg8Qi4wxkqSpqakFef7Z2Vn99ttvmpqaUlJS0oJ8Dcwf8nIOsnIW8nIW8vrDxX5wsS/EK/oS/oy8nIW8nIOsnIW8/nClfYml1GUEg0FJ0rJly2yeBAAAxKpgMKj09HS7x7ANfQkAAPyTf+pLLhPvv+a7jHA4rPHxcaWlpcnlcs37809NTWnZsmU6efKkvF7vvD8/5hd5OQdZOQt5OQt5/cEYo2AwqPz8fCUkxO87IdCX8Gfk5Szk5Rxk5Szk9Ycr7UtcKXUZCQkJKigoWPCv4/V64/4b1UnIyznIylnIy1nI64J4vkLqIvoSLoe8nIW8nIOsnIW8LriSvhS/v94DAAAAAACAbVhKAQAAAAAAwHIspWzgdrvV3t4ut9tt9yi4AuTlHGTlLOTlLOQFq/E95yzk5Szk5Rxk5Szk9e/xRucAAAAAAACwHFdKAQAAAAAAwHIspQAAAAAAAGA5llIAAAAAAACwHEspi23fvl3Lly/X4sWLVVVVpSNHjtg9EiR99dVXuvfee5Wfny+Xy6U9e/ZEnTfG6LnnnlNeXp5SUlJUU1OjH374wZ5hoY6ODq1evVppaWlaunSp6urqNDY2FvWYmZkZBQIBZWVlacmSJaqvr9epU6dsmjh+dXZ2qrS0VF6vV16vVz6fT/v27YucJ6fYtnXrVrlcLrW0tESOkRmsQF+KTfQlZ6EvOQudybnoS/8fllIW+uCDD9Ta2qr29nYdPXpUZWVlqq2t1eTkpN2jxb1QKKSysjJt3779sudfeuklbdu2TW+++aYOHz4sj8ej2tpazczMWDwpJKm/v1+BQEADAwPq7e3V7Oys7rrrLoVCochjnnzySX300Ufq7u5Wf3+/xsfHdf/999s4dXwqKCjQ1q1bNTQ0pG+++UZr167Vfffdp++//14SOcWywcFBvfXWWyotLY06TmZYaPSl2EVfchb6krPQmZyJvjQPDCxTWVlpAoFA5P7c3JzJz883HR0dNk6Fv5Jkenp6IvfD4bDJzc01L7/8cuTYmTNnjNvtNrt27bJhQvzV5OSkkWT6+/uNMRfySUpKMt3d3ZHHjI6OGknm0KFDdo2J/8rIyDDvvPMOOcWwYDBoiouLTW9vr7njjjtMc3OzMYafLViDvuQM9CXnoS85D50pttGX5gdXSlnk/PnzGhoaUk1NTeRYQkKCampqdOjQIRsnwz85ceKEJiYmorJLT09XVVUV2cWIs2fPSpIyMzMlSUNDQ5qdnY3K7KabblJhYSGZ2Whubk5dXV0KhULy+XzkFMMCgYDuueeeqGwkfraw8OhLzkVfin30JeegMzkDfWl+JNo9QLw4ffq05ubmlJOTE3U8JydHx48ft2kqXImJiQlJumx2F8/BPuFwWC0tLVqzZo1uueUWSRcyS05O1nXXXRf1WDKzx8jIiHw+n2ZmZrRkyRL19PRo1apVGh4eJqcY1NXVpaNHj2pwcPCSc/xsYaHRl5yLvhTb6EvOQGdyDvrS/GEpBcDRAoGAvvvuO3399dd2j4K/UVJSouHhYZ09e1a7d++W3+9Xf3+/3WPhMk6ePKnm5mb19vZq8eLFdo8DAJgn9CVnoDM5A31pfvHnexbJzs7WokWLLnnH/VOnTik3N9emqXAlLuZDdrGnsbFRH3/8sQ4cOKCCgoLI8dzcXJ0/f15nzpyJejyZ2SM5OVkrVqxQeXm5Ojo6VFZWptdff52cYtDQ0JAmJyd16623KjExUYmJierv79e2bduUmJionJwcMsOCoi85F30pdtGXnIPO5Az0pfnFUsoiycnJKi8vV19fX+RYOBxWX1+ffD6fjZPhnxQVFSk3Nzcqu6mpKR0+fJjsbGKMUWNjo3p6evTFF1+oqKgo6nx5ebmSkpKiMhsbG9NPP/1EZjEgHA7r3Llz5BSDqqurNTIyouHh4citoqJCDQ0NkY/JDAuJvuRc9KXYQ19yPjpTbKIvzS/+fM9Cra2t8vv9qqioUGVlpV577TWFQiE9+uijdo8W96anp/Xjjz9G7p84cULDw8PKzMxUYWGhWlpa9MILL6i4uFhFRUVqa2tTfn6+6urq7Bs6jgUCAe3cuVMffvih0tLSIn+bnZ6erpSUFKWnp+vxxx9Xa2urMjMz5fV61dTUJJ/Pp9tuu83m6ePL008/rfXr16uwsFDBYFA7d+7Ul19+qf3795NTDEpLS4u818hFHo9HWVlZkeNkhoVGX4pd9CVnoS85C53JOehL88zuf/8Xb9544w1TWFhokpOTTWVlpRkYGLB7JBhjDhw4YCRdcvP7/caYC//muK2tzeTk5Bi3222qq6vN2NiYvUPHsctlJcns2LEj8pjff//dbN682WRkZJjU1FSzYcMG8/PPP9s3dJx67LHHzA033GCSk5PN9ddfb6qrq81nn30WOU9Ose/P/+LYGDKDNehLsYm+5Cz0JWehMzkbfenquYwxxsolGAAAAAAAAMB7SgEAAAAAAMByLKUAAAAAAABgOZZSAAAAAAAAsBxLKQAAAAAAAFiOpRQAAAAAAAAsx1IKAAAAAAAAlmMpBQAAAAAAAMuxlAIAAAAAAIDlWEoBwAJxuVzas2eP3WMAAADELPoSEN9YSgG4Jj3yyCNyuVyX3NatW2f3aAAAADGBvgTAbol2DwAAC2XdunXasWNH1DG3223TNAAAALGHvgTATlwpBeCa5Xa7lZubG3XLyMiQdOFS8c7OTq1fv14pKSm68cYbtXv37qjPHxkZ0dq1a5WSkqKsrCxt3LhR09PTUY957733dPPNN8vtdisvL0+NjY1R50+fPq0NGzYoNTVVxcXF2rt378K+aAAAgH+BvgTATiylAMSttrY21dfX69ixY2poaNBDDz2k0dFRSVIoFFJtba0yMjI0ODio7u5uff7551ElqrOzU4FAQBs3btTIyIj27t2rFStWRH2N559/Xg8++KC+/fZb3X333WpoaNCvv/5q6esEAAC4WvQlAAvKAMA1yO/3m0WLFhmPxxN1e/HFF40xxkgymzZtivqcqqoq88QTTxhjjHn77bdNRkaGmZ6ejpz/5JNPTEJCgpmYmDDGGJOfn2+eeeaZv51Bknn22Wcj96enp40ks2/fvnl7nQAAAFeLvgTAbrynFIBr1p133qnOzs6oY5mZmZGPfT5f1Dmfz6fh4WFJ0ujoqMrKyuTxeCLn16xZo3A4rLGxMblcLo2Pj6u6uvp/zlBaWhr52OPxyOv1anJy8mpfEgAAwLyiLwGwE0spANcsj8dzyeXh8yUlJeWKHpeUlBR13+VyKRwOL8RIAAAA/xp9CYCdeE8pAHFrYGDgkvsrV66UJK1cuVLHjh1TKBSKnD948KASEhJUUlKitLQ0LV++XH19fZbODAAAYCX6EoCFxJVSAK5Z586d08TERNSxxMREZWdnS5K6u7tVUVGh22+/Xe+//76OHDmid999V5LU0NCg9vZ2+f1+bdmyRb/88ouampr08MMPKycnR5K0ZcsWbdq0SUuXLtX69esVDAZ18OBBNTU1WftCAQAArhJ9CYCdWEoBuGZ9+umnysvLizpWUlKi48ePS7rwn166urq0efNm5eXladeuXVq1apUkKTU1Vfv371dzc7NWr16t1NRU1dfX65VXXok8l9/v18zMjF599VU99dRTys7O1gMPPGDdCwQAAPg/0ZcA2MlljDF2DwEAVnO5XOrp6VFdXZ3dowAAAMQk+hKAhcZ7SgEAAAAAAMByLKUAAAAAAABgOf58DwAAAAAAAJbjSikAAAAAAABYjqUUAAAAAAAALMdSCgAAAAAAAJZjKQUAAAAAAADLsZQCAAAAAACA5VhKAQAAAAAAwHIspQAAAAAAAGA5llIAAAAAAACwHEspAAAAAAAAWO4/MpBEutK0xiIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================\n",
    "# 1. history 로드\n",
    "# ================================\n",
    "with open(\"voice_emotion_analyze_history.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# ================================\n",
    "# 2. 시각화\n",
    "# ================================\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능 개선 CNN + LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m192\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,252</span> (333.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,252\u001b[0m (333.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,060</span> (332.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,060\u001b[0m (332.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import TimeDistributed, Flatten, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# GPU 메모리 점진 할당 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "def build_cnn_lstm_model(input_shape=(40, 13, 1), num_classes=4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # CNN block\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = TimeDistributed(Flatten())(x)  # (batch, time_steps, features)\n",
    "\n",
    "    # LSTM block\n",
    "    x = LSTM(64, return_sequences=False)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 모델 생성\n",
    "model = build_cnn_lstm_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3330 - loss: 3.4030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 5s/step - accuracy: 0.3318 - loss: 3.3804 - val_accuracy: 0.3366 - val_loss: 2.3783\n",
      "Epoch 2/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2309 - loss: 1.8862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 5s/step - accuracy: 0.2318 - loss: 1.8747 - val_accuracy: 0.3035 - val_loss: 1.1941\n",
      "Epoch 3/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3762 - loss: 1.1913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 5s/step - accuracy: 0.3733 - loss: 1.1941 - val_accuracy: 0.2820 - val_loss: 1.1817\n",
      "Epoch 4/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3887 - loss: 1.1573 - val_accuracy: 0.3122 - val_loss: 1.1852\n",
      "Epoch 5/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2887 - loss: 1.1946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.2894 - loss: 1.1939 - val_accuracy: 0.2736 - val_loss: 1.1555\n",
      "Epoch 6/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3373 - loss: 1.1498 - val_accuracy: 0.2895 - val_loss: 1.1612\n",
      "Epoch 7/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4s/step - accuracy: 0.3011 - loss: 1.1918 - val_accuracy: 0.2477 - val_loss: 1.1595\n",
      "Epoch 8/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3375 - loss: 1.1465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3371 - loss: 1.1469 - val_accuracy: 0.2461 - val_loss: 1.1524\n",
      "Epoch 9/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.3362 - loss: 1.1382 - val_accuracy: 0.3112 - val_loss: 1.1646\n",
      "Epoch 10/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3383 - loss: 1.1414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3371 - loss: 1.1419 - val_accuracy: 0.2740 - val_loss: 1.1462\n",
      "Epoch 11/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3767 - loss: 1.1064 - val_accuracy: 0.2956 - val_loss: 1.1714\n",
      "Epoch 12/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3664 - loss: 1.1144 - val_accuracy: 0.2300 - val_loss: 1.1534\n",
      "Epoch 13/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3168 - loss: 1.1368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3181 - loss: 1.1363 - val_accuracy: 0.2181 - val_loss: 1.1455\n",
      "Epoch 14/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4154 - loss: 1.0989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 4s/step - accuracy: 0.4124 - loss: 1.1007 - val_accuracy: 0.2499 - val_loss: 1.1388\n",
      "Epoch 15/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3863 - loss: 1.1107 - val_accuracy: 0.2412 - val_loss: 1.1542\n",
      "Epoch 16/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.3952 - loss: 1.1046 - val_accuracy: 0.2838 - val_loss: 1.1612\n",
      "Epoch 17/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4026 - loss: 1.0892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 4s/step - accuracy: 0.4005 - loss: 1.0915 - val_accuracy: 0.3134 - val_loss: 1.1316\n",
      "Epoch 18/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 4s/step - accuracy: 0.3537 - loss: 1.1308 - val_accuracy: 0.3224 - val_loss: 1.1676\n",
      "Epoch 19/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3841 - loss: 1.1210 - val_accuracy: 0.2005 - val_loss: 1.1429\n",
      "Epoch 20/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3757 - loss: 1.1028 - val_accuracy: 0.1731 - val_loss: 1.1628\n",
      "Epoch 21/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.4201 - loss: 1.0753 - val_accuracy: 0.2076 - val_loss: 1.1630\n",
      "Epoch 22/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3313 - loss: 1.1223 - val_accuracy: 0.2430 - val_loss: 1.1677\n",
      "Epoch 23/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3609 - loss: 1.1030 - val_accuracy: 0.1968 - val_loss: 1.1529\n",
      "Epoch 24/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.3500 - loss: 1.1132 - val_accuracy: 0.1928 - val_loss: 1.1555\n",
      "Epoch 25/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 4s/step - accuracy: 0.4006 - loss: 1.0854 - val_accuracy: 0.3096 - val_loss: 1.1486\n",
      "Epoch 26/300\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.4089 - loss: 1.0712 - val_accuracy: 0.2402 - val_loss: 1.1557\n",
      "Epoch 27/300\n",
      "\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 4s/step - accuracy: 0.3603 - loss: 1.1134"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     61\u001b[39m callbacks = [\n\u001b[32m     62\u001b[39m     EarlyStopping(patience=\u001b[32m60\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     63\u001b[39m     ModelCheckpoint(\u001b[33m\"\u001b[39m\u001b[33mvoice_emotion_analyze.h5\u001b[39m\u001b[33m\"\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     64\u001b[39m ]\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# 6. 학습 실행\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 7. 학습 기록 저장 (.pkl)\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mvoice_emotion_analyze_history.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev_ws/superbad/deeplearning-repo-3/dolbom_venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# =============================\n",
    "# 1. 제너레이터 정의 (샘플 개수 맞춤 처리 포함)\n",
    "# =============================\n",
    "class MFCCGenerator(Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32):\n",
    "        self.mfcc_paths = sorted([os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "        self.label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.startswith(\"label_batch\")])\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.mfcc_paths[idx], allow_pickle=True)\n",
    "        y = np.load(self.label_paths[idx])\n",
    "\n",
    "        # 오류 방지: 길이 맞춤\n",
    "        min_len = min(len(x), len(y))\n",
    "        x = x[:min_len]\n",
    "        y = y[:min_len]\n",
    "\n",
    "        # Padding & Shape 변환\n",
    "        x = np.stack([\n",
    "            np.pad(sample, ((0, max(0, 40 - sample.shape[0])), (0, 0)), mode='constant')[:40]\n",
    "            for sample in x\n",
    "        ])\n",
    "        x = np.transpose(x, (0, 2, 1))            # (batch, 13, 40)\n",
    "        x = x[..., np.newaxis]                    # (batch, 13, 40, 1)\n",
    "        x = np.transpose(x, (0, 2, 1, 3))         # → (batch, 40, 13, 1)\n",
    "        return x, y\n",
    "\n",
    "# =============================\n",
    "# 2. 경로 설정\n",
    "# =============================\n",
    "train_mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/mfcc_batches\"\n",
    "train_label_dir = os.path.join(train_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_4class/validation/mfcc_batches\"\n",
    "val_label_dir = os.path.join(val_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "# =============================\n",
    "# 3. 제너레이터 준비\n",
    "# =============================\n",
    "train_gen = MFCCGenerator(train_mfcc_dir, train_label_dir, batch_size=32)\n",
    "val_gen = MFCCGenerator(val_mfcc_dir, val_label_dir, batch_size=32)\n",
    "\n",
    "# =============================\n",
    "# 4. 모델 불러오기 (4번 셀에서 정의된 함수 사용)\n",
    "# =============================\n",
    "model = build_cnn_model(input_shape=(40, 13, 1), num_classes=4)\n",
    "\n",
    "# =============================\n",
    "# 5. 콜백 설정\n",
    "# =============================\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=60, restore_best_weights=True, monitor='val_loss'),\n",
    "    ModelCheckpoint(\"voice_emotion_analyze.h5\", save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "# =============================\n",
    "# 6. 학습 실행\n",
    "# =============================\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=300,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# 7. 학습 기록 저장 (.pkl)\n",
    "# =============================\n",
    "with open(\"voice_emotion_analyze_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ 학습 완료 및 저장됨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정 4개로 할시 value accuracy가 \n",
    "- Train Accuracy: 점진적으로 상승하며 0.35 ~ 0.38 수준에 도달\n",
    "\n",
    "Val Accuracy: 초기에는 높았다가 점점 하락 → 과적합(overfitting) 경향 발생\n",
    "\n",
    "👉 의심되는 원인\n",
    "\n",
    "데이터 양은 충분하지만, 클래스 간 정보 차이 또는 모델 복잡도 부족/과도로 generalization이 부족할 수 있음\n",
    "\n",
    "Dropout이나 BatchNormalization은 들어가 있지만, 정규화/증강이 부족할 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7개 감정으로 처음부터 다시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON -> DataFrame(JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training JSON 탐색 중: 449it [04:59,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정상 처리된 데이터 수: 815491\n",
      "⚠️ 오류 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/라벨링데이터/\"\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/1.Training/원천데이터/\"\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/data_7class\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 2. 리스트 초기화\n",
    "# ========================================\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 파일 탐색 및 처리\n",
    "# ========================================\n",
    "for folder_path, _, files in tqdm(os.walk(label_root), desc=\"Training JSON 탐색 중\"):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "                relative_path = relative_path.replace(\"TL\", \"TS\")\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"⚠️ WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ JSON 읽기 오류: {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 저장\n",
    "# ========================================\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_path, \"metadata_cleaned.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(save_path, \"broken_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"✅ 정상 처리된 데이터 수: {len(df)}\")\n",
    "print(f\"⚠️ 오류 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON -> DataFrame(Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation JSON 탐색 중: 88it [00:41,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 데이터 수: 112157\n",
      "⚠️ 오류 파일 수: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "label_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/라벨링데이터/VL1\"\n",
    "wav_root = \"/media/usou/PortableSSD/mldl/015.감성 및 발화 스타일별 음성합성 데이터/01.데이터/2.Validation/원천데이터/VS1\"\n",
    "save_path = \"/media/usou/PortableSSD/mldl_project/data_7class/validation\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 2. 리스트 초기화\n",
    "# ========================================\n",
    "data = []\n",
    "broken_files = []\n",
    "\n",
    "# ========================================\n",
    "# 3. JSON 탐색 및 처리\n",
    "# ========================================\n",
    "for folder_path, _, files in tqdm(os.walk(label_root), desc=\"Validation JSON 탐색 중\"):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".json\"):\n",
    "            json_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                    content = json.load(f)\n",
    "\n",
    "                emotion = content[\"화자정보\"][\"Emotion\"]\n",
    "                style = content[\"화자정보\"].get(\"SpeechStyle\", \"N/A\")\n",
    "                sensitivity = content[\"화자정보\"].get(\"Sensitivity\", \"N/A\")\n",
    "                wav_file = content[\"파일정보\"][\"FileName\"]\n",
    "\n",
    "                relative_path = os.path.relpath(folder_path, start=label_root)\n",
    "                wav_path = os.path.join(wav_root, relative_path, wav_file)\n",
    "\n",
    "                if os.path.exists(wav_path):\n",
    "                    data.append({\n",
    "                        \"wav_path\": wav_path,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"style\": style,\n",
    "                        \"sensitivity\": sensitivity\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"⚠️ WAV 파일 없음: {wav_path}\")\n",
    "                    broken_files.append(wav_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ JSON 읽기 오류: {json_path}: {e}\")\n",
    "                broken_files.append(json_path)\n",
    "\n",
    "# ========================================\n",
    "# 4. 저장\n",
    "# ========================================\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(os.path.join(save_path, \"metadata_cleaned_val.csv\"), index=False)\n",
    "\n",
    "with open(os.path.join(save_path, \"broken_val_files.txt\"), \"w\") as f:\n",
    "    for path in broken_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"✅ Validation 데이터 수: {len(df)}\")\n",
    "print(f\"⚠️ 오류 파일 수: {len(broken_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5062/3329109215.py:16: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executing Split 1/10 (샘플 0~81549)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [20:56<00:00, 64.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Split 0 완료 / 저장된 배치 수: 81\n",
      "⚠️ 실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 0. Split index 설정 (여기만 매번 바꿔 실행!)\n",
    "# ========================================\n",
    "split_idx = 0  # ← 0~9 중 하나만 골라서 실행\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드 및 설정\n",
    "# ========================================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data_7class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "split_count = 10\n",
    "save_interval = 1000\n",
    "total = len(df)\n",
    "split_size = total // split_count\n",
    "\n",
    "save_counter = split_idx * (split_count + 1)  # 배치 번호 안 겹치게 보정\n",
    "error_files = []\n",
    "\n",
    "# ========================================\n",
    "# 2. 지정된 split만 처리\n",
    "# ========================================\n",
    "start = split_idx * split_size\n",
    "end = (split_idx + 1) * split_size if split_idx < split_count - 1 else total\n",
    "df_split = df.iloc[start:end]\n",
    "\n",
    "print(f\"\\n🔄 Executing Split {split_idx+1}/{split_count} (샘플 {start}~{end})\")\n",
    "\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "\n",
    "for _, row in tqdm(df_split.iterrows(), total=len(df_split)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 마지막 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# 에러 저장\n",
    "with open(f\"/media/usou/PortableSSD/mldl_project/data_7class/broken_audio_split{split_idx}.txt\", \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ Split {split_idx} 완료 / 저장된 배치 수: {save_counter}\")\n",
    "print(f\"⚠️ 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5062/171108593.py:16: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Executing Split 2/10 (샘플 81549~163098)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:54<00:00, 68.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Split 1 완료 / 저장된 배치 수: 92\n",
      "⚠️ 실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 0. Split index 설정 (여기만 매번 바꿔 실행!)\n",
    "# ========================================\n",
    "split_idx = 1  # ← 0~9 중 하나만 골라서 실행\n",
    "\n",
    "# ========================================\n",
    "# 1. 메타데이터 로드 및 설정\n",
    "# ========================================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data_7class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "split_count = 10\n",
    "save_interval = 1000\n",
    "total = len(df)\n",
    "split_size = total // split_count\n",
    "\n",
    "save_counter = split_idx * (split_count + 1)  # 배치 번호 안 겹치게 보정\n",
    "error_files = []\n",
    "\n",
    "# ========================================\n",
    "# 2. 지정된 split만 처리\n",
    "# ========================================\n",
    "start = split_idx * split_size\n",
    "end = (split_idx + 1) * split_size if split_idx < split_count - 1 else total\n",
    "df_split = df.iloc[start:end]\n",
    "\n",
    "print(f\"\\n🔄 Executing Split {split_idx+1}/{split_count} (샘플 {start}~{end})\")\n",
    "\n",
    "mfcc_features = []\n",
    "labels = []\n",
    "\n",
    "for _, row in tqdm(df_split.iterrows(), total=len(df_split)):\n",
    "    wav_path = row[\"wav_path\"]\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_features.append(mfcc.T)\n",
    "        labels.append(row[\"emotion\"])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {wav_path}: {e}\")\n",
    "        error_files.append(wav_path)\n",
    "\n",
    "    if len(mfcc_features) >= save_interval:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "        save_counter += 1\n",
    "        mfcc_features = []\n",
    "        labels = []\n",
    "\n",
    "# 마지막 저장\n",
    "if mfcc_features:\n",
    "    np.save(os.path.join(save_dir, f\"mfcc_batch_{save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "    np.save(os.path.join(save_dir, f\"label_batch_{save_counter}.npy\"), np.array(labels))\n",
    "\n",
    "# 에러 저장\n",
    "with open(f\"/media/usou/PortableSSD/mldl_project/data_7class/broken_audio_split{split_idx}.txt\", \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ Split {split_idx} 완료 / 저장된 배치 수: {save_counter}\")\n",
    "print(f\"⚠️ 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5062/3341483047.py:11: DtypeWarning: Columns (1,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 1/10 (샘플 0~81549)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:10<00:00, 70.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 2/10 (샘플 81549~163098)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:12<00:00, 70.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 3/10 (샘플 163098~244647)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:31<00:00, 69.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 4/10 (샘플 244647~326196)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:57<00:00, 68.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 5/10 (샘플 326196~407745)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:54<00:00, 68.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 6/10 (샘플 407745~489294)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:54<00:00, 68.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 7/10 (샘플 489294~570843)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [20:12<00:00, 67.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 8/10 (샘플 570843~652392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [19:47<00:00, 68.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 9/10 (샘플 652392~733941)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81549/81549 [20:18<00:00, 66.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Split 10/10 (샘플 733941~815491)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81550/81550 [20:25<00:00, 66.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 총 저장된 MFCC 배치 수: 820\n",
      "⚠️ 총 실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 설정 및 메타데이터 로드\n",
    "# ========================================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data_7class/metadata_cleaned.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "split_count = 10\n",
    "save_interval = 1000\n",
    "total = len(df)\n",
    "split_size = total // split_count\n",
    "\n",
    "global_save_counter = 0\n",
    "error_files = []\n",
    "\n",
    "# ========================================\n",
    "# 2. Split 전체 자동 반복\n",
    "# ========================================\n",
    "for split_idx in range(split_count):\n",
    "    start = split_idx * split_size\n",
    "    end = (split_idx + 1) * split_size if split_idx < split_count - 1 else total\n",
    "    df_split = df.iloc[start:end]\n",
    "\n",
    "    print(f\"\\n🔄 Split {split_idx+1}/{split_count} (샘플 {start}~{end})\")\n",
    "\n",
    "    mfcc_features = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in tqdm(df_split.iterrows(), total=len(df_split)):\n",
    "        wav_path = row[\"wav_path\"]\n",
    "        try:\n",
    "            y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            mfcc_features.append(mfcc.T)\n",
    "            labels.append(row[\"emotion\"])\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {wav_path}: {e}\")\n",
    "            error_files.append(wav_path)\n",
    "\n",
    "        # 내부 배치 저장\n",
    "        if len(mfcc_features) >= save_interval:\n",
    "            np.save(os.path.join(save_dir, f\"mfcc_batch_{global_save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "            np.save(os.path.join(save_dir, f\"label_batch_{global_save_counter}.npy\"), np.array(labels))\n",
    "            global_save_counter += 1\n",
    "            mfcc_features = []\n",
    "            labels = []\n",
    "\n",
    "    # 해당 split 마지막 저장\n",
    "    if mfcc_features:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{global_save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{global_save_counter}.npy\"), np.array(labels))\n",
    "        global_save_counter += 1\n",
    "\n",
    "# ========================================\n",
    "# 3. 에러 로그 저장\n",
    "# ========================================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data_7class/broken_audio_files.txt\", \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ 총 저장된 MFCC 배치 수: {global_save_counter}\")\n",
    "print(f\"⚠️ 총 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation mfcc 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Validation Split 1/5 (샘플 0~22431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22431/22431 [05:43<00:00, 65.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Validation Split 2/5 (샘플 22431~44862)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22431/22431 [05:39<00:00, 65.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Validation Split 3/5 (샘플 44862~67293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22431/22431 [05:30<00:00, 67.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Validation Split 4/5 (샘플 67293~89724)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22431/22431 [05:34<00:00, 66.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Validation Split 5/5 (샘플 89724~112157)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22433/22433 [05:40<00:00, 65.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 총 저장된 Validation MFCC 배치 수: 225\n",
      "⚠️ 총 실패한 파일 수: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 설정 및 메타데이터 로드\n",
    "# ========================================\n",
    "csv_path = \"/media/usou/PortableSSD/mldl_project/data_7class/validation/metadata_cleaned_val.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "sample_rate = 16000\n",
    "max_duration = 5.0\n",
    "save_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/validation/mfcc_batches\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "split_count = 5\n",
    "save_interval = 500\n",
    "total = len(df)\n",
    "split_size = total // split_count\n",
    "\n",
    "global_save_counter = 0\n",
    "error_files = []\n",
    "\n",
    "# ========================================\n",
    "# 2. Split 전체 반복\n",
    "# ========================================\n",
    "for split_idx in range(split_count):\n",
    "    start = split_idx * split_size\n",
    "    end = (split_idx + 1) * split_size if split_idx < split_count - 1 else total\n",
    "    df_split = df.iloc[start:end]\n",
    "\n",
    "    print(f\"\\n🔄 Validation Split {split_idx+1}/{split_count} (샘플 {start}~{end})\")\n",
    "\n",
    "    mfcc_features = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in tqdm(df_split.iterrows(), total=len(df_split)):\n",
    "        wav_path = row[\"wav_path\"]\n",
    "        try:\n",
    "            y, sr = librosa.load(wav_path, sr=sample_rate, duration=max_duration)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            mfcc_features.append(mfcc.T)\n",
    "            labels.append(row[\"emotion\"])\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error processing {wav_path}: {e}\")\n",
    "            error_files.append(wav_path)\n",
    "\n",
    "        if len(mfcc_features) >= save_interval:\n",
    "            np.save(os.path.join(save_dir, f\"mfcc_batch_{global_save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "            np.save(os.path.join(save_dir, f\"label_batch_{global_save_counter}.npy\"), np.array(labels))\n",
    "            global_save_counter += 1\n",
    "            mfcc_features = []\n",
    "            labels = []\n",
    "\n",
    "    # Split 마무리 저장\n",
    "    if mfcc_features:\n",
    "        np.save(os.path.join(save_dir, f\"mfcc_batch_{global_save_counter}.npy\"), np.array(mfcc_features, dtype=object))\n",
    "        np.save(os.path.join(save_dir, f\"label_batch_{global_save_counter}.npy\"), np.array(labels))\n",
    "        global_save_counter += 1\n",
    "\n",
    "# ========================================\n",
    "# 3. 에러 로그 저장\n",
    "# ========================================\n",
    "with open(\"/media/usou/PortableSSD/mldl_project/data_7class/validation/broken_val_files.txt\", \"w\") as f:\n",
    "    for path in error_files:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ 총 저장된 Validation MFCC 배치 수: {global_save_counter}\")\n",
    "print(f\"⚠️ 총 실패한 파일 수: {len(error_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 인코딩 (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "라벨 로드 중: 100%|██████████| 820/820 [00:00<00:00, 1365.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 인코딩된 감정 클래스:\n",
      "  0: Angry\n",
      "  1: Anxious\n",
      "  2: Embarrassed\n",
      "  3: Happy\n",
      "  4: Hurt\n",
      "  5: Neutrality\n",
      "  6: Sad\n",
      "  7: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "라벨 인코딩 저장 중: 100%|██████████| 820/820 [00:00<00:00, 1327.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 레이블 인코딩 완료 및 저장\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "label_files = sorted([f for f in os.listdir(mfcc_dir) if f.startswith(\"label_batch\")])\n",
    "\n",
    "save_dir = os.path.join(mfcc_dir, \"encoded_labels\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ========================================\n",
    "# 2. 전체 라벨 불러오기 및 인코더 학습\n",
    "# ========================================\n",
    "all_labels = []\n",
    "\n",
    "for file in tqdm(label_files, desc=\"라벨 로드 중\"):\n",
    "    labels = np.load(os.path.join(mfcc_dir, file))\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# 클래스 정보 출력\n",
    "print(\"🎯 인코딩된 감정 클래스:\")\n",
    "for idx, cls in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {idx}: {cls}\")\n",
    "\n",
    "# ========================================\n",
    "# 3. 인코딩 적용 및 저장\n",
    "# ========================================\n",
    "for file in tqdm(label_files, desc=\"라벨 인코딩 저장 중\"):\n",
    "    labels = np.load(os.path.join(mfcc_dir, file))\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    np.save(os.path.join(save_dir, file), encoded)\n",
    "\n",
    "# ========================================\n",
    "# 4. LabelEncoder 저장\n",
    "# ========================================\n",
    "joblib.dump(label_encoder, os.path.join(mfcc_dir, \"label_encoder.pkl\"))\n",
    "\n",
    "print(\"✅ 레이블 인코딩 완료 및 저장\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation 라벨 인코딩 중: 100%|██████████| 225/225 [00:00<00:00, 924.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation 라벨 인코딩 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================\n",
    "# 1. 경로 설정\n",
    "# ========================================\n",
    "val_label_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/validation/mfcc_batches\"\n",
    "save_dir = os.path.join(val_label_dir, \"encoded_labels\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 학습 데이터에서 저장한 인코더 불러오기\n",
    "encoder_path = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches/label_encoder.pkl\"\n",
    "label_encoder = joblib.load(encoder_path)\n",
    "\n",
    "# ========================================\n",
    "# 2. Validation 라벨 파일 리스트 로드\n",
    "# ========================================\n",
    "label_files = sorted([f for f in os.listdir(val_label_dir) if f.startswith(\"label_batch\")])\n",
    "\n",
    "# ========================================\n",
    "# 3. 인코딩 및 저장\n",
    "# ========================================\n",
    "for file in tqdm(label_files, desc=\"Validation 라벨 인코딩 중\"):\n",
    "    labels = np.load(os.path.join(val_label_dir, file))\n",
    "    encoded = label_encoder.transform(labels)\n",
    "    np.save(os.path.join(save_dir, file), encoded)\n",
    "\n",
    "print(\"✅ Validation 라벨 인코딩 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN + LSTM 기반 모델 정의 (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model(input_shape=(40, 13, 1), num_classes=8):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 수정된 Conv Block 3 (padding 추가)\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = create_cnn_model()\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_25          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_26          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_27          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,112</span> (434.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m111,112\u001b[0m (434.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,664</span> (432.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,664\u001b[0m (432.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m819/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2967 - loss: 2.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 71ms/step - accuracy: 0.2968 - loss: 1.9999 - val_accuracy: 0.2849 - val_loss: 2.0406\n",
      "Epoch 2/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3385 - loss: 1.9251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.3386 - loss: 1.9250 - val_accuracy: 0.2849 - val_loss: 2.0067\n",
      "Epoch 3/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 62ms/step - accuracy: 0.3565 - loss: 1.8590 - val_accuracy: 0.2124 - val_loss: 2.0139\n",
      "Epoch 4/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.3639 - loss: 1.7662 - val_accuracy: 0.1571 - val_loss: 2.1754\n",
      "Epoch 5/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3827 - loss: 1.6609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.3827 - loss: 1.6609 - val_accuracy: 0.2817 - val_loss: 2.0034\n",
      "Epoch 6/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.3997 - loss: 1.5768 - val_accuracy: 0.2831 - val_loss: 2.1249\n",
      "Epoch 7/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.4261 - loss: 1.5366 - val_accuracy: 0.2608 - val_loss: 2.0339\n",
      "Epoch 8/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.4490 - loss: 1.4269 - val_accuracy: 0.2806 - val_loss: 2.0508\n",
      "Epoch 9/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.4334 - loss: 1.4325 - val_accuracy: 0.1517 - val_loss: 2.2464\n",
      "Epoch 10/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.4611 - loss: 1.3580 - val_accuracy: 0.1177 - val_loss: 2.8202\n",
      "Epoch 11/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.4492 - loss: 1.3873 - val_accuracy: 0.1535 - val_loss: 2.2404\n",
      "Epoch 12/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.4756 - loss: 1.2921 - val_accuracy: 0.1632 - val_loss: 2.2975\n",
      "Epoch 13/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5003 - loss: 1.2501 - val_accuracy: 0.1316 - val_loss: 2.4195\n",
      "Epoch 14/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5085 - loss: 1.2256 - val_accuracy: 0.2778 - val_loss: 2.1504\n",
      "Epoch 15/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5278 - loss: 1.2102 - val_accuracy: 0.2606 - val_loss: 2.0806\n",
      "Epoch 16/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5337 - loss: 1.1974 - val_accuracy: 0.1980 - val_loss: 2.2045\n",
      "Epoch 17/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5222 - loss: 1.1713 - val_accuracy: 0.1797 - val_loss: 2.2368\n",
      "Epoch 18/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.5262 - loss: 1.1759 - val_accuracy: 0.1407 - val_loss: 2.3620\n",
      "Epoch 19/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5548 - loss: 1.1067 - val_accuracy: 0.2787 - val_loss: 2.3529\n",
      "Epoch 20/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 64ms/step - accuracy: 0.5622 - loss: 1.0932 - val_accuracy: 0.2461 - val_loss: 2.1842\n",
      "Epoch 21/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.5534 - loss: 1.1167 - val_accuracy: 0.2579 - val_loss: 2.5148\n",
      "Epoch 22/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 63ms/step - accuracy: 0.5671 - loss: 1.0727 - val_accuracy: 0.2802 - val_loss: 2.5959\n",
      "Epoch 23/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5512 - loss: 1.1060 - val_accuracy: 0.1335 - val_loss: 2.5397\n",
      "Epoch 24/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 64ms/step - accuracy: 0.6126 - loss: 0.9667 - val_accuracy: 0.2627 - val_loss: 2.6659\n",
      "Epoch 25/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.5770 - loss: 1.0595 - val_accuracy: 0.2334 - val_loss: 2.3490\n",
      "Epoch 26/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6429 - loss: 0.9055 - val_accuracy: 0.1260 - val_loss: 2.6344\n",
      "Epoch 27/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6137 - loss: 0.9598 - val_accuracy: 0.2402 - val_loss: 2.2571\n",
      "Epoch 28/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6458 - loss: 0.8857 - val_accuracy: 0.1261 - val_loss: 2.9791\n",
      "Epoch 29/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6547 - loss: 0.8780 - val_accuracy: 0.2723 - val_loss: 2.7053\n",
      "Epoch 30/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6638 - loss: 0.8527 - val_accuracy: 0.1191 - val_loss: 2.8952\n",
      "Epoch 31/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6911 - loss: 0.8269 - val_accuracy: 0.2132 - val_loss: 2.3852\n",
      "Epoch 32/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.6933 - loss: 0.8024 - val_accuracy: 0.1527 - val_loss: 2.5593\n",
      "Epoch 33/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.7137 - loss: 0.7378 - val_accuracy: 0.2756 - val_loss: 2.4477\n",
      "Epoch 34/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 63ms/step - accuracy: 0.7433 - loss: 0.6998 - val_accuracy: 0.1783 - val_loss: 2.7642\n",
      "Epoch 35/300\n",
      "\u001b[1m820/820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 64ms/step - accuracy: 0.7520 - loss: 0.6479 - val_accuracy: 0.1510 - val_loss: 2.5565\n",
      "✅ CNN 모델 학습 및 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# ========================================\n",
    "# 1. MFCC 배치 제너레이터 정의\n",
    "# ========================================\n",
    "class MFCCGenerator(Sequence):\n",
    "    def __init__(self, mfcc_dir, label_dir, batch_size=32):\n",
    "        self.mfcc_paths = sorted([os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.startswith(\"mfcc_batch\")])\n",
    "        self.label_paths = sorted([os.path.join(label_dir, f) for f in os.listdir(label_dir) if f.startswith(\"label_batch\")])\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.load(self.mfcc_paths[idx], allow_pickle=True)\n",
    "        y = np.load(self.label_paths[idx])\n",
    "\n",
    "        min_len = min(len(x), len(y))\n",
    "        x = x[:min_len]\n",
    "        y = y[:min_len]\n",
    "\n",
    "        # MFCC 길이(40 프레임)로 고정하고 (batch, 40, 13, 1) 형태로 변환\n",
    "        x = np.stack([\n",
    "            np.pad(sample, ((0, max(0, 40 - sample.shape[0])), (0, 0)), mode='constant')[:40]\n",
    "            for sample in x\n",
    "        ])\n",
    "        x = x[..., np.newaxis]  # (batch, 40, 13, 1)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# ========================================\n",
    "# 2. 학습 및 검증 데이터 경로\n",
    "# ========================================\n",
    "train_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/mfcc_batches\"\n",
    "train_label_dir = os.path.join(train_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "val_mfcc_dir = \"/media/usou/PortableSSD/mldl_project/data_7class/validation/mfcc_batches\"\n",
    "val_label_dir = os.path.join(val_mfcc_dir, \"encoded_labels\")\n",
    "\n",
    "# ========================================\n",
    "# 3. 제너레이터 생성\n",
    "# ========================================\n",
    "train_gen = MFCCGenerator(train_mfcc_dir, train_label_dir, batch_size=32)\n",
    "val_gen = MFCCGenerator(val_mfcc_dir, val_label_dir, batch_size=32)\n",
    "\n",
    "# ========================================\n",
    "# 4. 콜백 설정\n",
    "# ========================================\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=30, restore_best_weights=True, monitor='val_loss'),\n",
    "    ModelCheckpoint(\"voice_emotion_analyze_8class_cnn.h5\", save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "# ========================================\n",
    "# 5. 모델 학습 실행\n",
    "# ========================================\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=300,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ========================================\n",
    "# 6. 학습 이력 저장 (시각화용)\n",
    "# ========================================\n",
    "with open(\"voice_emotion_analyze_8class_cnn_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"✅ CNN 모델 학습 및 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========================================\n",
    "# 1. history.pkl 파일 로드\n",
    "# ========================================\n",
    "with open(\"/home/usou/dev_ws/superbad/deeplearning-repo-3/ai/training/voice_emotion_analyze_8class_cnn_history.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# ========================================\n",
    "# 2. 시각화: 정확도 & 손실\n",
    "# ========================================\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 정확도\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 손실\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========================================\n",
    "# 1. history.pkl 파일 로드\n",
    "# ========================================\n",
    "with open(\"/home/usou/dev_ws/superbad/deeplearning-repo-3/ai/training/voice_emotion_analyze_history.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "# ========================================\n",
    "# 2. 시각화: 정확도 & 손실\n",
    "# ========================================\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 정확도\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 손실\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolbom_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
